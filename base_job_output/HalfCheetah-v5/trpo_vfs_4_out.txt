No devices were found
Setting seed -  3
---------------------------------
Environment created
Box(-1.0, 1.0, (6,), float32) Box(-inf, inf, (17,), float64)
Loading Initial saved model
Model loaded
Starting evaluation
1953
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1137.5124388642628
avg cum rews: 1137.5124388642628, std: 0.0
the best agent: 0, best agent cum rewards: 1137.5124388642628
1963
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1189.9514265330993
avg cum rews: 1189.9514265330993, std: 0.0
the best agent: 0, best agent cum rewards: 1189.9514265330993
1973
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1185.5649047314753
avg cum rews: 1185.5649047314753, std: 0.0
the best agent: 0, best agent cum rewards: 1185.5649047314753
1983
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1031.181603922528
avg cum rews: 1031.181603922528, std: 0.0
the best agent: 0, best agent cum rewards: 1031.181603922528
1993
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1155.313446500455
avg cum rews: 1155.313446500455, std: 0.0
the best agent: 0, best agent cum rewards: 1155.313446500455
2003
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1142.4895545500622
avg cum rews: 1142.4895545500622, std: 0.0
the best agent: 0, best agent cum rewards: 1142.4895545500622
2013
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1183.078258534646
avg cum rews: 1183.078258534646, std: 0.0
the best agent: 0, best agent cum rewards: 1183.078258534646
2023
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1214.8312742090784
avg cum rews: 1214.8312742090784, std: 0.0
the best agent: 0, best agent cum rewards: 1214.8312742090784
2033
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1226.8543575647443
avg cum rews: 1226.8543575647443, std: 0.0
the best agent: 0, best agent cum rewards: 1226.8543575647443
2043
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1207.6528964997026
avg cum rews: 1207.6528964997026, std: 0.0
the best agent: 0, best agent cum rewards: 1207.6528964997026
2053
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1215.5922299829738
avg cum rews: 1215.5922299829738, std: 0.0
the best agent: 0, best agent cum rewards: 1215.5922299829738
2063
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1120.5592934902331
avg cum rews: 1120.5592934902331, std: 0.0
the best agent: 0, best agent cum rewards: 1120.5592934902331
2073
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1214.6278571944374
avg cum rews: 1214.6278571944374, std: 0.0
the best agent: 0, best agent cum rewards: 1214.6278571944374
2083
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1180.7765671869663
avg cum rews: 1180.7765671869663, std: 0.0
the best agent: 0, best agent cum rewards: 1180.7765671869663
2093
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1170.3893211289542
avg cum rews: 1170.3893211289542, std: 0.0
the best agent: 0, best agent cum rewards: 1170.3893211289542
2103
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1174.935215420536
avg cum rews: 1174.935215420536, std: 0.0
the best agent: 0, best agent cum rewards: 1174.935215420536
2113
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1198.10368115842
avg cum rews: 1198.10368115842, std: 0.0
the best agent: 0, best agent cum rewards: 1198.10368115842
2123
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1251.841026439448
avg cum rews: 1251.841026439448, std: 0.0
the best agent: 0, best agent cum rewards: 1251.841026439448
2133
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1242.9915290335266
avg cum rews: 1242.9915290335266, std: 0.0
the best agent: 0, best agent cum rewards: 1242.9915290335266
2143
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1259.792417874093
avg cum rews: 1259.792417874093, std: 0.0
the best agent: 0, best agent cum rewards: 1259.792417874093
2153
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1272.8459637755877
avg cum rews: 1272.8459637755877, std: 0.0
the best agent: 0, best agent cum rewards: 1272.8459637755877
2163
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1252.618916629445
avg cum rews: 1252.618916629445, std: 0.0
the best agent: 0, best agent cum rewards: 1252.618916629445
2173
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1211.1502918620827
avg cum rews: 1211.1502918620827, std: 0.0
the best agent: 0, best agent cum rewards: 1211.1502918620827
2183
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1247.3902334535767
avg cum rews: 1247.3902334535767, std: 0.0
the best agent: 0, best agent cum rewards: 1247.3902334535767
2193
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1249.798814842269
avg cum rews: 1249.798814842269, std: 0.0
the best agent: 0, best agent cum rewards: 1249.798814842269
2203
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1284.1877934374352
avg cum rews: 1284.1877934374352, std: 0.0
the best agent: 0, best agent cum rewards: 1284.1877934374352
2213
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1253.5781800645248
avg cum rews: 1253.5781800645248, std: 0.0
the best agent: 0, best agent cum rewards: 1253.5781800645248
2223
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1217.007225057713
avg cum rews: 1217.007225057713, std: 0.0
the best agent: 0, best agent cum rewards: 1217.007225057713
2233
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1217.8707903786624
avg cum rews: 1217.8707903786624, std: 0.0
the best agent: 0, best agent cum rewards: 1217.8707903786624
2243
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1249.7664799646202
avg cum rews: 1249.7664799646202, std: 0.0
the best agent: 0, best agent cum rewards: 1249.7664799646202
2253
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1270.3223592591628
avg cum rews: 1270.3223592591628, std: 0.0
the best agent: 0, best agent cum rewards: 1270.3223592591628
2263
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1217.306307011284
avg cum rews: 1217.306307011284, std: 0.0
the best agent: 0, best agent cum rewards: 1217.306307011284
2273
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1300.3793056538755
avg cum rews: 1300.3793056538755, std: 0.0
the best agent: 0, best agent cum rewards: 1300.3793056538755
2283
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1280.869562971401
avg cum rews: 1280.869562971401, std: 0.0
the best agent: 0, best agent cum rewards: 1280.869562971401
2293
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1317.3376275753155
avg cum rews: 1317.3376275753155, std: 0.0
the best agent: 0, best agent cum rewards: 1317.3376275753155
2303
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1225.2304634360237
avg cum rews: 1225.2304634360237, std: 0.0
the best agent: 0, best agent cum rewards: 1225.2304634360237
2313
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1255.88984638628
avg cum rews: 1255.88984638628, std: 0.0
the best agent: 0, best agent cum rewards: 1255.88984638628
2323
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1109.0595594931704
avg cum rews: 1109.0595594931704, std: 0.0
the best agent: 0, best agent cum rewards: 1109.0595594931704
2333
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1197.189184327377
avg cum rews: 1197.189184327377, std: 0.0
the best agent: 0, best agent cum rewards: 1197.189184327377
2343
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1207.4946020350706
avg cum rews: 1207.4946020350706, std: 0.0
the best agent: 0, best agent cum rewards: 1207.4946020350706
2353
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 940.4883185288054
avg cum rews: 940.4883185288054, std: 0.0
the best agent: 0, best agent cum rewards: 940.4883185288054
2363
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1139.4765763181106
avg cum rews: 1139.4765763181106, std: 0.0
the best agent: 0, best agent cum rewards: 1139.4765763181106
2373
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1139.0158805548272
avg cum rews: 1139.0158805548272, std: 0.0
the best agent: 0, best agent cum rewards: 1139.0158805548272
2383
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1120.9242846098496
avg cum rews: 1120.9242846098496, std: 0.0
the best agent: 0, best agent cum rewards: 1120.9242846098496
2393
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1149.4075404319835
avg cum rews: 1149.4075404319835, std: 0.0
the best agent: 0, best agent cum rewards: 1149.4075404319835
2403
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1222.010145591533
avg cum rews: 1222.010145591533, std: 0.0
the best agent: 0, best agent cum rewards: 1222.010145591533
2413
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1254.8295504875325
avg cum rews: 1254.8295504875325, std: 0.0
the best agent: 0, best agent cum rewards: 1254.8295504875325
2423
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1236.4407534999773
avg cum rews: 1236.4407534999773, std: 0.0
the best agent: 0, best agent cum rewards: 1236.4407534999773
2433
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1273.5256662242853
avg cum rews: 1273.5256662242853, std: 0.0
the best agent: 0, best agent cum rewards: 1273.5256662242853
2443
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1263.9740857795405
avg cum rews: 1263.9740857795405, std: 0.0
the best agent: 0, best agent cum rewards: 1263.9740857795405
2453
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1203.0222799937183
avg cum rews: 1203.0222799937183, std: 0.0
the best agent: 0, best agent cum rewards: 1203.0222799937183
2463
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1288.0800907864857
avg cum rews: 1288.0800907864857, std: 0.0
the best agent: 0, best agent cum rewards: 1288.0800907864857
2473
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1311.3964609444763
avg cum rews: 1311.3964609444763, std: 0.0
the best agent: 0, best agent cum rewards: 1311.3964609444763
2483
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1274.4064978373353
avg cum rews: 1274.4064978373353, std: 0.0
the best agent: 0, best agent cum rewards: 1274.4064978373353
2493
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1294.870687673465
avg cum rews: 1294.870687673465, std: 0.0
the best agent: 0, best agent cum rewards: 1294.870687673465
2503
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1255.8266898693207
avg cum rews: 1255.8266898693207, std: 0.0
the best agent: 0, best agent cum rewards: 1255.8266898693207
2513
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1263.7469441840658
avg cum rews: 1263.7469441840658, std: 0.0
the best agent: 0, best agent cum rewards: 1263.7469441840658
2523
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1256.6479616226861
avg cum rews: 1256.6479616226861, std: 0.0
the best agent: 0, best agent cum rewards: 1256.6479616226861
2533
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1304.3575694747658
avg cum rews: 1304.3575694747658, std: 0.0
the best agent: 0, best agent cum rewards: 1304.3575694747658
2543
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1206.0234029285882
avg cum rews: 1206.0234029285882, std: 0.0
the best agent: 0, best agent cum rewards: 1206.0234029285882
2553
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1272.2008856209966
avg cum rews: 1272.2008856209966, std: 0.0
the best agent: 0, best agent cum rewards: 1272.2008856209966
2563
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 880.0876656247614
avg cum rews: 880.0876656247614, std: 0.0
the best agent: 0, best agent cum rewards: 880.0876656247614
2573
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1289.544776166018
avg cum rews: 1289.544776166018, std: 0.0
the best agent: 0, best agent cum rewards: 1289.544776166018
2583
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1296.1141534868027
avg cum rews: 1296.1141534868027, std: 0.0
the best agent: 0, best agent cum rewards: 1296.1141534868027
2593
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1330.4035084789696
avg cum rews: 1330.4035084789696, std: 0.0
the best agent: 0, best agent cum rewards: 1330.4035084789696
2603
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1228.7579206314597
avg cum rews: 1228.7579206314597, std: 0.0
the best agent: 0, best agent cum rewards: 1228.7579206314597
2613
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1311.2516937328812
avg cum rews: 1311.2516937328812, std: 0.0
the best agent: 0, best agent cum rewards: 1311.2516937328812
2623
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1076.0910911017563
avg cum rews: 1076.0910911017563, std: 0.0
the best agent: 0, best agent cum rewards: 1076.0910911017563
2633
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1194.0094861086109
avg cum rews: 1194.0094861086109, std: 0.0
the best agent: 0, best agent cum rewards: 1194.0094861086109
2643
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1235.6777997794754
avg cum rews: 1235.6777997794754, std: 0.0
the best agent: 0, best agent cum rewards: 1235.6777997794754
2653
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1204.1991501960536
avg cum rews: 1204.1991501960536, std: 0.0
the best agent: 0, best agent cum rewards: 1204.1991501960536
2663
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1251.1564206713035
avg cum rews: 1251.1564206713035, std: 0.0
the best agent: 0, best agent cum rewards: 1251.1564206713035
2673
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1205.458494845693
avg cum rews: 1205.458494845693, std: 0.0
the best agent: 0, best agent cum rewards: 1205.458494845693
2683
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1178.3502993199315
avg cum rews: 1178.3502993199315, std: 0.0
the best agent: 0, best agent cum rewards: 1178.3502993199315
2693
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1225.3731425928029
avg cum rews: 1225.3731425928029, std: 0.0
the best agent: 0, best agent cum rewards: 1225.3731425928029
2703
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 925.5895431624182
avg cum rews: 925.5895431624182, std: 0.0
the best agent: 0, best agent cum rewards: 925.5895431624182
2713
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1154.20176906014
avg cum rews: 1154.20176906014, std: 0.0
the best agent: 0, best agent cum rewards: 1154.20176906014
2723
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1244.7174074569969
avg cum rews: 1244.7174074569969, std: 0.0
the best agent: 0, best agent cum rewards: 1244.7174074569969
2733
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1118.6851158435068
avg cum rews: 1118.6851158435068, std: 0.0
the best agent: 0, best agent cum rewards: 1118.6851158435068
2743
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1096.2993599654972
avg cum rews: 1096.2993599654972, std: 0.0
the best agent: 0, best agent cum rewards: 1096.2993599654972
2753
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1291.035114708803
avg cum rews: 1291.035114708803, std: 0.0
the best agent: 0, best agent cum rewards: 1291.035114708803
2763
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1258.2221785493941
avg cum rews: 1258.2221785493941, std: 0.0
the best agent: 0, best agent cum rewards: 1258.2221785493941
2773
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1259.0798387194227
avg cum rews: 1259.0798387194227, std: 0.0
the best agent: 0, best agent cum rewards: 1259.0798387194227
2783
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1219.0474686853995
avg cum rews: 1219.0474686853995, std: 0.0
the best agent: 0, best agent cum rewards: 1219.0474686853995
2793
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1165.451433230245
avg cum rews: 1165.451433230245, std: 0.0
the best agent: 0, best agent cum rewards: 1165.451433230245
2803
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 968.9574866439895
avg cum rews: 968.9574866439895, std: 0.0
the best agent: 0, best agent cum rewards: 968.9574866439895
2813
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1302.119520332412
avg cum rews: 1302.119520332412, std: 0.0
the best agent: 0, best agent cum rewards: 1302.119520332412
2823
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1263.2925992132143
avg cum rews: 1263.2925992132143, std: 0.0
the best agent: 0, best agent cum rewards: 1263.2925992132143
2833
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1222.1623919460933
avg cum rews: 1222.1623919460933, std: 0.0
the best agent: 0, best agent cum rewards: 1222.1623919460933
2843
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1270.752374894267
avg cum rews: 1270.752374894267, std: 0.0
the best agent: 0, best agent cum rewards: 1270.752374894267
2853
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1274.2880748811683
avg cum rews: 1274.2880748811683, std: 0.0
the best agent: 0, best agent cum rewards: 1274.2880748811683
2863
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1283.7166864923395
avg cum rews: 1283.7166864923395, std: 0.0
the best agent: 0, best agent cum rewards: 1283.7166864923395
2873
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1199.8960874298355
avg cum rews: 1199.8960874298355, std: 0.0
the best agent: 0, best agent cum rewards: 1199.8960874298355
2883
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1234.4778536396723
avg cum rews: 1234.4778536396723, std: 0.0
the best agent: 0, best agent cum rewards: 1234.4778536396723
2893
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 973.3338080001316
avg cum rews: 973.3338080001316, std: 0.0
the best agent: 0, best agent cum rewards: 973.3338080001316
2903
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1259.4240468366188
avg cum rews: 1259.4240468366188, std: 0.0
the best agent: 0, best agent cum rewards: 1259.4240468366188
2913
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1324.2209360996105
avg cum rews: 1324.2209360996105, std: 0.0
the best agent: 0, best agent cum rewards: 1324.2209360996105
2923
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1284.4432542667491
avg cum rews: 1284.4432542667491, std: 0.0
the best agent: 0, best agent cum rewards: 1284.4432542667491
2933
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1260.5164745144623
avg cum rews: 1260.5164745144623, std: 0.0
the best agent: 0, best agent cum rewards: 1260.5164745144623
2943
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1302.9245512740454
avg cum rews: 1302.9245512740454, std: 0.0
the best agent: 0, best agent cum rewards: 1302.9245512740454
2953
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1264.8391847706323
avg cum rews: 1264.8391847706323, std: 0.0
the best agent: 0, best agent cum rewards: 1264.8391847706323
2963
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1270.8469388678204
avg cum rews: 1270.8469388678204, std: 0.0
the best agent: 0, best agent cum rewards: 1270.8469388678204
2973
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1291.2846735562005
avg cum rews: 1291.2846735562005, std: 0.0
the best agent: 0, best agent cum rewards: 1291.2846735562005
2983
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1265.6750426768897
avg cum rews: 1265.6750426768897, std: 0.0
the best agent: 0, best agent cum rewards: 1265.6750426768897
2993
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1353.8296669228391
avg cum rews: 1353.8296669228391, std: 0.0
the best agent: 0, best agent cum rewards: 1353.8296669228391
3003
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 949.6994091765567
avg cum rews: 949.6994091765567, std: 0.0
the best agent: 0, best agent cum rewards: 949.6994091765567
3013
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1316.1180342870841
avg cum rews: 1316.1180342870841, std: 0.0
the best agent: 0, best agent cum rewards: 1316.1180342870841
3023
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1231.757312809844
avg cum rews: 1231.757312809844, std: 0.0
the best agent: 0, best agent cum rewards: 1231.757312809844
3033
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1212.1624365708933
avg cum rews: 1212.1624365708933, std: 0.0
the best agent: 0, best agent cum rewards: 1212.1624365708933
3043
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1233.0320789178368
avg cum rews: 1233.0320789178368, std: 0.0
the best agent: 0, best agent cum rewards: 1233.0320789178368
3053
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1290.989794112742
avg cum rews: 1290.989794112742, std: 0.0
the best agent: 0, best agent cum rewards: 1290.989794112742
3063
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1282.8672180232825
avg cum rews: 1282.8672180232825, std: 0.0
the best agent: 0, best agent cum rewards: 1282.8672180232825
3073
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1320.156246299157
avg cum rews: 1320.156246299157, std: 0.0
the best agent: 0, best agent cum rewards: 1320.156246299157
3083
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1278.9445019980387
avg cum rews: 1278.9445019980387, std: 0.0
the best agent: 0, best agent cum rewards: 1278.9445019980387
3093
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1224.93064589424
avg cum rews: 1224.93064589424, std: 0.0
the best agent: 0, best agent cum rewards: 1224.93064589424
3103
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1182.3006573167077
avg cum rews: 1182.3006573167077, std: 0.0
the best agent: 0, best agent cum rewards: 1182.3006573167077
3113
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1057.1779952427023
avg cum rews: 1057.1779952427023, std: 0.0
the best agent: 0, best agent cum rewards: 1057.1779952427023
3123
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1321.0929903578228
avg cum rews: 1321.0929903578228, std: 0.0
the best agent: 0, best agent cum rewards: 1321.0929903578228
3133
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1161.1538522217452
avg cum rews: 1161.1538522217452, std: 0.0
the best agent: 0, best agent cum rewards: 1161.1538522217452
3143
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1257.705160024634
avg cum rews: 1257.705160024634, std: 0.0
the best agent: 0, best agent cum rewards: 1257.705160024634
3153
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1305.3461680820328
avg cum rews: 1305.3461680820328, std: 0.0
the best agent: 0, best agent cum rewards: 1305.3461680820328
3163
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1275.5208901253452
avg cum rews: 1275.5208901253452, std: 0.0
the best agent: 0, best agent cum rewards: 1275.5208901253452
3173
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1289.3022138470162
avg cum rews: 1289.3022138470162, std: 0.0
the best agent: 0, best agent cum rewards: 1289.3022138470162
3183
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 920.8482757347034
avg cum rews: 920.8482757347034, std: 0.0
the best agent: 0, best agent cum rewards: 920.8482757347034
3193
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 956.0010611719141
avg cum rews: 956.0010611719141, std: 0.0
the best agent: 0, best agent cum rewards: 956.0010611719141
3203
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1322.249091496148
avg cum rews: 1322.249091496148, std: 0.0
the best agent: 0, best agent cum rewards: 1322.249091496148
3213
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1334.1913263471797
avg cum rews: 1334.1913263471797, std: 0.0
the best agent: 0, best agent cum rewards: 1334.1913263471797
3223
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1286.857379338083
avg cum rews: 1286.857379338083, std: 0.0
the best agent: 0, best agent cum rewards: 1286.857379338083
3233
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1326.3242424172047
avg cum rews: 1326.3242424172047, std: 0.0
the best agent: 0, best agent cum rewards: 1326.3242424172047
3243
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1288.305506787777
avg cum rews: 1288.305506787777, std: 0.0
the best agent: 0, best agent cum rewards: 1288.305506787777
3253
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1330.5264679687873
avg cum rews: 1330.5264679687873, std: 0.0
the best agent: 0, best agent cum rewards: 1330.5264679687873
3263
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1352.5891607620094
avg cum rews: 1352.5891607620094, std: 0.0
the best agent: 0, best agent cum rewards: 1352.5891607620094
3273
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1339.193969090411
avg cum rews: 1339.193969090411, std: 0.0
the best agent: 0, best agent cum rewards: 1339.193969090411
3283
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1122.7112090095568
avg cum rews: 1122.7112090095568, std: 0.0
the best agent: 0, best agent cum rewards: 1122.7112090095568
3293
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1341.7157389578545
avg cum rews: 1341.7157389578545, std: 0.0
the best agent: 0, best agent cum rewards: 1341.7157389578545
3303
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1297.4238910819668
avg cum rews: 1297.4238910819668, std: 0.0
the best agent: 0, best agent cum rewards: 1297.4238910819668
3313
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1308.7360532665916
avg cum rews: 1308.7360532665916, std: 0.0
the best agent: 0, best agent cum rewards: 1308.7360532665916
3323
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1306.9221852418898
avg cum rews: 1306.9221852418898, std: 0.0
the best agent: 0, best agent cum rewards: 1306.9221852418898
3333
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1345.259158274411
avg cum rews: 1345.259158274411, std: 0.0
the best agent: 0, best agent cum rewards: 1345.259158274411
3343
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1297.789537840387
avg cum rews: 1297.789537840387, std: 0.0
the best agent: 0, best agent cum rewards: 1297.789537840387
3353
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 936.2121007847745
avg cum rews: 936.2121007847745, std: 0.0
the best agent: 0, best agent cum rewards: 936.2121007847745
3363
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1244.7029218503546
avg cum rews: 1244.7029218503546, std: 0.0
the best agent: 0, best agent cum rewards: 1244.7029218503546
3373
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 988.9925110084199
avg cum rews: 988.9925110084199, std: 0.0
the best agent: 0, best agent cum rewards: 988.9925110084199
3383
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1327.0834744128708
avg cum rews: 1327.0834744128708, std: 0.0
the best agent: 0, best agent cum rewards: 1327.0834744128708
3393
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1344.1295096316996
avg cum rews: 1344.1295096316996, std: 0.0
the best agent: 0, best agent cum rewards: 1344.1295096316996
3403
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1371.5529055419222
avg cum rews: 1371.5529055419222, std: 0.0
the best agent: 0, best agent cum rewards: 1371.5529055419222
3413
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1298.829705296356
avg cum rews: 1298.829705296356, std: 0.0
the best agent: 0, best agent cum rewards: 1298.829705296356
3423
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 958.3885412983509
avg cum rews: 958.3885412983509, std: 0.0
the best agent: 0, best agent cum rewards: 958.3885412983509
3433
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1283.8002321302677
avg cum rews: 1283.8002321302677, std: 0.0
the best agent: 0, best agent cum rewards: 1283.8002321302677
3443
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1292.1940312946488
avg cum rews: 1292.1940312946488, std: 0.0
the best agent: 0, best agent cum rewards: 1292.1940312946488
3453
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1306.3478497761535
avg cum rews: 1306.3478497761535, std: 0.0
the best agent: 0, best agent cum rewards: 1306.3478497761535
3463
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 972.7270962634939
avg cum rews: 972.7270962634939, std: 0.0
the best agent: 0, best agent cum rewards: 972.7270962634939
3473
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 997.0091895496759
avg cum rews: 997.0091895496759, std: 0.0
the best agent: 0, best agent cum rewards: 997.0091895496759
3483
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1264.9003168330084
avg cum rews: 1264.9003168330084, std: 0.0
the best agent: 0, best agent cum rewards: 1264.9003168330084
3493
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 865.2955488164577
avg cum rews: 865.2955488164577, std: 0.0
the best agent: 0, best agent cum rewards: 865.2955488164577
3503
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1315.9498590582127
avg cum rews: 1315.9498590582127, std: 0.0
the best agent: 0, best agent cum rewards: 1315.9498590582127
3513
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1295.9126350457082
avg cum rews: 1295.9126350457082, std: 0.0
the best agent: 0, best agent cum rewards: 1295.9126350457082
3523
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1052.6047379954641
avg cum rews: 1052.6047379954641, std: 0.0
the best agent: 0, best agent cum rewards: 1052.6047379954641
3533
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1286.3145181978664
avg cum rews: 1286.3145181978664, std: 0.0
the best agent: 0, best agent cum rewards: 1286.3145181978664
3543
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1293.1600863713538
avg cum rews: 1293.1600863713538, std: 0.0
the best agent: 0, best agent cum rewards: 1293.1600863713538
3553
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1311.2701241960167
avg cum rews: 1311.2701241960167, std: 0.0
the best agent: 0, best agent cum rewards: 1311.2701241960167
3563
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1214.6231859709853
avg cum rews: 1214.6231859709853, std: 0.0
the best agent: 0, best agent cum rewards: 1214.6231859709853
3573
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1207.2326506170987
avg cum rews: 1207.2326506170987, std: 0.0
the best agent: 0, best agent cum rewards: 1207.2326506170987
3583
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1025.01088070884
avg cum rews: 1025.01088070884, std: 0.0
the best agent: 0, best agent cum rewards: 1025.01088070884
3593
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1050.6134744461353
avg cum rews: 1050.6134744461353, std: 0.0
the best agent: 0, best agent cum rewards: 1050.6134744461353
3603
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1351.0977754183032
avg cum rews: 1351.0977754183032, std: 0.0
the best agent: 0, best agent cum rewards: 1351.0977754183032
3613
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 922.0873418232271
avg cum rews: 922.0873418232271, std: 0.0
the best agent: 0, best agent cum rewards: 922.0873418232271
3623
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1328.1078705920954
avg cum rews: 1328.1078705920954, std: 0.0
the best agent: 0, best agent cum rewards: 1328.1078705920954
3633
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1277.1083641935954
avg cum rews: 1277.1083641935954, std: 0.0
the best agent: 0, best agent cum rewards: 1277.1083641935954
3643
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1364.6833993939
avg cum rews: 1364.6833993939, std: 0.0
the best agent: 0, best agent cum rewards: 1364.6833993939
3653
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1285.6806896317576
avg cum rews: 1285.6806896317576, std: 0.0
the best agent: 0, best agent cum rewards: 1285.6806896317576
3663
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1234.475407079677
avg cum rews: 1234.475407079677, std: 0.0
the best agent: 0, best agent cum rewards: 1234.475407079677
3673
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1334.83290468005
avg cum rews: 1334.83290468005, std: 0.0
the best agent: 0, best agent cum rewards: 1334.83290468005
3683
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1279.2914213143522
avg cum rews: 1279.2914213143522, std: 0.0
the best agent: 0, best agent cum rewards: 1279.2914213143522
3693
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1209.7342842471164
avg cum rews: 1209.7342842471164, std: 0.0
the best agent: 0, best agent cum rewards: 1209.7342842471164
3703
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1320.6293967697366
avg cum rews: 1320.6293967697366, std: 0.0
the best agent: 0, best agent cum rewards: 1320.6293967697366
3713
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1298.410434083237
avg cum rews: 1298.410434083237, std: 0.0
the best agent: 0, best agent cum rewards: 1298.410434083237
3723
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1226.556654746586
avg cum rews: 1226.556654746586, std: 0.0
the best agent: 0, best agent cum rewards: 1226.556654746586
3733
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1207.3669014739378
avg cum rews: 1207.3669014739378, std: 0.0
the best agent: 0, best agent cum rewards: 1207.3669014739378
3743
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1222.8980327359943
avg cum rews: 1222.8980327359943, std: 0.0
the best agent: 0, best agent cum rewards: 1222.8980327359943
3753
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1095.7159908094302
avg cum rews: 1095.7159908094302, std: 0.0
the best agent: 0, best agent cum rewards: 1095.7159908094302
3763
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1000.2514998779321
avg cum rews: 1000.2514998779321, std: 0.0
the best agent: 0, best agent cum rewards: 1000.2514998779321
3773
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1323.6537927823956
avg cum rews: 1323.6537927823956, std: 0.0
the best agent: 0, best agent cum rewards: 1323.6537927823956
3783
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1063.8326024939026
avg cum rews: 1063.8326024939026, std: 0.0
the best agent: 0, best agent cum rewards: 1063.8326024939026
3793
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1312.3326716345036
avg cum rews: 1312.3326716345036, std: 0.0
the best agent: 0, best agent cum rewards: 1312.3326716345036
3803
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1284.470261639537
avg cum rews: 1284.470261639537, std: 0.0
the best agent: 0, best agent cum rewards: 1284.470261639537
3813
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1356.6398827234952
avg cum rews: 1356.6398827234952, std: 0.0
the best agent: 0, best agent cum rewards: 1356.6398827234952
3823
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1295.1003524821547
avg cum rews: 1295.1003524821547, std: 0.0
the best agent: 0, best agent cum rewards: 1295.1003524821547
3833
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1273.7326787959512
avg cum rews: 1273.7326787959512, std: 0.0
the best agent: 0, best agent cum rewards: 1273.7326787959512
3843
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1311.0893070957027
avg cum rews: 1311.0893070957027, std: 0.0
the best agent: 0, best agent cum rewards: 1311.0893070957027
3853
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1332.9726288611103
avg cum rews: 1332.9726288611103, std: 0.0
the best agent: 0, best agent cum rewards: 1332.9726288611103
3863
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1227.4017845356914
avg cum rews: 1227.4017845356914, std: 0.0
the best agent: 0, best agent cum rewards: 1227.4017845356914
3873
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1359.3561747433268
avg cum rews: 1359.3561747433268, std: 0.0
the best agent: 0, best agent cum rewards: 1359.3561747433268
3883
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1325.8911940018795
avg cum rews: 1325.8911940018795, std: 0.0
the best agent: 0, best agent cum rewards: 1325.8911940018795
3893
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1372.642590449046
avg cum rews: 1372.642590449046, std: 0.0
the best agent: 0, best agent cum rewards: 1372.642590449046
3903
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1313.9670077682724
avg cum rews: 1313.9670077682724, std: 0.0
the best agent: 0, best agent cum rewards: 1313.9670077682724
3913
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1287.6527264493827
avg cum rews: 1287.6527264493827, std: 0.0
the best agent: 0, best agent cum rewards: 1287.6527264493827
3923
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 878.620086155502
avg cum rews: 878.620086155502, std: 0.0
the best agent: 0, best agent cum rewards: 878.620086155502
3933
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1304.1625592317043
avg cum rews: 1304.1625592317043, std: 0.0
the best agent: 0, best agent cum rewards: 1304.1625592317043
3943
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1296.9320097673335
avg cum rews: 1296.9320097673335, std: 0.0
the best agent: 0, best agent cum rewards: 1296.9320097673335
3953
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1340.471021747818
avg cum rews: 1340.471021747818, std: 0.0
the best agent: 0, best agent cum rewards: 1340.471021747818
3963
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1304.0153531495598
avg cum rews: 1304.0153531495598, std: 0.0
the best agent: 0, best agent cum rewards: 1304.0153531495598
3973
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1271.3193147329341
avg cum rews: 1271.3193147329341, std: 0.0
the best agent: 0, best agent cum rewards: 1271.3193147329341
3983
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1325.0130244202446
avg cum rews: 1325.0130244202446, std: 0.0
the best agent: 0, best agent cum rewards: 1325.0130244202446
3993
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1357.8403828794399
avg cum rews: 1357.8403828794399, std: 0.0
the best agent: 0, best agent cum rewards: 1357.8403828794399
4003
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1361.1325094408676
avg cum rews: 1361.1325094408676, std: 0.0
the best agent: 0, best agent cum rewards: 1361.1325094408676
4013
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1324.5857046026115
avg cum rews: 1324.5857046026115, std: 0.0
the best agent: 0, best agent cum rewards: 1324.5857046026115
4023
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1301.2468050013606
avg cum rews: 1301.2468050013606, std: 0.0
the best agent: 0, best agent cum rewards: 1301.2468050013606
4033
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1252.6114246908303
avg cum rews: 1252.6114246908303, std: 0.0
the best agent: 0, best agent cum rewards: 1252.6114246908303
4043
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 963.6149097684684
avg cum rews: 963.6149097684684, std: 0.0
the best agent: 0, best agent cum rewards: 963.6149097684684
4053
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1325.1195791121183
avg cum rews: 1325.1195791121183, std: 0.0
the best agent: 0, best agent cum rewards: 1325.1195791121183
4063
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1284.996898092053
avg cum rews: 1284.996898092053, std: 0.0
the best agent: 0, best agent cum rewards: 1284.996898092053
4073
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1217.5328937173279
avg cum rews: 1217.5328937173279, std: 0.0
the best agent: 0, best agent cum rewards: 1217.5328937173279
4083
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1126.963275859637
avg cum rews: 1126.963275859637, std: 0.0
the best agent: 0, best agent cum rewards: 1126.963275859637
4093
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1254.237867062756
avg cum rews: 1254.237867062756, std: 0.0
the best agent: 0, best agent cum rewards: 1254.237867062756
4103
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1274.6501512565617
avg cum rews: 1274.6501512565617, std: 0.0
the best agent: 0, best agent cum rewards: 1274.6501512565617
4113
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1164.520698358557
avg cum rews: 1164.520698358557, std: 0.0
the best agent: 0, best agent cum rewards: 1164.520698358557
4123
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1204.8835101222212
avg cum rews: 1204.8835101222212, std: 0.0
the best agent: 0, best agent cum rewards: 1204.8835101222212
4133
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1327.5620047848304
avg cum rews: 1327.5620047848304, std: 0.0
the best agent: 0, best agent cum rewards: 1327.5620047848304
4143
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1323.7604048055825
avg cum rews: 1323.7604048055825, std: 0.0
the best agent: 0, best agent cum rewards: 1323.7604048055825
4153
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1316.186726452317
avg cum rews: 1316.186726452317, std: 0.0
the best agent: 0, best agent cum rewards: 1316.186726452317
4163
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1163.895903798053
avg cum rews: 1163.895903798053, std: 0.0
the best agent: 0, best agent cum rewards: 1163.895903798053
4173
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1173.197865406478
avg cum rews: 1173.197865406478, std: 0.0
the best agent: 0, best agent cum rewards: 1173.197865406478
4183
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1262.1428598610219
avg cum rews: 1262.1428598610219, std: 0.0
the best agent: 0, best agent cum rewards: 1262.1428598610219
4193
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1323.6028065061619
avg cum rews: 1323.6028065061619, std: 0.0
the best agent: 0, best agent cum rewards: 1323.6028065061619
4203
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1355.6528844204342
avg cum rews: 1355.6528844204342, std: 0.0
the best agent: 0, best agent cum rewards: 1355.6528844204342
4213
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1280.2345272498496
avg cum rews: 1280.2345272498496, std: 0.0
the best agent: 0, best agent cum rewards: 1280.2345272498496
4223
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1285.0539823011884
avg cum rews: 1285.0539823011884, std: 0.0
the best agent: 0, best agent cum rewards: 1285.0539823011884
4233
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1325.1147030539723
avg cum rews: 1325.1147030539723, std: 0.0
the best agent: 0, best agent cum rewards: 1325.1147030539723
4243
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1308.8966688899006
avg cum rews: 1308.8966688899006, std: 0.0
the best agent: 0, best agent cum rewards: 1308.8966688899006
4253
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1312.9945312383813
avg cum rews: 1312.9945312383813, std: 0.0
the best agent: 0, best agent cum rewards: 1312.9945312383813
4263
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1182.9260865493754
avg cum rews: 1182.9260865493754, std: 0.0
the best agent: 0, best agent cum rewards: 1182.9260865493754
4273
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1239.071926227305
avg cum rews: 1239.071926227305, std: 0.0
the best agent: 0, best agent cum rewards: 1239.071926227305
4283
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1234.6816568806728
avg cum rews: 1234.6816568806728, std: 0.0
the best agent: 0, best agent cum rewards: 1234.6816568806728
4293
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1304.252527998964
avg cum rews: 1304.252527998964, std: 0.0
the best agent: 0, best agent cum rewards: 1304.252527998964
4303
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1249.9517871612527
avg cum rews: 1249.9517871612527, std: 0.0
the best agent: 0, best agent cum rewards: 1249.9517871612527
4313
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1309.4039153876365
avg cum rews: 1309.4039153876365, std: 0.0
the best agent: 0, best agent cum rewards: 1309.4039153876365
4323
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1338.3828117549153
avg cum rews: 1338.3828117549153, std: 0.0
the best agent: 0, best agent cum rewards: 1338.3828117549153
4333
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1324.337249523407
avg cum rews: 1324.337249523407, std: 0.0
the best agent: 0, best agent cum rewards: 1324.337249523407
4343
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1121.3001220957037
avg cum rews: 1121.3001220957037, std: 0.0
the best agent: 0, best agent cum rewards: 1121.3001220957037
4353
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1258.1100062405555
avg cum rews: 1258.1100062405555, std: 0.0
the best agent: 0, best agent cum rewards: 1258.1100062405555
4363
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1178.162671674363
avg cum rews: 1178.162671674363, std: 0.0
the best agent: 0, best agent cum rewards: 1178.162671674363
4373
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1333.32101037687
avg cum rews: 1333.32101037687, std: 0.0
the best agent: 0, best agent cum rewards: 1333.32101037687
4383
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1246.889702756899
avg cum rews: 1246.889702756899, std: 0.0
the best agent: 0, best agent cum rewards: 1246.889702756899
4393
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1233.5995535964223
avg cum rews: 1233.5995535964223, std: 0.0
the best agent: 0, best agent cum rewards: 1233.5995535964223
4403
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1252.1639215472194
avg cum rews: 1252.1639215472194, std: 0.0
the best agent: 0, best agent cum rewards: 1252.1639215472194
4413
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1300.8983085000461
avg cum rews: 1300.8983085000461, std: 0.0
the best agent: 0, best agent cum rewards: 1300.8983085000461
4423
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1316.3689756148185
avg cum rews: 1316.3689756148185, std: 0.0
the best agent: 0, best agent cum rewards: 1316.3689756148185
4433
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1285.7731937130739
avg cum rews: 1285.7731937130739, std: 0.0
the best agent: 0, best agent cum rewards: 1285.7731937130739
4443
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1295.1765160829916
avg cum rews: 1295.1765160829916, std: 0.0
the best agent: 0, best agent cum rewards: 1295.1765160829916
4453
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 899.7746917407688
avg cum rews: 899.7746917407688, std: 0.0
the best agent: 0, best agent cum rewards: 899.7746917407688
4463
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1319.0109761771503
avg cum rews: 1319.0109761771503, std: 0.0
the best agent: 0, best agent cum rewards: 1319.0109761771503
4473
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1275.521102310954
avg cum rews: 1275.521102310954, std: 0.0
the best agent: 0, best agent cum rewards: 1275.521102310954
4483
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1358.2119562417113
avg cum rews: 1358.2119562417113, std: 0.0
the best agent: 0, best agent cum rewards: 1358.2119562417113
4493
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1274.4458584934084
avg cum rews: 1274.4458584934084, std: 0.0
the best agent: 0, best agent cum rewards: 1274.4458584934084
4503
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1181.1776454506132
avg cum rews: 1181.1776454506132, std: 0.0
the best agent: 0, best agent cum rewards: 1181.1776454506132
4513
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1333.4561555281834
avg cum rews: 1333.4561555281834, std: 0.0
the best agent: 0, best agent cum rewards: 1333.4561555281834
4523
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1172.598430615685
avg cum rews: 1172.598430615685, std: 0.0
the best agent: 0, best agent cum rewards: 1172.598430615685
4533
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1174.1279642180696
avg cum rews: 1174.1279642180696, std: 0.0
the best agent: 0, best agent cum rewards: 1174.1279642180696
4543
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1350.0182902988552
avg cum rews: 1350.0182902988552, std: 0.0
the best agent: 0, best agent cum rewards: 1350.0182902988552
4553
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1319.156428683229
avg cum rews: 1319.156428683229, std: 0.0
the best agent: 0, best agent cum rewards: 1319.156428683229
4563
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1297.3792729581862
avg cum rews: 1297.3792729581862, std: 0.0
the best agent: 0, best agent cum rewards: 1297.3792729581862
4573
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1258.1591652294155
avg cum rews: 1258.1591652294155, std: 0.0
the best agent: 0, best agent cum rewards: 1258.1591652294155
4583
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1249.7224951963678
avg cum rews: 1249.7224951963678, std: 0.0
the best agent: 0, best agent cum rewards: 1249.7224951963678
4593
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1306.6836133590161
avg cum rews: 1306.6836133590161, std: 0.0
the best agent: 0, best agent cum rewards: 1306.6836133590161
4603
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 859.5121821181965
avg cum rews: 859.5121821181965, std: 0.0
the best agent: 0, best agent cum rewards: 859.5121821181965
4613
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1231.0523457322136
avg cum rews: 1231.0523457322136, std: 0.0
the best agent: 0, best agent cum rewards: 1231.0523457322136
4623
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1267.043731476646
avg cum rews: 1267.043731476646, std: 0.0
the best agent: 0, best agent cum rewards: 1267.043731476646
4633
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1227.6109684904684
avg cum rews: 1227.6109684904684, std: 0.0
the best agent: 0, best agent cum rewards: 1227.6109684904684
4643
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1297.147967193756
avg cum rews: 1297.147967193756, std: 0.0
the best agent: 0, best agent cum rewards: 1297.147967193756
4653
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1198.9991959403462
avg cum rews: 1198.9991959403462, std: 0.0
the best agent: 0, best agent cum rewards: 1198.9991959403462
4663
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1277.1272934791243
avg cum rews: 1277.1272934791243, std: 0.0
the best agent: 0, best agent cum rewards: 1277.1272934791243
4673
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1282.7495085158346
avg cum rews: 1282.7495085158346, std: 0.0
the best agent: 0, best agent cum rewards: 1282.7495085158346
4683
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1297.0039673362432
avg cum rews: 1297.0039673362432, std: 0.0
the best agent: 0, best agent cum rewards: 1297.0039673362432
4693
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1164.585073295127
avg cum rews: 1164.585073295127, std: 0.0
the best agent: 0, best agent cum rewards: 1164.585073295127
4703
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1100.5894413287558
avg cum rews: 1100.5894413287558, std: 0.0
the best agent: 0, best agent cum rewards: 1100.5894413287558
4713
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 817.4348801017173
avg cum rews: 817.4348801017173, std: 0.0
the best agent: 0, best agent cum rewards: 817.4348801017173
4723
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1232.9255175852838
avg cum rews: 1232.9255175852838, std: 0.0
the best agent: 0, best agent cum rewards: 1232.9255175852838
4733
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1306.9867707365192
avg cum rews: 1306.9867707365192, std: 0.0
the best agent: 0, best agent cum rewards: 1306.9867707365192
4743
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 775.2482035827506
avg cum rews: 775.2482035827506, std: 0.0
the best agent: 0, best agent cum rewards: 775.2482035827506
4753
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1082.7626415202951
avg cum rews: 1082.7626415202951, std: 0.0
the best agent: 0, best agent cum rewards: 1082.7626415202951
4763
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1152.8620750252255
avg cum rews: 1152.8620750252255, std: 0.0
the best agent: 0, best agent cum rewards: 1152.8620750252255
4773
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 774.491331145895
avg cum rews: 774.491331145895, std: 0.0
the best agent: 0, best agent cum rewards: 774.491331145895
4783
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1052.0343303659367
avg cum rews: 1052.0343303659367, std: 0.0
the best agent: 0, best agent cum rewards: 1052.0343303659367
4793
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1103.599031343222
avg cum rews: 1103.599031343222, std: 0.0
the best agent: 0, best agent cum rewards: 1103.599031343222
4803
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1068.7086292659853
avg cum rews: 1068.7086292659853, std: 0.0
the best agent: 0, best agent cum rewards: 1068.7086292659853
4813
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1132.9848901630223
avg cum rews: 1132.9848901630223, std: 0.0
the best agent: 0, best agent cum rewards: 1132.9848901630223
4823
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1147.430476441281
avg cum rews: 1147.430476441281, std: 0.0
the best agent: 0, best agent cum rewards: 1147.430476441281
4833
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1212.9347047340514
avg cum rews: 1212.9347047340514, std: 0.0
the best agent: 0, best agent cum rewards: 1212.9347047340514
4843
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1102.0452274296742
avg cum rews: 1102.0452274296742, std: 0.0
the best agent: 0, best agent cum rewards: 1102.0452274296742
4853
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 996.036707519767
avg cum rews: 996.036707519767, std: 0.0
the best agent: 0, best agent cum rewards: 996.036707519767
4863
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 991.3426142207076
avg cum rews: 991.3426142207076, std: 0.0
the best agent: 0, best agent cum rewards: 991.3426142207076
4873
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1241.5228111407876
avg cum rews: 1241.5228111407876, std: 0.0
the best agent: 0, best agent cum rewards: 1241.5228111407876
4883
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1207.7256060993823
avg cum rews: 1207.7256060993823, std: 0.0
the best agent: 0, best agent cum rewards: 1207.7256060993823
4893
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 903.3742442927056
avg cum rews: 903.3742442927056, std: 0.0
the best agent: 0, best agent cum rewards: 903.3742442927056
4903
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1241.642208462387
avg cum rews: 1241.642208462387, std: 0.0
the best agent: 0, best agent cum rewards: 1241.642208462387
4913
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1233.2355385642975
avg cum rews: 1233.2355385642975, std: 0.0
the best agent: 0, best agent cum rewards: 1233.2355385642975
4923
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1189.1302054059827
avg cum rews: 1189.1302054059827, std: 0.0
the best agent: 0, best agent cum rewards: 1189.1302054059827
4933
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 749.0543677321597
avg cum rews: 749.0543677321597, std: 0.0
the best agent: 0, best agent cum rewards: 749.0543677321597
4943
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1298.8018009933974
avg cum rews: 1298.8018009933974, std: 0.0
the best agent: 0, best agent cum rewards: 1298.8018009933974
4953
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1246.379944026082
avg cum rews: 1246.379944026082, std: 0.0
the best agent: 0, best agent cum rewards: 1246.379944026082
4963
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1218.1365580372221
avg cum rews: 1218.1365580372221, std: 0.0
the best agent: 0, best agent cum rewards: 1218.1365580372221
4973
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1006.8165430740142
avg cum rews: 1006.8165430740142, std: 0.0
the best agent: 0, best agent cum rewards: 1006.8165430740142
4983
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1118.5399597372652
avg cum rews: 1118.5399597372652, std: 0.0
the best agent: 0, best agent cum rewards: 1118.5399597372652
4993
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1276.9400130283611
avg cum rews: 1276.9400130283611, std: 0.0
the best agent: 0, best agent cum rewards: 1276.9400130283611
5003
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1166.6309688494657
avg cum rews: 1166.6309688494657, std: 0.0
the best agent: 0, best agent cum rewards: 1166.6309688494657
5013
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1115.2215922097967
avg cum rews: 1115.2215922097967, std: 0.0
the best agent: 0, best agent cum rewards: 1115.2215922097967
5023
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1062.109765652917
avg cum rews: 1062.109765652917, std: 0.0
the best agent: 0, best agent cum rewards: 1062.109765652917
5033
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1113.2201768885134
avg cum rews: 1113.2201768885134, std: 0.0
the best agent: 0, best agent cum rewards: 1113.2201768885134
5043
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1251.4146851130645
avg cum rews: 1251.4146851130645, std: 0.0
the best agent: 0, best agent cum rewards: 1251.4146851130645
5053
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1162.0700345091548
avg cum rews: 1162.0700345091548, std: 0.0
the best agent: 0, best agent cum rewards: 1162.0700345091548
5063
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1137.7253411147587
avg cum rews: 1137.7253411147587, std: 0.0
the best agent: 0, best agent cum rewards: 1137.7253411147587
5073
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1240.6582719333746
avg cum rews: 1240.6582719333746, std: 0.0
the best agent: 0, best agent cum rewards: 1240.6582719333746
5083
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1117.5847250990726
avg cum rews: 1117.5847250990726, std: 0.0
the best agent: 0, best agent cum rewards: 1117.5847250990726
5093
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1245.605431513611
avg cum rews: 1245.605431513611, std: 0.0
the best agent: 0, best agent cum rewards: 1245.605431513611
5103
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1268.5783977096046
avg cum rews: 1268.5783977096046, std: 0.0
the best agent: 0, best agent cum rewards: 1268.5783977096046
5113
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 936.3238401475537
avg cum rews: 936.3238401475537, std: 0.0
the best agent: 0, best agent cum rewards: 936.3238401475537
5123
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1299.0880830620008
avg cum rews: 1299.0880830620008, std: 0.0
the best agent: 0, best agent cum rewards: 1299.0880830620008
5133
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1074.2052619753038
avg cum rews: 1074.2052619753038, std: 0.0
the best agent: 0, best agent cum rewards: 1074.2052619753038
5143
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1253.9065442327021
avg cum rews: 1253.9065442327021, std: 0.0
the best agent: 0, best agent cum rewards: 1253.9065442327021
5153
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1166.8728983192898
avg cum rews: 1166.8728983192898, std: 0.0
the best agent: 0, best agent cum rewards: 1166.8728983192898
5163
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1078.0465785904478
avg cum rews: 1078.0465785904478, std: 0.0
the best agent: 0, best agent cum rewards: 1078.0465785904478
5173
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1333.716790355092
avg cum rews: 1333.716790355092, std: 0.0
the best agent: 0, best agent cum rewards: 1333.716790355092
5183
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1294.3394847916788
avg cum rews: 1294.3394847916788, std: 0.0
the best agent: 0, best agent cum rewards: 1294.3394847916788
5193
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1199.2601252543973
avg cum rews: 1199.2601252543973, std: 0.0
the best agent: 0, best agent cum rewards: 1199.2601252543973
5203
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1304.3468393354367
avg cum rews: 1304.3468393354367, std: 0.0
the best agent: 0, best agent cum rewards: 1304.3468393354367
5213
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1178.1809319465053
avg cum rews: 1178.1809319465053, std: 0.0
the best agent: 0, best agent cum rewards: 1178.1809319465053
5223
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1332.2644408546428
avg cum rews: 1332.2644408546428, std: 0.0
the best agent: 0, best agent cum rewards: 1332.2644408546428
5233
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1255.228383296829
avg cum rews: 1255.228383296829, std: 0.0
the best agent: 0, best agent cum rewards: 1255.228383296829
5243
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1241.9838037898298
avg cum rews: 1241.9838037898298, std: 0.0
the best agent: 0, best agent cum rewards: 1241.9838037898298
5253
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1335.9840853477144
avg cum rews: 1335.9840853477144, std: 0.0
the best agent: 0, best agent cum rewards: 1335.9840853477144
5263
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1216.7895728033884
avg cum rews: 1216.7895728033884, std: 0.0
the best agent: 0, best agent cum rewards: 1216.7895728033884
5273
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1252.60909771927
avg cum rews: 1252.60909771927, std: 0.0
the best agent: 0, best agent cum rewards: 1252.60909771927
5283
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1105.0944568561001
avg cum rews: 1105.0944568561001, std: 0.0
the best agent: 0, best agent cum rewards: 1105.0944568561001
5293
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1272.935756916646
avg cum rews: 1272.935756916646, std: 0.0
the best agent: 0, best agent cum rewards: 1272.935756916646
5303
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1231.7321293307566
avg cum rews: 1231.7321293307566, std: 0.0
the best agent: 0, best agent cum rewards: 1231.7321293307566
5313
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 993.1952104293159
avg cum rews: 993.1952104293159, std: 0.0
the best agent: 0, best agent cum rewards: 993.1952104293159
5323
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1262.4957318733893
avg cum rews: 1262.4957318733893, std: 0.0
the best agent: 0, best agent cum rewards: 1262.4957318733893
5333
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1258.4382776149334
avg cum rews: 1258.4382776149334, std: 0.0
the best agent: 0, best agent cum rewards: 1258.4382776149334
5343
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1234.65260945749
avg cum rews: 1234.65260945749, std: 0.0
the best agent: 0, best agent cum rewards: 1234.65260945749
5353
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1177.4352755223615
avg cum rews: 1177.4352755223615, std: 0.0
the best agent: 0, best agent cum rewards: 1177.4352755223615
5363
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1243.8017025222314
avg cum rews: 1243.8017025222314, std: 0.0
the best agent: 0, best agent cum rewards: 1243.8017025222314
5373
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1281.959847905023
avg cum rews: 1281.959847905023, std: 0.0
the best agent: 0, best agent cum rewards: 1281.959847905023
5383
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1277.7232782742165
avg cum rews: 1277.7232782742165, std: 0.0
the best agent: 0, best agent cum rewards: 1277.7232782742165
5393
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1256.0475948142184
avg cum rews: 1256.0475948142184, std: 0.0
the best agent: 0, best agent cum rewards: 1256.0475948142184
5403
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1180.299147008637
avg cum rews: 1180.299147008637, std: 0.0
the best agent: 0, best agent cum rewards: 1180.299147008637
5413
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1086.2912277191838
avg cum rews: 1086.2912277191838, std: 0.0
the best agent: 0, best agent cum rewards: 1086.2912277191838
5423
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1291.5585190207057
avg cum rews: 1291.5585190207057, std: 0.0
the best agent: 0, best agent cum rewards: 1291.5585190207057
5433
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1249.054217243053
avg cum rews: 1249.054217243053, std: 0.0
the best agent: 0, best agent cum rewards: 1249.054217243053
5443
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1355.8956994163261
avg cum rews: 1355.8956994163261, std: 0.0
the best agent: 0, best agent cum rewards: 1355.8956994163261
5453
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1326.4013572749489
avg cum rews: 1326.4013572749489, std: 0.0
the best agent: 0, best agent cum rewards: 1326.4013572749489
5463
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1290.824762282151
avg cum rews: 1290.824762282151, std: 0.0
the best agent: 0, best agent cum rewards: 1290.824762282151
5473
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 925.8839789528089
avg cum rews: 925.8839789528089, std: 0.0
the best agent: 0, best agent cum rewards: 925.8839789528089
5483
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1350.0453067292012
avg cum rews: 1350.0453067292012, std: 0.0
the best agent: 0, best agent cum rewards: 1350.0453067292012
5493
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1255.6228166483052
avg cum rews: 1255.6228166483052, std: 0.0
the best agent: 0, best agent cum rewards: 1255.6228166483052
5503
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1378.7169281112729
avg cum rews: 1378.7169281112729, std: 0.0
the best agent: 0, best agent cum rewards: 1378.7169281112729
5513
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1253.6971657298661
avg cum rews: 1253.6971657298661, std: 0.0
the best agent: 0, best agent cum rewards: 1253.6971657298661
5523
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1302.1585810373654
avg cum rews: 1302.1585810373654, std: 0.0
the best agent: 0, best agent cum rewards: 1302.1585810373654
5533
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1308.093381438385
avg cum rews: 1308.093381438385, std: 0.0
the best agent: 0, best agent cum rewards: 1308.093381438385
5543
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1256.8823375873835
avg cum rews: 1256.8823375873835, std: 0.0
the best agent: 0, best agent cum rewards: 1256.8823375873835
5553
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1256.1454253664463
avg cum rews: 1256.1454253664463, std: 0.0
the best agent: 0, best agent cum rewards: 1256.1454253664463
5563
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1226.7176956315914
avg cum rews: 1226.7176956315914, std: 0.0
the best agent: 0, best agent cum rewards: 1226.7176956315914
5573
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1240.3629522591364
avg cum rews: 1240.3629522591364, std: 0.0
the best agent: 0, best agent cum rewards: 1240.3629522591364
5583
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1269.057623137361
avg cum rews: 1269.057623137361, std: 0.0
the best agent: 0, best agent cum rewards: 1269.057623137361
5593
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1000.8159407603089
avg cum rews: 1000.8159407603089, std: 0.0
the best agent: 0, best agent cum rewards: 1000.8159407603089
5603
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1330.0513442007941
avg cum rews: 1330.0513442007941, std: 0.0
the best agent: 0, best agent cum rewards: 1330.0513442007941
5613
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1306.970129397608
avg cum rews: 1306.970129397608, std: 0.0
the best agent: 0, best agent cum rewards: 1306.970129397608
5623
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1288.7199951177074
avg cum rews: 1288.7199951177074, std: 0.0
the best agent: 0, best agent cum rewards: 1288.7199951177074
5633
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1341.067708866205
avg cum rews: 1341.067708866205, std: 0.0
the best agent: 0, best agent cum rewards: 1341.067708866205
5643
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1278.0134890900226
avg cum rews: 1278.0134890900226, std: 0.0
the best agent: 0, best agent cum rewards: 1278.0134890900226
5653
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1003.0091745610116
avg cum rews: 1003.0091745610116, std: 0.0
the best agent: 0, best agent cum rewards: 1003.0091745610116
5663
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1338.3624314090678
avg cum rews: 1338.3624314090678, std: 0.0
the best agent: 0, best agent cum rewards: 1338.3624314090678
5673
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1266.200167788348
avg cum rews: 1266.200167788348, std: 0.0
the best agent: 0, best agent cum rewards: 1266.200167788348
5683
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1215.4950594542315
avg cum rews: 1215.4950594542315, std: 0.0
the best agent: 0, best agent cum rewards: 1215.4950594542315
5693
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1276.6524108470574
avg cum rews: 1276.6524108470574, std: 0.0
the best agent: 0, best agent cum rewards: 1276.6524108470574
5703
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1200.6667607448496
avg cum rews: 1200.6667607448496, std: 0.0
the best agent: 0, best agent cum rewards: 1200.6667607448496
5713
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1266.7851862994478
avg cum rews: 1266.7851862994478, std: 0.0
the best agent: 0, best agent cum rewards: 1266.7851862994478
5723
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1194.8447659872133
avg cum rews: 1194.8447659872133, std: 0.0
the best agent: 0, best agent cum rewards: 1194.8447659872133
5733
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1218.9433998095628
avg cum rews: 1218.9433998095628, std: 0.0
the best agent: 0, best agent cum rewards: 1218.9433998095628
5743
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1264.2214357422101
avg cum rews: 1264.2214357422101, std: 0.0
the best agent: 0, best agent cum rewards: 1264.2214357422101
5753
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1257.1525856402684
avg cum rews: 1257.1525856402684, std: 0.0
the best agent: 0, best agent cum rewards: 1257.1525856402684
5763
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1297.9458769859048
avg cum rews: 1297.9458769859048, std: 0.0
the best agent: 0, best agent cum rewards: 1297.9458769859048
5773
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1271.2087122298933
avg cum rews: 1271.2087122298933, std: 0.0
the best agent: 0, best agent cum rewards: 1271.2087122298933
5783
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1243.276824834058
avg cum rews: 1243.276824834058, std: 0.0
the best agent: 0, best agent cum rewards: 1243.276824834058
5793
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1317.6070031701431
avg cum rews: 1317.6070031701431, std: 0.0
the best agent: 0, best agent cum rewards: 1317.6070031701431
5803
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1266.2611168970373
avg cum rews: 1266.2611168970373, std: 0.0
the best agent: 0, best agent cum rewards: 1266.2611168970373
5813
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1251.418698418381
avg cum rews: 1251.418698418381, std: 0.0
the best agent: 0, best agent cum rewards: 1251.418698418381
5823
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1310.3389881456194
avg cum rews: 1310.3389881456194, std: 0.0
the best agent: 0, best agent cum rewards: 1310.3389881456194
5833
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1218.5580206502834
avg cum rews: 1218.5580206502834, std: 0.0
the best agent: 0, best agent cum rewards: 1218.5580206502834
5843
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1321.5016679076882
avg cum rews: 1321.5016679076882, std: 0.0
the best agent: 0, best agent cum rewards: 1321.5016679076882
5853
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1146.1073168235598
avg cum rews: 1146.1073168235598, std: 0.0
the best agent: 0, best agent cum rewards: 1146.1073168235598
Average distance of random agents to nearest neighbors: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Time taken for each iteration: [11.865429162979126, 23.686926126480103, 35.53425359725952, 47.357932567596436, 59.18724966049194, 71.01583862304688, 82.82926607131958, 94.70354628562927, 106.58737087249756, 118.42076134681702, 130.24387288093567, 142.0792465209961, 153.88912510871887, 165.73254489898682, 177.52056241035461, 189.3419852256775, 201.16612267494202, 212.98859786987305, 224.7630181312561, 236.54998207092285, 248.34603881835938, 260.16516399383545, 271.91178846359253, 283.70102429389954, 295.49108266830444, 307.2404291629791, 319.0097031593323, 330.73018169403076, 342.45700120925903, 354.2235994338989, 366.01162981987, 377.7961564064026, 389.56774163246155, 401.37686228752136, 413.1872868537903, 424.9717471599579, 436.72860741615295, 448.5263204574585, 460.2985997200012, 472.06171679496765, 483.79051303863525, 495.58377385139465, 507.3646035194397, 519.1398379802704, 530.9188742637634, 542.7380847930908, 554.5428268909454, 566.3141527175903, 578.0571146011353, 589.7881603240967, 601.6039087772369, 613.4050140380859, 625.1694602966309, 636.9069972038269, 648.6566367149353, 660.4042234420776, 672.2012274265289, 684.0306844711304, 695.8507764339447, 707.683577299118, 719.4884316921234, 731.2505054473877, 742.9848885536194, 754.7540082931519, 766.5183417797089, 778.3155069351196, 790.0178260803223, 801.7462611198425, 813.494461774826, 825.2372894287109, 836.98175740242, 848.7248816490173, 860.4584143161774, 872.1827652454376, 883.8843314647675, 895.6846630573273, 907.4418208599091, 919.1887221336365, 930.9311394691467, 942.6810054779053, 954.4033858776093, 966.1071155071259, 977.8361287117004, 989.5985443592072, 1001.3498094081879, 1013.05442237854, 1024.7209887504578, 1036.4666180610657, 1048.2048716545105, 1059.9658365249634, 1071.7367768287659, 1083.5198423862457, 1095.2368559837341, 1106.9290943145752, 1118.6886694431305, 1130.3950307369232, 1142.101390838623, 1153.7949078083038, 1165.5298373699188, 1177.2501020431519, 1188.9631147384644, 1200.7219302654266, 1212.4600648880005, 1224.1964786052704, 1235.9534215927124, 1247.746150970459, 1259.4611113071442, 1271.1883883476257, 1282.8732664585114, 1294.5642125606537, 1306.286841392517, 1318.0116605758667, 1329.7283375263214, 1341.4766840934753, 1353.231594324112, 1364.9731352329254, 1376.722324371338, 1388.451413154602, 1400.1685276031494, 1411.8730421066284, 1423.6025168895721, 1435.3377163410187, 1447.0571293830872, 1458.73956990242, 1470.4239404201508, 1482.1720025539398, 1493.9417955875397, 1505.7058129310608, 1517.4560616016388, 1529.2335662841797, 1540.9460082054138, 1552.6666762828827, 1564.3802027702332, 1576.126618385315, 1587.869380235672, 1599.5877051353455, 1611.2603042125702, 1622.9844906330109, 1634.7291569709778, 1646.469586133957, 1658.2092640399933, 1669.9322056770325, 1681.6718108654022, 1693.3607687950134, 1705.061205148697, 1716.7840642929077, 1728.5331258773804, 1740.3309745788574, 1752.1551735401154, 1763.9476487636566, 1775.7148530483246, 1787.5539526939392, 1799.5564229488373, 1811.4964320659637, 1823.2964615821838, 1835.0856454372406, 1846.9004800319672, 1858.847285270691, 1870.958369255066, 1882.9522466659546, 1894.8467273712158, 1906.7804684638977, 1918.8703501224518, 1930.7883303165436, 1942.737230539322, 1954.90828871727, 1967.1094825267792, 1979.2622604370117, 1991.3754091262817, 2003.6517062187195, 2015.907623052597, 2028.1345624923706, 2040.4054419994354, 2052.8422305583954, 2065.1082084178925, 2077.385313510895, 2089.74880695343, 2102.067884683609, 2114.3867609500885, 2126.6752982139587, 2138.9397926330566, 2151.3988828659058, 2163.7300341129303, 2176.033781528473, 2188.3891081809998, 2200.9601736068726, 2213.200229406357, 2225.48868227005, 2237.7487137317657, 2250.2073426246643, 2262.4598066806793, 2274.7237679958344, 2287.028135538101, 2299.4807064533234, 2311.7009313106537, 2323.9950728416443, 2336.2995705604553, 2348.703553199768, 2360.9537823200226, 2373.170922756195, 2385.4638776779175, 2397.798790693283, 2410.0289487838745, 2422.3076276779175, 2434.6499211788177, 2447.059690952301, 2459.2457258701324, 2471.4576473236084, 2483.821089744568, 2496.2630100250244, 2508.56472492218, 2520.8295497894287, 2533.185269355774, 2545.4416830539703, 2557.706483602524, 2569.9386496543884, 2582.4110894203186, 2594.7240314483643, 2606.9904220104218, 2619.2271547317505, 2631.596047401428, 2643.8710713386536, 2656.094513654709, 2668.3030953407288, 2680.679700613022, 2692.916346311569, 2705.1111977100372, 2717.352578639984, 2729.798591375351, 2742.0145659446716, 2754.3701300621033, 2766.761989593506, 2779.218448162079, 2791.4781682491302, 2803.7678847312927, 2816.0333008766174, 2828.4557209014893, 2840.722407579422, 2852.986537218094, 2865.2973866462708, 2877.7240896224976, 2889.990526676178, 2902.2425146102905, 2914.6346769332886, 2927.0371911525726, 2939.3040137290955, 2951.566018819809, 2963.836841583252, 2976.18963265419, 2988.4322698116302, 3000.687304496765, 3012.9796578884125, 3025.344053506851, 3037.6097962856293, 3049.8768167495728, 3062.2368638515472, 3074.6911804676056, 3087.0531318187714, 3099.3661227226257, 3111.707357406616, 3124.05917096138, 3136.270414352417, 3148.5146601200104, 3160.7453162670135, 3172.9494230747223, 3185.277281522751, 3197.7523725032806, 3210.058882713318, 3222.301425218582, 3234.580006837845, 3246.913293838501, 3259.207947254181, 3271.5387921333313, 3283.796267747879, 3296.107062101364, 3308.5360219478607, 3320.9244453907013, 3333.2341067790985, 3345.5246460437775, 3357.894491672516, 3370.148547410965, 3382.4181423187256, 3394.70684838295, 3407.0208451747894, 3419.365294933319, 3431.6561636924744, 3443.971725463867, 3456.3097472190857, 3468.475854873657, 3480.7189435958862, 3492.9862792491913, 3505.3147354125977, 3517.5524356365204, 3529.7700877189636, 3542.095321893692, 3554.5964093208313, 3566.851320505142, 3579.2112905979156, 3591.584527015686, 3603.905794620514, 3616.170379638672, 3628.4971227645874, 3640.8295414447784, 3653.198244333267, 3665.4631102085114, 3677.766725063324, 3690.026290655136, 3702.4012422561646, 3714.7988064289093, 3727.0992119312286, 3739.39239358902, 3751.7138860225677, 3763.9226899147034, 3776.1494698524475, 3788.4684636592865, 3800.822099685669, 3813.1712193489075, 3825.518706560135, 3837.874959230423, 3850.1594989299774, 3862.4827642440796, 3874.8145954608917, 3887.2889745235443, 3899.702576160431, 3911.9742817878723, 3924.2680628299713, 3936.652204275131, 3949.063580751419, 3961.372244119644, 3973.6345613002777, 3985.9757578372955, 3998.3578033447266, 4010.5925722122192, 4022.855700492859, 4035.26327252388, 4047.585475921631, 4059.8478734493256, 4072.11212849617, 4084.5635645389557, 4096.812557220459, 4108.975127458572, 4121.143372058868, 4133.468266248703, 4145.692100286484, 4157.859199285507, 4170.076529741287, 4182.434970855713, 4194.574626922607, 4206.727608203888, 4218.976426124573, 4231.20768904686, 4243.223756551743, 4255.308358430862, 4267.283985137939, 4279.3582808971405, 4291.4210522174835, 4303.4342648983, 4315.229061126709, 4327.147196054459, 4338.895261049271, 4350.682928085327, 4362.532993793488, 4374.354981660843, 4386.0793035030365, 4397.757113933563, 4409.4350781440735, 4421.18169093132, 4432.912496328354, 4444.719563961029, 4456.458339214325, 4468.229637145996, 4479.963780403137, 4491.6722576618195, 4503.343065500259, 4515.033176183701, 4526.737790584564, 4538.453761339188, 4550.084540128708, 4561.774984836578, 4573.461071014404, 4585.222410202026, 4596.940523862839, 4608.71416759491, 4620.433226823807, 4632.156892299652, 4643.846987724304, 4655.564570426941, 4667.006319999695, 4678.006136894226, 4689.037420511246, 4699.941431760788]
