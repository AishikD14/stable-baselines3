No devices were found
Setting seed -  0
Creating multiple envs -  4
---------------------------------
Environment created
Box(-1.0, 1.0, (2,), float32) Box(-inf, inf, (8,), float64)
Loading Initial saved model
Model loaded
Starting evaluation
244
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 352.12963860240956
avg cum rews: 352.12963860240956, std: 0.0
the best agent: 0, best agent cum rewards: 352.12963860240956
254
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 352.29623033605986
avg cum rews: 352.29623033605986, std: 0.0
the best agent: 0, best agent cum rewards: 352.29623033605986
264
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 353.24933265384965
avg cum rews: 353.24933265384965, std: 0.0
the best agent: 0, best agent cum rewards: 353.24933265384965
274
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 348.60151044448025
avg cum rews: 348.60151044448025, std: 0.0
the best agent: 0, best agent cum rewards: 348.60151044448025
284
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 339.27670259076694
avg cum rews: 339.27670259076694, std: 0.0
the best agent: 0, best agent cum rewards: 339.27670259076694
294
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 327.36060164509786
avg cum rews: 327.36060164509786, std: 0.0
the best agent: 0, best agent cum rewards: 327.36060164509786
304
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 328.38938056111954
avg cum rews: 328.38938056111954, std: 0.0
the best agent: 0, best agent cum rewards: 328.38938056111954
314
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 325.31421143855215
avg cum rews: 325.31421143855215, std: 0.0
the best agent: 0, best agent cum rewards: 325.31421143855215
324
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 308.122405774317
avg cum rews: 308.122405774317, std: 0.0
the best agent: 0, best agent cum rewards: 308.122405774317
334
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 314.630562073714
avg cum rews: 314.630562073714, std: 0.0
the best agent: 0, best agent cum rewards: 314.630562073714
344
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 324.3365313875211
avg cum rews: 324.3365313875211, std: 0.0
the best agent: 0, best agent cum rewards: 324.3365313875211
354
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 331.3274557146563
avg cum rews: 331.3274557146563, std: 0.0
the best agent: 0, best agent cum rewards: 331.3274557146563
364
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 324.40193625310945
avg cum rews: 324.40193625310945, std: 0.0
the best agent: 0, best agent cum rewards: 324.40193625310945
374
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 323.3520951105923
avg cum rews: 323.3520951105923, std: 0.0
the best agent: 0, best agent cum rewards: 323.3520951105923
384
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 324.1621561871841
avg cum rews: 324.1621561871841, std: 0.0
the best agent: 0, best agent cum rewards: 324.1621561871841
394
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 324.0283333859948
avg cum rews: 324.0283333859948, std: 0.0
the best agent: 0, best agent cum rewards: 324.0283333859948
404
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 324.5294101619349
avg cum rews: 324.5294101619349, std: 0.0
the best agent: 0, best agent cum rewards: 324.5294101619349
414
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 322.0797871588179
avg cum rews: 322.0797871588179, std: 0.0
the best agent: 0, best agent cum rewards: 322.0797871588179
424
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 329.54001293685116
avg cum rews: 329.54001293685116, std: 0.0
the best agent: 0, best agent cum rewards: 329.54001293685116
434
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 332.1131243331837
avg cum rews: 332.1131243331837, std: 0.0
the best agent: 0, best agent cum rewards: 332.1131243331837
444
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 333.4162713795444
avg cum rews: 333.4162713795444, std: 0.0
the best agent: 0, best agent cum rewards: 333.4162713795444
454
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 326.95250024062693
avg cum rews: 326.95250024062693, std: 0.0
the best agent: 0, best agent cum rewards: 326.95250024062693
464
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 331.70140944930216
avg cum rews: 331.70140944930216, std: 0.0
the best agent: 0, best agent cum rewards: 331.70140944930216
474
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 332.05307207578426
avg cum rews: 332.05307207578426, std: 0.0
the best agent: 0, best agent cum rewards: 332.05307207578426
484
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 329.62349477445076
avg cum rews: 329.62349477445076, std: 0.0
the best agent: 0, best agent cum rewards: 329.62349477445076
494
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 333.763631703629
avg cum rews: 333.763631703629, std: 0.0
the best agent: 0, best agent cum rewards: 333.763631703629
504
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 340.71888108363345
avg cum rews: 340.71888108363345, std: 0.0
the best agent: 0, best agent cum rewards: 340.71888108363345
514
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 335.8153802773913
avg cum rews: 335.8153802773913, std: 0.0
the best agent: 0, best agent cum rewards: 335.8153802773913
524
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 340.95397705348995
avg cum rews: 340.95397705348995, std: 0.0
the best agent: 0, best agent cum rewards: 340.95397705348995
534
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 340.9842834726455
avg cum rews: 340.9842834726455, std: 0.0
the best agent: 0, best agent cum rewards: 340.9842834726455
544
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 346.531914522154
avg cum rews: 346.531914522154, std: 0.0
the best agent: 0, best agent cum rewards: 346.531914522154
554
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 351.84732371117326
avg cum rews: 351.84732371117326, std: 0.0
the best agent: 0, best agent cum rewards: 351.84732371117326
564
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 346.9171433241764
avg cum rews: 346.9171433241764, std: 0.0
the best agent: 0, best agent cum rewards: 346.9171433241764
574
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 350.0762833627202
avg cum rews: 350.0762833627202, std: 0.0
the best agent: 0, best agent cum rewards: 350.0762833627202
584
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 346.6678742892148
avg cum rews: 346.6678742892148, std: 0.0
the best agent: 0, best agent cum rewards: 346.6678742892148
594
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 348.16155462254574
avg cum rews: 348.16155462254574, std: 0.0
the best agent: 0, best agent cum rewards: 348.16155462254574
604
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 348.96567928222356
avg cum rews: 348.96567928222356, std: 0.0
the best agent: 0, best agent cum rewards: 348.96567928222356
614
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 347.02172379529765
avg cum rews: 347.02172379529765, std: 0.0
the best agent: 0, best agent cum rewards: 347.02172379529765
624
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 347.33300631043403
avg cum rews: 347.33300631043403, std: 0.0
the best agent: 0, best agent cum rewards: 347.33300631043403
634
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 352.72194221025865
avg cum rews: 352.72194221025865, std: 0.0
the best agent: 0, best agent cum rewards: 352.72194221025865
644
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 351.3817905770217
avg cum rews: 351.3817905770217, std: 0.0
the best agent: 0, best agent cum rewards: 351.3817905770217
654
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 352.3898030704013
avg cum rews: 352.3898030704013, std: 0.0
the best agent: 0, best agent cum rewards: 352.3898030704013
664
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 350.46241207492926
avg cum rews: 350.46241207492926, std: 0.0
the best agent: 0, best agent cum rewards: 350.46241207492926
674
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 352.6011354076555
avg cum rews: 352.6011354076555, std: 0.0
the best agent: 0, best agent cum rewards: 352.6011354076555
684
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 352.6965241040131
avg cum rews: 352.6965241040131, std: 0.0
the best agent: 0, best agent cum rewards: 352.6965241040131
694
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 352.9522847939416
avg cum rews: 352.9522847939416, std: 0.0
the best agent: 0, best agent cum rewards: 352.9522847939416
704
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 354.7308843504702
avg cum rews: 354.7308843504702, std: 0.0
the best agent: 0, best agent cum rewards: 354.7308843504702
714
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 354.2492311864989
avg cum rews: 354.2492311864989, std: 0.0
the best agent: 0, best agent cum rewards: 354.2492311864989
724
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 354.6368248287932
avg cum rews: 354.6368248287932, std: 0.0
the best agent: 0, best agent cum rewards: 354.6368248287932
Average distance of random agents to nearest neighbors: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Time taken for each iteration: [43.6836941242218, 87.62354063987732, 132.14115524291992, 176.95531511306763, 222.60134506225586, 269.6020622253418, 317.6256105899811, 365.2550210952759, 413.2358593940735, 460.8941876888275, 508.43565034866333, 556.2206499576569, 604.2536089420319, 651.893581867218, 699.9139940738678, 747.6560668945312, 795.4400086402893, 843.5707228183746, 891.4341351985931, 939.4199454784393, 987.6871118545532, 1036.1045551300049, 1083.8737905025482, 1132.0489192008972, 1180.547644853592, 1228.2741191387177, 1276.3497097492218, 1324.6333270072937, 1372.9986736774445, 1421.0643572807312, 1469.3434138298035, 1518.1988351345062, 1566.6956350803375, 1615.2631242275238, 1664.1317117214203, 1712.6257195472717, 1760.648470401764, 1809.2513375282288, 1857.7138602733612, 1905.7376658916473, 1953.672084569931, 2002.1930713653564, 2049.9307458400726, 2097.9682347774506, 2146.245662212372, 2194.297012090683, 2242.6265046596527, 2290.6530311107635, 2338.4736728668213]
