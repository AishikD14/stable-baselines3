No devices were found
Setting seed -  1
Creating multiple envs -  4
---------------------------------
Environment created
Box(-1.0, 1.0, (2,), float32) Box(-inf, inf, (8,), float64)
Loading Initial saved model
Model loaded
Starting evaluation
244
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 350.22617143812766
avg cum rews: 350.22617143812766, std: 0.0
the best agent: 0, best agent cum rewards: 350.22617143812766
254
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 351.00777505594505
avg cum rews: 351.00777505594505, std: 0.0
the best agent: 0, best agent cum rewards: 351.00777505594505
264
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 352.79099841200986
avg cum rews: 352.79099841200986, std: 0.0
the best agent: 0, best agent cum rewards: 352.79099841200986
274
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 352.1717286799687
avg cum rews: 352.1717286799687, std: 0.0
the best agent: 0, best agent cum rewards: 352.1717286799687
284
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 355.33674939641855
avg cum rews: 355.33674939641855, std: 0.0
the best agent: 0, best agent cum rewards: 355.33674939641855
294
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 352.09530198526835
avg cum rews: 352.09530198526835, std: 0.0
the best agent: 0, best agent cum rewards: 352.09530198526835
304
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 351.5122137116662
avg cum rews: 351.5122137116662, std: 0.0
the best agent: 0, best agent cum rewards: 351.5122137116662
314
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 350.9853403413114
avg cum rews: 350.9853403413114, std: 0.0
the best agent: 0, best agent cum rewards: 350.9853403413114
324
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 351.7606081473752
avg cum rews: 351.7606081473752, std: 0.0
the best agent: 0, best agent cum rewards: 351.7606081473752
334
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 353.2273057095114
avg cum rews: 353.2273057095114, std: 0.0
the best agent: 0, best agent cum rewards: 353.2273057095114
344
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 352.6938705487749
avg cum rews: 352.6938705487749, std: 0.0
the best agent: 0, best agent cum rewards: 352.6938705487749
354
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 352.1182064337452
avg cum rews: 352.1182064337452, std: 0.0
the best agent: 0, best agent cum rewards: 352.1182064337452
364
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 346.03438500408174
avg cum rews: 346.03438500408174, std: 0.0
the best agent: 0, best agent cum rewards: 346.03438500408174
374
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 349.71511331891816
avg cum rews: 349.71511331891816, std: 0.0
the best agent: 0, best agent cum rewards: 349.71511331891816
384
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 350.3696293934818
avg cum rews: 350.3696293934818, std: 0.0
the best agent: 0, best agent cum rewards: 350.3696293934818
394
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 354.2224878325347
avg cum rews: 354.2224878325347, std: 0.0
the best agent: 0, best agent cum rewards: 354.2224878325347
404
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 359.74031517344
avg cum rews: 359.74031517344, std: 0.0
the best agent: 0, best agent cum rewards: 359.74031517344
414
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 357.7533322811178
avg cum rews: 357.7533322811178, std: 0.0
the best agent: 0, best agent cum rewards: 357.7533322811178
424
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 359.06183451357236
avg cum rews: 359.06183451357236, std: 0.0
the best agent: 0, best agent cum rewards: 359.06183451357236
434
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 362.0764976347927
avg cum rews: 362.0764976347927, std: 0.0
the best agent: 0, best agent cum rewards: 362.0764976347927
444
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 361.6791711105421
avg cum rews: 361.6791711105421, std: 0.0
the best agent: 0, best agent cum rewards: 361.6791711105421
454
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 357.9687187755537
avg cum rews: 357.9687187755537, std: 0.0
the best agent: 0, best agent cum rewards: 357.9687187755537
464
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 358.6394852714722
avg cum rews: 358.6394852714722, std: 0.0
the best agent: 0, best agent cum rewards: 358.6394852714722
474
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 361.2476092543223
avg cum rews: 361.2476092543223, std: 0.0
the best agent: 0, best agent cum rewards: 361.2476092543223
484
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 359.09279774665237
avg cum rews: 359.09279774665237, std: 0.0
the best agent: 0, best agent cum rewards: 359.09279774665237
494
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 359.44094422872894
avg cum rews: 359.44094422872894, std: 0.0
the best agent: 0, best agent cum rewards: 359.44094422872894
504
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 360.60426491904076
avg cum rews: 360.60426491904076, std: 0.0
the best agent: 0, best agent cum rewards: 360.60426491904076
514
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 360.2636774756499
avg cum rews: 360.2636774756499, std: 0.0
the best agent: 0, best agent cum rewards: 360.2636774756499
524
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 360.29407846052897
avg cum rews: 360.29407846052897, std: 0.0
the best agent: 0, best agent cum rewards: 360.29407846052897
534
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 359.3676500804877
avg cum rews: 359.3676500804877, std: 0.0
the best agent: 0, best agent cum rewards: 359.3676500804877
544
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 363.2561478512211
avg cum rews: 363.2561478512211, std: 0.0
the best agent: 0, best agent cum rewards: 363.2561478512211
554
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 362.9255239022827
avg cum rews: 362.9255239022827, std: 0.0
the best agent: 0, best agent cum rewards: 362.9255239022827
564
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 359.493792198359
avg cum rews: 359.493792198359, std: 0.0
the best agent: 0, best agent cum rewards: 359.493792198359
574
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 363.3918548782994
avg cum rews: 363.3918548782994, std: 0.0
the best agent: 0, best agent cum rewards: 363.3918548782994
584
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 360.1267170831213
avg cum rews: 360.1267170831213, std: 0.0
the best agent: 0, best agent cum rewards: 360.1267170831213
594
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 360.46179196321737
avg cum rews: 360.46179196321737, std: 0.0
the best agent: 0, best agent cum rewards: 360.46179196321737
604
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 360.1718878442379
avg cum rews: 360.1718878442379, std: 0.0
the best agent: 0, best agent cum rewards: 360.1718878442379
614
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 360.2803213881231
avg cum rews: 360.2803213881231, std: 0.0
the best agent: 0, best agent cum rewards: 360.2803213881231
624
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 361.1012511251469
avg cum rews: 361.1012511251469, std: 0.0
the best agent: 0, best agent cum rewards: 361.1012511251469
634
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 363.29935430866635
avg cum rews: 363.29935430866635, std: 0.0
the best agent: 0, best agent cum rewards: 363.29935430866635
644
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 361.6385481320913
avg cum rews: 361.6385481320913, std: 0.0
the best agent: 0, best agent cum rewards: 361.6385481320913
654
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 363.69225897804034
avg cum rews: 363.69225897804034, std: 0.0
the best agent: 0, best agent cum rewards: 363.69225897804034
664
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 363.64880563779315
avg cum rews: 363.64880563779315, std: 0.0
the best agent: 0, best agent cum rewards: 363.64880563779315
674
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 361.3865284559738
avg cum rews: 361.3865284559738, std: 0.0
the best agent: 0, best agent cum rewards: 361.3865284559738
684
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 363.54487459149505
avg cum rews: 363.54487459149505, std: 0.0
the best agent: 0, best agent cum rewards: 363.54487459149505
694
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 360.4925342877489
avg cum rews: 360.4925342877489, std: 0.0
the best agent: 0, best agent cum rewards: 360.4925342877489
704
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 361.05082700466386
avg cum rews: 361.05082700466386, std: 0.0
the best agent: 0, best agent cum rewards: 361.05082700466386
714
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 364.5846858496953
avg cum rews: 364.5846858496953, std: 0.0
the best agent: 0, best agent cum rewards: 364.5846858496953
724
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 361.3611824027253
avg cum rews: 361.3611824027253, std: 0.0
the best agent: 0, best agent cum rewards: 361.3611824027253
Average distance of random agents to nearest neighbors: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Time taken for each iteration: [45.44792985916138, 91.28198599815369, 138.60862135887146, 186.8765983581543, 234.89872813224792, 283.4543788433075, 331.8188006877899, 379.94459414482117, 428.19463181495667, 476.2728536128998, 524.0998728275299, 572.2686517238617, 620.0672233104706, 668.0141201019287, 716.3416922092438, 764.8002727031708, 813.0284597873688, 861.9601919651031, 910.6102645397186, 958.4234795570374, 1006.6483755111694, 1055.2503521442413, 1103.2327222824097, 1151.786182641983, 1200.2529036998749, 1249.221046447754, 1297.617548942566, 1346.6757600307465, 1395.717784166336, 1444.3482594490051, 1492.58402633667, 1541.3652412891388, 1589.7207071781158, 1638.1827747821808, 1686.4407260417938, 1734.9263224601746, 1783.1546866893768, 1831.2864422798157, 1880.2275168895721, 1928.5749025344849, 1976.8498740196228, 2025.1917181015015, 2073.506108045578, 2122.1503505706787, 2170.4644854068756, 2218.5576872825623, 2265.9558765888214, 2313.010747909546, 2359.806350708008]
