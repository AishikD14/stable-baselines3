No devices were found
Setting seed -  2
Creating multiple envs -  4
---------------------------------
Environment created
Box(-1.0, 1.0, (2,), float32) Box(-inf, inf, (8,), float64)
Loading Initial saved model
Model loaded
Starting evaluation
244
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 341.6956795257833
avg cum rews: 341.6956795257833, std: 0.0
the best agent: 0, best agent cum rewards: 341.6956795257833
254
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 340.9494813518905
avg cum rews: 340.9494813518905, std: 0.0
the best agent: 0, best agent cum rewards: 340.9494813518905
264
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 339.4682787763747
avg cum rews: 339.4682787763747, std: 0.0
the best agent: 0, best agent cum rewards: 339.4682787763747
274
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 338.48252911460645
avg cum rews: 338.48252911460645, std: 0.0
the best agent: 0, best agent cum rewards: 338.48252911460645
284
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 332.5915105731703
avg cum rews: 332.5915105731703, std: 0.0
the best agent: 0, best agent cum rewards: 332.5915105731703
294
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 334.26235116098684
avg cum rews: 334.26235116098684, std: 0.0
the best agent: 0, best agent cum rewards: 334.26235116098684
304
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 338.26636136521256
avg cum rews: 338.26636136521256, std: 0.0
the best agent: 0, best agent cum rewards: 338.26636136521256
314
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 339.85957257808093
avg cum rews: 339.85957257808093, std: 0.0
the best agent: 0, best agent cum rewards: 339.85957257808093
324
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 338.14781500241594
avg cum rews: 338.14781500241594, std: 0.0
the best agent: 0, best agent cum rewards: 338.14781500241594
334
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 341.64434290543545
avg cum rews: 341.64434290543545, std: 0.0
the best agent: 0, best agent cum rewards: 341.64434290543545
344
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 336.68715714261015
avg cum rews: 336.68715714261015, std: 0.0
the best agent: 0, best agent cum rewards: 336.68715714261015
354
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 337.2786993901623
avg cum rews: 337.2786993901623, std: 0.0
the best agent: 0, best agent cum rewards: 337.2786993901623
364
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 337.6803153505519
avg cum rews: 337.6803153505519, std: 0.0
the best agent: 0, best agent cum rewards: 337.6803153505519
374
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 336.30698483746943
avg cum rews: 336.30698483746943, std: 0.0
the best agent: 0, best agent cum rewards: 336.30698483746943
384
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 337.7438579044169
avg cum rews: 337.7438579044169, std: 0.0
the best agent: 0, best agent cum rewards: 337.7438579044169
394
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 337.61139915295087
avg cum rews: 337.61139915295087, std: 0.0
the best agent: 0, best agent cum rewards: 337.61139915295087
404
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 341.5467289056994
avg cum rews: 341.5467289056994, std: 0.0
the best agent: 0, best agent cum rewards: 341.5467289056994
414
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 338.1486645450819
avg cum rews: 338.1486645450819, std: 0.0
the best agent: 0, best agent cum rewards: 338.1486645450819
424
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 339.6697553488769
avg cum rews: 339.6697553488769, std: 0.0
the best agent: 0, best agent cum rewards: 339.6697553488769
434
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 341.0413664811988
avg cum rews: 341.0413664811988, std: 0.0
the best agent: 0, best agent cum rewards: 341.0413664811988
444
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 340.2624004695596
avg cum rews: 340.2624004695596, std: 0.0
the best agent: 0, best agent cum rewards: 340.2624004695596
454
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 340.20433143594573
avg cum rews: 340.20433143594573, std: 0.0
the best agent: 0, best agent cum rewards: 340.20433143594573
464
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 338.1904100610855
avg cum rews: 338.1904100610855, std: 0.0
the best agent: 0, best agent cum rewards: 338.1904100610855
474
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 339.3966163795634
avg cum rews: 339.3966163795634, std: 0.0
the best agent: 0, best agent cum rewards: 339.3966163795634
484
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 339.89704182145715
avg cum rews: 339.89704182145715, std: 0.0
the best agent: 0, best agent cum rewards: 339.89704182145715
494
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 343.34420468972957
avg cum rews: 343.34420468972957, std: 0.0
the best agent: 0, best agent cum rewards: 343.34420468972957
504
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 344.4883766844191
avg cum rews: 344.4883766844191, std: 0.0
the best agent: 0, best agent cum rewards: 344.4883766844191
514
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 342.6339371773188
avg cum rews: 342.6339371773188, std: 0.0
the best agent: 0, best agent cum rewards: 342.6339371773188
524
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 340.82095644333043
avg cum rews: 340.82095644333043, std: 0.0
the best agent: 0, best agent cum rewards: 340.82095644333043
534
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 340.41414710554153
avg cum rews: 340.41414710554153, std: 0.0
the best agent: 0, best agent cum rewards: 340.41414710554153
544
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 342.0018247989076
avg cum rews: 342.0018247989076, std: 0.0
the best agent: 0, best agent cum rewards: 342.0018247989076
554
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 342.1432084932419
avg cum rews: 342.1432084932419, std: 0.0
the best agent: 0, best agent cum rewards: 342.1432084932419
564
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 343.415398549925
avg cum rews: 343.415398549925, std: 0.0
the best agent: 0, best agent cum rewards: 343.415398549925
574
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 343.99487144064983
avg cum rews: 343.99487144064983, std: 0.0
the best agent: 0, best agent cum rewards: 343.99487144064983
584
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 347.18180470891804
avg cum rews: 347.18180470891804, std: 0.0
the best agent: 0, best agent cum rewards: 347.18180470891804
594
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 341.39009063697114
avg cum rews: 341.39009063697114, std: 0.0
the best agent: 0, best agent cum rewards: 341.39009063697114
604
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 341.38799874843966
avg cum rews: 341.38799874843966, std: 0.0
the best agent: 0, best agent cum rewards: 341.38799874843966
614
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 346.2507198645332
avg cum rews: 346.2507198645332, std: 0.0
the best agent: 0, best agent cum rewards: 346.2507198645332
624
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 346.13619238965674
avg cum rews: 346.13619238965674, std: 0.0
the best agent: 0, best agent cum rewards: 346.13619238965674
634
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 341.7475338584289
avg cum rews: 341.7475338584289, std: 0.0
the best agent: 0, best agent cum rewards: 341.7475338584289
644
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 346.1472554251771
avg cum rews: 346.1472554251771, std: 0.0
the best agent: 0, best agent cum rewards: 346.1472554251771
654
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 341.5230814789695
avg cum rews: 341.5230814789695, std: 0.0
the best agent: 0, best agent cum rewards: 341.5230814789695
664
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 341.6527067591283
avg cum rews: 341.6527067591283, std: 0.0
the best agent: 0, best agent cum rewards: 341.6527067591283
674
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 344.6501535808429
avg cum rews: 344.6501535808429, std: 0.0
the best agent: 0, best agent cum rewards: 344.6501535808429
684
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 344.14730672289005
avg cum rews: 344.14730672289005, std: 0.0
the best agent: 0, best agent cum rewards: 344.14730672289005
694
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 345.9635681965756
avg cum rews: 345.9635681965756, std: 0.0
the best agent: 0, best agent cum rewards: 345.9635681965756
704
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 346.24523827139114
avg cum rews: 346.24523827139114, std: 0.0
the best agent: 0, best agent cum rewards: 346.24523827139114
714
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 344.26439634462685
avg cum rews: 344.26439634462685, std: 0.0
the best agent: 0, best agent cum rewards: 344.26439634462685
724
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 344.4556631466578
avg cum rews: 344.4556631466578, std: 0.0
the best agent: 0, best agent cum rewards: 344.4556631466578
Average distance of random agents to nearest neighbors: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Time taken for each iteration: [47.36603403091431, 95.38808941841125, 143.46585750579834, 191.69747829437256, 239.84015083312988, 287.9658999443054, 335.9283788204193, 383.86016488075256, 431.769407749176, 479.94631123542786, 527.695152759552, 575.7782783508301, 624.3556849956512, 672.7347731590271, 720.9660341739655, 769.5813438892365, 818.0380301475525, 865.8525123596191, 914.1446449756622, 962.6112904548645, 1010.7997169494629, 1059.1297192573547, 1107.396443605423, 1156.414992570877, 1204.2571399211884, 1252.2168517112732, 1300.6386592388153, 1348.7144994735718, 1396.627581357956, 1445.2263095378876, 1492.859700679779, 1540.147533416748, 1587.926157951355, 1635.8634855747223, 1683.1938781738281, 1730.6511075496674, 1778.193396806717, 1825.7747893333435, 1873.4957642555237, 1920.9495694637299, 1968.5354256629944, 2016.472808599472, 2064.007566690445, 2111.4695575237274, 2158.5568187236786, 2205.352921485901, 2251.8251860141754, 2297.726511478424, 2343.142290353775]
