No devices were found
Setting seed -  2
Creating multiple envs -  4
---------------------------------
Environment created
Box(-1.0, 1.0, (4,), float32) Box([-3.1415927 -5.        -5.        -5.        -3.1415927 -5.
 -3.1415927 -5.        -0.        -3.1415927 -5.        -3.1415927
 -5.        -0.        -1.        -1.        -1.        -1.
 -1.        -1.        -1.        -1.        -1.        -1.       ], [3.1415927 5.        5.        5.        3.1415927 5.        3.1415927
 5.        5.        3.1415927 5.        3.1415927 5.        5.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.       ], (24,), float32)
Starting evaluation
0
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -111.50825517080942
avg cum rews: -111.50825517080942, std: 0.0
the best agent: 0, best agent cum rewards: -111.50825517080942
1
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -112.34069791533254
avg cum rews: -112.34069791533254, std: 0.0
the best agent: 0, best agent cum rewards: -112.34069791533254
2
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -112.76883637784515
avg cum rews: -112.76883637784515, std: 0.0
the best agent: 0, best agent cum rewards: -112.76883637784515
3
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -112.925664775284
avg cum rews: -112.925664775284, std: 0.0
the best agent: 0, best agent cum rewards: -112.925664775284
4
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -33.82513921106785
avg cum rews: -33.82513921106785, std: 0.0
the best agent: 0, best agent cum rewards: -33.82513921106785
5
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -34.746294646312855
avg cum rews: -34.746294646312855, std: 0.0
the best agent: 0, best agent cum rewards: -34.746294646312855
6
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -110.1625217468366
avg cum rews: -110.1625217468366, std: 0.0
the best agent: 0, best agent cum rewards: -110.1625217468366
7
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -108.90260096419851
avg cum rews: -108.90260096419851, std: 0.0
the best agent: 0, best agent cum rewards: -108.90260096419851
8
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -113.18323077332353
avg cum rews: -113.18323077332353, std: 0.0
the best agent: 0, best agent cum rewards: -113.18323077332353
9
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -35.46776506488953
avg cum rews: -35.46776506488953, std: 0.0
the best agent: 0, best agent cum rewards: -35.46776506488953
10
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -43.75463842382429
avg cum rews: -43.75463842382429, std: 0.0
the best agent: 0, best agent cum rewards: -43.75463842382429
11
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -108.4711754511365
avg cum rews: -108.4711754511365, std: 0.0
the best agent: 0, best agent cum rewards: -108.4711754511365
12
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -44.81546373474351
avg cum rews: -44.81546373474351, std: 0.0
the best agent: 0, best agent cum rewards: -44.81546373474351
13
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -47.51349199648323
avg cum rews: -47.51349199648323, std: 0.0
the best agent: 0, best agent cum rewards: -47.51349199648323
14
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -47.102528386123325
avg cum rews: -47.102528386123325, std: 0.0
the best agent: 0, best agent cum rewards: -47.102528386123325
15
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -52.66225454170037
avg cum rews: -52.66225454170037, std: 0.0
the best agent: 0, best agent cum rewards: -52.66225454170037
16
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -33.506168430858914
avg cum rews: -33.506168430858914, std: 0.0
the best agent: 0, best agent cum rewards: -33.506168430858914
17
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -36.41648906793668
avg cum rews: -36.41648906793668, std: 0.0
the best agent: 0, best agent cum rewards: -36.41648906793668
18
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -40.1206843870997
avg cum rews: -40.1206843870997, std: 0.0
the best agent: 0, best agent cum rewards: -40.1206843870997
19
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 106.7800253514085
avg cum rews: 106.7800253514085, std: 0.0
the best agent: 0, best agent cum rewards: 106.7800253514085
20
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -110.75398228214262
avg cum rews: -110.75398228214262, std: 0.0
the best agent: 0, best agent cum rewards: -110.75398228214262
21
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -111.37241165116554
avg cum rews: -111.37241165116554, std: 0.0
the best agent: 0, best agent cum rewards: -111.37241165116554
22
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -110.90489926843345
avg cum rews: -110.90489926843345, std: 0.0
the best agent: 0, best agent cum rewards: -110.90489926843345
23
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -111.54963086173187
avg cum rews: -111.54963086173187, std: 0.0
the best agent: 0, best agent cum rewards: -111.54963086173187
24
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -110.66003441246102
avg cum rews: -110.66003441246102, std: 0.0
the best agent: 0, best agent cum rewards: -110.66003441246102
25
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -110.80425408395877
avg cum rews: -110.80425408395877, std: 0.0
the best agent: 0, best agent cum rewards: -110.80425408395877
26
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 123.24902176802588
avg cum rews: 123.24902176802588, std: 0.0
the best agent: 0, best agent cum rewards: 123.24902176802588
27
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -110.37989503731082
avg cum rews: -110.37989503731082, std: 0.0
the best agent: 0, best agent cum rewards: -110.37989503731082
28
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 188.18782714681794
avg cum rews: 188.18782714681794, std: 0.0
the best agent: 0, best agent cum rewards: 188.18782714681794
29
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 202.8610995094753
avg cum rews: 202.8610995094753, std: 0.0
the best agent: 0, best agent cum rewards: 202.8610995094753
30
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -94.76081677946075
avg cum rews: -94.76081677946075, std: 0.0
the best agent: 0, best agent cum rewards: -94.76081677946075
31
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 219.36011230434346
avg cum rews: 219.36011230434346, std: 0.0
the best agent: 0, best agent cum rewards: 219.36011230434346
32
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -108.79169427225366
avg cum rews: -108.79169427225366, std: 0.0
the best agent: 0, best agent cum rewards: -108.79169427225366
33
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 248.21223517142383
avg cum rews: 248.21223517142383, std: 0.0
the best agent: 0, best agent cum rewards: 248.21223517142383
34
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -115.98808814374358
avg cum rews: -115.98808814374358, std: 0.0
the best agent: 0, best agent cum rewards: -115.98808814374358
35
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 252.85333893335277
avg cum rews: 252.85333893335277, std: 0.0
the best agent: 0, best agent cum rewards: 252.85333893335277
36
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -14.998218229992958
avg cum rews: -14.998218229992958, std: 0.0
the best agent: 0, best agent cum rewards: -14.998218229992958
37
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 276.2643424826136
avg cum rews: 276.2643424826136, std: 0.0
the best agent: 0, best agent cum rewards: 276.2643424826136
38
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -109.63279799246291
avg cum rews: -109.63279799246291, std: 0.0
the best agent: 0, best agent cum rewards: -109.63279799246291
39
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -116.28693117320663
avg cum rews: -116.28693117320663, std: 0.0
the best agent: 0, best agent cum rewards: -116.28693117320663
40
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 249.7513966120265
avg cum rews: 249.7513966120265, std: 0.0
the best agent: 0, best agent cum rewards: 249.7513966120265
41
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 1.0999970977617153
avg cum rews: 1.0999970977617153, std: 0.0
the best agent: 0, best agent cum rewards: 1.0999970977617153
42
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -109.88246006596212
avg cum rews: -109.88246006596212, std: 0.0
the best agent: 0, best agent cum rewards: -109.88246006596212
43
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -109.83217146114882
avg cum rews: -109.83217146114882, std: 0.0
the best agent: 0, best agent cum rewards: -109.83217146114882
44
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -109.72938099845375
avg cum rews: -109.72938099845375, std: 0.0
the best agent: 0, best agent cum rewards: -109.72938099845375
45
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -109.44280877360453
avg cum rews: -109.44280877360453, std: 0.0
the best agent: 0, best agent cum rewards: -109.44280877360453
46
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -127.32312201989814
avg cum rews: -127.32312201989814, std: 0.0
the best agent: 0, best agent cum rewards: -127.32312201989814
47
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -117.83964553355054
avg cum rews: -117.83964553355054, std: 0.0
the best agent: 0, best agent cum rewards: -117.83964553355054
48
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -118.19512324689329
avg cum rews: -118.19512324689329, std: 0.0
the best agent: 0, best agent cum rewards: -118.19512324689329
49
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -117.33412046778574
avg cum rews: -117.33412046778574, std: 0.0
the best agent: 0, best agent cum rewards: -117.33412046778574
50
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -116.49865910471355
avg cum rews: -116.49865910471355, std: 0.0
the best agent: 0, best agent cum rewards: -116.49865910471355
51
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -117.75396570910141
avg cum rews: -117.75396570910141, std: 0.0
the best agent: 0, best agent cum rewards: -117.75396570910141
52
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -113.35638780243944
avg cum rews: -113.35638780243944, std: 0.0
the best agent: 0, best agent cum rewards: -113.35638780243944
53
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 287.9738047720616
avg cum rews: 287.9738047720616, std: 0.0
the best agent: 0, best agent cum rewards: 287.9738047720616
54
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -95.87625140207136
avg cum rews: -95.87625140207136, std: 0.0
the best agent: 0, best agent cum rewards: -95.87625140207136
55
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 290.22795737792455
avg cum rews: 290.22795737792455, std: 0.0
the best agent: 0, best agent cum rewards: 290.22795737792455
56
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -126.52971609936034
avg cum rews: -126.52971609936034, std: 0.0
the best agent: 0, best agent cum rewards: -126.52971609936034
57
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 292.790413900309
avg cum rews: 292.790413900309, std: 0.0
the best agent: 0, best agent cum rewards: 292.790413900309
58
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -123.92469377467906
avg cum rews: -123.92469377467906, std: 0.0
the best agent: 0, best agent cum rewards: -123.92469377467906
59
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -94.63796829053263
avg cum rews: -94.63796829053263, std: 0.0
the best agent: 0, best agent cum rewards: -94.63796829053263
60
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -96.17328835877156
avg cum rews: -96.17328835877156, std: 0.0
the best agent: 0, best agent cum rewards: -96.17328835877156
61
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 296.46107067122574
avg cum rews: 296.46107067122574, std: 0.0
the best agent: 0, best agent cum rewards: 296.46107067122574
62
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -91.24426712500303
avg cum rews: -91.24426712500303, std: 0.0
the best agent: 0, best agent cum rewards: -91.24426712500303
63
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 31.068274801296894
avg cum rews: 31.068274801296894, std: 0.0
the best agent: 0, best agent cum rewards: 31.068274801296894
64
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 296.45360496220843
avg cum rews: 296.45360496220843, std: 0.0
the best agent: 0, best agent cum rewards: 296.45360496220843
65
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 291.54322636964764
avg cum rews: 291.54322636964764, std: 0.0
the best agent: 0, best agent cum rewards: 291.54322636964764
66
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 294.05909640501545
avg cum rews: 294.05909640501545, std: 0.0
the best agent: 0, best agent cum rewards: 294.05909640501545
67
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -29.083507006150157
avg cum rews: -29.083507006150157, std: 0.0
the best agent: 0, best agent cum rewards: -29.083507006150157
68
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -92.01129562585429
avg cum rews: -92.01129562585429, std: 0.0
the best agent: 0, best agent cum rewards: -92.01129562585429
69
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -120.60954176509877
avg cum rews: -120.60954176509877, std: 0.0
the best agent: 0, best agent cum rewards: -120.60954176509877
70
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 283.85222390108737
avg cum rews: 283.85222390108737, std: 0.0
the best agent: 0, best agent cum rewards: 283.85222390108737
71
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -124.06943745607138
avg cum rews: -124.06943745607138, std: 0.0
the best agent: 0, best agent cum rewards: -124.06943745607138
72
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -90.19988155541508
avg cum rews: -90.19988155541508, std: 0.0
the best agent: 0, best agent cum rewards: -90.19988155541508
73
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 295.5560063727052
avg cum rews: 295.5560063727052, std: 0.0
the best agent: 0, best agent cum rewards: 295.5560063727052
74
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 152.3816778302254
avg cum rews: 152.3816778302254, std: 0.0
the best agent: 0, best agent cum rewards: 152.3816778302254
75
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 289.8831243692291
avg cum rews: 289.8831243692291, std: 0.0
the best agent: 0, best agent cum rewards: 289.8831243692291
76
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 144.64046283718815
avg cum rews: 144.64046283718815, std: 0.0
the best agent: 0, best agent cum rewards: 144.64046283718815
77
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 293.2541600141695
avg cum rews: 293.2541600141695, std: 0.0
the best agent: 0, best agent cum rewards: 293.2541600141695
78
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -52.18226039271056
avg cum rews: -52.18226039271056, std: 0.0
the best agent: 0, best agent cum rewards: -52.18226039271056
79
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -75.9003567549903
avg cum rews: -75.9003567549903, std: 0.0
the best agent: 0, best agent cum rewards: -75.9003567549903
80
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 25.795459939678608
avg cum rews: 25.795459939678608, std: 0.0
the best agent: 0, best agent cum rewards: 25.795459939678608
81
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 141.80922635507284
avg cum rews: 141.80922635507284, std: 0.0
the best agent: 0, best agent cum rewards: 141.80922635507284
82
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 292.3452006762395
avg cum rews: 292.3452006762395, std: 0.0
the best agent: 0, best agent cum rewards: 292.3452006762395
83
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 290.41660410431916
avg cum rews: 290.41660410431916, std: 0.0
the best agent: 0, best agent cum rewards: 290.41660410431916
84
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 296.6670757339815
avg cum rews: 296.6670757339815, std: 0.0
the best agent: 0, best agent cum rewards: 296.6670757339815
85
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 289.51963249387774
avg cum rews: 289.51963249387774, std: 0.0
the best agent: 0, best agent cum rewards: 289.51963249387774
86
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 291.4208739700611
avg cum rews: 291.4208739700611, std: 0.0
the best agent: 0, best agent cum rewards: 291.4208739700611
87
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 292.54870004707976
avg cum rews: 292.54870004707976, std: 0.0
the best agent: 0, best agent cum rewards: 292.54870004707976
88
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 294.229578600382
avg cum rews: 294.229578600382, std: 0.0
the best agent: 0, best agent cum rewards: 294.229578600382
89
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 293.4214004063146
avg cum rews: 293.4214004063146, std: 0.0
the best agent: 0, best agent cum rewards: 293.4214004063146
90
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 289.084199993413
avg cum rews: 289.084199993413, std: 0.0
the best agent: 0, best agent cum rewards: 289.084199993413
91
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 297.7028920939121
avg cum rews: 297.7028920939121, std: 0.0
the best agent: 0, best agent cum rewards: 297.7028920939121
92
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 291.21050622767865
avg cum rews: 291.21050622767865, std: 0.0
the best agent: 0, best agent cum rewards: 291.21050622767865
93
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -91.58348916569973
avg cum rews: -91.58348916569973, std: 0.0
the best agent: 0, best agent cum rewards: -91.58348916569973
94
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 292.0576646501767
avg cum rews: 292.0576646501767, std: 0.0
the best agent: 0, best agent cum rewards: 292.0576646501767
95
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 292.5360430624422
avg cum rews: 292.5360430624422, std: 0.0
the best agent: 0, best agent cum rewards: 292.5360430624422
96
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 293.3488648101894
avg cum rews: 293.3488648101894, std: 0.0
the best agent: 0, best agent cum rewards: 293.3488648101894
97
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 288.0793098414533
avg cum rews: 288.0793098414533, std: 0.0
the best agent: 0, best agent cum rewards: 288.0793098414533
98
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 295.18988748689515
avg cum rews: 295.18988748689515, std: 0.0
the best agent: 0, best agent cum rewards: 295.18988748689515
99
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 294.1857253591728
avg cum rews: 294.1857253591728, std: 0.0
the best agent: 0, best agent cum rewards: 294.1857253591728
100
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 295.5415547129179
avg cum rews: 295.5415547129179, std: 0.0
the best agent: 0, best agent cum rewards: 295.5415547129179
101
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 295.6656636486723
avg cum rews: 295.6656636486723, std: 0.0
the best agent: 0, best agent cum rewards: 295.6656636486723
102
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 291.3568304081297
avg cum rews: 291.3568304081297, std: 0.0
the best agent: 0, best agent cum rewards: 291.3568304081297
103
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 297.30811431929936
avg cum rews: 297.30811431929936, std: 0.0
the best agent: 0, best agent cum rewards: 297.30811431929936
104
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 296.6893080046338
avg cum rews: 296.6893080046338, std: 0.0
the best agent: 0, best agent cum rewards: 296.6893080046338
105
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 295.6603666087394
avg cum rews: 295.6603666087394, std: 0.0
the best agent: 0, best agent cum rewards: 295.6603666087394
106
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 299.85924043269614
avg cum rews: 299.85924043269614, std: 0.0
the best agent: 0, best agent cum rewards: 299.85924043269614
107
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 297.0182302586137
avg cum rews: 297.0182302586137, std: 0.0
the best agent: 0, best agent cum rewards: 297.0182302586137
108
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 297.9312993510334
avg cum rews: 297.9312993510334, std: 0.0
the best agent: 0, best agent cum rewards: 297.9312993510334
109
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 294.3753654216937
avg cum rews: 294.3753654216937, std: 0.0
the best agent: 0, best agent cum rewards: 294.3753654216937
110
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 298.8445598143582
avg cum rews: 298.8445598143582, std: 0.0
the best agent: 0, best agent cum rewards: 298.8445598143582
111
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 298.6514358339031
avg cum rews: 298.6514358339031, std: 0.0
the best agent: 0, best agent cum rewards: 298.6514358339031
112
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 297.60402563080714
avg cum rews: 297.60402563080714, std: 0.0
the best agent: 0, best agent cum rewards: 297.60402563080714
113
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 298.64595504604677
avg cum rews: 298.64595504604677, std: 0.0
the best agent: 0, best agent cum rewards: 298.64595504604677
114
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 296.238042176926
avg cum rews: 296.238042176926, std: 0.0
the best agent: 0, best agent cum rewards: 296.238042176926
115
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 295.14681215868785
avg cum rews: 295.14681215868785, std: 0.0
the best agent: 0, best agent cum rewards: 295.14681215868785
116
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 295.75727098341054
avg cum rews: 295.75727098341054, std: 0.0
the best agent: 0, best agent cum rewards: 295.75727098341054
117
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 294.0085347677872
avg cum rews: 294.0085347677872, std: 0.0
the best agent: 0, best agent cum rewards: 294.0085347677872
118
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 294.94848855451403
avg cum rews: 294.94848855451403, std: 0.0
the best agent: 0, best agent cum rewards: 294.94848855451403
119
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 292.4787553056304
avg cum rews: 292.4787553056304, std: 0.0
the best agent: 0, best agent cum rewards: 292.4787553056304
120
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 293.1466318683642
avg cum rews: 293.1466318683642, std: 0.0
the best agent: 0, best agent cum rewards: 293.1466318683642
121
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 289.2466471249659
avg cum rews: 289.2466471249659, std: 0.0
the best agent: 0, best agent cum rewards: 289.2466471249659
Average distance of random agents to nearest neighbors: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Time taken for each iteration: [20.086785793304443, 41.742156982421875, 63.41952419281006, 84.74810695648193, 108.92130708694458, 132.95124435424805, 153.94627904891968, 174.81954526901245, 195.98582291603088, 219.32876873016357, 242.87904047966003, 263.9520637989044, 287.70703387260437, 311.6631464958191, 335.65687704086304, 359.58291721343994, 383.65020966529846, 407.9070568084717, 431.79603338241577, 455.75890016555786, 476.91253185272217, 497.934285402298, 518.7835309505463, 539.4338808059692, 560.2526080608368, 581.2872271537781, 605.4078369140625, 626.267014503479, 649.8684267997742, 673.3746967315674, 694.4657428264618, 718.2790710926056, 739.4850354194641, 762.9307215213776, 783.4531631469727, 806.9254193305969, 829.2497797012329, 852.6452922821045, 873.5900628566742, 894.2101726531982, 917.8834233283997, 939.9581968784332, 960.6668567657471, 981.346334695816, 1002.1120223999023, 1023.2056887149811, 1045.2571506500244, 1066.8742835521698, 1088.516189813614, 1110.3360950946808, 1131.3873195648193, 1152.0256383419037, 1172.517034292221, 1196.139274597168, 1216.8704948425293, 1240.579864025116, 1261.9136838912964, 1285.4803023338318, 1306.7662210464478, 1327.7528595924377, 1349.0183999538422, 1372.5827758312225, 1394.1162905693054, 1416.1699237823486, 1439.5153872966766, 1462.7241315841675, 1486.4774949550629, 1508.2684359550476, 1528.9757857322693, 1549.7475340366364, 1572.9735367298126, 1593.655611038208, 1614.399526834488, 1637.8236067295074, 1661.0410175323486, 1683.9302155971527, 1706.8827016353607, 1730.0554184913635, 1751.3766205310822, 1772.2669067382812, 1793.939121723175, 1816.5926530361176, 1839.4957773685455, 1862.3675706386566, 1885.582441329956, 1908.6200022697449, 1931.5432450771332, 1954.7498269081116, 1977.8173670768738, 2001.1786487102509, 2024.5788700580597, 2047.7903180122375, 2071.083104610443, 2092.2499599456787, 2115.3032970428467, 2139.260437965393, 2163.6014890670776, 2187.5009112358093, 2211.0620930194855, 2234.9337520599365, 2258.4546167850494, 2281.812049627304, 2305.501054763794, 2328.65074634552, 2351.7804346084595, 2374.9272792339325, 2397.6901783943176, 2420.595193386078, 2443.381864309311, 2466.2901322841644, 2489.284333229065, 2511.9725279808044, 2534.754403591156, 2557.5241017341614, 2580.4159994125366, 2603.3261675834656, 2626.356592655182, 2649.4317560195923, 2672.539587020874, 2695.836811542511, 2719.219459295273, 2741.4167494773865]
