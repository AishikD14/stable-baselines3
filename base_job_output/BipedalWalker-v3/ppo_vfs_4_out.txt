No devices were found
Setting seed -  3
Creating multiple envs -  4
---------------------------------
Environment created
Box(-1.0, 1.0, (4,), float32) Box([-3.1415927 -5.        -5.        -5.        -3.1415927 -5.
 -3.1415927 -5.        -0.        -3.1415927 -5.        -3.1415927
 -5.        -0.        -1.        -1.        -1.        -1.
 -1.        -1.        -1.        -1.        -1.        -1.       ], [3.1415927 5.        5.        5.        3.1415927 5.        3.1415927
 5.        5.        3.1415927 5.        3.1415927 5.        5.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.       ], (24,), float32)
Starting evaluation
0
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -92.93640614789942
avg cum rews: -92.93640614789942, std: 0.0
the best agent: 0, best agent cum rewards: -92.93640614789942
1
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -93.35556890201134
avg cum rews: -93.35556890201134, std: 0.0
the best agent: 0, best agent cum rewards: -93.35556890201134
2
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -24.805293822215088
avg cum rews: -24.805293822215088, std: 0.0
the best agent: 0, best agent cum rewards: -24.805293822215088
3
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -103.75046092478497
avg cum rews: -103.75046092478497, std: 0.0
the best agent: 0, best agent cum rewards: -103.75046092478497
4
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -8.056032280951134
avg cum rews: -8.056032280951134, std: 0.0
the best agent: 0, best agent cum rewards: -8.056032280951134
5
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -21.491954462887474
avg cum rews: -21.491954462887474, std: 0.0
the best agent: 0, best agent cum rewards: -21.491954462887474
6
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -25.617081004609005
avg cum rews: -25.617081004609005, std: 0.0
the best agent: 0, best agent cum rewards: -25.617081004609005
7
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -25.93968303723321
avg cum rews: -25.93968303723321, std: 0.0
the best agent: 0, best agent cum rewards: -25.93968303723321
8
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -35.239396147161585
avg cum rews: -35.239396147161585, std: 0.0
the best agent: 0, best agent cum rewards: -35.239396147161585
9
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -34.45893962531822
avg cum rews: -34.45893962531822, std: 0.0
the best agent: 0, best agent cum rewards: -34.45893962531822
10
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -48.42440413669974
avg cum rews: -48.42440413669974, std: 0.0
the best agent: 0, best agent cum rewards: -48.42440413669974
11
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -50.97345640198423
avg cum rews: -50.97345640198423, std: 0.0
the best agent: 0, best agent cum rewards: -50.97345640198423
12
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -39.73765457399307
avg cum rews: -39.73765457399307, std: 0.0
the best agent: 0, best agent cum rewards: -39.73765457399307
13
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -47.166450517221186
avg cum rews: -47.166450517221186, std: 0.0
the best agent: 0, best agent cum rewards: -47.166450517221186
14
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -42.19824124787271
avg cum rews: -42.19824124787271, std: 0.0
the best agent: 0, best agent cum rewards: -42.19824124787271
15
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -40.26314116261767
avg cum rews: -40.26314116261767, std: 0.0
the best agent: 0, best agent cum rewards: -40.26314116261767
16
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -48.231163121803064
avg cum rews: -48.231163121803064, std: 0.0
the best agent: 0, best agent cum rewards: -48.231163121803064
17
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -32.9503281656379
avg cum rews: -32.9503281656379, std: 0.0
the best agent: 0, best agent cum rewards: -32.9503281656379
18
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 108.56835045626525
avg cum rews: 108.56835045626525, std: 0.0
the best agent: 0, best agent cum rewards: 108.56835045626525
19
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 119.08439018099861
avg cum rews: 119.08439018099861, std: 0.0
the best agent: 0, best agent cum rewards: 119.08439018099861
20
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 131.3662880813607
avg cum rews: 131.3662880813607, std: 0.0
the best agent: 0, best agent cum rewards: 131.3662880813607
21
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 109.52641961612865
avg cum rews: 109.52641961612865, std: 0.0
the best agent: 0, best agent cum rewards: 109.52641961612865
22
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 99.6057373941274
avg cum rews: 99.6057373941274, std: 0.0
the best agent: 0, best agent cum rewards: 99.6057373941274
23
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 100.71904360077711
avg cum rews: 100.71904360077711, std: 0.0
the best agent: 0, best agent cum rewards: 100.71904360077711
24
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 102.80121206974303
avg cum rews: 102.80121206974303, std: 0.0
the best agent: 0, best agent cum rewards: 102.80121206974303
25
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 107.82652028313773
avg cum rews: 107.82652028313773, std: 0.0
the best agent: 0, best agent cum rewards: 107.82652028313773
26
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 123.13094171582371
avg cum rews: 123.13094171582371, std: 0.0
the best agent: 0, best agent cum rewards: 123.13094171582371
27
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 114.57217643356233
avg cum rews: 114.57217643356233, std: 0.0
the best agent: 0, best agent cum rewards: 114.57217643356233
28
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 140.49784286172627
avg cum rews: 140.49784286172627, std: 0.0
the best agent: 0, best agent cum rewards: 140.49784286172627
29
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 161.331416765574
avg cum rews: 161.331416765574, std: 0.0
the best agent: 0, best agent cum rewards: 161.331416765574
30
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 20.97032517725782
avg cum rews: 20.97032517725782, std: 0.0
the best agent: 0, best agent cum rewards: 20.97032517725782
31
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -92.54626032303398
avg cum rews: -92.54626032303398, std: 0.0
the best agent: 0, best agent cum rewards: -92.54626032303398
32
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -77.17835955529877
avg cum rews: -77.17835955529877, std: 0.0
the best agent: 0, best agent cum rewards: -77.17835955529877
33
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -91.25314279264397
avg cum rews: -91.25314279264397, std: 0.0
the best agent: 0, best agent cum rewards: -91.25314279264397
34
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -65.45042504045603
avg cum rews: -65.45042504045603, std: 0.0
the best agent: 0, best agent cum rewards: -65.45042504045603
35
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -81.43335593105574
avg cum rews: -81.43335593105574, std: 0.0
the best agent: 0, best agent cum rewards: -81.43335593105574
36
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -83.7169121234361
avg cum rews: -83.7169121234361, std: 0.0
the best agent: 0, best agent cum rewards: -83.7169121234361
37
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -93.90390198921163
avg cum rews: -93.90390198921163, std: 0.0
the best agent: 0, best agent cum rewards: -93.90390198921163
38
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -92.11183239403863
avg cum rews: -92.11183239403863, std: 0.0
the best agent: 0, best agent cum rewards: -92.11183239403863
39
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -104.30342243151739
avg cum rews: -104.30342243151739, std: 0.0
the best agent: 0, best agent cum rewards: -104.30342243151739
40
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -99.25638645044218
avg cum rews: -99.25638645044218, std: 0.0
the best agent: 0, best agent cum rewards: -99.25638645044218
41
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -73.27418457230306
avg cum rews: -73.27418457230306, std: 0.0
the best agent: 0, best agent cum rewards: -73.27418457230306
42
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -86.89301131072143
avg cum rews: -86.89301131072143, std: 0.0
the best agent: 0, best agent cum rewards: -86.89301131072143
43
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -60.07323901080092
avg cum rews: -60.07323901080092, std: 0.0
the best agent: 0, best agent cum rewards: -60.07323901080092
44
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -106.74103017025317
avg cum rews: -106.74103017025317, std: 0.0
the best agent: 0, best agent cum rewards: -106.74103017025317
45
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -46.64215584532047
avg cum rews: -46.64215584532047, std: 0.0
the best agent: 0, best agent cum rewards: -46.64215584532047
46
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 10.302753738913594
avg cum rews: 10.302753738913594, std: 0.0
the best agent: 0, best agent cum rewards: 10.302753738913594
47
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -41.61630930612736
avg cum rews: -41.61630930612736, std: 0.0
the best agent: 0, best agent cum rewards: -41.61630930612736
48
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 58.963221572177986
avg cum rews: 58.963221572177986, std: 0.0
the best agent: 0, best agent cum rewards: 58.963221572177986
49
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -78.01839024346697
avg cum rews: -78.01839024346697, std: 0.0
the best agent: 0, best agent cum rewards: -78.01839024346697
50
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -91.64238965184614
avg cum rews: -91.64238965184614, std: 0.0
the best agent: 0, best agent cum rewards: -91.64238965184614
51
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 114.34414219101441
avg cum rews: 114.34414219101441, std: 0.0
the best agent: 0, best agent cum rewards: 114.34414219101441
52
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -46.74432281937636
avg cum rews: -46.74432281937636, std: 0.0
the best agent: 0, best agent cum rewards: -46.74432281937636
53
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -73.99187564564497
avg cum rews: -73.99187564564497, std: 0.0
the best agent: 0, best agent cum rewards: -73.99187564564497
54
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -44.74276590085154
avg cum rews: -44.74276590085154, std: 0.0
the best agent: 0, best agent cum rewards: -44.74276590085154
55
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -45.4276561590135
avg cum rews: -45.4276561590135, std: 0.0
the best agent: 0, best agent cum rewards: -45.4276561590135
56
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -89.46220056489607
avg cum rews: -89.46220056489607, std: 0.0
the best agent: 0, best agent cum rewards: -89.46220056489607
57
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -76.56414684281623
avg cum rews: -76.56414684281623, std: 0.0
the best agent: 0, best agent cum rewards: -76.56414684281623
58
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 95.80415186594914
avg cum rews: 95.80415186594914, std: 0.0
the best agent: 0, best agent cum rewards: 95.80415186594914
59
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 28.265521374606976
avg cum rews: 28.265521374606976, std: 0.0
the best agent: 0, best agent cum rewards: 28.265521374606976
60
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -87.0652943019867
avg cum rews: -87.0652943019867, std: 0.0
the best agent: 0, best agent cum rewards: -87.0652943019867
61
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 109.21254318540838
avg cum rews: 109.21254318540838, std: 0.0
the best agent: 0, best agent cum rewards: 109.21254318540838
62
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -39.770896598046015
avg cum rews: -39.770896598046015, std: 0.0
the best agent: 0, best agent cum rewards: -39.770896598046015
63
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 43.47658755827703
avg cum rews: 43.47658755827703, std: 0.0
the best agent: 0, best agent cum rewards: 43.47658755827703
64
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -2.459863904565495
avg cum rews: -2.459863904565495, std: 0.0
the best agent: 0, best agent cum rewards: -2.459863904565495
65
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 277.7756437713977
avg cum rews: 277.7756437713977, std: 0.0
the best agent: 0, best agent cum rewards: 277.7756437713977
66
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 12.192560270768894
avg cum rews: 12.192560270768894, std: 0.0
the best agent: 0, best agent cum rewards: 12.192560270768894
67
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -62.418607999559505
avg cum rews: -62.418607999559505, std: 0.0
the best agent: 0, best agent cum rewards: -62.418607999559505
68
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 14.121162054613308
avg cum rews: 14.121162054613308, std: 0.0
the best agent: 0, best agent cum rewards: 14.121162054613308
69
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 43.417924651696666
avg cum rews: 43.417924651696666, std: 0.0
the best agent: 0, best agent cum rewards: 43.417924651696666
70
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -63.6467606768844
avg cum rews: -63.6467606768844, std: 0.0
the best agent: 0, best agent cum rewards: -63.6467606768844
71
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -85.69362177285056
avg cum rews: -85.69362177285056, std: 0.0
the best agent: 0, best agent cum rewards: -85.69362177285056
72
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -82.6794970864753
avg cum rews: -82.6794970864753, std: 0.0
the best agent: 0, best agent cum rewards: -82.6794970864753
73
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -87.77739604885132
avg cum rews: -87.77739604885132, std: 0.0
the best agent: 0, best agent cum rewards: -87.77739604885132
74
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 136.70277593899053
avg cum rews: 136.70277593899053, std: 0.0
the best agent: 0, best agent cum rewards: 136.70277593899053
75
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 287.4171279337509
avg cum rews: 287.4171279337509, std: 0.0
the best agent: 0, best agent cum rewards: 287.4171279337509
76
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 283.4998604919429
avg cum rews: 283.4998604919429, std: 0.0
the best agent: 0, best agent cum rewards: 283.4998604919429
77
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 277.26029754369677
avg cum rews: 277.26029754369677, std: 0.0
the best agent: 0, best agent cum rewards: 277.26029754369677
78
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 136.53630765593942
avg cum rews: 136.53630765593942, std: 0.0
the best agent: 0, best agent cum rewards: 136.53630765593942
79
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 65.81676424802583
avg cum rews: 65.81676424802583, std: 0.0
the best agent: 0, best agent cum rewards: 65.81676424802583
80
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 106.98958404678217
avg cum rews: 106.98958404678217, std: 0.0
the best agent: 0, best agent cum rewards: 106.98958404678217
81
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 284.6371168809446
avg cum rews: 284.6371168809446, std: 0.0
the best agent: 0, best agent cum rewards: 284.6371168809446
82
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 139.42002257454268
avg cum rews: 139.42002257454268, std: 0.0
the best agent: 0, best agent cum rewards: 139.42002257454268
83
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 113.74086498365443
avg cum rews: 113.74086498365443, std: 0.0
the best agent: 0, best agent cum rewards: 113.74086498365443
84
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -61.72020582654827
avg cum rews: -61.72020582654827, std: 0.0
the best agent: 0, best agent cum rewards: -61.72020582654827
85
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -14.632997044708617
avg cum rews: -14.632997044708617, std: 0.0
the best agent: 0, best agent cum rewards: -14.632997044708617
86
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -14.713703967858123
avg cum rews: -14.713703967858123, std: 0.0
the best agent: 0, best agent cum rewards: -14.713703967858123
87
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -56.47585144237926
avg cum rews: -56.47585144237926, std: 0.0
the best agent: 0, best agent cum rewards: -56.47585144237926
88
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 9.79579718389246
avg cum rews: 9.79579718389246, std: 0.0
the best agent: 0, best agent cum rewards: 9.79579718389246
89
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 56.38448065279539
avg cum rews: 56.38448065279539, std: 0.0
the best agent: 0, best agent cum rewards: 56.38448065279539
90
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 127.85490944693734
avg cum rews: 127.85490944693734, std: 0.0
the best agent: 0, best agent cum rewards: 127.85490944693734
91
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -71.52889228814843
avg cum rews: -71.52889228814843, std: 0.0
the best agent: 0, best agent cum rewards: -71.52889228814843
92
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -69.42953868578998
avg cum rews: -69.42953868578998, std: 0.0
the best agent: 0, best agent cum rewards: -69.42953868578998
93
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -4.336345169682048
avg cum rews: -4.336345169682048, std: 0.0
the best agent: 0, best agent cum rewards: -4.336345169682048
94
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -56.35205117196218
avg cum rews: -56.35205117196218, std: 0.0
the best agent: 0, best agent cum rewards: -56.35205117196218
95
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 16.883288680892463
avg cum rews: 16.883288680892463, std: 0.0
the best agent: 0, best agent cum rewards: 16.883288680892463
96
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -72.29046626331285
avg cum rews: -72.29046626331285, std: 0.0
the best agent: 0, best agent cum rewards: -72.29046626331285
97
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 165.55601616708822
avg cum rews: 165.55601616708822, std: 0.0
the best agent: 0, best agent cum rewards: 165.55601616708822
98
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -58.07447776987778
avg cum rews: -58.07447776987778, std: 0.0
the best agent: 0, best agent cum rewards: -58.07447776987778
99
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 111.45539851924806
avg cum rews: 111.45539851924806, std: 0.0
the best agent: 0, best agent cum rewards: 111.45539851924806
100
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 292.4316972370101
avg cum rews: 292.4316972370101, std: 0.0
the best agent: 0, best agent cum rewards: 292.4316972370101
101
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 293.4007010364536
avg cum rews: 293.4007010364536, std: 0.0
the best agent: 0, best agent cum rewards: 293.4007010364536
102
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 135.29867185144133
avg cum rews: 135.29867185144133, std: 0.0
the best agent: 0, best agent cum rewards: 135.29867185144133
103
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -38.81895651067291
avg cum rews: -38.81895651067291, std: 0.0
the best agent: 0, best agent cum rewards: -38.81895651067291
104
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 297.8857537684411
avg cum rews: 297.8857537684411, std: 0.0
the best agent: 0, best agent cum rewards: 297.8857537684411
105
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -16.101360102739903
avg cum rews: -16.101360102739903, std: 0.0
the best agent: 0, best agent cum rewards: -16.101360102739903
106
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 44.6920503721046
avg cum rews: 44.6920503721046, std: 0.0
the best agent: 0, best agent cum rewards: 44.6920503721046
107
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 72.59613991780768
avg cum rews: 72.59613991780768, std: 0.0
the best agent: 0, best agent cum rewards: 72.59613991780768
108
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 291.87122895786763
avg cum rews: 291.87122895786763, std: 0.0
the best agent: 0, best agent cum rewards: 291.87122895786763
109
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -2.1731585035739585
avg cum rews: -2.1731585035739585, std: 0.0
the best agent: 0, best agent cum rewards: -2.1731585035739585
110
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 17.498672260715978
avg cum rews: 17.498672260715978, std: 0.0
the best agent: 0, best agent cum rewards: 17.498672260715978
111
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 296.4796897616864
avg cum rews: 296.4796897616864, std: 0.0
the best agent: 0, best agent cum rewards: 296.4796897616864
112
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 9.189428979932075
avg cum rews: 9.189428979932075, std: 0.0
the best agent: 0, best agent cum rewards: 9.189428979932075
113
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 118.64762440386602
avg cum rews: 118.64762440386602, std: 0.0
the best agent: 0, best agent cum rewards: 118.64762440386602
114
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 299.7673312539987
avg cum rews: 299.7673312539987, std: 0.0
the best agent: 0, best agent cum rewards: 299.7673312539987
115
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 297.3052724496203
avg cum rews: 297.3052724496203, std: 0.0
the best agent: 0, best agent cum rewards: 297.3052724496203
116
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 116.4467637231217
avg cum rews: 116.4467637231217, std: 0.0
the best agent: 0, best agent cum rewards: 116.4467637231217
117
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 294.72282481646147
avg cum rews: 294.72282481646147, std: 0.0
the best agent: 0, best agent cum rewards: 294.72282481646147
118
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 299.32216164245904
avg cum rews: 299.32216164245904, std: 0.0
the best agent: 0, best agent cum rewards: 299.32216164245904
119
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -22.10221261064912
avg cum rews: -22.10221261064912, std: 0.0
the best agent: 0, best agent cum rewards: -22.10221261064912
120
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 300.18062393662615
avg cum rews: 300.18062393662615, std: 0.0
the best agent: 0, best agent cum rewards: 300.18062393662615
121
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 294.22424941768827
avg cum rews: 294.22424941768827, std: 0.0
the best agent: 0, best agent cum rewards: 294.22424941768827
Average distance of random agents to nearest neighbors: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Time taken for each iteration: [20.974323749542236, 42.29084324836731, 66.09767723083496, 87.47416877746582, 111.46657800674438, 135.53106546401978, 159.6107201576233, 183.69151973724365, 207.8116753101349, 232.04114174842834, 255.4455988407135, 279.2492823600769, 302.8494019508362, 326.59396862983704, 350.2602438926697, 373.99832034111023, 397.8033812046051, 421.58232522010803, 445.7041862010956, 469.4031801223755, 493.05917596817017, 516.7513718605042, 540.7128117084503, 564.4431984424591, 588.1420936584473, 611.8305542469025, 635.7274880409241, 659.7106745243073, 683.503956079483, 707.5147521495819, 730.7632179260254, 751.9321970939636, 773.3438181877136, 794.6033134460449, 816.5728821754456, 838.3348867893219, 859.8379018306732, 881.0266635417938, 902.4687724113464, 923.861823797226, 944.941109418869, 966.1562776565552, 987.2110221385956, 1009.1612777709961, 1030.7894954681396, 1053.2440466880798, 1076.031962633133, 1097.8376460075378, 1120.9229009151459, 1142.574828863144, 1164.036911725998, 1187.502594947815, 1208.8074362277985, 1230.4825406074524, 1251.9752774238586, 1273.6277935504913, 1294.5935440063477, 1315.774626493454, 1338.5272364616394, 1360.9052875041962, 1381.9000356197357, 1405.277702331543, 1426.8806064128876, 1450.0723805427551, 1472.4177241325378, 1496.5799040794373, 1518.6958494186401, 1540.0247776508331, 1562.0601379871368, 1584.4038887023926, 1605.7274005413055, 1626.8515079021454, 1648.157517194748, 1669.3569612503052, 1692.873518705368, 1716.8362851142883, 1740.360746383667, 1763.7380511760712, 1787.319874048233, 1810.133870601654, 1832.4739816188812, 1856.1899089813232, 1879.2188200950623, 1902.0496757030487, 1923.3697865009308, 1944.8261926174164, 1966.5247592926025, 1987.9933671951294, 2009.9597194194794, 2032.1571116447449, 2055.203178882599, 2076.6857945919037, 2098.090883731842, 2120.016667842865, 2142.1496562957764, 2164.3865728378296, 2186.207306623459, 2209.304776906967, 2230.4713304042816, 2253.796229839325, 2277.3368577957153, 2300.5384464263916, 2323.119273662567, 2344.5816366672516, 2367.6962127685547, 2389.7080681324005, 2411.8948407173157, 2434.4058277606964, 2458.2974298000336, 2480.0856783390045, 2502.411067724228, 2525.692718744278, 2547.6257450580597, 2570.906653404236, 2593.859710454941, 2616.873635530472, 2639.7296755313873, 2662.833941221237, 2685.4608097076416, 2706.4950246810913, 2728.212049484253, 2749.9928090572357]
