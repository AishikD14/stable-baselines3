No devices were found
Setting seed -  0
Creating multiple envs -  4
---------------------------------
Environment created
Box(-1.0, 1.0, (4,), float32) Box([-3.1415927 -5.        -5.        -5.        -3.1415927 -5.
 -3.1415927 -5.        -0.        -3.1415927 -5.        -3.1415927
 -5.        -0.        -1.        -1.        -1.        -1.
 -1.        -1.        -1.        -1.        -1.        -1.       ], [3.1415927 5.        5.        5.        3.1415927 5.        3.1415927
 5.        5.        3.1415927 5.        3.1415927 5.        5.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.       ], (24,), float32)
Starting evaluation
0
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -92.99665235240974
avg cum rews: -92.99665235240974, std: 0.0
the best agent: 0, best agent cum rewards: -92.99665235240974
1
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -93.00332745006246
avg cum rews: -93.00332745006246, std: 0.0
the best agent: 0, best agent cum rewards: -93.00332745006246
2
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -93.20017597522548
avg cum rews: -93.20017597522548, std: 0.0
the best agent: 0, best agent cum rewards: -93.20017597522548
3
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -96.66125492864226
avg cum rews: -96.66125492864226, std: 0.0
the best agent: 0, best agent cum rewards: -96.66125492864226
4
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -94.60982792866913
avg cum rews: -94.60982792866913, std: 0.0
the best agent: 0, best agent cum rewards: -94.60982792866913
5
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -94.56924114148754
avg cum rews: -94.56924114148754, std: 0.0
the best agent: 0, best agent cum rewards: -94.56924114148754
6
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -41.93865098512182
avg cum rews: -41.93865098512182, std: 0.0
the best agent: 0, best agent cum rewards: -41.93865098512182
7
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -99.54487476884636
avg cum rews: -99.54487476884636, std: 0.0
the best agent: 0, best agent cum rewards: -99.54487476884636
8
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -95.08789975729026
avg cum rews: -95.08789975729026, std: 0.0
the best agent: 0, best agent cum rewards: -95.08789975729026
9
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -96.4284396261995
avg cum rews: -96.4284396261995, std: 0.0
the best agent: 0, best agent cum rewards: -96.4284396261995
10
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -48.30720434220942
avg cum rews: -48.30720434220942, std: 0.0
the best agent: 0, best agent cum rewards: -48.30720434220942
11
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -55.883786992688435
avg cum rews: -55.883786992688435, std: 0.0
the best agent: 0, best agent cum rewards: -55.883786992688435
12
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -104.99044969986132
avg cum rews: -104.99044969986132, std: 0.0
the best agent: 0, best agent cum rewards: -104.99044969986132
13
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -104.27229034140396
avg cum rews: -104.27229034140396, std: 0.0
the best agent: 0, best agent cum rewards: -104.27229034140396
14
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -61.87094443687409
avg cum rews: -61.87094443687409, std: 0.0
the best agent: 0, best agent cum rewards: -61.87094443687409
15
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -104.4168077334861
avg cum rews: -104.4168077334861, std: 0.0
the best agent: 0, best agent cum rewards: -104.4168077334861
16
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -104.68892055297023
avg cum rews: -104.68892055297023, std: 0.0
the best agent: 0, best agent cum rewards: -104.68892055297023
17
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -54.44245878926557
avg cum rews: -54.44245878926557, std: 0.0
the best agent: 0, best agent cum rewards: -54.44245878926557
18
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -97.287314680644
avg cum rews: -97.287314680644, std: 0.0
the best agent: 0, best agent cum rewards: -97.287314680644
19
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -116.40768319507254
avg cum rews: -116.40768319507254, std: 0.0
the best agent: 0, best agent cum rewards: -116.40768319507254
20
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -114.7639079030687
avg cum rews: -114.7639079030687, std: 0.0
the best agent: 0, best agent cum rewards: -114.7639079030687
21
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -110.65529473793444
avg cum rews: -110.65529473793444, std: 0.0
the best agent: 0, best agent cum rewards: -110.65529473793444
22
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -50.43035364364081
avg cum rews: -50.43035364364081, std: 0.0
the best agent: 0, best agent cum rewards: -50.43035364364081
23
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -76.80397662901677
avg cum rews: -76.80397662901677, std: 0.0
the best agent: 0, best agent cum rewards: -76.80397662901677
24
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -111.55935063675915
avg cum rews: -111.55935063675915, std: 0.0
the best agent: 0, best agent cum rewards: -111.55935063675915
25
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -114.08860669571285
avg cum rews: -114.08860669571285, std: 0.0
the best agent: 0, best agent cum rewards: -114.08860669571285
26
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -116.28091139696383
avg cum rews: -116.28091139696383, std: 0.0
the best agent: 0, best agent cum rewards: -116.28091139696383
27
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -67.59550066301873
avg cum rews: -67.59550066301873, std: 0.0
the best agent: 0, best agent cum rewards: -67.59550066301873
28
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -58.70723232200275
avg cum rews: -58.70723232200275, std: 0.0
the best agent: 0, best agent cum rewards: -58.70723232200275
29
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -62.934000183531694
avg cum rews: -62.934000183531694, std: 0.0
the best agent: 0, best agent cum rewards: -62.934000183531694
30
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -53.96329625924569
avg cum rews: -53.96329625924569, std: 0.0
the best agent: 0, best agent cum rewards: -53.96329625924569
31
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -59.393255370242116
avg cum rews: -59.393255370242116, std: 0.0
the best agent: 0, best agent cum rewards: -59.393255370242116
32
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -47.29377882654732
avg cum rews: -47.29377882654732, std: 0.0
the best agent: 0, best agent cum rewards: -47.29377882654732
33
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -117.25330395258001
avg cum rews: -117.25330395258001, std: 0.0
the best agent: 0, best agent cum rewards: -117.25330395258001
34
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -103.43608582893883
avg cum rews: -103.43608582893883, std: 0.0
the best agent: 0, best agent cum rewards: -103.43608582893883
35
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -25.290844627256188
avg cum rews: -25.290844627256188, std: 0.0
the best agent: 0, best agent cum rewards: -25.290844627256188
36
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -24.72569737973188
avg cum rews: -24.72569737973188, std: 0.0
the best agent: 0, best agent cum rewards: -24.72569737973188
37
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -29.223083903556077
avg cum rews: -29.223083903556077, std: 0.0
the best agent: 0, best agent cum rewards: -29.223083903556077
38
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -105.16927266826356
avg cum rews: -105.16927266826356, std: 0.0
the best agent: 0, best agent cum rewards: -105.16927266826356
39
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -104.02606233819449
avg cum rews: -104.02606233819449, std: 0.0
the best agent: 0, best agent cum rewards: -104.02606233819449
40
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -43.51657682868224
avg cum rews: -43.51657682868224, std: 0.0
the best agent: 0, best agent cum rewards: -43.51657682868224
41
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -103.80233290671433
avg cum rews: -103.80233290671433, std: 0.0
the best agent: 0, best agent cum rewards: -103.80233290671433
42
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -103.81510793017969
avg cum rews: -103.81510793017969, std: 0.0
the best agent: 0, best agent cum rewards: -103.81510793017969
43
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -101.10235286658505
avg cum rews: -101.10235286658505, std: 0.0
the best agent: 0, best agent cum rewards: -101.10235286658505
44
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -23.466509118318598
avg cum rews: -23.466509118318598, std: 0.0
the best agent: 0, best agent cum rewards: -23.466509118318598
45
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 83.06066794723142
avg cum rews: 83.06066794723142, std: 0.0
the best agent: 0, best agent cum rewards: 83.06066794723142
46
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -105.7716588527225
avg cum rews: -105.7716588527225, std: 0.0
the best agent: 0, best agent cum rewards: -105.7716588527225
47
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 85.31775304417192
avg cum rews: 85.31775304417192, std: 0.0
the best agent: 0, best agent cum rewards: 85.31775304417192
48
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 91.96589533416044
avg cum rews: 91.96589533416044, std: 0.0
the best agent: 0, best agent cum rewards: 91.96589533416044
49
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -105.33876959253475
avg cum rews: -105.33876959253475, std: 0.0
the best agent: 0, best agent cum rewards: -105.33876959253475
50
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -20.36751861130071
avg cum rews: -20.36751861130071, std: 0.0
the best agent: 0, best agent cum rewards: -20.36751861130071
51
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -107.69065850830698
avg cum rews: -107.69065850830698, std: 0.0
the best agent: 0, best agent cum rewards: -107.69065850830698
52
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -88.58277676034346
avg cum rews: -88.58277676034346, std: 0.0
the best agent: 0, best agent cum rewards: -88.58277676034346
53
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 66.24257407883914
avg cum rews: 66.24257407883914, std: 0.0
the best agent: 0, best agent cum rewards: 66.24257407883914
54
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 199.1971680226701
avg cum rews: 199.1971680226701, std: 0.0
the best agent: 0, best agent cum rewards: 199.1971680226701
55
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -99.01244990729168
avg cum rews: -99.01244990729168, std: 0.0
the best agent: 0, best agent cum rewards: -99.01244990729168
56
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 210.0057830185792
avg cum rews: 210.0057830185792, std: 0.0
the best agent: 0, best agent cum rewards: 210.0057830185792
57
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 213.87881993643452
avg cum rews: 213.87881993643452, std: 0.0
the best agent: 0, best agent cum rewards: 213.87881993643452
58
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -49.915205976897234
avg cum rews: -49.915205976897234, std: 0.0
the best agent: 0, best agent cum rewards: -49.915205976897234
59
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 91.4550798152685
avg cum rews: 91.4550798152685, std: 0.0
the best agent: 0, best agent cum rewards: 91.4550798152685
60
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -92.26761383553222
avg cum rews: -92.26761383553222, std: 0.0
the best agent: 0, best agent cum rewards: -92.26761383553222
61
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 37.838878744810245
avg cum rews: 37.838878744810245, std: 0.0
the best agent: 0, best agent cum rewards: 37.838878744810245
62
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -43.89725303102342
avg cum rews: -43.89725303102342, std: 0.0
the best agent: 0, best agent cum rewards: -43.89725303102342
63
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 211.68880547836054
avg cum rews: 211.68880547836054, std: 0.0
the best agent: 0, best agent cum rewards: 211.68880547836054
64
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 227.3720920310754
avg cum rews: 227.3720920310754, std: 0.0
the best agent: 0, best agent cum rewards: 227.3720920310754
65
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 230.57299324276943
avg cum rews: 230.57299324276943, std: 0.0
the best agent: 0, best agent cum rewards: 230.57299324276943
66
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 251.36842145242346
avg cum rews: 251.36842145242346, std: 0.0
the best agent: 0, best agent cum rewards: 251.36842145242346
67
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 239.9773701000496
avg cum rews: 239.9773701000496, std: 0.0
the best agent: 0, best agent cum rewards: 239.9773701000496
68
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 234.8478282381938
avg cum rews: 234.8478282381938, std: 0.0
the best agent: 0, best agent cum rewards: 234.8478282381938
69
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 248.4048773538886
avg cum rews: 248.4048773538886, std: 0.0
the best agent: 0, best agent cum rewards: 248.4048773538886
70
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 263.0215332311672
avg cum rews: 263.0215332311672, std: 0.0
the best agent: 0, best agent cum rewards: 263.0215332311672
71
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 267.073576033993
avg cum rews: 267.073576033993, std: 0.0
the best agent: 0, best agent cum rewards: 267.073576033993
72
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 269.51722034766385
avg cum rews: 269.51722034766385, std: 0.0
the best agent: 0, best agent cum rewards: 269.51722034766385
73
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 270.77252911855106
avg cum rews: 270.77252911855106, std: 0.0
the best agent: 0, best agent cum rewards: 270.77252911855106
74
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 272.072516635116
avg cum rews: 272.072516635116, std: 0.0
the best agent: 0, best agent cum rewards: 272.072516635116
75
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 270.088183327715
avg cum rews: 270.088183327715, std: 0.0
the best agent: 0, best agent cum rewards: 270.088183327715
76
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 244.6644490051647
avg cum rews: 244.6644490051647, std: 0.0
the best agent: 0, best agent cum rewards: 244.6644490051647
77
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 232.82420519420694
avg cum rews: 232.82420519420694, std: 0.0
the best agent: 0, best agent cum rewards: 232.82420519420694
78
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 262.34305834423924
avg cum rews: 262.34305834423924, std: 0.0
the best agent: 0, best agent cum rewards: 262.34305834423924
79
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 258.00454146273063
avg cum rews: 258.00454146273063, std: 0.0
the best agent: 0, best agent cum rewards: 258.00454146273063
80
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 254.7012514953491
avg cum rews: 254.7012514953491, std: 0.0
the best agent: 0, best agent cum rewards: 254.7012514953491
81
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 274.34690653621664
avg cum rews: 274.34690653621664, std: 0.0
the best agent: 0, best agent cum rewards: 274.34690653621664
82
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 259.8756354282352
avg cum rews: 259.8756354282352, std: 0.0
the best agent: 0, best agent cum rewards: 259.8756354282352
83
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 254.30831098327764
avg cum rews: 254.30831098327764, std: 0.0
the best agent: 0, best agent cum rewards: 254.30831098327764
84
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 256.7942471330808
avg cum rews: 256.7942471330808, std: 0.0
the best agent: 0, best agent cum rewards: 256.7942471330808
85
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 258.94092592025413
avg cum rews: 258.94092592025413, std: 0.0
the best agent: 0, best agent cum rewards: 258.94092592025413
86
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 260.1530257427891
avg cum rews: 260.1530257427891, std: 0.0
the best agent: 0, best agent cum rewards: 260.1530257427891
87
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 268.8432228732045
avg cum rews: 268.8432228732045, std: 0.0
the best agent: 0, best agent cum rewards: 268.8432228732045
88
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 272.17897470114633
avg cum rews: 272.17897470114633, std: 0.0
the best agent: 0, best agent cum rewards: 272.17897470114633
89
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 272.5921309682228
avg cum rews: 272.5921309682228, std: 0.0
the best agent: 0, best agent cum rewards: 272.5921309682228
90
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 273.4715610199765
avg cum rews: 273.4715610199765, std: 0.0
the best agent: 0, best agent cum rewards: 273.4715610199765
91
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -108.2945891737286
avg cum rews: -108.2945891737286, std: 0.0
the best agent: 0, best agent cum rewards: -108.2945891737286
92
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 272.92640081886265
avg cum rews: 272.92640081886265, std: 0.0
the best agent: 0, best agent cum rewards: 272.92640081886265
93
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 256.12490816870707
avg cum rews: 256.12490816870707, std: 0.0
the best agent: 0, best agent cum rewards: 256.12490816870707
94
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 265.1462578362355
avg cum rews: 265.1462578362355, std: 0.0
the best agent: 0, best agent cum rewards: 265.1462578362355
95
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 271.5681030016294
avg cum rews: 271.5681030016294, std: 0.0
the best agent: 0, best agent cum rewards: 271.5681030016294
96
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 265.11307584760374
avg cum rews: 265.11307584760374, std: 0.0
the best agent: 0, best agent cum rewards: 265.11307584760374
97
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 249.58265178108454
avg cum rews: 249.58265178108454, std: 0.0
the best agent: 0, best agent cum rewards: 249.58265178108454
98
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 264.66967921262506
avg cum rews: 264.66967921262506, std: 0.0
the best agent: 0, best agent cum rewards: 264.66967921262506
99
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 276.9110236915717
avg cum rews: 276.9110236915717, std: 0.0
the best agent: 0, best agent cum rewards: 276.9110236915717
100
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 270.8419526167638
avg cum rews: 270.8419526167638, std: 0.0
the best agent: 0, best agent cum rewards: 270.8419526167638
101
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 275.2632258907742
avg cum rews: 275.2632258907742, std: 0.0
the best agent: 0, best agent cum rewards: 275.2632258907742
102
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 278.8182927017802
avg cum rews: 278.8182927017802, std: 0.0
the best agent: 0, best agent cum rewards: 278.8182927017802
103
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 282.87475856452585
avg cum rews: 282.87475856452585, std: 0.0
the best agent: 0, best agent cum rewards: 282.87475856452585
104
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 283.2634146476802
avg cum rews: 283.2634146476802, std: 0.0
the best agent: 0, best agent cum rewards: 283.2634146476802
105
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 287.30786597544034
avg cum rews: 287.30786597544034, std: 0.0
the best agent: 0, best agent cum rewards: 287.30786597544034
106
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 284.27428224865275
avg cum rews: 284.27428224865275, std: 0.0
the best agent: 0, best agent cum rewards: 284.27428224865275
107
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 274.6436523835027
avg cum rews: 274.6436523835027, std: 0.0
the best agent: 0, best agent cum rewards: 274.6436523835027
108
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 285.8099684221734
avg cum rews: 285.8099684221734, std: 0.0
the best agent: 0, best agent cum rewards: 285.8099684221734
109
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 287.2968600724183
avg cum rews: 287.2968600724183, std: 0.0
the best agent: 0, best agent cum rewards: 287.2968600724183
110
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 283.36028432353044
avg cum rews: 283.36028432353044, std: 0.0
the best agent: 0, best agent cum rewards: 283.36028432353044
111
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 291.10516442451876
avg cum rews: 291.10516442451876, std: 0.0
the best agent: 0, best agent cum rewards: 291.10516442451876
112
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 289.32548257576127
avg cum rews: 289.32548257576127, std: 0.0
the best agent: 0, best agent cum rewards: 289.32548257576127
113
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 286.53002653447743
avg cum rews: 286.53002653447743, std: 0.0
the best agent: 0, best agent cum rewards: 286.53002653447743
114
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 288.94559244773797
avg cum rews: 288.94559244773797, std: 0.0
the best agent: 0, best agent cum rewards: 288.94559244773797
115
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 287.31849207358255
avg cum rews: 287.31849207358255, std: 0.0
the best agent: 0, best agent cum rewards: 287.31849207358255
116
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 290.110329788218
avg cum rews: 290.110329788218, std: 0.0
the best agent: 0, best agent cum rewards: 290.110329788218
117
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 287.3781284890803
avg cum rews: 287.3781284890803, std: 0.0
the best agent: 0, best agent cum rewards: 287.3781284890803
118
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 291.1053227669445
avg cum rews: 291.1053227669445, std: 0.0
the best agent: 0, best agent cum rewards: 291.1053227669445
119
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 291.22730920319873
avg cum rews: 291.22730920319873, std: 0.0
the best agent: 0, best agent cum rewards: 291.22730920319873
120
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 123.43661276826236
avg cum rews: 123.43661276826236, std: 0.0
the best agent: 0, best agent cum rewards: 123.43661276826236
121
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 292.1673274223386
avg cum rews: 292.1673274223386, std: 0.0
the best agent: 0, best agent cum rewards: 292.1673274223386
Average distance of random agents to nearest neighbors: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Time taken for each iteration: [19.22507333755493, 39.256373167037964, 59.18442249298096, 79.36347246170044, 99.49749994277954, 120.49747920036316, 143.98311352729797, 165.02219891548157, 186.41119742393494, 207.63016319274902, 231.55720233917236, 255.77755999565125, 277.21810245513916, 298.296902179718, 322.6965446472168, 344.06513929367065, 365.62092876434326, 389.5985505580902, 410.6008560657501, 431.86953115463257, 453.49535489082336, 475.02499318122864, 499.1119182109833, 523.2639105319977, 544.7078115940094, 566.2181522846222, 588.0173888206482, 612.0404014587402, 635.8830194473267, 659.5885963439941, 683.4213101863861, 707.1283488273621, 730.9458951950073, 751.9172480106354, 772.7848632335663, 796.4277510643005, 820.0953516960144, 843.8051347732544, 865.0111148357391, 886.1378943920135, 910.2064378261566, 931.4721364974976, 952.9651455879211, 974.1879370212555, 998.1818072795868, 1022.176518201828, 1043.7463629245758, 1067.7010996341705, 1091.806254863739, 1113.3666203022003, 1136.2440853118896, 1158.244408607483, 1180.2912185192108, 1204.755816936493, 1229.2599892616272, 1250.7399339675903, 1275.2342896461487, 1299.5263314247131, 1322.0594918727875, 1346.2769033908844, 1367.6865029335022, 1392.0223667621613, 1414.1683883666992, 1438.461879491806, 1462.6861746311188, 1486.7554659843445, 1510.754905462265, 1534.896260023117, 1558.8587350845337, 1582.9396946430206, 1607.2162041664124, 1631.4649755954742, 1655.5264537334442, 1679.6358852386475, 1703.4458479881287, 1727.1924397945404, 1750.7974562644958, 1774.4207754135132, 1798.1465241909027, 1822.2728445529938, 1846.4508593082428, 1870.3735847473145, 1894.1066935062408, 1917.8168098926544, 1942.0130500793457, 1966.2546064853668, 1990.1702482700348, 2013.9901258945465, 2037.8038485050201, 2061.7824771404266, 2085.734820127487, 2106.9844188690186, 2130.9915177822113, 2154.938397169113, 2178.7314043045044, 2202.7809007167816, 2227.0327022075653, 2251.686360359192, 2276.082665205002, 2300.4045181274414, 2324.3512279987335, 2348.0861496925354, 2372.0137236118317, 2395.9675056934357, 2419.905901670456, 2443.792534351349, 2467.430074930191, 2491.366498231888, 2515.194750070572, 2539.100060939789, 2563.1073586940765, 2586.828896045685, 2610.9938685894012, 2634.9758133888245, 2659.10967874527, 2683.0676114559174, 2707.088397026062, 2731.253793001175, 2754.9592695236206, 2778.506057739258, 2801.822364091873, 2825.456315279007]
