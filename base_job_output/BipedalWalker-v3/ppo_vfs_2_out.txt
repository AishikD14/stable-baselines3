No devices were found
Setting seed -  1
Creating multiple envs -  4
---------------------------------
Environment created
Box(-1.0, 1.0, (4,), float32) Box([-3.1415927 -5.        -5.        -5.        -3.1415927 -5.
 -3.1415927 -5.        -0.        -3.1415927 -5.        -3.1415927
 -5.        -0.        -1.        -1.        -1.        -1.
 -1.        -1.        -1.        -1.        -1.        -1.       ], [3.1415927 5.        5.        5.        3.1415927 5.        3.1415927
 5.        5.        3.1415927 5.        3.1415927 5.        5.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.       ], (24,), float32)
Starting evaluation
0
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -112.12358117636852
avg cum rews: -112.12358117636852, std: 0.0
the best agent: 0, best agent cum rewards: -112.12358117636852
1
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -92.89408992825139
avg cum rews: -92.89408992825139, std: 0.0
the best agent: 0, best agent cum rewards: -92.89408992825139
2
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -104.74188538802073
avg cum rews: -104.74188538802073, std: 0.0
the best agent: 0, best agent cum rewards: -104.74188538802073
3
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -104.24893692352002
avg cum rews: -104.24893692352002, std: 0.0
the best agent: 0, best agent cum rewards: -104.24893692352002
4
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -34.74657575403617
avg cum rews: -34.74657575403617, std: 0.0
the best agent: 0, best agent cum rewards: -34.74657575403617
5
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -35.901057797238074
avg cum rews: -35.901057797238074, std: 0.0
the best agent: 0, best agent cum rewards: -35.901057797238074
6
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -46.16894848213556
avg cum rews: -46.16894848213556, std: 0.0
the best agent: 0, best agent cum rewards: -46.16894848213556
7
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -47.831863777917995
avg cum rews: -47.831863777917995, std: 0.0
the best agent: 0, best agent cum rewards: -47.831863777917995
8
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -66.93601284880394
avg cum rews: -66.93601284880394, std: 0.0
the best agent: 0, best agent cum rewards: -66.93601284880394
9
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -71.4343209182052
avg cum rews: -71.4343209182052, std: 0.0
the best agent: 0, best agent cum rewards: -71.4343209182052
10
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -42.5453515233036
avg cum rews: -42.5453515233036, std: 0.0
the best agent: 0, best agent cum rewards: -42.5453515233036
11
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -67.53878843329998
avg cum rews: -67.53878843329998, std: 0.0
the best agent: 0, best agent cum rewards: -67.53878843329998
12
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -47.69315937953869
avg cum rews: -47.69315937953869, std: 0.0
the best agent: 0, best agent cum rewards: -47.69315937953869
13
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -55.160265993907714
avg cum rews: -55.160265993907714, std: 0.0
the best agent: 0, best agent cum rewards: -55.160265993907714
14
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -44.34958211989075
avg cum rews: -44.34958211989075, std: 0.0
the best agent: 0, best agent cum rewards: -44.34958211989075
15
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -42.24355866985594
avg cum rews: -42.24355866985594, std: 0.0
the best agent: 0, best agent cum rewards: -42.24355866985594
16
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -46.77129951959147
avg cum rews: -46.77129951959147, std: 0.0
the best agent: 0, best agent cum rewards: -46.77129951959147
17
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -41.541259206924614
avg cum rews: -41.541259206924614, std: 0.0
the best agent: 0, best agent cum rewards: -41.541259206924614
18
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -45.32108330825971
avg cum rews: -45.32108330825971, std: 0.0
the best agent: 0, best agent cum rewards: -45.32108330825971
19
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -19.974932082473664
avg cum rews: -19.974932082473664, std: 0.0
the best agent: 0, best agent cum rewards: -19.974932082473664
20
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 121.52989379689775
avg cum rews: 121.52989379689775, std: 0.0
the best agent: 0, best agent cum rewards: 121.52989379689775
21
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 122.27887234142918
avg cum rews: 122.27887234142918, std: 0.0
the best agent: 0, best agent cum rewards: 122.27887234142918
22
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 123.84421703656783
avg cum rews: 123.84421703656783, std: 0.0
the best agent: 0, best agent cum rewards: 123.84421703656783
23
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 135.95926696769905
avg cum rews: 135.95926696769905, std: 0.0
the best agent: 0, best agent cum rewards: 135.95926696769905
24
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -99.11240032928065
avg cum rews: -99.11240032928065, std: 0.0
the best agent: 0, best agent cum rewards: -99.11240032928065
25
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 141.04953792477724
avg cum rews: 141.04953792477724, std: 0.0
the best agent: 0, best agent cum rewards: 141.04953792477724
26
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 120.93809389922656
avg cum rews: 120.93809389922656, std: 0.0
the best agent: 0, best agent cum rewards: 120.93809389922656
27
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 113.02336422408241
avg cum rews: 113.02336422408241, std: 0.0
the best agent: 0, best agent cum rewards: 113.02336422408241
28
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 108.4431829462782
avg cum rews: 108.4431829462782, std: 0.0
the best agent: 0, best agent cum rewards: 108.4431829462782
29
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 114.45939993436441
avg cum rews: 114.45939993436441, std: 0.0
the best agent: 0, best agent cum rewards: 114.45939993436441
30
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 109.2134773425106
avg cum rews: 109.2134773425106, std: 0.0
the best agent: 0, best agent cum rewards: 109.2134773425106
31
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 122.23653948089229
avg cum rews: 122.23653948089229, std: 0.0
the best agent: 0, best agent cum rewards: 122.23653948089229
32
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 132.12593473386156
avg cum rews: 132.12593473386156, std: 0.0
the best agent: 0, best agent cum rewards: 132.12593473386156
33
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 190.24208176065608
avg cum rews: 190.24208176065608, std: 0.0
the best agent: 0, best agent cum rewards: 190.24208176065608
34
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 211.07942711773808
avg cum rews: 211.07942711773808, std: 0.0
the best agent: 0, best agent cum rewards: 211.07942711773808
35
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -51.79711271465322
avg cum rews: -51.79711271465322, std: 0.0
the best agent: 0, best agent cum rewards: -51.79711271465322
36
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 65.75684368599852
avg cum rews: 65.75684368599852, std: 0.0
the best agent: 0, best agent cum rewards: 65.75684368599852
37
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -54.091465093708244
avg cum rews: -54.091465093708244, std: 0.0
the best agent: 0, best agent cum rewards: -54.091465093708244
38
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -60.21182677381732
avg cum rews: -60.21182677381732, std: 0.0
the best agent: 0, best agent cum rewards: -60.21182677381732
39
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -59.73726782157277
avg cum rews: -59.73726782157277, std: 0.0
the best agent: 0, best agent cum rewards: -59.73726782157277
40
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -17.716942257602327
avg cum rews: -17.716942257602327, std: 0.0
the best agent: 0, best agent cum rewards: -17.716942257602327
41
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 262.5605702543873
avg cum rews: 262.5605702543873, std: 0.0
the best agent: 0, best agent cum rewards: 262.5605702543873
42
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 223.38567440312787
avg cum rews: 223.38567440312787, std: 0.0
the best agent: 0, best agent cum rewards: 223.38567440312787
43
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 224.34411742285897
avg cum rews: 224.34411742285897, std: 0.0
the best agent: 0, best agent cum rewards: 224.34411742285897
44
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 245.91096442755676
avg cum rews: 245.91096442755676, std: 0.0
the best agent: 0, best agent cum rewards: 245.91096442755676
45
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 260.5080597871199
avg cum rews: 260.5080597871199, std: 0.0
the best agent: 0, best agent cum rewards: 260.5080597871199
46
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 272.1663800380525
avg cum rews: 272.1663800380525, std: 0.0
the best agent: 0, best agent cum rewards: 272.1663800380525
47
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 113.72603068270178
avg cum rews: 113.72603068270178, std: 0.0
the best agent: 0, best agent cum rewards: 113.72603068270178
48
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -78.72015324695161
avg cum rews: -78.72015324695161, std: 0.0
the best agent: 0, best agent cum rewards: -78.72015324695161
49
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -24.689396734751753
avg cum rews: -24.689396734751753, std: 0.0
the best agent: 0, best agent cum rewards: -24.689396734751753
50
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -98.92201907105122
avg cum rews: -98.92201907105122, std: 0.0
the best agent: 0, best agent cum rewards: -98.92201907105122
51
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 15.719083331619217
avg cum rews: 15.719083331619217, std: 0.0
the best agent: 0, best agent cum rewards: 15.719083331619217
52
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 254.02805525548
avg cum rews: 254.02805525548, std: 0.0
the best agent: 0, best agent cum rewards: 254.02805525548
53
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 262.8311035247389
avg cum rews: 262.8311035247389, std: 0.0
the best agent: 0, best agent cum rewards: 262.8311035247389
54
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -50.48143136204412
avg cum rews: -50.48143136204412, std: 0.0
the best agent: 0, best agent cum rewards: -50.48143136204412
55
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 15.996836666832323
avg cum rews: 15.996836666832323, std: 0.0
the best agent: 0, best agent cum rewards: 15.996836666832323
56
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 51.95068876319942
avg cum rews: 51.95068876319942, std: 0.0
the best agent: 0, best agent cum rewards: 51.95068876319942
57
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 225.90753646562223
avg cum rews: 225.90753646562223, std: 0.0
the best agent: 0, best agent cum rewards: 225.90753646562223
58
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -83.28154473153936
avg cum rews: -83.28154473153936, std: 0.0
the best agent: 0, best agent cum rewards: -83.28154473153936
59
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 22.37292991080494
avg cum rews: 22.37292991080494, std: 0.0
the best agent: 0, best agent cum rewards: 22.37292991080494
60
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 283.4514560158564
avg cum rews: 283.4514560158564, std: 0.0
the best agent: 0, best agent cum rewards: 283.4514560158564
61
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 262.4190242011994
avg cum rews: 262.4190242011994, std: 0.0
the best agent: 0, best agent cum rewards: 262.4190242011994
62
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 268.329616640699
avg cum rews: 268.329616640699, std: 0.0
the best agent: 0, best agent cum rewards: 268.329616640699
63
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 53.00652544641744
avg cum rews: 53.00652544641744, std: 0.0
the best agent: 0, best agent cum rewards: 53.00652544641744
64
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 152.14210347620795
avg cum rews: 152.14210347620795, std: 0.0
the best agent: 0, best agent cum rewards: 152.14210347620795
65
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 279.3331203978607
avg cum rews: 279.3331203978607, std: 0.0
the best agent: 0, best agent cum rewards: 279.3331203978607
66
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -55.18003569894284
avg cum rews: -55.18003569894284, std: 0.0
the best agent: 0, best agent cum rewards: -55.18003569894284
67
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 289.8317737024123
avg cum rews: 289.8317737024123, std: 0.0
the best agent: 0, best agent cum rewards: 289.8317737024123
68
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -55.51729660508875
avg cum rews: -55.51729660508875, std: 0.0
the best agent: 0, best agent cum rewards: -55.51729660508875
69
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 292.3558204890391
avg cum rews: 292.3558204890391, std: 0.0
the best agent: 0, best agent cum rewards: 292.3558204890391
70
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 287.2325486976845
avg cum rews: 287.2325486976845, std: 0.0
the best agent: 0, best agent cum rewards: 287.2325486976845
71
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: -45.93238736097512
avg cum rews: -45.93238736097512, std: 0.0
the best agent: 0, best agent cum rewards: -45.93238736097512
72
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 288.8239179859741
avg cum rews: 288.8239179859741, std: 0.0
the best agent: 0, best agent cum rewards: 288.8239179859741
73
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 63.86441383769301
avg cum rews: 63.86441383769301, std: 0.0
the best agent: 0, best agent cum rewards: 63.86441383769301
74
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 286.0340803550148
avg cum rews: 286.0340803550148, std: 0.0
the best agent: 0, best agent cum rewards: 286.0340803550148
75
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 284.7645832197214
avg cum rews: 284.7645832197214, std: 0.0
the best agent: 0, best agent cum rewards: 284.7645832197214
76
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 286.4403839542733
avg cum rews: 286.4403839542733, std: 0.0
the best agent: 0, best agent cum rewards: 286.4403839542733
77
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 284.18115706194607
avg cum rews: 284.18115706194607, std: 0.0
the best agent: 0, best agent cum rewards: 284.18115706194607
78
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 287.0724683035063
avg cum rews: 287.0724683035063, std: 0.0
the best agent: 0, best agent cum rewards: 287.0724683035063
79
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 280.734176851401
avg cum rews: 280.734176851401, std: 0.0
the best agent: 0, best agent cum rewards: 280.734176851401
80
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 166.29908779680295
avg cum rews: 166.29908779680295, std: 0.0
the best agent: 0, best agent cum rewards: 166.29908779680295
81
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 277.94771985385097
avg cum rews: 277.94771985385097, std: 0.0
the best agent: 0, best agent cum rewards: 277.94771985385097
82
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 281.7784972363156
avg cum rews: 281.7784972363156, std: 0.0
the best agent: 0, best agent cum rewards: 281.7784972363156
83
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 110.26831398597753
avg cum rews: 110.26831398597753, std: 0.0
the best agent: 0, best agent cum rewards: 110.26831398597753
84
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 277.9093003024302
avg cum rews: 277.9093003024302, std: 0.0
the best agent: 0, best agent cum rewards: 277.9093003024302
85
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 284.26728651497376
avg cum rews: 284.26728651497376, std: 0.0
the best agent: 0, best agent cum rewards: 284.26728651497376
86
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 281.4084843379152
avg cum rews: 281.4084843379152, std: 0.0
the best agent: 0, best agent cum rewards: 281.4084843379152
87
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 285.11220510356145
avg cum rews: 285.11220510356145, std: 0.0
the best agent: 0, best agent cum rewards: 285.11220510356145
88
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 280.7378820087674
avg cum rews: 280.7378820087674, std: 0.0
the best agent: 0, best agent cum rewards: 280.7378820087674
89
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 275.42298610057753
avg cum rews: 275.42298610057753, std: 0.0
the best agent: 0, best agent cum rewards: 275.42298610057753
90
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 272.4544797845149
avg cum rews: 272.4544797845149, std: 0.0
the best agent: 0, best agent cum rewards: 272.4544797845149
91
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 284.4862002250473
avg cum rews: 284.4862002250473, std: 0.0
the best agent: 0, best agent cum rewards: 284.4862002250473
92
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 274.51170388528027
avg cum rews: 274.51170388528027, std: 0.0
the best agent: 0, best agent cum rewards: 274.51170388528027
93
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 277.13020368205713
avg cum rews: 277.13020368205713, std: 0.0
the best agent: 0, best agent cum rewards: 277.13020368205713
94
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 279.19551581823066
avg cum rews: 279.19551581823066, std: 0.0
the best agent: 0, best agent cum rewards: 279.19551581823066
95
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 279.3865282636832
avg cum rews: 279.3865282636832, std: 0.0
the best agent: 0, best agent cum rewards: 279.3865282636832
96
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 283.89575229418494
avg cum rews: 283.89575229418494, std: 0.0
the best agent: 0, best agent cum rewards: 283.89575229418494
97
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 280.6046964054418
avg cum rews: 280.6046964054418, std: 0.0
the best agent: 0, best agent cum rewards: 280.6046964054418
98
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 284.7020687687498
avg cum rews: 284.7020687687498, std: 0.0
the best agent: 0, best agent cum rewards: 284.7020687687498
99
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 43.70480019134175
avg cum rews: 43.70480019134175, std: 0.0
the best agent: 0, best agent cum rewards: 43.70480019134175
100
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 282.37534364502307
avg cum rews: 282.37534364502307, std: 0.0
the best agent: 0, best agent cum rewards: 282.37534364502307
101
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 279.63991125256456
avg cum rews: 279.63991125256456, std: 0.0
the best agent: 0, best agent cum rewards: 279.63991125256456
102
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 280.6894270079198
avg cum rews: 280.6894270079198, std: 0.0
the best agent: 0, best agent cum rewards: 280.6894270079198
103
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 281.3738133174588
avg cum rews: 281.3738133174588, std: 0.0
the best agent: 0, best agent cum rewards: 281.3738133174588
104
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 281.0249016335375
avg cum rews: 281.0249016335375, std: 0.0
the best agent: 0, best agent cum rewards: 281.0249016335375
105
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 277.2640202251378
avg cum rews: 277.2640202251378, std: 0.0
the best agent: 0, best agent cum rewards: 277.2640202251378
106
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 279.0070324884591
avg cum rews: 279.0070324884591, std: 0.0
the best agent: 0, best agent cum rewards: 279.0070324884591
107
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 278.3659268340325
avg cum rews: 278.3659268340325, std: 0.0
the best agent: 0, best agent cum rewards: 278.3659268340325
108
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 276.8855874467533
avg cum rews: 276.8855874467533, std: 0.0
the best agent: 0, best agent cum rewards: 276.8855874467533
109
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 281.046593810272
avg cum rews: 281.046593810272, std: 0.0
the best agent: 0, best agent cum rewards: 281.046593810272
110
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 280.0873805766131
avg cum rews: 280.0873805766131, std: 0.0
the best agent: 0, best agent cum rewards: 280.0873805766131
111
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 283.36964339089945
avg cum rews: 283.36964339089945, std: 0.0
the best agent: 0, best agent cum rewards: 283.36964339089945
112
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 287.17091041698217
avg cum rews: 287.17091041698217, std: 0.0
the best agent: 0, best agent cum rewards: 287.17091041698217
113
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 285.7800810308885
avg cum rews: 285.7800810308885, std: 0.0
the best agent: 0, best agent cum rewards: 285.7800810308885
114
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 283.98977278379755
avg cum rews: 283.98977278379755, std: 0.0
the best agent: 0, best agent cum rewards: 283.98977278379755
115
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 285.355159411642
avg cum rews: 285.355159411642, std: 0.0
the best agent: 0, best agent cum rewards: 285.355159411642
116
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 284.40944911912334
avg cum rews: 284.40944911912334, std: 0.0
the best agent: 0, best agent cum rewards: 284.40944911912334
117
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 280.26328477469644
avg cum rews: 280.26328477469644, std: 0.0
the best agent: 0, best agent cum rewards: 280.26328477469644
118
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 287.09483745061704
avg cum rews: 287.09483745061704, std: 0.0
the best agent: 0, best agent cum rewards: 287.09483745061704
119
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 282.2676533016574
avg cum rews: 282.2676533016574, std: 0.0
the best agent: 0, best agent cum rewards: 282.2676533016574
120
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 281.20394687138537
avg cum rews: 281.20394687138537, std: 0.0
the best agent: 0, best agent cum rewards: 281.20394687138537
121
---------------------------------
Searching policies using Value Function Search
avg return on 3 trajectories of agent0: 287.2470483382038
avg cum rews: 287.2470483382038, std: 0.0
the best agent: 0, best agent cum rewards: 287.2470483382038
Average distance of random agents to nearest neighbors: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Time taken for each iteration: [19.883440494537354, 40.703527212142944, 61.62294793128967, 83.2010748386383, 107.7288031578064, 132.26997303962708, 156.22226309776306, 180.43793368339539, 204.45914483070374, 228.34021401405334, 252.2846417427063, 276.16873812675476, 300.68578577041626, 324.5278871059418, 348.5907063484192, 372.7755913734436, 397.0244927406311, 421.5906662940979, 446.04590106010437, 470.3380331993103, 494.565593957901, 518.8113875389099, 543.2796251773834, 567.0896747112274, 588.6019115447998, 612.7747280597687, 637.0725386142731, 661.2258687019348, 685.2520513534546, 709.5034067630768, 733.6276116371155, 757.6302537918091, 781.7863292694092, 805.9452865123749, 830.3744602203369, 852.1576836109161, 875.6860847473145, 897.5763754844666, 919.8451337814331, 941.5706765651703, 963.6730031967163, 987.658777475357, 1011.6426265239716, 1035.7288031578064, 1060.2586724758148, 1084.9569156169891, 1109.511004447937, 1133.4988355636597, 1155.8150401115417, 1178.1554207801819, 1199.724169254303, 1222.191365480423, 1246.5469393730164, 1270.8448822498322, 1292.8899207115173, 1316.2798671722412, 1339.5688211917877, 1364.1039309501648, 1385.8929657936096, 1408.3722314834595, 1432.556035041809, 1456.4260172843933, 1480.6019115447998, 1503.7881026268005, 1527.9232246875763, 1552.2987034320831, 1574.4079194068909, 1598.1968324184418, 1619.7563524246216, 1643.3517270088196, 1666.9753103256226, 1688.4155654907227, 1711.8767709732056, 1734.2710273265839, 1757.719032049179, 1781.1621768474579, 1804.5716814994812, 1828.0725030899048, 1851.7178246974945, 1875.263944864273, 1898.8987147808075, 1922.8492548465729, 1946.6330392360687, 1969.5890562534332, 1993.024429321289, 2016.652619600296, 2040.6485571861267, 2064.307324409485, 2088.109658241272, 2111.9054205417633, 2135.9471576213837, 2159.612846136093, 2183.784208536148, 2207.9469418525696, 2231.889881849289, 2255.703216314316, 2279.3019967079163, 2302.973731279373, 2326.7921917438507, 2349.8735868930817, 2373.363744735718, 2396.898923397064, 2420.5507242679596, 2444.127865791321, 2467.5059401988983, 2491.2665667533875, 2515.087605714798, 2538.887730360031, 2562.356776237488, 2586.047407388687, 2609.874789953232, 2633.5433115959167, 2657.0974118709564, 2680.676915884018, 2704.080873966217, 2727.978701353073, 2751.6716208457947, 2774.414032459259, 2796.4240956306458, 2818.6157619953156, 2840.522099018097, 2862.269213438034]
