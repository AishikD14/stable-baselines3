No devices were found
Setting seed -  1
Creating multiple envs -  4
---------------------------------
Environment created
Box(-2.0, 2.0, (1,), float32) Box([-1. -1. -8.], [1. 1. 8.], (3,), float32)
Starting evaluation
0
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1587.3607764348058
avg cum rews: -1587.3607764348058, std: 0.0
the best agent: 0, best agent cum rewards: -1587.3607764348058
1
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1569.2198552248615
avg cum rews: -1569.2198552248615, std: 0.0
the best agent: 0, best agent cum rewards: -1569.2198552248615
2
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1496.5802644207683
avg cum rews: -1496.5802644207683, std: 0.0
the best agent: 0, best agent cum rewards: -1496.5802644207683
3
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1372.7943678483828
avg cum rews: -1372.7943678483828, std: 0.0
the best agent: 0, best agent cum rewards: -1372.7943678483828
4
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1496.5802644207683
avg cum rews: -1496.5802644207683, std: 0.0
the best agent: 0, best agent cum rewards: -1496.5802644207683
5
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1373.0503685111382
avg cum rews: -1373.0503685111382, std: 0.0
the best agent: 0, best agent cum rewards: -1373.0503685111382
6
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1370.3816874188008
avg cum rews: -1370.3816874188008, std: 0.0
the best agent: 0, best agent cum rewards: -1370.3816874188008
7
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1555.4522651833688
avg cum rews: -1555.4522651833688, std: 0.0
the best agent: 0, best agent cum rewards: -1555.4522651833688
8
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1247.7909338197724
avg cum rews: -1247.7909338197724, std: 0.0
the best agent: 0, best agent cum rewards: -1247.7909338197724
9
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1554.854966992478
avg cum rews: -1554.854966992478, std: 0.0
the best agent: 0, best agent cum rewards: -1554.854966992478
10
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1534.807227200068
avg cum rews: -1534.807227200068, std: 0.0
the best agent: 0, best agent cum rewards: -1534.807227200068
11
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1543.6618578645475
avg cum rews: -1543.6618578645475, std: 0.0
the best agent: 0, best agent cum rewards: -1543.6618578645475
12
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1548.5263345328735
avg cum rews: -1548.5263345328735, std: 0.0
the best agent: 0, best agent cum rewards: -1548.5263345328735
13
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1540.5429894901238
avg cum rews: -1540.5429894901238, std: 0.0
the best agent: 0, best agent cum rewards: -1540.5429894901238
14
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1548.1301492217933
avg cum rews: -1548.1301492217933, std: 0.0
the best agent: 0, best agent cum rewards: -1548.1301492217933
15
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1013.5382007388118
avg cum rews: -1013.5382007388118, std: 0.0
the best agent: 0, best agent cum rewards: -1013.5382007388118
16
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1232.7454025775571
avg cum rews: -1232.7454025775571, std: 0.0
the best agent: 0, best agent cum rewards: -1232.7454025775571
17
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1186.5902360152008
avg cum rews: -1186.5902360152008, std: 0.0
the best agent: 0, best agent cum rewards: -1186.5902360152008
18
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -766.5268092268446
avg cum rews: -766.5268092268446, std: 0.0
the best agent: 0, best agent cum rewards: -766.5268092268446
19
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -753.4185337635957
avg cum rews: -753.4185337635957, std: 0.0
the best agent: 0, best agent cum rewards: -753.4185337635957
20
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -890.5295889617393
avg cum rews: -890.5295889617393, std: 0.0
the best agent: 0, best agent cum rewards: -890.5295889617393
21
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1100.8556687030157
avg cum rews: -1100.8556687030157, std: 0.0
the best agent: 0, best agent cum rewards: -1100.8556687030157
22
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1263.8994164618666
avg cum rews: -1263.8994164618666, std: 0.0
the best agent: 0, best agent cum rewards: -1263.8994164618666
23
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1168.346726459596
avg cum rews: -1168.346726459596, std: 0.0
the best agent: 0, best agent cum rewards: -1168.346726459596
24
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1277.216640885334
avg cum rews: -1277.216640885334, std: 0.0
the best agent: 0, best agent cum rewards: -1277.216640885334
25
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1245.8785166760993
avg cum rews: -1245.8785166760993, std: 0.0
the best agent: 0, best agent cum rewards: -1245.8785166760993
26
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1274.1739623315395
avg cum rews: -1274.1739623315395, std: 0.0
the best agent: 0, best agent cum rewards: -1274.1739623315395
27
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1122.6040998142325
avg cum rews: -1122.6040998142325, std: 0.0
the best agent: 0, best agent cum rewards: -1122.6040998142325
28
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1085.6071951913095
avg cum rews: -1085.6071951913095, std: 0.0
the best agent: 0, best agent cum rewards: -1085.6071951913095
29
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1094.4903588620887
avg cum rews: -1094.4903588620887, std: 0.0
the best agent: 0, best agent cum rewards: -1094.4903588620887
30
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1005.0506921468962
avg cum rews: -1005.0506921468962, std: 0.0
the best agent: 0, best agent cum rewards: -1005.0506921468962
31
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1074.7136118836097
avg cum rews: -1074.7136118836097, std: 0.0
the best agent: 0, best agent cum rewards: -1074.7136118836097
32
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1204.4036721731502
avg cum rews: -1204.4036721731502, std: 0.0
the best agent: 0, best agent cum rewards: -1204.4036721731502
33
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1228.243659849123
avg cum rews: -1228.243659849123, std: 0.0
the best agent: 0, best agent cum rewards: -1228.243659849123
34
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1165.943517718782
avg cum rews: -1165.943517718782, std: 0.0
the best agent: 0, best agent cum rewards: -1165.943517718782
35
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1256.954697042155
avg cum rews: -1256.954697042155, std: 0.0
the best agent: 0, best agent cum rewards: -1256.954697042155
36
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1493.8279973923468
avg cum rews: -1493.8279973923468, std: 0.0
the best agent: 0, best agent cum rewards: -1493.8279973923468
37
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1364.9373603098522
avg cum rews: -1364.9373603098522, std: 0.0
the best agent: 0, best agent cum rewards: -1364.9373603098522
38
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -912.49075382106
avg cum rews: -912.49075382106, std: 0.0
the best agent: 0, best agent cum rewards: -912.49075382106
39
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1528.7942983579958
avg cum rews: -1528.7942983579958, std: 0.0
the best agent: 0, best agent cum rewards: -1528.7942983579958
40
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1569.1377600773983
avg cum rews: -1569.1377600773983, std: 0.0
the best agent: 0, best agent cum rewards: -1569.1377600773983
41
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1393.3769487589332
avg cum rews: -1393.3769487589332, std: 0.0
the best agent: 0, best agent cum rewards: -1393.3769487589332
42
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1425.3605480379701
avg cum rews: -1425.3605480379701, std: 0.0
the best agent: 0, best agent cum rewards: -1425.3605480379701
43
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1364.7436101418284
avg cum rews: -1364.7436101418284, std: 0.0
the best agent: 0, best agent cum rewards: -1364.7436101418284
44
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1385.053444361009
avg cum rews: -1385.053444361009, std: 0.0
the best agent: 0, best agent cum rewards: -1385.053444361009
45
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1519.0148223868293
avg cum rews: -1519.0148223868293, std: 0.0
the best agent: 0, best agent cum rewards: -1519.0148223868293
46
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1253.35335972521
avg cum rews: -1253.35335972521, std: 0.0
the best agent: 0, best agent cum rewards: -1253.35335972521
47
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1204.4959088641044
avg cum rews: -1204.4959088641044, std: 0.0
the best agent: 0, best agent cum rewards: -1204.4959088641044
Average distance of random agents to nearest neighbors: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Time taken for each iteration: [8.70721173286438, 17.40398097038269, 26.101274013519287, 34.784963607788086, 43.50944113731384, 52.20643997192383, 60.90458655357361, 69.62357187271118, 78.35268354415894, 87.07572889328003, 95.77067399024963, 104.47937512397766, 113.2216477394104, 121.93309044837952, 130.66849994659424, 139.4035861492157, 148.15591597557068, 156.8903579711914, 165.62952399253845, 174.36237812042236, 183.154527425766, 191.89926290512085, 200.632479429245, 209.38467979431152, 218.1199128627777, 226.87952375411987, 235.64031553268433, 244.3870358467102, 253.1548135280609, 261.8957085609436, 270.6262311935425, 279.38695073127747, 288.1479275226593, 296.86950159072876, 305.5954039096832, 314.3243980407715, 323.06999158859253, 331.80497097969055, 340.53931975364685, 349.2684054374695, 357.99055910110474, 366.7137806415558, 375.45024728775024, 384.2683548927307, 393.03832817077637, 401.85462951660156, 410.65493631362915, 419.4563419818878]
