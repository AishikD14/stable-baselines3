No devices were found
Setting seed -  1
Creating multiple envs -  4
---------------------------------
Environment created
Box(-2.0, 2.0, (1,), float32) Box([-1. -1. -8.], [1. 1. 8.], (3,), float32)
Starting evaluation
0
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1608.1561831785646
avg cum rews: -1608.1561831785646, std: 0.0
the best agent: 0, best agent cum rewards: -1608.1561831785646
2
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1536.4221728695836
avg cum rews: -1536.4221728695836, std: 0.0
the best agent: 0, best agent cum rewards: -1536.4221728695836
4
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1542.7220326573731
avg cum rews: -1542.7220326573731, std: 0.0
the best agent: 0, best agent cum rewards: -1542.7220326573731
6
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1414.974673812108
avg cum rews: -1414.974673812108, std: 0.0
the best agent: 0, best agent cum rewards: -1414.974673812108
8
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1649.5642415882362
avg cum rews: -1649.5642415882362, std: 0.0
the best agent: 0, best agent cum rewards: -1649.5642415882362
10
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1423.9499855506722
avg cum rews: -1423.9499855506722, std: 0.0
the best agent: 0, best agent cum rewards: -1423.9499855506722
12
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1258.9091466243158
avg cum rews: -1258.9091466243158, std: 0.0
the best agent: 0, best agent cum rewards: -1258.9091466243158
14
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1496.5802644207683
avg cum rews: -1496.5802644207683, std: 0.0
the best agent: 0, best agent cum rewards: -1496.5802644207683
16
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1496.5802644207683
avg cum rews: -1496.5802644207683, std: 0.0
the best agent: 0, best agent cum rewards: -1496.5802644207683
18
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1496.5802644207683
avg cum rews: -1496.5802644207683, std: 0.0
the best agent: 0, best agent cum rewards: -1496.5802644207683
20
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1347.96379746508
avg cum rews: -1347.96379746508, std: 0.0
the best agent: 0, best agent cum rewards: -1347.96379746508
22
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1244.0034833327043
avg cum rews: -1244.0034833327043, std: 0.0
the best agent: 0, best agent cum rewards: -1244.0034833327043
24
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -916.8855743673121
avg cum rews: -916.8855743673121, std: 0.0
the best agent: 0, best agent cum rewards: -916.8855743673121
26
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -914.9069235532515
avg cum rews: -914.9069235532515, std: 0.0
the best agent: 0, best agent cum rewards: -914.9069235532515
28
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1292.0206754932235
avg cum rews: -1292.0206754932235, std: 0.0
the best agent: 0, best agent cum rewards: -1292.0206754932235
30
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1764.9761107225208
avg cum rews: -1764.9761107225208, std: 0.0
the best agent: 0, best agent cum rewards: -1764.9761107225208
32
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1508.3944338972708
avg cum rews: -1508.3944338972708, std: 0.0
the best agent: 0, best agent cum rewards: -1508.3944338972708
34
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1499.4260407291986
avg cum rews: -1499.4260407291986, std: 0.0
the best agent: 0, best agent cum rewards: -1499.4260407291986
36
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1525.245053842949
avg cum rews: -1525.245053842949, std: 0.0
the best agent: 0, best agent cum rewards: -1525.245053842949
38
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1531.937339817949
avg cum rews: -1531.937339817949, std: 0.0
the best agent: 0, best agent cum rewards: -1531.937339817949
40
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1516.573529602255
avg cum rews: -1516.573529602255, std: 0.0
the best agent: 0, best agent cum rewards: -1516.573529602255
42
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1368.5321443663343
avg cum rews: -1368.5321443663343, std: 0.0
the best agent: 0, best agent cum rewards: -1368.5321443663343
44
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1167.1712878240523
avg cum rews: -1167.1712878240523, std: 0.0
the best agent: 0, best agent cum rewards: -1167.1712878240523
46
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -386.56754175464766
avg cum rews: -386.56754175464766, std: 0.0
the best agent: 0, best agent cum rewards: -386.56754175464766
Average distance of random agents to nearest neighbors: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Time taken for each iteration: [21.615004777908325, 43.96246123313904, 66.0943911075592, 88.99605560302734, 112.47750425338745, 135.89250946044922, 159.3155300617218, 183.30358171463013, 206.98092460632324, 230.77971744537354, 254.72680234909058, 278.63473773002625, 302.6909828186035, 326.54092741012573, 350.65470027923584, 374.2199218273163, 398.23508524894714, 421.85784673690796, 445.47089314460754, 469.16110610961914, 491.72856545448303, 514.1313471794128, 536.4769856929779, 558.7565512657166]
