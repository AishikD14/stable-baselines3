No devices were found
Setting seed -  3
Creating multiple envs -  4
---------------------------------
Environment created
Box(-2.0, 2.0, (1,), float32) Box([-1. -1. -8.], [1. 1. 8.], (3,), float32)
Starting evaluation
0
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -921.0230487156035
avg cum rews: -921.0230487156035, std: 0.0
the best agent: 0, best agent cum rewards: -921.0230487156035
2
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1060.8349899728141
avg cum rews: -1060.8349899728141, std: 0.0
the best agent: 0, best agent cum rewards: -1060.8349899728141
4
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1243.4863582252738
avg cum rews: -1243.4863582252738, std: 0.0
the best agent: 0, best agent cum rewards: -1243.4863582252738
6
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1615.6326538965568
avg cum rews: -1615.6326538965568, std: 0.0
the best agent: 0, best agent cum rewards: -1615.6326538965568
8
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1615.2949519153449
avg cum rews: -1615.2949519153449, std: 0.0
the best agent: 0, best agent cum rewards: -1615.2949519153449
10
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1419.918014235084
avg cum rews: -1419.918014235084, std: 0.0
the best agent: 0, best agent cum rewards: -1419.918014235084
12
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -817.1344385347606
avg cum rews: -817.1344385347606, std: 0.0
the best agent: 0, best agent cum rewards: -817.1344385347606
14
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1519.6802704471272
avg cum rews: -1519.6802704471272, std: 0.0
the best agent: 0, best agent cum rewards: -1519.6802704471272
16
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1390.7961508778228
avg cum rews: -1390.7961508778228, std: 0.0
the best agent: 0, best agent cum rewards: -1390.7961508778228
18
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -271.4317157046317
avg cum rews: -271.4317157046317, std: 0.0
the best agent: 0, best agent cum rewards: -271.4317157046317
20
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1090.1849056213368
avg cum rews: -1090.1849056213368, std: 0.0
the best agent: 0, best agent cum rewards: -1090.1849056213368
22
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1053.266752214066
avg cum rews: -1053.266752214066, std: 0.0
the best agent: 0, best agent cum rewards: -1053.266752214066
24
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -675.1243872322734
avg cum rews: -675.1243872322734, std: 0.0
the best agent: 0, best agent cum rewards: -675.1243872322734
26
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1084.341129557409
avg cum rews: -1084.341129557409, std: 0.0
the best agent: 0, best agent cum rewards: -1084.341129557409
28
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1161.8636124587372
avg cum rews: -1161.8636124587372, std: 0.0
the best agent: 0, best agent cum rewards: -1161.8636124587372
30
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1192.6897569346459
avg cum rews: -1192.6897569346459, std: 0.0
the best agent: 0, best agent cum rewards: -1192.6897569346459
32
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -990.9613053704833
avg cum rews: -990.9613053704833, std: 0.0
the best agent: 0, best agent cum rewards: -990.9613053704833
34
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -671.5097827242146
avg cum rews: -671.5097827242146, std: 0.0
the best agent: 0, best agent cum rewards: -671.5097827242146
36
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1178.892953948077
avg cum rews: -1178.892953948077, std: 0.0
the best agent: 0, best agent cum rewards: -1178.892953948077
38
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -820.1776855297545
avg cum rews: -820.1776855297545, std: 0.0
the best agent: 0, best agent cum rewards: -820.1776855297545
40
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1242.512081157985
avg cum rews: -1242.512081157985, std: 0.0
the best agent: 0, best agent cum rewards: -1242.512081157985
42
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1231.342336819604
avg cum rews: -1231.342336819604, std: 0.0
the best agent: 0, best agent cum rewards: -1231.342336819604
44
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1369.1813148780118
avg cum rews: -1369.1813148780118, std: 0.0
the best agent: 0, best agent cum rewards: -1369.1813148780118
46
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1622.9321356337582
avg cum rews: -1622.9321356337582, std: 0.0
the best agent: 0, best agent cum rewards: -1622.9321356337582
Average distance of random agents to nearest neighbors: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Time taken for each iteration: [22.687055826187134, 45.53524994850159, 68.51711916923523, 91.47458219528198, 114.40808749198914, 137.2940571308136, 160.439781665802, 183.24576044082642, 206.21663570404053, 229.4695611000061, 253.37778234481812, 276.64426851272583, 300.2507381439209, 323.94494462013245, 347.52928614616394, 371.3782138824463, 394.1092791557312, 416.37040758132935, 438.8608069419861, 461.1568486690521, 482.5705997943878, 504.04067397117615, 524.9321777820587, 545.9677906036377]
