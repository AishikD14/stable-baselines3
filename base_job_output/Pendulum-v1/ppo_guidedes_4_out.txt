No devices were found
Setting seed -  3
Creating multiple envs -  4
---------------------------------
Environment created
Box(-2.0, 2.0, (1,), float32) Box([-1. -1. -8.], [1. 1. 8.], (3,), float32)
Starting evaluation
0
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1776.8898669107762
avg cum rews: -1776.8898669107762, std: 0.0
the best agent: 0, best agent cum rewards: -1776.8898669107762
1
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1560.6751096060002
avg cum rews: -1560.6751096060002, std: 0.0
the best agent: 0, best agent cum rewards: -1560.6751096060002
2
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -524.0514941205685
avg cum rews: -524.0514941205685, std: 0.0
the best agent: 0, best agent cum rewards: -524.0514941205685
3
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1671.5460271247807
avg cum rews: -1671.5460271247807, std: 0.0
the best agent: 0, best agent cum rewards: -1671.5460271247807
4
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1403.210837962954
avg cum rews: -1403.210837962954, std: 0.0
the best agent: 0, best agent cum rewards: -1403.210837962954
5
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1641.5084934609206
avg cum rews: -1641.5084934609206, std: 0.0
the best agent: 0, best agent cum rewards: -1641.5084934609206
6
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1205.8179195385524
avg cum rews: -1205.8179195385524, std: 0.0
the best agent: 0, best agent cum rewards: -1205.8179195385524
7
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1030.6981090680188
avg cum rews: -1030.6981090680188, std: 0.0
the best agent: 0, best agent cum rewards: -1030.6981090680188
8
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1322.0102089261316
avg cum rews: -1322.0102089261316, std: 0.0
the best agent: 0, best agent cum rewards: -1322.0102089261316
9
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -943.6838952302752
avg cum rews: -943.6838952302752, std: 0.0
the best agent: 0, best agent cum rewards: -943.6838952302752
10
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1131.2231753804158
avg cum rews: -1131.2231753804158, std: 0.0
the best agent: 0, best agent cum rewards: -1131.2231753804158
11
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1271.9358696436207
avg cum rews: -1271.9358696436207, std: 0.0
the best agent: 0, best agent cum rewards: -1271.9358696436207
12
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1320.290985292113
avg cum rews: -1320.290985292113, std: 0.0
the best agent: 0, best agent cum rewards: -1320.290985292113
13
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1558.7865304843206
avg cum rews: -1558.7865304843206, std: 0.0
the best agent: 0, best agent cum rewards: -1558.7865304843206
14
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1241.5251537505728
avg cum rews: -1241.5251537505728, std: 0.0
the best agent: 0, best agent cum rewards: -1241.5251537505728
15
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1362.0474181845161
avg cum rews: -1362.0474181845161, std: 0.0
the best agent: 0, best agent cum rewards: -1362.0474181845161
16
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1634.5657884654415
avg cum rews: -1634.5657884654415, std: 0.0
the best agent: 0, best agent cum rewards: -1634.5657884654415
17
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1572.1727949385697
avg cum rews: -1572.1727949385697, std: 0.0
the best agent: 0, best agent cum rewards: -1572.1727949385697
18
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1574.7608216077347
avg cum rews: -1574.7608216077347, std: 0.0
the best agent: 0, best agent cum rewards: -1574.7608216077347
19
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1579.5179397608354
avg cum rews: -1579.5179397608354, std: 0.0
the best agent: 0, best agent cum rewards: -1579.5179397608354
20
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1615.2949519153449
avg cum rews: -1615.2949519153449, std: 0.0
the best agent: 0, best agent cum rewards: -1615.2949519153449
21
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1606.1793646948606
avg cum rews: -1606.1793646948606, std: 0.0
the best agent: 0, best agent cum rewards: -1606.1793646948606
22
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1567.1263883182748
avg cum rews: -1567.1263883182748, std: 0.0
the best agent: 0, best agent cum rewards: -1567.1263883182748
23
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1416.9353478798657
avg cum rews: -1416.9353478798657, std: 0.0
the best agent: 0, best agent cum rewards: -1416.9353478798657
24
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1405.8178114310451
avg cum rews: -1405.8178114310451, std: 0.0
the best agent: 0, best agent cum rewards: -1405.8178114310451
25
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1603.1099052424868
avg cum rews: -1603.1099052424868, std: 0.0
the best agent: 0, best agent cum rewards: -1603.1099052424868
26
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1572.7943460824877
avg cum rews: -1572.7943460824877, std: 0.0
the best agent: 0, best agent cum rewards: -1572.7943460824877
27
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1631.507433155832
avg cum rews: -1631.507433155832, std: 0.0
the best agent: 0, best agent cum rewards: -1631.507433155832
28
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1618.5583650422645
avg cum rews: -1618.5583650422645, std: 0.0
the best agent: 0, best agent cum rewards: -1618.5583650422645
29
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1622.9321356337582
avg cum rews: -1622.9321356337582, std: 0.0
the best agent: 0, best agent cum rewards: -1622.9321356337582
30
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1520.5548574441148
avg cum rews: -1520.5548574441148, std: 0.0
the best agent: 0, best agent cum rewards: -1520.5548574441148
31
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1438.967364825541
avg cum rews: -1438.967364825541, std: 0.0
the best agent: 0, best agent cum rewards: -1438.967364825541
32
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1591.0677813896514
avg cum rews: -1591.0677813896514, std: 0.0
the best agent: 0, best agent cum rewards: -1591.0677813896514
33
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1365.4382804427064
avg cum rews: -1365.4382804427064, std: 0.0
the best agent: 0, best agent cum rewards: -1365.4382804427064
34
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1294.1075820962506
avg cum rews: -1294.1075820962506, std: 0.0
the best agent: 0, best agent cum rewards: -1294.1075820962506
35
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1594.228695543555
avg cum rews: -1594.228695543555, std: 0.0
the best agent: 0, best agent cum rewards: -1594.228695543555
36
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1591.503368433838
avg cum rews: -1591.503368433838, std: 0.0
the best agent: 0, best agent cum rewards: -1591.503368433838
37
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1606.1793646948606
avg cum rews: -1606.1793646948606, std: 0.0
the best agent: 0, best agent cum rewards: -1606.1793646948606
38
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1606.1793646948606
avg cum rews: -1606.1793646948606, std: 0.0
the best agent: 0, best agent cum rewards: -1606.1793646948606
39
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1572.0209339102053
avg cum rews: -1572.0209339102053, std: 0.0
the best agent: 0, best agent cum rewards: -1572.0209339102053
40
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1573.0418625096868
avg cum rews: -1573.0418625096868, std: 0.0
the best agent: 0, best agent cum rewards: -1573.0418625096868
41
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1554.5567760497422
avg cum rews: -1554.5567760497422, std: 0.0
the best agent: 0, best agent cum rewards: -1554.5567760497422
42
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1606.1793646948606
avg cum rews: -1606.1793646948606, std: 0.0
the best agent: 0, best agent cum rewards: -1606.1793646948606
43
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1606.1793646948606
avg cum rews: -1606.1793646948606, std: 0.0
the best agent: 0, best agent cum rewards: -1606.1793646948606
44
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1606.1793646948606
avg cum rews: -1606.1793646948606, std: 0.0
the best agent: 0, best agent cum rewards: -1606.1793646948606
45
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1606.1793646948606
avg cum rews: -1606.1793646948606, std: 0.0
the best agent: 0, best agent cum rewards: -1606.1793646948606
46
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1596.9169847719782
avg cum rews: -1596.9169847719782, std: 0.0
the best agent: 0, best agent cum rewards: -1596.9169847719782
47
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1596.9169847719782
avg cum rews: -1596.9169847719782, std: 0.0
the best agent: 0, best agent cum rewards: -1596.9169847719782
Average distance of random agents to nearest neighbors: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Time taken for each iteration: [8.408596992492676, 16.826996564865112, 25.231022596359253, 33.661109924316406, 42.07217216491699, 50.50517702102661, 58.93163299560547, 67.34861326217651, 75.80747151374817, 84.24247097969055, 92.66173148155212, 101.08601546287537, 109.53020238876343, 117.95596122741699, 126.36573958396912, 134.79227900505066, 143.21082997322083, 151.6344985961914, 160.05930352210999, 168.45919513702393, 176.8764786720276, 185.28033351898193, 193.70070815086365, 202.14210033416748, 210.5500042438507, 218.95773100852966, 227.3627462387085, 236.11474752426147, 244.93213295936584, 253.7058117389679, 262.5037331581116, 271.3424742221832, 280.1238672733307, 288.8461163043976, 297.572536945343, 306.3595268726349, 315.14626145362854, 323.9310255050659, 332.71558475494385, 341.49477887153625, 350.26951694488525, 358.99190068244934, 367.752215385437, 376.5295135974884, 385.32613015174866, 394.1180350780487, 402.8715546131134, 411.7023980617523]
