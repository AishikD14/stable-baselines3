No devices were found
Setting seed -  1
Creating multiple envs -  2
---------------------------------
Environment created
Box(-2.0, 2.0, (1,), float32) Box([-1. -1. -8.], [1. 1. 8.], (3,), float32)
Starting evaluation
0
---------------------------------
Searching empty space policies
(10, 4545)
(20, 4545)
(20, 4545)
Average distance of agents to nearest neighbors: 0.051118142811447775
avg return on 3 trajectories of agent0: -1489.0318875805808
avg return on 3 trajectories of agent1: -1468.8863448979432
avg return on 3 trajectories of agent2: -1448.0443410961127
avg return on 3 trajectories of agent3: -1427.4823894945312
avg return on 3 trajectories of agent4: -1504.7617072601247
avg return on 3 trajectories of agent5: -1496.3288194060676
avg return on 3 trajectories of agent6: -1488.9130076733975
avg return on 3 trajectories of agent7: -1483.7528351360595
avg return on 3 trajectories of agent8: -1323.6354367549575
avg return on 3 trajectories of agent9: -1314.8970648892528
avg return on 3 trajectories of agent10: -1305.1511059335273
avg return on 3 trajectories of agent11: -1293.7658736720964
avg return on 3 trajectories of agent12: -1178.0972963292215
avg return on 3 trajectories of agent13: -1200.2612228723965
avg return on 3 trajectories of agent14: -1224.4728379491974
avg return on 3 trajectories of agent15: -1248.0693270411189
avg return on 3 trajectories of agent16: -1210.4491021661388
avg return on 3 trajectories of agent17: -1226.806637426472
avg return on 3 trajectories of agent18: -1244.1445731724261
avg return on 3 trajectories of agent19: -1264.2159680779105
avg cum rews: -1342.0583889414766, std: 115.93190235769718
the best agent: 12, best agent cum rewards: -1178.0972963292215
10
---------------------------------
Searching empty space policies
(10, 4545)
(20, 4545)
(20, 4545)
Average distance of agents to nearest neighbors: 0.05620575401532042
avg return on 3 trajectories of agent0: -1158.605240504632
avg return on 3 trajectories of agent1: -1169.908220471529
avg return on 3 trajectories of agent2: -1181.2449144566156
avg return on 3 trajectories of agent3: -1193.1119066125539
avg return on 3 trajectories of agent4: -1169.3870694564032
avg return on 3 trajectories of agent5: -1167.4852551311717
avg return on 3 trajectories of agent6: -1167.620926189258
avg return on 3 trajectories of agent7: -1168.9495837685863
avg return on 3 trajectories of agent8: -1143.434341875342
avg return on 3 trajectories of agent9: -1146.6625075712304
avg return on 3 trajectories of agent10: -1149.2687798304119
avg return on 3 trajectories of agent11: -1151.9334465040836
avg return on 3 trajectories of agent12: -1082.9613428978187
avg return on 3 trajectories of agent13: -1076.0571090413541
avg return on 3 trajectories of agent14: -1068.448511561188
avg return on 3 trajectories of agent15: -1060.739923157405
avg return on 3 trajectories of agent16: -1034.364784215026
avg return on 3 trajectories of agent17: -1042.5709748537167
avg return on 3 trajectories of agent18: -1052.0559713818755
avg return on 3 trajectories of agent19: -1062.4970610609712
avg cum rews: -1122.3653935270588, std: 53.001683919590285
the best agent: 16, best agent cum rewards: -1034.364784215026
20
---------------------------------
Searching empty space policies
(10, 4545)
(20, 4545)
(20, 4545)
Average distance of agents to nearest neighbors: 0.06171318387736363
avg return on 3 trajectories of agent0: -423.61477490133603
avg return on 3 trajectories of agent1: -425.311841886518
avg return on 3 trajectories of agent2: -692.5729078571131
avg return on 3 trajectories of agent3: -693.4403460750665
avg return on 3 trajectories of agent4: -424.43975923909096
avg return on 3 trajectories of agent5: -424.6101575570181
avg return on 3 trajectories of agent6: -424.8180190466595
avg return on 3 trajectories of agent7: -425.0633653097576
avg return on 3 trajectories of agent8: -420.7999813324422
avg return on 3 trajectories of agent9: -420.32486760504327
avg return on 3 trajectories of agent10: -420.5101510082262
avg return on 3 trajectories of agent11: -420.2548191425648
avg return on 3 trajectories of agent12: -280.9028805617183
avg return on 3 trajectories of agent13: -280.910193644108
avg return on 3 trajectories of agent14: -280.8400030644785
avg return on 3 trajectories of agent15: -280.4833913528696
avg return on 3 trajectories of agent16: -281.6321036927423
avg return on 3 trajectories of agent17: -281.53684458490164
avg return on 3 trajectories of agent18: -281.4784678470971
avg return on 3 trajectories of agent19: -281.44396967354504
avg cum rews: -393.2494422691148, std: 120.23186253628218
the best agent: 15, best agent cum rewards: -280.4833913528696
30
---------------------------------
Searching empty space policies
(10, 4545)
(20, 4545)
(20, 4545)
Average distance of agents to nearest neighbors: 0.04034650671255888
avg return on 3 trajectories of agent0: -275.304489252276
avg return on 3 trajectories of agent1: -274.9792763080714
avg return on 3 trajectories of agent2: -274.86778943694105
avg return on 3 trajectories of agent3: -274.9255871911462
avg return on 3 trajectories of agent4: -275.53360668417923
avg return on 3 trajectories of agent5: -275.7659301727542
avg return on 3 trajectories of agent6: -275.7299934782507
avg return on 3 trajectories of agent7: -275.624493246774
avg return on 3 trajectories of agent8: -274.38365541185794
avg return on 3 trajectories of agent9: -274.388429505771
avg return on 3 trajectories of agent10: -274.5212459639139
avg return on 3 trajectories of agent11: -274.74862385209195
avg return on 3 trajectories of agent12: -273.0180031094963
avg return on 3 trajectories of agent13: -272.9998146982098
avg return on 3 trajectories of agent14: -272.99321853572326
avg return on 3 trajectories of agent15: -273.02398218147255
avg return on 3 trajectories of agent16: -273.01404693673123
avg return on 3 trajectories of agent17: -273.14418059797686
avg return on 3 trajectories of agent18: -273.2900975286038
avg return on 3 trajectories of agent19: -273.4479164065375
avg cum rews: -274.285219024939, std: 1.0324766705911934
the best agent: 14, best agent cum rewards: -272.99321853572326
40
---------------------------------
Searching empty space policies
(10, 4545)
(20, 4545)
(20, 4545)
Average distance of agents to nearest neighbors: 0.04770290454238021
avg return on 3 trajectories of agent0: -142.57283417883056
avg return on 3 trajectories of agent1: -142.70742579213785
avg return on 3 trajectories of agent2: -142.85060942668534
avg return on 3 trajectories of agent3: -143.0256590369003
avg return on 3 trajectories of agent4: -143.15175345074286
avg return on 3 trajectories of agent5: -143.43197614881683
avg return on 3 trajectories of agent6: -143.84233584275864
avg return on 3 trajectories of agent7: -144.50010372790362
avg return on 3 trajectories of agent8: -141.9842728315769
avg return on 3 trajectories of agent9: -141.83835168199155
avg return on 3 trajectories of agent10: -141.70932054569505
avg return on 3 trajectories of agent11: -141.56892329234077
avg return on 3 trajectories of agent12: -141.14576842804163
avg return on 3 trajectories of agent13: -140.76313758759912
avg return on 3 trajectories of agent14: -140.4022179566325
avg return on 3 trajectories of agent15: -140.0612468749979
avg return on 3 trajectories of agent16: -141.36324171268618
avg return on 3 trajectories of agent17: -141.17817187154523
avg return on 3 trajectories of agent18: -141.01325504762164
avg return on 3 trajectories of agent19: -140.82835068037275
avg cum rews: -141.9969478057938, std: 1.1815441031587703
the best agent: 15, best agent cum rewards: -140.0612468749979
50
---------------------------------
Searching empty space policies
(10, 4545)
(20, 4545)
(20, 4545)
Average distance of agents to nearest neighbors: 0.04293017464894697
avg return on 3 trajectories of agent0: -274.81745198416303
avg return on 3 trajectories of agent1: -274.855826328759
avg return on 3 trajectories of agent2: -274.6356759573914
avg return on 3 trajectories of agent3: -274.9424953446575
avg return on 3 trajectories of agent4: -274.5194290552658
avg return on 3 trajectories of agent5: -274.16181460638654
avg return on 3 trajectories of agent6: -274.4203681715774
avg return on 3 trajectories of agent7: -274.10837794001543
avg return on 3 trajectories of agent8: -274.0232393977878
avg return on 3 trajectories of agent9: -274.0862396351178
avg return on 3 trajectories of agent10: -274.3640911773052
avg return on 3 trajectories of agent11: -275.3104889980584
avg return on 3 trajectories of agent12: -274.454988111555
avg return on 3 trajectories of agent13: -274.6616754130145
avg return on 3 trajectories of agent14: -275.4701758520757
avg return on 3 trajectories of agent15: -276.60777849744886
avg return on 3 trajectories of agent16: -273.91177623223285
avg return on 3 trajectories of agent17: -273.8900663431092
avg return on 3 trajectories of agent18: -273.98598206043806
avg return on 3 trajectories of agent19: -274.2253909727263
avg cum rews: -274.5726666039543, std: 0.6385176031925439
the best agent: 17, best agent cum rewards: -273.8900663431092
60
---------------------------------
Searching empty space policies
(10, 4545)
(20, 4545)
(20, 4545)
Average distance of agents to nearest neighbors: 0.04063177144287421
avg return on 3 trajectories of agent0: -138.26841779007916
avg return on 3 trajectories of agent1: -138.3557516659976
avg return on 3 trajectories of agent2: -138.43827026176854
avg return on 3 trajectories of agent3: -138.49951744538188
avg return on 3 trajectories of agent4: -138.60438373100433
avg return on 3 trajectories of agent5: -138.7017549558153
avg return on 3 trajectories of agent6: -138.75088122278908
avg return on 3 trajectories of agent7: -138.74685757852512
avg return on 3 trajectories of agent8: -136.94659811478294
avg return on 3 trajectories of agent9: -137.05831345404215
avg return on 3 trajectories of agent10: -137.17134645520434
avg return on 3 trajectories of agent11: -137.286022309382
avg return on 3 trajectories of agent12: -136.19798376351233
avg return on 3 trajectories of agent13: -136.21541880124133
avg return on 3 trajectories of agent14: -136.240004477222
avg return on 3 trajectories of agent15: -136.26704252309298
avg return on 3 trajectories of agent16: -135.83999905429977
avg return on 3 trajectories of agent17: -135.93135906004528
avg return on 3 trajectories of agent18: -136.0353999082987
avg return on 3 trajectories of agent19: -136.13782252350973
avg cum rews: -137.28465725479973, std: 1.1041529742562448
the best agent: 16, best agent cum rewards: -135.83999905429977
70
---------------------------------
Searching empty space policies
(10, 4545)
(20, 4545)
(20, 4545)
Average distance of agents to nearest neighbors: 0.034088365744378034
avg return on 3 trajectories of agent0: -139.37875291183903
avg return on 3 trajectories of agent1: -139.29449121709072
avg return on 3 trajectories of agent2: -139.22698912506746
avg return on 3 trajectories of agent3: -139.19431552304573
avg return on 3 trajectories of agent4: -138.3552845373487
avg return on 3 trajectories of agent5: -138.35202035174072
avg return on 3 trajectories of agent6: -138.27885024866885
avg return on 3 trajectories of agent7: -138.16830766166024
avg return on 3 trajectories of agent8: -139.13035045216557
avg return on 3 trajectories of agent9: -139.06525562089368
avg return on 3 trajectories of agent10: -139.0606423696275
avg return on 3 trajectories of agent11: -139.06946703939988
avg return on 3 trajectories of agent12: -138.30965741104953
avg return on 3 trajectories of agent13: -138.25998338660915
avg return on 3 trajectories of agent14: -138.23459926770147
avg return on 3 trajectories of agent15: -138.22597885285387
avg return on 3 trajectories of agent16: -138.57768652121698
avg return on 3 trajectories of agent17: -138.5075077764061
avg return on 3 trajectories of agent18: -138.44037282509578
avg return on 3 trajectories of agent19: -138.3769058785272
avg cum rews: -138.67537094890042, std: 0.4254591107412929
the best agent: 7, best agent cum rewards: -138.16830766166024
80
---------------------------------
Searching empty space policies
(10, 4545)
(20, 4545)
(20, 4545)
Average distance of agents to nearest neighbors: 0.03988750064945036
avg return on 3 trajectories of agent0: -136.63365855547886
avg return on 3 trajectories of agent1: -136.5961663626574
avg return on 3 trajectories of agent2: -136.56712922545435
avg return on 3 trajectories of agent3: -136.5453372306857
avg return on 3 trajectories of agent4: -136.80036155098523
avg return on 3 trajectories of agent5: -136.8240276449443
avg return on 3 trajectories of agent6: -136.85857248114846
avg return on 3 trajectories of agent7: -136.90978214825398
avg return on 3 trajectories of agent8: -136.55044259771222
avg return on 3 trajectories of agent9: -136.536909859741
avg return on 3 trajectories of agent10: -136.51962883740214
avg return on 3 trajectories of agent11: -136.50006356006168
avg return on 3 trajectories of agent12: -136.37867904522085
avg return on 3 trajectories of agent13: -136.37933877039245
avg return on 3 trajectories of agent14: -136.3807213004288
avg return on 3 trajectories of agent15: -136.38066615714237
avg return on 3 trajectories of agent16: -136.37774158465953
avg return on 3 trajectories of agent17: -136.34971300286296
avg return on 3 trajectories of agent18: -136.3187723407815
avg return on 3 trajectories of agent19: -136.28687070632833
avg cum rews: -136.5347291481171, std: 0.1842684918924072
the best agent: 19, best agent cum rewards: -136.28687070632833
90
---------------------------------
Searching empty space policies
(10, 4545)
(20, 4545)
(20, 4545)
Average distance of agents to nearest neighbors: 0.033914369513514134
avg return on 3 trajectories of agent0: -136.52926025810925
avg return on 3 trajectories of agent1: -136.58293552563748
avg return on 3 trajectories of agent2: -136.6341083730526
avg return on 3 trajectories of agent3: -136.68319319878094
avg return on 3 trajectories of agent4: -136.5610035112693
avg return on 3 trajectories of agent5: -136.54928797838917
avg return on 3 trajectories of agent6: -136.5312636812538
avg return on 3 trajectories of agent7: -136.5044955254366
avg return on 3 trajectories of agent8: -136.8278556305465
avg return on 3 trajectories of agent9: -136.91186115652388
avg return on 3 trajectories of agent10: -136.99079120668526
avg return on 3 trajectories of agent11: -137.06649658137437
avg return on 3 trajectories of agent12: -138.0409174311115
avg return on 3 trajectories of agent13: -137.9536320965653
avg return on 3 trajectories of agent14: -137.8885884503917
avg return on 3 trajectories of agent15: -137.8643701810519
avg return on 3 trajectories of agent16: -137.68003985971373
avg return on 3 trajectories of agent17: -137.7278541981918
avg return on 3 trajectories of agent18: -137.77481275173136
avg return on 3 trajectories of agent19: -137.80702019988183
avg cum rews: -137.15548938978492, std: 0.5840693525945861
the best agent: 7, best agent cum rewards: -136.5044955254366
Average distance of random agents to nearest neighbors: [0.051118142811447775, 0.05620575401532042, 0.06171318387736363, 0.04034650671255888, 0.04770290454238021, 0.04293017464894697, 0.04063177144287421, 0.034088365744378034, 0.03988750064945036, 0.033914369513514134]
Time taken for each iteration: [936.2868087291718, 1803.977998495102, 2643.8526496887207, 3845.830655813217, 4590.940884113312, 5437.432359695435, 6218.268678665161, 7696.078717708588, 9176.849406957626, 10697.562434911728]
