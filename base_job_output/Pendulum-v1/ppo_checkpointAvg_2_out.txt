No devices were found
Setting seed -  1
Creating multiple envs -  4
---------------------------------
Environment created
Box(-2.0, 2.0, (1,), float32) Box([-1. -1. -8.], [1. 1. 8.], (3,), float32)
Starting evaluation
0
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -1515.3385642049773
2
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -1027.8730481122657
4
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -368.80873545838654
6
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -360.9049416589191
8
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -366.8134806625754
10
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -360.910793107604
12
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -365.9250461072122
14
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -365.2633371000776
16
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -361.8251106067822
18
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -361.3853194018785
20
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -361.4026418995803
22
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -362.8295682533953
24
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -363.4524897748492
26
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -362.98623668654784
28
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -362.45082048612136
30
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -364.4945746091477
32
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -364.8244354699041
34
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -362.2507973590425
36
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -360.59037502858087
38
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -359.4283160959982
40
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -361.10048256598634
42
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -359.3028152588596
44
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -359.6110333649603
46
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -360.3252580163216
Average distance of random agents to nearest neighbors: []
Time taken for each iteration: [18.204415798187256, 37.194087982177734, 55.993555545806885, 75.24827790260315, 94.66153144836426, 114.17166042327881, 133.73914527893066, 153.16388869285583, 172.78585243225098, 192.38617849349976, 212.29384589195251, 232.07971286773682, 251.72786736488342, 271.6409013271332, 291.42934012413025, 311.09008526802063, 330.9214606285095, 350.4319624900818, 370.0467162132263, 389.7647907733917, 409.75682044029236, 429.58743357658386, 448.3466281890869, 467.03106594085693]
