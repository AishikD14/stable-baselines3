No devices were found
Setting seed -  0
Creating multiple envs -  4
---------------------------------
Environment created
Box(-2.0, 2.0, (1,), float32) Box([-1. -1. -8.], [1. 1. 8.], (3,), float32)
Starting evaluation
0
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -1414.7234055711428
2
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -540.8653675526002
4
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -133.18083963157355
6
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -130.08197173292032
8
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -128.04855938567462
10
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -127.4479100349221
12
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -127.13908441978566
14
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -127.20942878178056
16
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -125.88664937279782
18
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -125.23274154683124
20
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -124.96981804810466
22
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -124.63068877364942
24
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -125.57565753355662
26
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -124.34849691456638
28
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -123.78026341433595
30
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -125.51952585605434
32
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -127.2343222000699
34
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -127.26245946971436
36
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -127.72076760314052
38
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -126.5786102303766
40
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -128.49188827729012
42
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -129.4580829883521
44
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -129.81600535991234
46
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -130.20363126758173
Average distance of random agents to nearest neighbors: []
Time taken for each iteration: [17.815370321273804, 35.91531467437744, 54.259523153305054, 73.41862201690674, 92.35013437271118, 111.56552171707153, 131.04304766654968, 150.86233353614807, 170.47654128074646, 190.10529017448425, 209.80216646194458, 229.19619941711426, 249.04246401786804, 268.977055311203, 289.01408100128174, 308.87660241127014, 328.59263610839844, 348.3569962978363, 368.3312768936157, 388.0957350730896, 407.94688057899475, 427.4250454902649, 447.2274513244629, 467.1646263599396]
