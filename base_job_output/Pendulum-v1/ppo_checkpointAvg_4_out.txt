No devices were found
Setting seed -  3
Creating multiple envs -  4
---------------------------------
Environment created
Box(-2.0, 2.0, (1,), float32) Box([-1. -1. -8.], [1. 1. 8.], (3,), float32)
Starting evaluation
0
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -1092.9240795871438
2
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -469.2728689129918
4
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -129.4496509321318
6
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -128.94440344070267
8
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -129.39303796421544
10
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -129.3484441142483
12
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -130.19493191907983
14
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -130.84908825343388
16
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -131.6671403977463
18
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -130.81702133010361
20
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -130.83555743916972
22
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -130.3859805898316
24
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -131.08349844971167
26
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -130.5087244654395
28
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -131.57350242794226
30
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -131.93417604731633
32
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -132.64601312437037
34
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -131.68829096509128
36
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -131.42591989857112
38
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -131.4002825284107
40
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -133.49685717361794
42
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -132.45759455761805
44
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -131.18055691804972
46
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -131.99158283333253
Average distance of random agents to nearest neighbors: []
Time taken for each iteration: [19.233611345291138, 38.277255058288574, 57.62722563743591, 76.80833387374878, 96.051997423172, 115.35016393661499, 134.6938750743866, 154.16919136047363, 173.63614749908447, 193.01448822021484, 212.46337842941284, 232.12216711044312, 252.03833484649658, 271.6712737083435, 291.39704942703247, 311.15963912010193, 330.60971331596375, 350.55249762535095, 369.16250872612, 387.8399324417114, 405.83459758758545, 423.6974217891693, 441.27671575546265, 458.9185719490051]
