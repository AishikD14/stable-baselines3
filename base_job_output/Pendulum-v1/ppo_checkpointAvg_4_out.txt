No devices were found
Setting seed -  3
Creating multiple envs -  4
---------------------------------
Environment created
Box(-2.0, 2.0, (1,), float32) Box([-1. -1. -8.], [1. 1. 8.], (3,), float32)
Starting evaluation
0
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -1394.8168064287345
1
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -938.2676052971509
2
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -855.3430878850188
3
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -584.2198715416667
4
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -132.76107621954228
5
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -130.6735769733502
6
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -129.8873266914313
7
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -129.64431259140963
8
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -129.27229701602795
9
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -129.28246617313712
10
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -129.1162513150904
11
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -129.1710439047278
12
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -129.9596292490814
13
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -130.00688889431217
14
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -130.08167091260734
15
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -130.66260452860263
16
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -130.68421765391264
17
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -130.9605536072956
18
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -130.64388388424257
19
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -130.39984398885198
20
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -131.69597191594653
21
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -131.48298928901912
22
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -130.8390730362549
23
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -131.05900190437362
24
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -130.78338389871075
25
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -130.4728201915344
26
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -130.96832306963103
27
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -131.1861118637474
28
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -131.74460176522726
29
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -131.96159210779487
30
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -131.42481377503384
31
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -131.26560381763625
32
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -130.92913275125912
33
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -130.45526912897293
34
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -130.03409867169165
35
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -130.357886876886
36
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -130.28327353603515
37
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -130.5224886311445
38
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -130.52187467123528
39
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -130.48371210867245
40
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -131.14579866439837
41
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -131.3341750130701
42
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -131.03541763137267
43
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -130.92747850433355
44
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -131.44511262610777
45
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -131.34953670822503
46
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -131.69318100771517
47
Average policy vector shape:  (1, 4545)
avg return on 3 trajectories of agent: -131.68025997366033
Average distance of random agents to nearest neighbors: []
Time taken for each iteration: [16.882484197616577, 34.95521545410156, 52.06397747993469, 69.27150368690491, 86.74756693840027, 104.0395348072052, 121.41713285446167, 138.84339237213135, 156.87568545341492, 173.95216274261475, 191.28208112716675, 208.51204991340637, 225.8097698688507, 243.502135515213, 260.98690032958984, 278.9212455749512, 296.3570625782013, 313.7279167175293, 331.0181441307068, 348.68537425994873, 366.2057945728302, 383.68714237213135, 402.16882729530334, 419.1740725040436, 436.8416073322296, 454.0216763019562, 471.4415125846863, 488.499306678772, 506.06259083747864, 524.1297190189362, 541.2510361671448, 558.8729963302612, 576.5081923007965, 594.0492527484894, 611.7423961162567, 629.1035122871399, 647.5596499443054, 664.5734796524048, 681.1171116828918, 696.8595697879791, 713.5067889690399, 729.3956959247589, 745.2025151252747, 760.7069885730743, 775.6093463897705, 790.0843434333801, 804.4102320671082, 818.67751121521]
