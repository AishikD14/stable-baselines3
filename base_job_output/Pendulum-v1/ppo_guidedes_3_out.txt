No devices were found
Setting seed -  2
Creating multiple envs -  4
---------------------------------
Environment created
Box(-2.0, 2.0, (1,), float32) Box([-1. -1. -8.], [1. 1. 8.], (3,), float32)
Starting evaluation
0
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1579.0301609364597
avg cum rews: -1579.0301609364597, std: 0.0
the best agent: 0, best agent cum rewards: -1579.0301609364597
2
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -885.6554259647285
avg cum rews: -885.6554259647285, std: 0.0
the best agent: 0, best agent cum rewards: -885.6554259647285
4
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1308.838307613477
avg cum rews: -1308.838307613477, std: 0.0
the best agent: 0, best agent cum rewards: -1308.838307613477
6
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1345.1381210701195
avg cum rews: -1345.1381210701195, std: 0.0
the best agent: 0, best agent cum rewards: -1345.1381210701195
8
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1038.6701916341794
avg cum rews: -1038.6701916341794, std: 0.0
the best agent: 0, best agent cum rewards: -1038.6701916341794
10
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1025.6390806785882
avg cum rews: -1025.6390806785882, std: 0.0
the best agent: 0, best agent cum rewards: -1025.6390806785882
12
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -5.903557209890071
avg cum rews: -5.903557209890071, std: 0.0
the best agent: 0, best agent cum rewards: -5.903557209890071
14
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -4.074206209109277
avg cum rews: -4.074206209109277, std: 0.0
the best agent: 0, best agent cum rewards: -4.074206209109277
16
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -687.1268702703959
avg cum rews: -687.1268702703959, std: 0.0
the best agent: 0, best agent cum rewards: -687.1268702703959
18
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -6.888388901404016
avg cum rews: -6.888388901404016, std: 0.0
the best agent: 0, best agent cum rewards: -6.888388901404016
20
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1604.8837642511762
avg cum rews: -1604.8837642511762, std: 0.0
the best agent: 0, best agent cum rewards: -1604.8837642511762
22
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -284.79715010444454
avg cum rews: -284.79715010444454, std: 0.0
the best agent: 0, best agent cum rewards: -284.79715010444454
24
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1349.4161228085616
avg cum rews: -1349.4161228085616, std: 0.0
the best agent: 0, best agent cum rewards: -1349.4161228085616
26
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1518.7856947440964
avg cum rews: -1518.7856947440964, std: 0.0
the best agent: 0, best agent cum rewards: -1518.7856947440964
28
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1588.7928564577173
avg cum rews: -1588.7928564577173, std: 0.0
the best agent: 0, best agent cum rewards: -1588.7928564577173
30
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -12.128163333716603
avg cum rews: -12.128163333716603, std: 0.0
the best agent: 0, best agent cum rewards: -12.128163333716603
32
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -4.7521710854675625
avg cum rews: -4.7521710854675625, std: 0.0
the best agent: 0, best agent cum rewards: -4.7521710854675625
34
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -409.80632228343313
avg cum rews: -409.80632228343313, std: 0.0
the best agent: 0, best agent cum rewards: -409.80632228343313
36
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1267.6603874591194
avg cum rews: -1267.6603874591194, std: 0.0
the best agent: 0, best agent cum rewards: -1267.6603874591194
38
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -189.6621981360182
avg cum rews: -189.6621981360182, std: 0.0
the best agent: 0, best agent cum rewards: -189.6621981360182
40
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -13.2683692965141
avg cum rews: -13.2683692965141, std: 0.0
the best agent: 0, best agent cum rewards: -13.2683692965141
42
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1584.9326616873566
avg cum rews: -1584.9326616873566, std: 0.0
the best agent: 0, best agent cum rewards: -1584.9326616873566
44
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1441.3809607256637
avg cum rews: -1441.3809607256637, std: 0.0
the best agent: 0, best agent cum rewards: -1441.3809607256637
46
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1587.1507826566522
avg cum rews: -1587.1507826566522, std: 0.0
the best agent: 0, best agent cum rewards: -1587.1507826566522
Average distance of random agents to nearest neighbors: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Time taken for each iteration: [21.904507160186768, 44.76813197135925, 67.29842925071716, 89.63876366615295, 112.08815932273865, 134.92980194091797, 157.95460057258606, 181.4369421005249, 205.38277006149292, 228.93307638168335, 252.87919449806213, 276.9485025405884, 300.4453856945038, 323.49829387664795, 347.8284475803375, 371.54650378227234, 395.16104316711426, 419.2394061088562, 441.87292528152466, 464.0299925804138, 486.58065032958984, 508.76987171173096, 530.2003297805786, 551.8983376026154]
