No devices were found
Setting seed -  0
Creating multiple envs -  4
---------------------------------
Environment created
Box(-2.0, 2.0, (1,), float32) Box([-1. -1. -8.], [1. 1. 8.], (3,), float32)
Loading Initial saved model
Model loaded
Starting evaluation
9
---------------------------------
Searching empty space policies
(10, 4545)
(20, 4545)
(20, 4545)
Average distance of agents to nearest neighbors: 0.04277046333275971
avg return on 3 trajectories of agent0: -124.551129448701
avg return on 3 trajectories of agent1: -124.5995379153687
avg return on 3 trajectories of agent2: -124.65263779053481
avg return on 3 trajectories of agent3: -124.72261691869194
avg return on 3 trajectories of agent4: -124.37562188741803
avg return on 3 trajectories of agent5: -124.43229767863176
avg return on 3 trajectories of agent6: -124.49981980042914
avg return on 3 trajectories of agent7: -124.61653906596773
avg return on 3 trajectories of agent8: -124.74776662074837
avg return on 3 trajectories of agent9: -124.7175406217366
avg return on 3 trajectories of agent10: -124.67099497515407
avg return on 3 trajectories of agent11: -124.59458888802948
avg return on 3 trajectories of agent12: -125.26549075832449
avg return on 3 trajectories of agent13: -125.39141593837584
avg return on 3 trajectories of agent14: -125.52687687222692
avg return on 3 trajectories of agent15: -125.65520074786444
avg return on 3 trajectories of agent16: -124.92055556726308
avg return on 3 trajectories of agent17: -124.98845704661899
avg return on 3 trajectories of agent18: -125.04533628981771
avg return on 3 trajectories of agent19: -125.05588691290292
avg cum rews: -124.8515155872403, std: 0.3595879908926328
the best agent: 4, best agent cum rewards: -124.37562188741803
10
---------------------------------
Searching empty space policies
(10, 4545)
(20, 4545)
(20, 4545)
Average distance of agents to nearest neighbors: 0.03375129155923434
avg return on 3 trajectories of agent0: -126.38083037101471
avg return on 3 trajectories of agent1: -126.39116776989314
avg return on 3 trajectories of agent2: -126.31531023929965
avg return on 3 trajectories of agent3: -126.2048090205721
avg return on 3 trajectories of agent4: -126.15825624280907
avg return on 3 trajectories of agent5: -126.12097697832466
avg return on 3 trajectories of agent6: -126.07859085966338
avg return on 3 trajectories of agent7: -126.03612971967645
avg return on 3 trajectories of agent8: -126.34065131736337
avg return on 3 trajectories of agent9: -126.28930757980882
avg return on 3 trajectories of agent10: -126.21109441820614
avg return on 3 trajectories of agent11: -126.13074579207886
avg return on 3 trajectories of agent12: -126.87585833631186
avg return on 3 trajectories of agent13: -126.83578339207504
avg return on 3 trajectories of agent14: -126.78989955147578
avg return on 3 trajectories of agent15: -126.75485835550231
avg return on 3 trajectories of agent16: -126.87598430803756
avg return on 3 trajectories of agent17: -126.85186279273069
avg return on 3 trajectories of agent18: -126.84103395805815
avg return on 3 trajectories of agent19: -126.84836377701895
avg cum rews: -126.46657573899604, std: 0.31413411279510617
the best agent: 7, best agent cum rewards: -126.03612971967645
11
---------------------------------
Searching empty space policies
(10, 4545)
(20, 4545)
(20, 4545)
Average distance of agents to nearest neighbors: 0.032322922640385346
avg return on 3 trajectories of agent0: -125.41176183527567
avg return on 3 trajectories of agent1: -125.41338806253063
avg return on 3 trajectories of agent2: -125.44672961987372
avg return on 3 trajectories of agent3: -125.47643419767874
avg return on 3 trajectories of agent4: -125.07985743768627
avg return on 3 trajectories of agent5: -125.04726019569814
avg return on 3 trajectories of agent6: -125.009176639955
avg return on 3 trajectories of agent7: -124.96491459413937
avg return on 3 trajectories of agent8: -125.51269870003087
avg return on 3 trajectories of agent9: -125.56832656249357
avg return on 3 trajectories of agent10: -125.66178546478041
avg return on 3 trajectories of agent11: -125.76923111261755
avg return on 3 trajectories of agent12: -124.00644838711641
avg return on 3 trajectories of agent13: -123.96215674650877
avg return on 3 trajectories of agent14: -123.91533252838629
avg return on 3 trajectories of agent15: -123.87529507942077
avg return on 3 trajectories of agent16: -124.40355600201833
avg return on 3 trajectories of agent17: -124.35016740307111
avg return on 3 trajectories of agent18: -124.30290863754067
avg return on 3 trajectories of agent19: -124.26404822503952
avg cum rews: -124.87207387159307, std: 0.6471656405532367
the best agent: 15, best agent cum rewards: -123.87529507942077
12
---------------------------------
Searching empty space policies
(10, 4545)
(20, 4545)
(20, 4545)
Average distance of agents to nearest neighbors: 0.04615993161118019
avg return on 3 trajectories of agent0: -123.67961791533413
avg return on 3 trajectories of agent1: -123.70935385693262
avg return on 3 trajectories of agent2: -123.71797465117358
avg return on 3 trajectories of agent3: -123.72829685839439
avg return on 3 trajectories of agent4: -123.60208257157068
avg return on 3 trajectories of agent5: -123.55599361054585
avg return on 3 trajectories of agent6: -123.52196248470486
avg return on 3 trajectories of agent7: -123.49073424758488
avg return on 3 trajectories of agent8: -123.94369434782749
avg return on 3 trajectories of agent9: -124.04363830705279
avg return on 3 trajectories of agent10: -124.14121261392617
avg return on 3 trajectories of agent11: -124.23049833225649
avg return on 3 trajectories of agent12: -123.68118956366537
avg return on 3 trajectories of agent13: -123.56221590187252
avg return on 3 trajectories of agent14: -123.451161774487
avg return on 3 trajectories of agent15: -123.33917880841457
avg return on 3 trajectories of agent16: -123.81218491124879
avg return on 3 trajectories of agent17: -123.67193386580394
avg return on 3 trajectories of agent18: -123.53795491153227
avg return on 3 trajectories of agent19: -123.43088813825607
avg cum rews: -123.69258838362926, std: 0.23274644815719622
the best agent: 15, best agent cum rewards: -123.33917880841457
13
---------------------------------
Searching empty space policies
(10, 4545)
(20, 4545)
(20, 4545)
Average distance of agents to nearest neighbors: 0.036838619439113617
avg return on 3 trajectories of agent0: -123.49660085941893
avg return on 3 trajectories of agent1: -123.36320828241936
avg return on 3 trajectories of agent2: -123.2515526295677
avg return on 3 trajectories of agent3: -123.15527298515141
avg return on 3 trajectories of agent4: -123.51248546209379
avg return on 3 trajectories of agent5: -123.43664276032277
avg return on 3 trajectories of agent6: -123.36833518419824
avg return on 3 trajectories of agent7: -123.31045819967989
avg return on 3 trajectories of agent8: -123.71031166218802
avg return on 3 trajectories of agent9: -123.70964701685446
avg return on 3 trajectories of agent10: -123.7292291015589
avg return on 3 trajectories of agent11: -123.75360583764383
avg return on 3 trajectories of agent12: -123.82211019094548
avg return on 3 trajectories of agent13: -123.7620333356695
avg return on 3 trajectories of agent14: -123.7327522326013
avg return on 3 trajectories of agent15: -123.73513917887064
avg return on 3 trajectories of agent16: -123.8034410724752
avg return on 3 trajectories of agent17: -123.86881975245605
avg return on 3 trajectories of agent18: -123.89939200589127
avg return on 3 trajectories of agent19: -123.9266453987654
avg cum rews: -123.6173841574386, std: 0.22778359114429322
the best agent: 3, best agent cum rewards: -123.15527298515141
14
---------------------------------
Searching empty space policies
(10, 4545)
(20, 4545)
(20, 4545)
Average distance of agents to nearest neighbors: 0.04732531403470133
avg return on 3 trajectories of agent0: -124.76112130561631
avg return on 3 trajectories of agent1: -124.71353051396473
avg return on 3 trajectories of agent2: -124.6997032336457
avg return on 3 trajectories of agent3: -124.72014669962361
avg return on 3 trajectories of agent4: -124.79069097278224
avg return on 3 trajectories of agent5: -124.81940388050064
avg return on 3 trajectories of agent6: -124.84722144919773
avg return on 3 trajectories of agent7: -124.87849998723507
avg return on 3 trajectories of agent8: -125.04293499878744
avg return on 3 trajectories of agent9: -125.07584194728848
avg return on 3 trajectories of agent10: -125.13421356275832
avg return on 3 trajectories of agent11: -125.21047191485842
avg return on 3 trajectories of agent12: -125.23751827766648
avg return on 3 trajectories of agent13: -125.27799535611547
avg return on 3 trajectories of agent14: -125.34935993416347
avg return on 3 trajectories of agent15: -125.4457097090612
avg return on 3 trajectories of agent16: -125.2070851302527
avg return on 3 trajectories of agent17: -125.2922473059982
avg return on 3 trajectories of agent18: -125.3798076727375
avg return on 3 trajectories of agent19: -125.48019045160864
avg cum rews: -125.06818471519311, std: 0.260443077377358
the best agent: 2, best agent cum rewards: -124.6997032336457
15
---------------------------------
Searching empty space policies
(10, 4545)
(20, 4545)
(20, 4545)
Average distance of agents to nearest neighbors: 0.04096589558514571
avg return on 3 trajectories of agent0: -125.0182772506806
avg return on 3 trajectories of agent1: -125.0001516685296
avg return on 3 trajectories of agent2: -124.9847058828313
avg return on 3 trajectories of agent3: -124.97644895911094
avg return on 3 trajectories of agent4: -125.10334229904512
avg return on 3 trajectories of agent5: -125.10152955626724
avg return on 3 trajectories of agent6: -125.09620564468425
avg return on 3 trajectories of agent7: -125.08211958155513
avg return on 3 trajectories of agent8: -124.81928296970248
avg return on 3 trajectories of agent9: -124.75703562656811
avg return on 3 trajectories of agent10: -124.68815242821009
avg return on 3 trajectories of agent11: -124.63828927685981
avg return on 3 trajectories of agent12: -125.2470251494893
avg return on 3 trajectories of agent13: -125.34654280512554
avg return on 3 trajectories of agent14: -125.46459734439647
avg return on 3 trajectories of agent15: -125.58897303844584
avg return on 3 trajectories of agent16: -124.91993596454134
avg return on 3 trajectories of agent17: -125.00146328898599
avg return on 3 trajectories of agent18: -125.08899585058522
avg return on 3 trajectories of agent19: -125.18846312725447
avg cum rews: -125.05557688564348, std: 0.23343222077359196
the best agent: 11, best agent cum rewards: -124.63828927685981
16
---------------------------------
Searching empty space policies
(10, 4545)
(20, 4545)
(20, 4545)
Average distance of agents to nearest neighbors: 0.046252215373341496
avg return on 3 trajectories of agent0: -125.03237615484305
avg return on 3 trajectories of agent1: -125.19973159164874
avg return on 3 trajectories of agent2: -125.34442123795107
avg return on 3 trajectories of agent3: -125.48445066027955
avg return on 3 trajectories of agent4: -124.69796689644018
avg return on 3 trajectories of agent5: -124.76063321799221
avg return on 3 trajectories of agent6: -124.80122792299203
avg return on 3 trajectories of agent7: -124.79721591899289
avg return on 3 trajectories of agent8: -125.43026517787297
avg return on 3 trajectories of agent9: -125.4600001001797
avg return on 3 trajectories of agent10: -125.52845245549712
avg return on 3 trajectories of agent11: -125.62156691078697
avg return on 3 trajectories of agent12: -125.06484452569262
avg return on 3 trajectories of agent13: -125.01726658134977
avg return on 3 trajectories of agent14: -124.95913645961494
avg return on 3 trajectories of agent15: -124.89728769086273
avg return on 3 trajectories of agent16: -125.10018860472346
avg return on 3 trajectories of agent17: -125.00188705157497
avg return on 3 trajectories of agent18: -124.92926894888724
avg return on 3 trajectories of agent19: -124.85639970980094
avg cum rews: -125.09922939089915, std: 0.27759733105018314
the best agent: 4, best agent cum rewards: -124.69796689644018
17
---------------------------------
Searching empty space policies
(10, 4545)
(20, 4545)
(20, 4545)
Average distance of agents to nearest neighbors: 0.04730480967516269
avg return on 3 trajectories of agent0: -123.58464246820057
avg return on 3 trajectories of agent1: -123.59288415569735
avg return on 3 trajectories of agent2: -123.60747468220394
avg return on 3 trajectories of agent3: -123.63008627567842
avg return on 3 trajectories of agent4: -123.87778437100965
avg return on 3 trajectories of agent5: -123.9597954513573
avg return on 3 trajectories of agent6: -124.06893798742345
avg return on 3 trajectories of agent7: -124.19469821427012
avg return on 3 trajectories of agent8: -123.54904382155938
avg return on 3 trajectories of agent9: -123.54248081402622
avg return on 3 trajectories of agent10: -123.53957915532918
avg return on 3 trajectories of agent11: -123.54685011483504
avg return on 3 trajectories of agent12: -124.0749965276787
avg return on 3 trajectories of agent13: -124.15192980393527
avg return on 3 trajectories of agent14: -124.23081121869733
avg return on 3 trajectories of agent15: -124.31002573552752
avg return on 3 trajectories of agent16: -123.81753883881834
avg return on 3 trajectories of agent17: -123.85900341152502
avg return on 3 trajectories of agent18: -123.87723820268583
avg return on 3 trajectories of agent19: -123.89938842512277
avg cum rews: -123.84575948377906, std: 0.2548594987537744
the best agent: 10, best agent cum rewards: -123.53957915532918
18
---------------------------------
Searching empty space policies
(10, 4545)
(20, 4545)
(20, 4545)
Average distance of agents to nearest neighbors: 0.04438425451649072
avg return on 3 trajectories of agent0: -123.06448923169752
avg return on 3 trajectories of agent1: -123.02481769637396
avg return on 3 trajectories of agent2: -123.00318204220761
avg return on 3 trajectories of agent3: -123.00228491030417
avg return on 3 trajectories of agent4: -123.08501959449283
avg return on 3 trajectories of agent5: -123.07103141274938
avg return on 3 trajectories of agent6: -123.05983087886803
avg return on 3 trajectories of agent7: -123.05007185451025
avg return on 3 trajectories of agent8: -123.24888038447803
avg return on 3 trajectories of agent9: -123.27391458343192
avg return on 3 trajectories of agent10: -123.30642132570075
avg return on 3 trajectories of agent11: -123.3285371870877
avg return on 3 trajectories of agent12: -123.21322396224225
avg return on 3 trajectories of agent13: -123.18308175137626
avg return on 3 trajectories of agent14: -123.14410094920517
avg return on 3 trajectories of agent15: -123.10109178965583
avg return on 3 trajectories of agent16: -123.06104290983713
avg return on 3 trajectories of agent17: -123.02722218657345
avg return on 3 trajectories of agent18: -122.98845133849923
avg return on 3 trajectories of agent19: -122.95036132772162
avg cum rews: -123.10935286585064, std: 0.10950431211704423
the best agent: 19, best agent cum rewards: -122.95036132772162
19
---------------------------------
Searching empty space policies
(10, 4545)
(20, 4545)
(20, 4545)
Average distance of agents to nearest neighbors: 0.03217661774309187
avg return on 3 trajectories of agent0: -123.31560499771247
avg return on 3 trajectories of agent1: -123.24894012104218
avg return on 3 trajectories of agent2: -123.18767184719628
avg return on 3 trajectories of agent3: -123.13928262087302
avg return on 3 trajectories of agent4: -123.48388414142448
avg return on 3 trajectories of agent5: -123.49918259949578
avg return on 3 trajectories of agent6: -123.50703348176002
avg return on 3 trajectories of agent7: -123.51410803479058
avg return on 3 trajectories of agent8: -123.26715552363056
avg return on 3 trajectories of agent9: -123.2066287343841
avg return on 3 trajectories of agent10: -123.16434484091471
avg return on 3 trajectories of agent11: -123.12398366126153
avg return on 3 trajectories of agent12: -123.00414931422203
avg return on 3 trajectories of agent13: -122.9770700371481
avg return on 3 trajectories of agent14: -122.95538263660949
avg return on 3 trajectories of agent15: -122.94344363216499
avg return on 3 trajectories of agent16: -123.02430906338162
avg return on 3 trajectories of agent17: -122.99344285052736
avg return on 3 trajectories of agent18: -122.9757495206966
avg return on 3 trajectories of agent19: -122.960378267491
avg cum rews: -123.17458729633636, std: 0.19701188416931498
the best agent: 15, best agent cum rewards: -122.94344363216499
20
---------------------------------
Searching empty space policies
(10, 4545)
(20, 4545)
(20, 4545)
Average distance of agents to nearest neighbors: 0.045244450867352584
avg return on 3 trajectories of agent0: -122.43115700598413
avg return on 3 trajectories of agent1: -122.41421736904333
avg return on 3 trajectories of agent2: -122.38990504898398
avg return on 3 trajectories of agent3: -122.36279650249024
avg return on 3 trajectories of agent4: -122.38109008166357
avg return on 3 trajectories of agent5: -122.34840883726447
avg return on 3 trajectories of agent6: -122.31135044920288
avg return on 3 trajectories of agent7: -122.27444494811523
avg return on 3 trajectories of agent8: -122.51392897595936
avg return on 3 trajectories of agent9: -122.51017511943114
avg return on 3 trajectories of agent10: -122.51063799843098
avg return on 3 trajectories of agent11: -122.51479781366743
avg return on 3 trajectories of agent12: -122.37936043066486
avg return on 3 trajectories of agent13: -122.3728935526972
avg return on 3 trajectories of agent14: -122.36440257437532
avg return on 3 trajectories of agent15: -122.35408905008771
avg return on 3 trajectories of agent16: -122.3367077566255
avg return on 3 trajectories of agent17: -122.32117991979787
avg return on 3 trajectories of agent18: -122.31089747153972
avg return on 3 trajectories of agent19: -122.30471097863398
avg cum rews: -122.38535759423294, std: 0.07325439740354621
the best agent: 7, best agent cum rewards: -122.27444494811523
21
---------------------------------
Searching empty space policies
(10, 4545)
(20, 4545)
(20, 4545)
Average distance of agents to nearest neighbors: 0.0438169253310304
avg return on 3 trajectories of agent0: -122.66133696551756
avg return on 3 trajectories of agent1: -122.74652462613871
avg return on 3 trajectories of agent2: -122.83402540552733
avg return on 3 trajectories of agent3: -122.92315019025513
avg return on 3 trajectories of agent4: -122.58621430590503
avg return on 3 trajectories of agent5: -122.6436638299447
avg return on 3 trajectories of agent6: -122.69591273523376
avg return on 3 trajectories of agent7: -122.74266087516746
avg return on 3 trajectories of agent8: -122.65579162964951
avg return on 3 trajectories of agent9: -122.62408799728286
avg return on 3 trajectories of agent10: -122.60188559887213
avg return on 3 trajectories of agent11: -122.59410868881076
avg return on 3 trajectories of agent12: -122.83360583215791
avg return on 3 trajectories of agent13: -122.83809462235621
avg return on 3 trajectories of agent14: -122.84729197500691
avg return on 3 trajectories of agent15: -122.85975067958422
avg return on 3 trajectories of agent16: -122.92813461227198
avg return on 3 trajectories of agent17: -122.91543319701135
avg return on 3 trajectories of agent18: -122.90653342629885
avg return on 3 trajectories of agent19: -122.90768202232513
avg cum rews: -122.76729446076585, std: 0.12160220220483575
the best agent: 4, best agent cum rewards: -122.58621430590503
22
---------------------------------
Searching empty space policies
(10, 4545)
(20, 4545)
(20, 4545)
Average distance of agents to nearest neighbors: 0.04949420049891332
avg return on 3 trajectories of agent0: -122.66453880461778
avg return on 3 trajectories of agent1: -122.7067006448565
avg return on 3 trajectories of agent2: -122.75073602853493
avg return on 3 trajectories of agent3: -122.79562732741377
avg return on 3 trajectories of agent4: -122.54233500970447
avg return on 3 trajectories of agent5: -122.55391248009784
avg return on 3 trajectories of agent6: -122.55834915036742
avg return on 3 trajectories of agent7: -122.55519014290203
avg return on 3 trajectories of agent8: -122.67981784076945
avg return on 3 trajectories of agent9: -122.6835660046658
avg return on 3 trajectories of agent10: -122.68820459547649
avg return on 3 trajectories of agent11: -122.69458740582552
avg return on 3 trajectories of agent12: -122.57087559390799
avg return on 3 trajectories of agent13: -122.57934486248409
avg return on 3 trajectories of agent14: -122.58048149377821
avg return on 3 trajectories of agent15: -122.57792027022757
avg return on 3 trajectories of agent16: -122.59947963232712
avg return on 3 trajectories of agent17: -122.56451982115036
avg return on 3 trajectories of agent18: -122.53402023120634
avg return on 3 trajectories of agent19: -122.50933934714172
avg cum rews: -122.61947733437277, std: 0.07880435438366773
the best agent: 19, best agent cum rewards: -122.50933934714172
23
---------------------------------
Searching empty space policies
(10, 4545)
(20, 4545)
(20, 4545)
Average distance of agents to nearest neighbors: 0.05142734093787963
avg return on 3 trajectories of agent0: -126.28166205322017
avg return on 3 trajectories of agent1: -126.23112451096253
avg return on 3 trajectories of agent2: -126.1831111888475
avg return on 3 trajectories of agent3: -126.13721971051417
avg return on 3 trajectories of agent4: -125.73163157605714
avg return on 3 trajectories of agent5: -125.61353106155532
avg return on 3 trajectories of agent6: -125.49540571646781
avg return on 3 trajectories of agent7: -125.38080090675672
avg return on 3 trajectories of agent8: -127.1031528326961
avg return on 3 trajectories of agent9: -127.13038374640435
avg return on 3 trajectories of agent10: -127.1666888489558
avg return on 3 trajectories of agent11: -127.21516787893333
avg return on 3 trajectories of agent12: -127.2670882732681
avg return on 3 trajectories of agent13: -127.17547618394045
avg return on 3 trajectories of agent14: -127.06678206257568
avg return on 3 trajectories of agent15: -126.95740864130204
avg return on 3 trajectories of agent16: -127.34449750170012
avg return on 3 trajectories of agent17: -127.26481046638892
avg return on 3 trajectories of agent18: -127.1700016854734
avg return on 3 trajectories of agent19: -127.058859027319
avg cum rews: -126.64874019366695, std: 0.6670518750135941
the best agent: 7, best agent cum rewards: -125.38080090675672
24
---------------------------------
Searching empty space policies
(10, 4545)
(20, 4545)
(20, 4545)
Average distance of agents to nearest neighbors: 0.05327590129299873
avg return on 3 trajectories of agent0: -125.76729006755559
avg return on 3 trajectories of agent1: -125.89466636939329
avg return on 3 trajectories of agent2: -126.02077198491698
avg return on 3 trajectories of agent3: -126.1368046816174
avg return on 3 trajectories of agent4: -125.39307087833078
avg return on 3 trajectories of agent5: -125.43216480809592
avg return on 3 trajectories of agent6: -125.43698551840205
avg return on 3 trajectories of agent7: -125.39783519003024
avg return on 3 trajectories of agent8: -125.77339707288375
avg return on 3 trajectories of agent9: -125.82013732968176
avg return on 3 trajectories of agent10: -125.86313795179996
avg return on 3 trajectories of agent11: -125.90362050461721
avg return on 3 trajectories of agent12: -125.28181532970561
avg return on 3 trajectories of agent13: -125.25620545519025
avg return on 3 trajectories of agent14: -125.21981848822735
avg return on 3 trajectories of agent15: -125.17266352639489
avg return on 3 trajectories of agent16: -125.85533469433129
avg return on 3 trajectories of agent17: -125.83257055778284
avg return on 3 trajectories of agent18: -125.81913236144686
avg return on 3 trajectories of agent19: -125.81636793241246
avg cum rews: -125.6546895351408, std: 0.28803644281760576
the best agent: 15, best agent cum rewards: -125.17266352639489
25
---------------------------------
Searching empty space policies
(10, 4545)
(20, 4545)
(20, 4545)
Average distance of agents to nearest neighbors: 0.05579865557413699
avg return on 3 trajectories of agent0: -125.73780260706283
avg return on 3 trajectories of agent1: -125.61230385824958
avg return on 3 trajectories of agent2: -125.45928603900856
avg return on 3 trajectories of agent3: -125.30981553032308
avg return on 3 trajectories of agent4: -125.836497246895
avg return on 3 trajectories of agent5: -125.74551541846968
avg return on 3 trajectories of agent6: -125.68402468558025
avg return on 3 trajectories of agent7: -125.65423720756385
avg return on 3 trajectories of agent8: -126.0539291260069
avg return on 3 trajectories of agent9: -126.09664290744868
avg return on 3 trajectories of agent10: -126.10831676206959
avg return on 3 trajectories of agent11: -126.10330701145482
avg return on 3 trajectories of agent12: -126.60787539390967
avg return on 3 trajectories of agent13: -126.59021107469133
avg return on 3 trajectories of agent14: -126.56910876640873
avg return on 3 trajectories of agent15: -126.54708155047268
avg return on 3 trajectories of agent16: -126.85705926784294
avg return on 3 trajectories of agent17: -126.81400398626799
avg return on 3 trajectories of agent18: -126.79629538890538
avg return on 3 trajectories of agent19: -126.80690980074382
avg cum rews: -126.14951118146878, std: 0.4954613246654191
the best agent: 3, best agent cum rewards: -125.30981553032308
26
---------------------------------
Searching empty space policies
(10, 4545)
(20, 4545)
(20, 4545)
Average distance of agents to nearest neighbors: 0.04164136103158338
avg return on 3 trajectories of agent0: -124.73711067933031
avg return on 3 trajectories of agent1: -124.59816088030408
avg return on 3 trajectories of agent2: -124.45718671926983
avg return on 3 trajectories of agent3: -124.31528441400552
avg return on 3 trajectories of agent4: -124.9739276602054
avg return on 3 trajectories of agent5: -124.8814123770519
avg return on 3 trajectories of agent6: -124.80623162089535
avg return on 3 trajectories of agent7: -124.75532369892265
avg return on 3 trajectories of agent8: -124.86113480037501
avg return on 3 trajectories of agent9: -124.83283062959289
avg return on 3 trajectories of agent10: -124.80334874549396
avg return on 3 trajectories of agent11: -124.76722126989266
avg return on 3 trajectories of agent12: -124.5486151019235
avg return on 3 trajectories of agent13: -124.48231850094666
avg return on 3 trajectories of agent14: -124.42650671337559
avg return on 3 trajectories of agent15: -124.37782903882753
avg return on 3 trajectories of agent16: -124.50949430245673
avg return on 3 trajectories of agent17: -124.50238531653413
avg return on 3 trajectories of agent18: -124.48077138959133
avg return on 3 trajectories of agent19: -124.45140354140187
avg cum rews: -124.62842487001983, std: 0.19123993250526108
the best agent: 3, best agent cum rewards: -124.31528441400552
27
---------------------------------
Searching empty space policies
(10, 4545)
(20, 4545)
(20, 4545)
Average distance of agents to nearest neighbors: 0.03380129033733856
avg return on 3 trajectories of agent0: -125.07249524765953
avg return on 3 trajectories of agent1: -125.15813104829253
avg return on 3 trajectories of agent2: -125.22629036972083
avg return on 3 trajectories of agent3: -125.23710605621311
avg return on 3 trajectories of agent4: -124.61563549911337
avg return on 3 trajectories of agent5: -124.59021865469087
avg return on 3 trajectories of agent6: -124.51075066728282
avg return on 3 trajectories of agent7: -124.43015778399733
avg return on 3 trajectories of agent8: -125.37223830718389
avg return on 3 trajectories of agent9: -125.50216670669388
avg return on 3 trajectories of agent10: -125.62900715552458
avg return on 3 trajectories of agent11: -125.72940604984835
avg return on 3 trajectories of agent12: -124.72705106219408
avg return on 3 trajectories of agent13: -124.7231317970608
avg return on 3 trajectories of agent14: -124.72221536799955
avg return on 3 trajectories of agent15: -124.72111391731434
avg return on 3 trajectories of agent16: -124.72044481902824
avg return on 3 trajectories of agent17: -124.66335983246397
avg return on 3 trajectories of agent18: -124.61682431957875
avg return on 3 trajectories of agent19: -124.5859280740445
avg cum rews: -124.9276836367953, std: 0.39032730105222235
the best agent: 7, best agent cum rewards: -124.43015778399733
28
---------------------------------
Searching empty space policies
(10, 4545)
(20, 4545)
(20, 4545)
Average distance of agents to nearest neighbors: 0.052095686783408424
avg return on 3 trajectories of agent0: -123.84030133548224
avg return on 3 trajectories of agent1: -123.7755567435325
avg return on 3 trajectories of agent2: -123.70929667714302
avg return on 3 trajectories of agent3: -123.64455812077144
avg return on 3 trajectories of agent4: -124.08225237526263
avg return on 3 trajectories of agent5: -124.0520048357614
avg return on 3 trajectories of agent6: -124.02491302840716
avg return on 3 trajectories of agent7: -123.99956532159774
avg return on 3 trajectories of agent8: -124.05108826083375
avg return on 3 trajectories of agent9: -124.11856842952284
avg return on 3 trajectories of agent10: -124.1729231911213
avg return on 3 trajectories of agent11: -124.20921732836737
avg return on 3 trajectories of agent12: -123.97456331450424
avg return on 3 trajectories of agent13: -124.00906055579712
avg return on 3 trajectories of agent14: -124.05925666928707
avg return on 3 trajectories of agent15: -124.13394151952511
avg return on 3 trajectories of agent16: -124.22396485649503
avg return on 3 trajectories of agent17: -124.32117311566122
avg return on 3 trajectories of agent18: -124.42978760984832
avg return on 3 trajectories of agent19: -124.51512848383568
avg cum rews: -124.06735608863787, std: 0.2147080014781278
the best agent: 3, best agent cum rewards: -123.64455812077144
Average distance of random agents to nearest neighbors: [0.04277046333275971, 0.03375129155923434, 0.032322922640385346, 0.04615993161118019, 0.036838619439113617, 0.04732531403470133, 0.04096589558514571, 0.046252215373341496, 0.04730480967516269, 0.04438425451649072, 0.03217661774309187, 0.045244450867352584, 0.0438169253310304, 0.04949420049891332, 0.05142734093787963, 0.05327590129299873, 0.05579865557413699, 0.04164136103158338, 0.03380129033733856, 0.052095686783408424]
Time taken for each iteration: [141.22617173194885, 290.7995009422302, 447.25211358070374, 604.7329435348511, 763.9411408901215, 924.4044177532196, 1086.7732269763947, 1248.3269577026367, 1408.7186057567596, 1567.4919106960297, 1723.5169422626495, 1880.1917748451233, 2037.0526714324951, 2197.891761779785, 2354.122150182724, 2511.7159259319305, 2667.840784072876, 2824.918540239334, 2982.9361934661865, 3144.999157190323]
