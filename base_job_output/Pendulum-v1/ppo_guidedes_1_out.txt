No devices were found
Setting seed -  0
Creating multiple envs -  4
---------------------------------
Environment created
Box(-2.0, 2.0, (1,), float32) Box([-1. -1. -8.], [1. 1. 8.], (3,), float32)
Starting evaluation
0
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1355.9303414135002
avg cum rews: -1355.9303414135002, std: 0.0
the best agent: 0, best agent cum rewards: -1355.9303414135002
1
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1599.4254939726345
avg cum rews: -1599.4254939726345, std: 0.0
the best agent: 0, best agent cum rewards: -1599.4254939726345
2
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1602.6538955168955
avg cum rews: -1602.6538955168955, std: 0.0
the best agent: 0, best agent cum rewards: -1602.6538955168955
3
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1585.9969154123498
avg cum rews: -1585.9969154123498, std: 0.0
the best agent: 0, best agent cum rewards: -1585.9969154123498
4
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1576.1026114678025
avg cum rews: -1576.1026114678025, std: 0.0
the best agent: 0, best agent cum rewards: -1576.1026114678025
5
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1555.4810872849644
avg cum rews: -1555.4810872849644, std: 0.0
the best agent: 0, best agent cum rewards: -1555.4810872849644
6
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1804.9344731711906
avg cum rews: -1804.9344731711906, std: 0.0
the best agent: 0, best agent cum rewards: -1804.9344731711906
7
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1256.1068646014971
avg cum rews: -1256.1068646014971, std: 0.0
the best agent: 0, best agent cum rewards: -1256.1068646014971
8
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1138.5719080735746
avg cum rews: -1138.5719080735746, std: 0.0
the best agent: 0, best agent cum rewards: -1138.5719080735746
9
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -774.6664223420246
avg cum rews: -774.6664223420246, std: 0.0
the best agent: 0, best agent cum rewards: -774.6664223420246
10
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1059.4344961741767
avg cum rews: -1059.4344961741767, std: 0.0
the best agent: 0, best agent cum rewards: -1059.4344961741767
11
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1060.6640424178754
avg cum rews: -1060.6640424178754, std: 0.0
the best agent: 0, best agent cum rewards: -1060.6640424178754
12
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1495.9654580026572
avg cum rews: -1495.9654580026572, std: 0.0
the best agent: 0, best agent cum rewards: -1495.9654580026572
13
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1093.6160485915332
avg cum rews: -1093.6160485915332, std: 0.0
the best agent: 0, best agent cum rewards: -1093.6160485915332
14
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1569.7848447500971
avg cum rews: -1569.7848447500971, std: 0.0
the best agent: 0, best agent cum rewards: -1569.7848447500971
15
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1392.4397039450748
avg cum rews: -1392.4397039450748, std: 0.0
the best agent: 0, best agent cum rewards: -1392.4397039450748
16
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1161.1872544300809
avg cum rews: -1161.1872544300809, std: 0.0
the best agent: 0, best agent cum rewards: -1161.1872544300809
17
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1103.4411664031797
avg cum rews: -1103.4411664031797, std: 0.0
the best agent: 0, best agent cum rewards: -1103.4411664031797
18
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1014.2720586252121
avg cum rews: -1014.2720586252121, std: 0.0
the best agent: 0, best agent cum rewards: -1014.2720586252121
19
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1248.7386289506453
avg cum rews: -1248.7386289506453, std: 0.0
the best agent: 0, best agent cum rewards: -1248.7386289506453
20
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1543.4960033500054
avg cum rews: -1543.4960033500054, std: 0.0
the best agent: 0, best agent cum rewards: -1543.4960033500054
21
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1261.3911415323153
avg cum rews: -1261.3911415323153, std: 0.0
the best agent: 0, best agent cum rewards: -1261.3911415323153
22
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1381.6193652666805
avg cum rews: -1381.6193652666805, std: 0.0
the best agent: 0, best agent cum rewards: -1381.6193652666805
23
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1394.1139849112487
avg cum rews: -1394.1139849112487, std: 0.0
the best agent: 0, best agent cum rewards: -1394.1139849112487
24
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1350.2574808897525
avg cum rews: -1350.2574808897525, std: 0.0
the best agent: 0, best agent cum rewards: -1350.2574808897525
25
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1059.6492377435952
avg cum rews: -1059.6492377435952, std: 0.0
the best agent: 0, best agent cum rewards: -1059.6492377435952
26
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1582.7434936636137
avg cum rews: -1582.7434936636137, std: 0.0
the best agent: 0, best agent cum rewards: -1582.7434936636137
27
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1534.5740215103333
avg cum rews: -1534.5740215103333, std: 0.0
the best agent: 0, best agent cum rewards: -1534.5740215103333
28
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1338.667260614971
avg cum rews: -1338.667260614971, std: 0.0
the best agent: 0, best agent cum rewards: -1338.667260614971
29
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1047.7914409342886
avg cum rews: -1047.7914409342886, std: 0.0
the best agent: 0, best agent cum rewards: -1047.7914409342886
30
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1491.8332608378805
avg cum rews: -1491.8332608378805, std: 0.0
the best agent: 0, best agent cum rewards: -1491.8332608378805
31
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1198.516526615369
avg cum rews: -1198.516526615369, std: 0.0
the best agent: 0, best agent cum rewards: -1198.516526615369
32
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -989.4428825377838
avg cum rews: -989.4428825377838, std: 0.0
the best agent: 0, best agent cum rewards: -989.4428825377838
33
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1407.5600994062138
avg cum rews: -1407.5600994062138, std: 0.0
the best agent: 0, best agent cum rewards: -1407.5600994062138
34
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1309.4970909924252
avg cum rews: -1309.4970909924252, std: 0.0
the best agent: 0, best agent cum rewards: -1309.4970909924252
35
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1335.6591229158312
avg cum rews: -1335.6591229158312, std: 0.0
the best agent: 0, best agent cum rewards: -1335.6591229158312
36
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1340.5583455800954
avg cum rews: -1340.5583455800954, std: 0.0
the best agent: 0, best agent cum rewards: -1340.5583455800954
37
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1242.7085227024343
avg cum rews: -1242.7085227024343, std: 0.0
the best agent: 0, best agent cum rewards: -1242.7085227024343
38
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1422.769042917174
avg cum rews: -1422.769042917174, std: 0.0
the best agent: 0, best agent cum rewards: -1422.769042917174
39
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1492.6487918974133
avg cum rews: -1492.6487918974133, std: 0.0
the best agent: 0, best agent cum rewards: -1492.6487918974133
40
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1035.6684146378523
avg cum rews: -1035.6684146378523, std: 0.0
the best agent: 0, best agent cum rewards: -1035.6684146378523
41
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1016.2454672970388
avg cum rews: -1016.2454672970388, std: 0.0
the best agent: 0, best agent cum rewards: -1016.2454672970388
42
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1103.7864579902423
avg cum rews: -1103.7864579902423, std: 0.0
the best agent: 0, best agent cum rewards: -1103.7864579902423
43
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1148.4353420440068
avg cum rews: -1148.4353420440068, std: 0.0
the best agent: 0, best agent cum rewards: -1148.4353420440068
44
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1194.400045354104
avg cum rews: -1194.400045354104, std: 0.0
the best agent: 0, best agent cum rewards: -1194.400045354104
45
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1308.8181412543147
avg cum rews: -1308.8181412543147, std: 0.0
the best agent: 0, best agent cum rewards: -1308.8181412543147
46
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1107.508020595014
avg cum rews: -1107.508020595014, std: 0.0
the best agent: 0, best agent cum rewards: -1107.508020595014
47
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1327.7032678503222
avg cum rews: -1327.7032678503222, std: 0.0
the best agent: 0, best agent cum rewards: -1327.7032678503222
Average distance of random agents to nearest neighbors: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Time taken for each iteration: [8.486612796783447, 16.91012692451477, 25.32006812095642, 34.12890124320984, 42.87293004989624, 51.61391878128052, 60.3415093421936, 69.07005786895752, 77.789137840271, 86.49554872512817, 95.210031747818, 103.94000458717346, 112.65927052497864, 121.39389491081238, 130.12195801734924, 138.85958671569824, 147.6142439842224, 156.3485541343689, 165.0965096950531, 173.861967086792, 182.62197852134705, 191.38367247581482, 200.1411018371582, 208.90266942977905, 217.68103504180908, 226.43881464004517, 235.19729948043823, 243.97936868667603, 252.76073145866394, 261.53852939605713, 270.33125042915344, 279.0955591201782, 287.8667175769806, 296.6258418560028, 305.39660120010376, 314.16775846481323, 322.93702840805054, 331.73054456710815, 340.5027930736542, 349.27015948295593, 358.03097581863403, 366.76811695098877, 375.5086841583252, 384.2734203338623, 393.04448556900024, 401.7936644554138, 410.54801201820374, 419.2907271385193]
