No devices were found
Setting seed -  0
Creating multiple envs -  4
---------------------------------
Environment created
Box(-2.0, 2.0, (1,), float32) Box([-1. -1. -8.], [1. 1. 8.], (3,), float32)
Starting evaluation
0
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1189.3226826627258
avg cum rews: -1189.3226826627258, std: 0.0
the best agent: 0, best agent cum rewards: -1189.3226826627258
2
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1573.8821364363596
avg cum rews: -1573.8821364363596, std: 0.0
the best agent: 0, best agent cum rewards: -1573.8821364363596
4
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1101.4725616969358
avg cum rews: -1101.4725616969358, std: 0.0
the best agent: 0, best agent cum rewards: -1101.4725616969358
6
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1579.5480632673696
avg cum rews: -1579.5480632673696, std: 0.0
the best agent: 0, best agent cum rewards: -1579.5480632673696
8
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1576.4618661761363
avg cum rews: -1576.4618661761363, std: 0.0
the best agent: 0, best agent cum rewards: -1576.4618661761363
10
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1264.4440101357832
avg cum rews: -1264.4440101357832, std: 0.0
the best agent: 0, best agent cum rewards: -1264.4440101357832
12
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1160.579226716589
avg cum rews: -1160.579226716589, std: 0.0
the best agent: 0, best agent cum rewards: -1160.579226716589
14
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -985.9397332712889
avg cum rews: -985.9397332712889, std: 0.0
the best agent: 0, best agent cum rewards: -985.9397332712889
16
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -420.0920134718808
avg cum rews: -420.0920134718808, std: 0.0
the best agent: 0, best agent cum rewards: -420.0920134718808
18
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1369.0445820217883
avg cum rews: -1369.0445820217883, std: 0.0
the best agent: 0, best agent cum rewards: -1369.0445820217883
20
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1474.208008144532
avg cum rews: -1474.208008144532, std: 0.0
the best agent: 0, best agent cum rewards: -1474.208008144532
22
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1279.859652661497
avg cum rews: -1279.859652661497, std: 0.0
the best agent: 0, best agent cum rewards: -1279.859652661497
24
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1502.033236087552
avg cum rews: -1502.033236087552, std: 0.0
the best agent: 0, best agent cum rewards: -1502.033236087552
26
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1453.1981000118399
avg cum rews: -1453.1981000118399, std: 0.0
the best agent: 0, best agent cum rewards: -1453.1981000118399
28
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1323.715091449543
avg cum rews: -1323.715091449543, std: 0.0
the best agent: 0, best agent cum rewards: -1323.715091449543
30
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1448.8663600633092
avg cum rews: -1448.8663600633092, std: 0.0
the best agent: 0, best agent cum rewards: -1448.8663600633092
32
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1442.0998675579199
avg cum rews: -1442.0998675579199, std: 0.0
the best agent: 0, best agent cum rewards: -1442.0998675579199
34
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1284.045674835649
avg cum rews: -1284.045674835649, std: 0.0
the best agent: 0, best agent cum rewards: -1284.045674835649
36
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1529.7107426437658
avg cum rews: -1529.7107426437658, std: 0.0
the best agent: 0, best agent cum rewards: -1529.7107426437658
38
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1030.1692089007054
avg cum rews: -1030.1692089007054, std: 0.0
the best agent: 0, best agent cum rewards: -1030.1692089007054
40
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1197.9819006950645
avg cum rews: -1197.9819006950645, std: 0.0
the best agent: 0, best agent cum rewards: -1197.9819006950645
42
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -588.4279016907408
avg cum rews: -588.4279016907408, std: 0.0
the best agent: 0, best agent cum rewards: -588.4279016907408
44
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1229.553325208796
avg cum rews: -1229.553325208796, std: 0.0
the best agent: 0, best agent cum rewards: -1229.553325208796
46
---------------------------------
Searching policies using Guided Evolutionary Strategies
avg return on 3 trajectories of agent0: -1133.549734162315
avg cum rews: -1133.549734162315, std: 0.0
the best agent: 0, best agent cum rewards: -1133.549734162315
Average distance of random agents to nearest neighbors: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Time taken for each iteration: [21.234572887420654, 42.737860441207886, 64.07060527801514, 85.57111430168152, 107.02712416648865, 128.93224143981934, 150.9344744682312, 173.47948384284973, 196.64540767669678, 219.96984934806824, 243.4485924243927, 267.45880460739136, 291.17489743232727, 314.90040731430054, 338.8790180683136, 362.76755142211914, 386.6526372432709, 410.5394403934479, 434.4239978790283, 458.02935791015625, 481.9276375770569, 505.67829871177673, 529.423707485199, 553.1904582977295]
