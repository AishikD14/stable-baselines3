No devices were found
Setting seed -  2
---------------------------------
Environment created
Box(-1.0, 1.0, (4,), float32) Box(-inf, inf, (16,), float64)
Starting training from scratch
Starting evaluation
1
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.017710420958562494
avg return on 3 trajectories of agent0: -50.0
avg return on 3 trajectories of agent1: -50.0
avg return on 3 trajectories of agent2: -50.0
avg return on 3 trajectories of agent3: -50.0
avg return on 3 trajectories of agent4: -50.0
avg return on 3 trajectories of agent5: -50.0
avg return on 3 trajectories of agent6: -50.0
avg return on 3 trajectories of agent7: -50.0
avg return on 3 trajectories of agent8: -50.0
avg return on 3 trajectories of agent9: -50.0
avg return on 3 trajectories of agent10: -50.0
avg return on 3 trajectories of agent11: -50.0
avg return on 3 trajectories of agent12: -50.0
avg return on 3 trajectories of agent13: -50.0
avg return on 3 trajectories of agent14: -50.0
avg return on 3 trajectories of agent15: -50.0
avg return on 3 trajectories of agent16: -50.0
avg return on 3 trajectories of agent17: -50.0
avg return on 3 trajectories of agent18: -50.0
avg return on 3 trajectories of agent19: -50.0
avg cum rews: -50.0, std: 0.0
the best agent: 19, best agent cum rewards: -50.0
2
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.020859460664031142
avg return on 3 trajectories of agent0: -48.0
avg return on 3 trajectories of agent1: -50.0
avg return on 3 trajectories of agent2: -50.0
avg return on 3 trajectories of agent3: -50.0
avg return on 3 trajectories of agent4: -50.0
avg return on 3 trajectories of agent5: -50.0
avg return on 3 trajectories of agent6: -50.0
avg return on 3 trajectories of agent7: -50.0
avg return on 3 trajectories of agent8: -50.0
avg return on 3 trajectories of agent9: -50.0
avg return on 3 trajectories of agent10: -50.0
avg return on 3 trajectories of agent11: -50.0
avg return on 3 trajectories of agent12: -46.666666666666664
avg return on 3 trajectories of agent13: -44.0
avg return on 3 trajectories of agent14: -41.0
avg return on 3 trajectories of agent15: -40.666666666666664
avg return on 3 trajectories of agent16: -50.0
avg return on 3 trajectories of agent17: -50.0
avg return on 3 trajectories of agent18: -48.333333333333336
avg return on 3 trajectories of agent19: -46.0
avg cum rews: -48.233333333333334, std: 2.9629189811550516
the best agent: 15, best agent cum rewards: -40.666666666666664
3
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.023388083684381576
avg return on 3 trajectories of agent0: -50.0
avg return on 3 trajectories of agent1: -50.0
avg return on 3 trajectories of agent2: -48.666666666666664
avg return on 3 trajectories of agent3: -47.333333333333336
avg return on 3 trajectories of agent4: -50.0
avg return on 3 trajectories of agent5: -50.0
avg return on 3 trajectories of agent6: -48.0
avg return on 3 trajectories of agent7: -47.333333333333336
avg return on 3 trajectories of agent8: -50.0
avg return on 3 trajectories of agent9: -50.0
avg return on 3 trajectories of agent10: -50.0
avg return on 3 trajectories of agent11: -50.0
avg return on 3 trajectories of agent12: -50.0
avg return on 3 trajectories of agent13: -50.0
avg return on 3 trajectories of agent14: -50.0
avg return on 3 trajectories of agent15: -50.0
avg return on 3 trajectories of agent16: -50.0
avg return on 3 trajectories of agent17: -50.0
avg return on 3 trajectories of agent18: -50.0
avg return on 3 trajectories of agent19: -50.0
avg cum rews: -49.56666666666667, std: 0.9012337223063845
the best agent: 7, best agent cum rewards: -47.333333333333336
4
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02816908020745252
avg return on 3 trajectories of agent0: -44.0
avg return on 3 trajectories of agent1: -48.333333333333336
avg return on 3 trajectories of agent2: -50.0
avg return on 3 trajectories of agent3: -50.0
avg return on 3 trajectories of agent4: -42.666666666666664
avg return on 3 trajectories of agent5: -46.0
avg return on 3 trajectories of agent6: -48.333333333333336
avg return on 3 trajectories of agent7: -50.0
avg return on 3 trajectories of agent8: -45.333333333333336
avg return on 3 trajectories of agent9: -44.0
avg return on 3 trajectories of agent10: -42.333333333333336
avg return on 3 trajectories of agent11: -41.333333333333336
avg return on 3 trajectories of agent12: -48.0
avg return on 3 trajectories of agent13: -48.333333333333336
avg return on 3 trajectories of agent14: -49.333333333333336
avg return on 3 trajectories of agent15: -49.666666666666664
avg return on 3 trajectories of agent16: -48.0
avg return on 3 trajectories of agent17: -48.333333333333336
avg return on 3 trajectories of agent18: -48.0
avg return on 3 trajectories of agent19: -45.666666666666664
avg cum rews: -46.88333333333334, std: 2.698301935168363
the best agent: 11, best agent cum rewards: -41.333333333333336
5
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.022676409441297993
avg return on 3 trajectories of agent0: -50.0
avg return on 3 trajectories of agent1: -49.666666666666664
avg return on 3 trajectories of agent2: -48.333333333333336
avg return on 3 trajectories of agent3: -48.333333333333336
avg return on 3 trajectories of agent4: -47.666666666666664
avg return on 3 trajectories of agent5: -46.666666666666664
avg return on 3 trajectories of agent6: -46.0
avg return on 3 trajectories of agent7: -45.0
avg return on 3 trajectories of agent8: -50.0
avg return on 3 trajectories of agent9: -49.333333333333336
avg return on 3 trajectories of agent10: -49.0
avg return on 3 trajectories of agent11: -49.0
avg return on 3 trajectories of agent12: -47.333333333333336
avg return on 3 trajectories of agent13: -46.666666666666664
avg return on 3 trajectories of agent14: -46.333333333333336
avg return on 3 trajectories of agent15: -45.666666666666664
avg return on 3 trajectories of agent16: -47.666666666666664
avg return on 3 trajectories of agent17: -46.666666666666664
avg return on 3 trajectories of agent18: -46.333333333333336
avg return on 3 trajectories of agent19: -45.333333333333336
avg cum rews: -47.55, std: 1.546591233792706
the best agent: 7, best agent cum rewards: -45.0
6
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.031358012476222726
avg return on 3 trajectories of agent0: -50.0
avg return on 3 trajectories of agent1: -48.0
avg return on 3 trajectories of agent2: -47.0
avg return on 3 trajectories of agent3: -50.0
avg return on 3 trajectories of agent4: -50.0
avg return on 3 trajectories of agent5: -50.0
avg return on 3 trajectories of agent6: -50.0
avg return on 3 trajectories of agent7: -50.0
avg return on 3 trajectories of agent8: -50.0
avg return on 3 trajectories of agent9: -50.0
avg return on 3 trajectories of agent10: -50.0
avg return on 3 trajectories of agent11: -50.0
avg return on 3 trajectories of agent12: -50.0
avg return on 3 trajectories of agent13: -50.0
avg return on 3 trajectories of agent14: -50.0
avg return on 3 trajectories of agent15: -50.0
avg return on 3 trajectories of agent16: -45.333333333333336
avg return on 3 trajectories of agent17: -45.333333333333336
avg return on 3 trajectories of agent18: -49.0
avg return on 3 trajectories of agent19: -50.0
avg cum rews: -49.233333333333334, std: 1.513274595042155
the best agent: 16, best agent cum rewards: -45.333333333333336
7
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.027563763520831508
avg return on 3 trajectories of agent0: -50.0
avg return on 3 trajectories of agent1: -50.0
avg return on 3 trajectories of agent2: -50.0
avg return on 3 trajectories of agent3: -50.0
avg return on 3 trajectories of agent4: -50.0
avg return on 3 trajectories of agent5: -50.0
avg return on 3 trajectories of agent6: -50.0
avg return on 3 trajectories of agent7: -50.0
avg return on 3 trajectories of agent8: -50.0
avg return on 3 trajectories of agent9: -50.0
avg return on 3 trajectories of agent10: -50.0
avg return on 3 trajectories of agent11: -50.0
avg return on 3 trajectories of agent12: -50.0
avg return on 3 trajectories of agent13: -50.0
avg return on 3 trajectories of agent14: -50.0
avg return on 3 trajectories of agent15: -50.0
avg return on 3 trajectories of agent16: -50.0
avg return on 3 trajectories of agent17: -50.0
avg return on 3 trajectories of agent18: -50.0
avg return on 3 trajectories of agent19: -50.0
avg cum rews: -50.0, std: 0.0
the best agent: 19, best agent cum rewards: -50.0
8
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.028053835567248026
avg return on 3 trajectories of agent0: -50.0
avg return on 3 trajectories of agent1: -50.0
avg return on 3 trajectories of agent2: -50.0
avg return on 3 trajectories of agent3: -50.0
avg return on 3 trajectories of agent4: -50.0
avg return on 3 trajectories of agent5: -50.0
avg return on 3 trajectories of agent6: -50.0
avg return on 3 trajectories of agent7: -50.0
avg return on 3 trajectories of agent8: -50.0
avg return on 3 trajectories of agent9: -50.0
avg return on 3 trajectories of agent10: -50.0
avg return on 3 trajectories of agent11: -47.0
avg return on 3 trajectories of agent12: -50.0
avg return on 3 trajectories of agent13: -50.0
avg return on 3 trajectories of agent14: -50.0
avg return on 3 trajectories of agent15: -50.0
avg return on 3 trajectories of agent16: -50.0
avg return on 3 trajectories of agent17: -50.0
avg return on 3 trajectories of agent18: -50.0
avg return on 3 trajectories of agent19: -50.0
avg cum rews: -49.85, std: 0.6538348415311009
the best agent: 11, best agent cum rewards: -47.0
9
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.026506795000441185
avg return on 3 trajectories of agent0: -50.0
avg return on 3 trajectories of agent1: -49.333333333333336
avg return on 3 trajectories of agent2: -39.333333333333336
avg return on 3 trajectories of agent3: -39.0
avg return on 3 trajectories of agent4: -50.0
avg return on 3 trajectories of agent5: -50.0
avg return on 3 trajectories of agent6: -50.0
avg return on 3 trajectories of agent7: -50.0
avg return on 3 trajectories of agent8: -50.0
avg return on 3 trajectories of agent9: -39.333333333333336
avg return on 3 trajectories of agent10: -39.0
avg return on 3 trajectories of agent11: -39.0
avg return on 3 trajectories of agent12: -50.0
avg return on 3 trajectories of agent13: -50.0
avg return on 3 trajectories of agent14: -50.0
avg return on 3 trajectories of agent15: -50.0
avg return on 3 trajectories of agent16: -50.0
avg return on 3 trajectories of agent17: -50.0
avg return on 3 trajectories of agent18: -50.0
avg return on 3 trajectories of agent19: -50.0
avg cum rews: -47.25, std: 4.689083066016212
the best agent: 11, best agent cum rewards: -39.0
10
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02622065071155314
avg return on 3 trajectories of agent0: -50.0
avg return on 3 trajectories of agent1: -50.0
avg return on 3 trajectories of agent2: -50.0
avg return on 3 trajectories of agent3: -50.0
avg return on 3 trajectories of agent4: -50.0
avg return on 3 trajectories of agent5: -50.0
avg return on 3 trajectories of agent6: -50.0
avg return on 3 trajectories of agent7: -50.0
avg return on 3 trajectories of agent8: -50.0
avg return on 3 trajectories of agent9: -50.0
avg return on 3 trajectories of agent10: -50.0
avg return on 3 trajectories of agent11: -48.666666666666664
avg return on 3 trajectories of agent12: -50.0
avg return on 3 trajectories of agent13: -50.0
avg return on 3 trajectories of agent14: -50.0
avg return on 3 trajectories of agent15: -50.0
avg return on 3 trajectories of agent16: -50.0
avg return on 3 trajectories of agent17: -50.0
avg return on 3 trajectories of agent18: -48.0
avg return on 3 trajectories of agent19: -45.0
avg cum rews: -49.58333333333333, std: 1.168451016422074
the best agent: 19, best agent cum rewards: -45.0
11
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.023756987735174494
avg return on 3 trajectories of agent0: -50.0
avg return on 3 trajectories of agent1: -50.0
avg return on 3 trajectories of agent2: -47.666666666666664
avg return on 3 trajectories of agent3: -42.333333333333336
avg return on 3 trajectories of agent4: -50.0
avg return on 3 trajectories of agent5: -50.0
avg return on 3 trajectories of agent6: -47.666666666666664
avg return on 3 trajectories of agent7: -46.666666666666664
avg return on 3 trajectories of agent8: -50.0
avg return on 3 trajectories of agent9: -46.0
avg return on 3 trajectories of agent10: -41.666666666666664
avg return on 3 trajectories of agent11: -40.666666666666664
avg return on 3 trajectories of agent12: -45.0
avg return on 3 trajectories of agent13: -49.333333333333336
avg return on 3 trajectories of agent14: -50.0
avg return on 3 trajectories of agent15: -50.0
avg return on 3 trajectories of agent16: -41.666666666666664
avg return on 3 trajectories of agent17: -50.0
avg return on 3 trajectories of agent18: -50.0
avg return on 3 trajectories of agent19: -50.0
avg cum rews: -47.43333333333333, std: 3.2898834832457724
the best agent: 11, best agent cum rewards: -40.666666666666664
12
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.025207309469282894
avg return on 3 trajectories of agent0: -48.333333333333336
avg return on 3 trajectories of agent1: -45.666666666666664
avg return on 3 trajectories of agent2: -46.333333333333336
avg return on 3 trajectories of agent3: -47.333333333333336
avg return on 3 trajectories of agent4: -50.0
avg return on 3 trajectories of agent5: -50.0
avg return on 3 trajectories of agent6: -50.0
avg return on 3 trajectories of agent7: -50.0
avg return on 3 trajectories of agent8: -50.0
avg return on 3 trajectories of agent9: -50.0
avg return on 3 trajectories of agent10: -50.0
avg return on 3 trajectories of agent11: -50.0
avg return on 3 trajectories of agent12: -46.0
avg return on 3 trajectories of agent13: -44.666666666666664
avg return on 3 trajectories of agent14: -46.0
avg return on 3 trajectories of agent15: -47.333333333333336
avg return on 3 trajectories of agent16: -44.333333333333336
avg return on 3 trajectories of agent17: -38.0
avg return on 3 trajectories of agent18: -37.666666666666664
avg return on 3 trajectories of agent19: -37.666666666666664
avg cum rews: -46.46666666666667, std: 4.124991582482994
the best agent: 19, best agent cum rewards: -37.666666666666664
13
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.027854786886491095
avg return on 3 trajectories of agent0: -38.666666666666664
avg return on 3 trajectories of agent1: -36.333333333333336
avg return on 3 trajectories of agent2: -36.333333333333336
avg return on 3 trajectories of agent3: -36.333333333333336
avg return on 3 trajectories of agent4: -36.333333333333336
avg return on 3 trajectories of agent5: -36.333333333333336
avg return on 3 trajectories of agent6: -36.333333333333336
avg return on 3 trajectories of agent7: -36.0
avg return on 3 trajectories of agent8: -39.0
avg return on 3 trajectories of agent9: -44.333333333333336
avg return on 3 trajectories of agent10: -48.0
avg return on 3 trajectories of agent11: -50.0
avg return on 3 trajectories of agent12: -36.333333333333336
avg return on 3 trajectories of agent13: -36.0
avg return on 3 trajectories of agent14: -35.666666666666664
avg return on 3 trajectories of agent15: -35.666666666666664
avg return on 3 trajectories of agent16: -36.333333333333336
avg return on 3 trajectories of agent17: -36.0
avg return on 3 trajectories of agent18: -35.666666666666664
avg return on 3 trajectories of agent19: -35.666666666666664
avg cum rews: -38.06666666666666, std: 4.131989028704376
the best agent: 19, best agent cum rewards: -35.666666666666664
14
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02776704077588426
avg return on 3 trajectories of agent0: -35.333333333333336
avg return on 3 trajectories of agent1: -35.666666666666664
avg return on 3 trajectories of agent2: -35.666666666666664
avg return on 3 trajectories of agent3: -49.0
avg return on 3 trajectories of agent4: -35.333333333333336
avg return on 3 trajectories of agent5: -35.333333333333336
avg return on 3 trajectories of agent6: -35.333333333333336
avg return on 3 trajectories of agent7: -35.333333333333336
avg return on 3 trajectories of agent8: -35.333333333333336
avg return on 3 trajectories of agent9: -35.333333333333336
avg return on 3 trajectories of agent10: -35.333333333333336
avg return on 3 trajectories of agent11: -35.333333333333336
avg return on 3 trajectories of agent12: -35.333333333333336
avg return on 3 trajectories of agent13: -35.333333333333336
avg return on 3 trajectories of agent14: -35.333333333333336
avg return on 3 trajectories of agent15: -35.333333333333336
avg return on 3 trajectories of agent16: -35.333333333333336
avg return on 3 trajectories of agent17: -35.333333333333336
avg return on 3 trajectories of agent18: -35.0
avg return on 3 trajectories of agent19: -35.0
avg cum rews: -36.01666666666667, std: 2.9823089488962515
the best agent: 19, best agent cum rewards: -35.0
15
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02833635987254679
avg return on 3 trajectories of agent0: -34.666666666666664
avg return on 3 trajectories of agent1: -39.0
avg return on 3 trajectories of agent2: -44.333333333333336
avg return on 3 trajectories of agent3: -48.333333333333336
avg return on 3 trajectories of agent4: -39.0
avg return on 3 trajectories of agent5: -43.0
avg return on 3 trajectories of agent6: -46.666666666666664
avg return on 3 trajectories of agent7: -49.333333333333336
avg return on 3 trajectories of agent8: -34.666666666666664
avg return on 3 trajectories of agent9: -34.666666666666664
avg return on 3 trajectories of agent10: -34.666666666666664
avg return on 3 trajectories of agent11: -34.666666666666664
avg return on 3 trajectories of agent12: -38.666666666666664
avg return on 3 trajectories of agent13: -34.666666666666664
avg return on 3 trajectories of agent14: -34.666666666666664
avg return on 3 trajectories of agent15: -34.666666666666664
avg return on 3 trajectories of agent16: -36.0
avg return on 3 trajectories of agent17: -41.333333333333336
avg return on 3 trajectories of agent18: -44.333333333333336
avg return on 3 trajectories of agent19: -46.0
avg cum rews: -39.66666666666667, std: 5.1499730312131
the best agent: 11, best agent cum rewards: -34.666666666666664
16
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.022248129854409274
avg return on 3 trajectories of agent0: -35.0
avg return on 3 trajectories of agent1: -35.0
avg return on 3 trajectories of agent2: -35.0
avg return on 3 trajectories of agent3: -35.333333333333336
avg return on 3 trajectories of agent4: -35.0
avg return on 3 trajectories of agent5: -35.0
avg return on 3 trajectories of agent6: -35.0
avg return on 3 trajectories of agent7: -35.0
avg return on 3 trajectories of agent8: -35.0
avg return on 3 trajectories of agent9: -35.0
avg return on 3 trajectories of agent10: -35.0
avg return on 3 trajectories of agent11: -36.0
avg return on 3 trajectories of agent12: -35.0
avg return on 3 trajectories of agent13: -35.0
avg return on 3 trajectories of agent14: -35.0
avg return on 3 trajectories of agent15: -49.333333333333336
avg return on 3 trajectories of agent16: -35.0
avg return on 3 trajectories of agent17: -35.0
avg return on 3 trajectories of agent18: -35.0
avg return on 3 trajectories of agent19: -35.0
avg cum rews: -35.78333333333334, std: 3.116755791952053
the best agent: 19, best agent cum rewards: -35.0
17
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02481040600905219
avg return on 3 trajectories of agent0: -35.0
avg return on 3 trajectories of agent1: -35.0
avg return on 3 trajectories of agent2: -35.0
avg return on 3 trajectories of agent3: -35.0
avg return on 3 trajectories of agent4: -35.0
avg return on 3 trajectories of agent5: -35.0
avg return on 3 trajectories of agent6: -49.666666666666664
avg return on 3 trajectories of agent7: -50.0
avg return on 3 trajectories of agent8: -34.666666666666664
avg return on 3 trajectories of agent9: -34.666666666666664
avg return on 3 trajectories of agent10: -41.333333333333336
avg return on 3 trajectories of agent11: -45.333333333333336
avg return on 3 trajectories of agent12: -35.0
avg return on 3 trajectories of agent13: -35.333333333333336
avg return on 3 trajectories of agent14: -50.0
avg return on 3 trajectories of agent15: -50.0
avg return on 3 trajectories of agent16: -35.0
avg return on 3 trajectories of agent17: -35.0
avg return on 3 trajectories of agent18: -48.0
avg return on 3 trajectories of agent19: -50.0
avg cum rews: -40.2, std: 6.672830483885131
the best agent: 8, best agent cum rewards: -34.666666666666664
18
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.025148636363643638
avg return on 3 trajectories of agent0: -45.666666666666664
avg return on 3 trajectories of agent1: -42.666666666666664
avg return on 3 trajectories of agent2: -41.666666666666664
avg return on 3 trajectories of agent3: -41.666666666666664
avg return on 3 trajectories of agent4: -49.333333333333336
avg return on 3 trajectories of agent5: -49.666666666666664
avg return on 3 trajectories of agent6: -50.0
avg return on 3 trajectories of agent7: -50.0
avg return on 3 trajectories of agent8: -39.333333333333336
avg return on 3 trajectories of agent9: -46.666666666666664
avg return on 3 trajectories of agent10: -50.0
avg return on 3 trajectories of agent11: -50.0
avg return on 3 trajectories of agent12: -35.0
avg return on 3 trajectories of agent13: -35.0
avg return on 3 trajectories of agent14: -35.0
avg return on 3 trajectories of agent15: -34.666666666666664
avg return on 3 trajectories of agent16: -38.666666666666664
avg return on 3 trajectories of agent17: -35.0
avg return on 3 trajectories of agent18: -35.0
avg return on 3 trajectories of agent19: -35.0
avg cum rews: -41.99999999999999, std: 6.206627282366989
the best agent: 15, best agent cum rewards: -34.666666666666664
19
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.021247084942505247
avg return on 3 trajectories of agent0: -35.0
avg return on 3 trajectories of agent1: -35.0
avg return on 3 trajectories of agent2: -35.0
avg return on 3 trajectories of agent3: -34.666666666666664
avg return on 3 trajectories of agent4: -37.666666666666664
avg return on 3 trajectories of agent5: -35.0
avg return on 3 trajectories of agent6: -35.0
avg return on 3 trajectories of agent7: -35.0
avg return on 3 trajectories of agent8: -37.333333333333336
avg return on 3 trajectories of agent9: -35.0
avg return on 3 trajectories of agent10: -35.0
avg return on 3 trajectories of agent11: -35.0
avg return on 3 trajectories of agent12: -35.0
avg return on 3 trajectories of agent13: -35.0
avg return on 3 trajectories of agent14: -34.666666666666664
avg return on 3 trajectories of agent15: -36.666666666666664
avg return on 3 trajectories of agent16: -35.0
avg return on 3 trajectories of agent17: -35.0
avg return on 3 trajectories of agent18: -34.666666666666664
avg return on 3 trajectories of agent19: -34.666666666666664
avg cum rews: -35.266666666666666, std: 0.8472176684759223
the best agent: 19, best agent cum rewards: -34.666666666666664
20
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02289757924058524
avg return on 3 trajectories of agent0: -35.0
avg return on 3 trajectories of agent1: -43.0
avg return on 3 trajectories of agent2: -49.0
avg return on 3 trajectories of agent3: -50.0
avg return on 3 trajectories of agent4: -35.0
avg return on 3 trajectories of agent5: -42.333333333333336
avg return on 3 trajectories of agent6: -46.333333333333336
avg return on 3 trajectories of agent7: -48.333333333333336
avg return on 3 trajectories of agent8: -35.0
avg return on 3 trajectories of agent9: -43.666666666666664
avg return on 3 trajectories of agent10: -49.0
avg return on 3 trajectories of agent11: -50.0
avg return on 3 trajectories of agent12: -38.333333333333336
avg return on 3 trajectories of agent13: -38.333333333333336
avg return on 3 trajectories of agent14: -35.333333333333336
avg return on 3 trajectories of agent15: -35.333333333333336
avg return on 3 trajectories of agent16: -38.666666666666664
avg return on 3 trajectories of agent17: -45.0
avg return on 3 trajectories of agent18: -47.666666666666664
avg return on 3 trajectories of agent19: -48.666666666666664
avg cum rews: -42.699999999999996, std: 5.649877088141927
the best agent: 4, best agent cum rewards: -35.0
21
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02489084401210515
avg return on 3 trajectories of agent0: -50.0
avg return on 3 trajectories of agent1: -45.0
avg return on 3 trajectories of agent2: -45.666666666666664
avg return on 3 trajectories of agent3: -47.333333333333336
avg return on 3 trajectories of agent4: -50.0
avg return on 3 trajectories of agent5: -49.0
avg return on 3 trajectories of agent6: -47.0
avg return on 3 trajectories of agent7: -46.666666666666664
avg return on 3 trajectories of agent8: -50.0
avg return on 3 trajectories of agent9: -50.0
avg return on 3 trajectories of agent10: -50.0
avg return on 3 trajectories of agent11: -50.0
avg return on 3 trajectories of agent12: -47.333333333333336
avg return on 3 trajectories of agent13: -49.333333333333336
avg return on 3 trajectories of agent14: -50.0
avg return on 3 trajectories of agent15: -50.0
avg return on 3 trajectories of agent16: -44.666666666666664
avg return on 3 trajectories of agent17: -46.0
avg return on 3 trajectories of agent18: -45.333333333333336
avg return on 3 trajectories of agent19: -48.0
avg cum rews: -48.06666666666667, std: 1.9367785395111936
the best agent: 16, best agent cum rewards: -44.666666666666664
22
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.023564419448061917
avg return on 3 trajectories of agent0: -49.0
avg return on 3 trajectories of agent1: -50.0
avg return on 3 trajectories of agent2: -50.0
avg return on 3 trajectories of agent3: -50.0
avg return on 3 trajectories of agent4: -47.0
avg return on 3 trajectories of agent5: -49.333333333333336
avg return on 3 trajectories of agent6: -50.0
avg return on 3 trajectories of agent7: -50.0
avg return on 3 trajectories of agent8: -38.666666666666664
avg return on 3 trajectories of agent9: -35.333333333333336
avg return on 3 trajectories of agent10: -35.333333333333336
avg return on 3 trajectories of agent11: -35.0
avg return on 3 trajectories of agent12: -41.333333333333336
avg return on 3 trajectories of agent13: -45.666666666666664
avg return on 3 trajectories of agent14: -49.0
avg return on 3 trajectories of agent15: -49.666666666666664
avg return on 3 trajectories of agent16: -41.333333333333336
avg return on 3 trajectories of agent17: -46.0
avg return on 3 trajectories of agent18: -49.0
avg return on 3 trajectories of agent19: -50.0
avg cum rews: -45.583333333333336, std: 5.4363744045702616
the best agent: 11, best agent cum rewards: -35.0
23
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.025576117420754486
avg return on 3 trajectories of agent0: -31.0
avg return on 3 trajectories of agent1: -35.0
avg return on 3 trajectories of agent2: -35.0
avg return on 3 trajectories of agent3: -35.333333333333336
avg return on 3 trajectories of agent4: -25.666666666666668
avg return on 3 trajectories of agent5: -21.333333333333332
avg return on 3 trajectories of agent6: -19.666666666666668
avg return on 3 trajectories of agent7: -35.0
avg return on 3 trajectories of agent8: -35.0
avg return on 3 trajectories of agent9: -34.666666666666664
avg return on 3 trajectories of agent10: -34.666666666666664
avg return on 3 trajectories of agent11: -34.666666666666664
avg return on 3 trajectories of agent12: -28.333333333333332
avg return on 3 trajectories of agent13: -24.333333333333332
avg return on 3 trajectories of agent14: -23.666666666666668
avg return on 3 trajectories of agent15: -29.333333333333332
avg return on 3 trajectories of agent16: -30.666666666666668
avg return on 3 trajectories of agent17: -31.0
avg return on 3 trajectories of agent18: -28.333333333333332
avg return on 3 trajectories of agent19: -34.666666666666664
avg cum rews: -30.366666666666664, std: 4.970915408654627
the best agent: 6, best agent cum rewards: -19.666666666666668
24
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02607832554991204
avg return on 3 trajectories of agent0: -25.0
avg return on 3 trajectories of agent1: -49.666666666666664
avg return on 3 trajectories of agent2: -50.0
avg return on 3 trajectories of agent3: -50.0
avg return on 3 trajectories of agent4: -21.666666666666668
avg return on 3 trajectories of agent5: -19.666666666666668
avg return on 3 trajectories of agent6: -22.666666666666668
avg return on 3 trajectories of agent7: -26.333333333333332
avg return on 3 trajectories of agent8: -22.666666666666668
avg return on 3 trajectories of agent9: -22.0
avg return on 3 trajectories of agent10: -23.333333333333332
avg return on 3 trajectories of agent11: -29.666666666666668
avg return on 3 trajectories of agent12: -25.333333333333332
avg return on 3 trajectories of agent13: -35.0
avg return on 3 trajectories of agent14: -36.333333333333336
avg return on 3 trajectories of agent15: -43.333333333333336
avg return on 3 trajectories of agent16: -23.666666666666668
avg return on 3 trajectories of agent17: -35.333333333333336
avg return on 3 trajectories of agent18: -35.333333333333336
avg return on 3 trajectories of agent19: -36.333333333333336
avg cum rews: -31.666666666666675, std: 9.909030673526493
the best agent: 5, best agent cum rewards: -19.666666666666668
25
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02854021527271148
avg return on 3 trajectories of agent0: -11.0
avg return on 3 trajectories of agent1: -14.333333333333334
avg return on 3 trajectories of agent2: -12.0
avg return on 3 trajectories of agent3: -18.666666666666668
avg return on 3 trajectories of agent4: -12.333333333333334
avg return on 3 trajectories of agent5: -20.333333333333332
avg return on 3 trajectories of agent6: -20.333333333333332
avg return on 3 trajectories of agent7: -21.333333333333332
avg return on 3 trajectories of agent8: -10.666666666666666
avg return on 3 trajectories of agent9: -15.666666666666666
avg return on 3 trajectories of agent10: -20.0
avg return on 3 trajectories of agent11: -21.666666666666668
avg return on 3 trajectories of agent12: -13.0
avg return on 3 trajectories of agent13: -11.0
avg return on 3 trajectories of agent14: -11.333333333333334
avg return on 3 trajectories of agent15: -11.666666666666666
avg return on 3 trajectories of agent16: -10.666666666666666
avg return on 3 trajectories of agent17: -14.0
avg return on 3 trajectories of agent18: -17.0
avg return on 3 trajectories of agent19: -23.666666666666668
avg cum rews: -15.533333333333335, std: 4.297803056342985
the best agent: 16, best agent cum rewards: -10.666666666666666
26
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.027678258203400995
avg return on 3 trajectories of agent0: -9.333333333333334
avg return on 3 trajectories of agent1: -15.0
avg return on 3 trajectories of agent2: -21.0
avg return on 3 trajectories of agent3: -23.333333333333332
avg return on 3 trajectories of agent4: -8.666666666666666
avg return on 3 trajectories of agent5: -14.0
avg return on 3 trajectories of agent6: -18.333333333333332
avg return on 3 trajectories of agent7: -23.333333333333332
avg return on 3 trajectories of agent8: -8.666666666666666
avg return on 3 trajectories of agent9: -8.333333333333334
avg return on 3 trajectories of agent10: -8.0
avg return on 3 trajectories of agent11: -14.0
avg return on 3 trajectories of agent12: -8.333333333333334
avg return on 3 trajectories of agent13: -9.0
avg return on 3 trajectories of agent14: -13.0
avg return on 3 trajectories of agent15: -17.666666666666668
avg return on 3 trajectories of agent16: -8.333333333333334
avg return on 3 trajectories of agent17: -19.333333333333332
avg return on 3 trajectories of agent18: -23.0
avg return on 3 trajectories of agent19: -24.666666666666668
avg cum rews: -14.76666666666667, std: 5.936796741977576
the best agent: 10, best agent cum rewards: -8.0
27
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.027822585340344746
avg return on 3 trajectories of agent0: -7.666666666666667
avg return on 3 trajectories of agent1: -12.0
avg return on 3 trajectories of agent2: -15.0
avg return on 3 trajectories of agent3: -17.333333333333332
avg return on 3 trajectories of agent4: -9.333333333333334
avg return on 3 trajectories of agent5: -8.333333333333334
avg return on 3 trajectories of agent6: -9.0
avg return on 3 trajectories of agent7: -20.0
avg return on 3 trajectories of agent8: -11.333333333333334
avg return on 3 trajectories of agent9: -14.666666666666666
avg return on 3 trajectories of agent10: -16.0
avg return on 3 trajectories of agent11: -17.666666666666668
avg return on 3 trajectories of agent12: -7.333333333333333
avg return on 3 trajectories of agent13: -12.666666666666666
avg return on 3 trajectories of agent14: -15.0
avg return on 3 trajectories of agent15: -19.666666666666668
avg return on 3 trajectories of agent16: -7.666666666666667
avg return on 3 trajectories of agent17: -12.0
avg return on 3 trajectories of agent18: -18.333333333333332
avg return on 3 trajectories of agent19: -43.666666666666664
avg cum rews: -14.733333333333334, std: 7.770742850232817
the best agent: 12, best agent cum rewards: -7.333333333333333
28
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.025916629227222432
avg return on 3 trajectories of agent0: -19.0
avg return on 3 trajectories of agent1: -21.333333333333332
avg return on 3 trajectories of agent2: -22.666666666666668
avg return on 3 trajectories of agent3: -29.666666666666668
avg return on 3 trajectories of agent4: -19.0
avg return on 3 trajectories of agent5: -20.333333333333332
avg return on 3 trajectories of agent6: -22.333333333333332
avg return on 3 trajectories of agent7: -22.666666666666668
avg return on 3 trajectories of agent8: -7.333333333333333
avg return on 3 trajectories of agent9: -7.0
avg return on 3 trajectories of agent10: -13.0
avg return on 3 trajectories of agent11: -28.333333333333332
avg return on 3 trajectories of agent12: -7.0
avg return on 3 trajectories of agent13: -7.0
avg return on 3 trajectories of agent14: -7.0
avg return on 3 trajectories of agent15: -15.666666666666666
avg return on 3 trajectories of agent16: -7.333333333333333
avg return on 3 trajectories of agent17: -6.666666666666667
avg return on 3 trajectories of agent18: -6.0
avg return on 3 trajectories of agent19: -6.0
avg cum rews: -14.76666666666667, std: 7.978512810459519
the best agent: 19, best agent cum rewards: -6.0
29
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.025810135360792956
avg return on 3 trajectories of agent0: -6.666666666666667
avg return on 3 trajectories of agent1: -18.0
avg return on 3 trajectories of agent2: -33.333333333333336
avg return on 3 trajectories of agent3: -43.0
avg return on 3 trajectories of agent4: -11.666666666666666
avg return on 3 trajectories of agent5: -20.0
avg return on 3 trajectories of agent6: -22.666666666666668
avg return on 3 trajectories of agent7: -35.666666666666664
avg return on 3 trajectories of agent8: -6.0
avg return on 3 trajectories of agent9: -5.333333333333333
avg return on 3 trajectories of agent10: -12.666666666666666
avg return on 3 trajectories of agent11: -15.666666666666666
avg return on 3 trajectories of agent12: -5.666666666666667
avg return on 3 trajectories of agent13: -15.333333333333334
avg return on 3 trajectories of agent14: -20.0
avg return on 3 trajectories of agent15: -20.666666666666668
avg return on 3 trajectories of agent16: -5.666666666666667
avg return on 3 trajectories of agent17: -12.666666666666666
avg return on 3 trajectories of agent18: -20.0
avg return on 3 trajectories of agent19: -20.333333333333332
avg cum rews: -17.550000000000004, std: 10.151778716614695
the best agent: 9, best agent cum rewards: -5.333333333333333
30
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.026075135497006918
avg return on 3 trajectories of agent0: -5.333333333333333
avg return on 3 trajectories of agent1: -6.0
avg return on 3 trajectories of agent2: -15.666666666666666
avg return on 3 trajectories of agent3: -20.333333333333332
avg return on 3 trajectories of agent4: -5.333333333333333
avg return on 3 trajectories of agent5: -5.666666666666667
avg return on 3 trajectories of agent6: -5.666666666666667
avg return on 3 trajectories of agent7: -6.0
avg return on 3 trajectories of agent8: -5.333333333333333
avg return on 3 trajectories of agent9: -5.333333333333333
avg return on 3 trajectories of agent10: -5.333333333333333
avg return on 3 trajectories of agent11: -5.333333333333333
avg return on 3 trajectories of agent12: -5.666666666666667
avg return on 3 trajectories of agent13: -5.666666666666667
avg return on 3 trajectories of agent14: -6.0
avg return on 3 trajectories of agent15: -11.666666666666666
avg return on 3 trajectories of agent16: -5.666666666666667
avg return on 3 trajectories of agent17: -5.666666666666667
avg return on 3 trajectories of agent18: -6.0
avg return on 3 trajectories of agent19: -10.333333333333334
avg cum rews: -7.4, std: 3.9617616732402707
the best agent: 11, best agent cum rewards: -5.333333333333333
31
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.026021160973582015
avg return on 3 trajectories of agent0: -5.0
avg return on 3 trajectories of agent1: -5.333333333333333
avg return on 3 trajectories of agent2: -5.666666666666667
avg return on 3 trajectories of agent3: -15.333333333333334
avg return on 3 trajectories of agent4: -5.0
avg return on 3 trajectories of agent5: -5.333333333333333
avg return on 3 trajectories of agent6: -7.333333333333333
avg return on 3 trajectories of agent7: -17.333333333333332
avg return on 3 trajectories of agent8: -5.333333333333333
avg return on 3 trajectories of agent9: -5.666666666666667
avg return on 3 trajectories of agent10: -6.0
avg return on 3 trajectories of agent11: -7.666666666666667
avg return on 3 trajectories of agent12: -4.666666666666667
avg return on 3 trajectories of agent13: -4.666666666666667
avg return on 3 trajectories of agent14: -4.666666666666667
avg return on 3 trajectories of agent15: -4.666666666666667
avg return on 3 trajectories of agent16: -4.666666666666667
avg return on 3 trajectories of agent17: -5.0
avg return on 3 trajectories of agent18: -4.666666666666667
avg return on 3 trajectories of agent19: -4.666666666666667
avg cum rews: -6.4333333333333345, std: 3.415812901459589
the best agent: 19, best agent cum rewards: -4.666666666666667
32
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.024888972053705462
avg return on 3 trajectories of agent0: -4.333333333333333
avg return on 3 trajectories of agent1: -4.666666666666667
avg return on 3 trajectories of agent2: -5.0
avg return on 3 trajectories of agent3: -14.666666666666666
avg return on 3 trajectories of agent4: -4.666666666666667
avg return on 3 trajectories of agent5: -4.666666666666667
avg return on 3 trajectories of agent6: -4.666666666666667
avg return on 3 trajectories of agent7: -5.0
avg return on 3 trajectories of agent8: -4.666666666666667
avg return on 3 trajectories of agent9: -4.666666666666667
avg return on 3 trajectories of agent10: -4.333333333333333
avg return on 3 trajectories of agent11: -8.333333333333334
avg return on 3 trajectories of agent12: -4.666666666666667
avg return on 3 trajectories of agent13: -4.333333333333333
avg return on 3 trajectories of agent14: -4.666666666666667
avg return on 3 trajectories of agent15: -5.333333333333333
avg return on 3 trajectories of agent16: -4.666666666666667
avg return on 3 trajectories of agent17: -4.333333333333333
avg return on 3 trajectories of agent18: -4.666666666666667
avg return on 3 trajectories of agent19: -5.0
avg cum rews: -5.366666666666666, std: 2.2898325994127458
the best agent: 17, best agent cum rewards: -4.333333333333333
33
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.026641928865816546
avg return on 3 trajectories of agent0: -4.333333333333333
avg return on 3 trajectories of agent1: -4.666666666666667
avg return on 3 trajectories of agent2: -5.0
avg return on 3 trajectories of agent3: -5.666666666666667
avg return on 3 trajectories of agent4: -4.333333333333333
avg return on 3 trajectories of agent5: -4.666666666666667
avg return on 3 trajectories of agent6: -4.666666666666667
avg return on 3 trajectories of agent7: -5.0
avg return on 3 trajectories of agent8: -4.0
avg return on 3 trajectories of agent9: -4.0
avg return on 3 trajectories of agent10: -4.0
avg return on 3 trajectories of agent11: -4.0
avg return on 3 trajectories of agent12: -4.0
avg return on 3 trajectories of agent13: -4.0
avg return on 3 trajectories of agent14: -3.6666666666666665
avg return on 3 trajectories of agent15: -4.0
avg return on 3 trajectories of agent16: -4.0
avg return on 3 trajectories of agent17: -3.6666666666666665
avg return on 3 trajectories of agent18: -4.0
avg return on 3 trajectories of agent19: -4.0
avg cum rews: -4.283333333333333, std: 0.4974937185533101
the best agent: 17, best agent cum rewards: -3.6666666666666665
34
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.024617305014721563
avg return on 3 trajectories of agent0: -3.6666666666666665
avg return on 3 trajectories of agent1: -4.0
avg return on 3 trajectories of agent2: -4.333333333333333
avg return on 3 trajectories of agent3: -5.0
avg return on 3 trajectories of agent4: -3.6666666666666665
avg return on 3 trajectories of agent5: -4.0
avg return on 3 trajectories of agent6: -4.0
avg return on 3 trajectories of agent7: -4.0
avg return on 3 trajectories of agent8: -3.6666666666666665
avg return on 3 trajectories of agent9: -3.6666666666666665
avg return on 3 trajectories of agent10: -3.6666666666666665
avg return on 3 trajectories of agent11: -3.6666666666666665
avg return on 3 trajectories of agent12: -3.3333333333333335
avg return on 3 trajectories of agent13: -3.3333333333333335
avg return on 3 trajectories of agent14: -3.3333333333333335
avg return on 3 trajectories of agent15: -3.6666666666666665
avg return on 3 trajectories of agent16: -3.3333333333333335
avg return on 3 trajectories of agent17: -3.3333333333333335
avg return on 3 trajectories of agent18: -3.6666666666666665
avg return on 3 trajectories of agent19: -3.6666666666666665
avg cum rews: -3.75, std: 0.3926406329796582
the best agent: 16, best agent cum rewards: -3.3333333333333335
35
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.025290862070049262
avg return on 3 trajectories of agent0: -3.0
avg return on 3 trajectories of agent1: -3.3333333333333335
avg return on 3 trajectories of agent2: -3.3333333333333335
avg return on 3 trajectories of agent3: -3.3333333333333335
avg return on 3 trajectories of agent4: -3.0
avg return on 3 trajectories of agent5: -3.6666666666666665
avg return on 3 trajectories of agent6: -3.6666666666666665
avg return on 3 trajectories of agent7: -4.333333333333333
avg return on 3 trajectories of agent8: -3.0
avg return on 3 trajectories of agent9: -3.0
avg return on 3 trajectories of agent10: -3.0
avg return on 3 trajectories of agent11: -3.0
avg return on 3 trajectories of agent12: -3.0
avg return on 3 trajectories of agent13: -3.0
avg return on 3 trajectories of agent14: -3.0
avg return on 3 trajectories of agent15: -3.0
avg return on 3 trajectories of agent16: -3.0
avg return on 3 trajectories of agent17: -3.0
avg return on 3 trajectories of agent18: -3.0
avg return on 3 trajectories of agent19: -3.0
avg cum rews: -3.183333333333333, std: 0.34115815817431194
the best agent: 19, best agent cum rewards: -3.0
36
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.025920773441129925
avg return on 3 trajectories of agent0: -3.0
avg return on 3 trajectories of agent1: -3.0
avg return on 3 trajectories of agent2: -3.0
avg return on 3 trajectories of agent3: -3.0
avg return on 3 trajectories of agent4: -3.0
avg return on 3 trajectories of agent5: -3.0
avg return on 3 trajectories of agent6: -3.0
avg return on 3 trajectories of agent7: -3.0
avg return on 3 trajectories of agent8: -3.0
avg return on 3 trajectories of agent9: -3.0
avg return on 3 trajectories of agent10: -3.0
avg return on 3 trajectories of agent11: -3.0
avg return on 3 trajectories of agent12: -3.0
avg return on 3 trajectories of agent13: -3.0
avg return on 3 trajectories of agent14: -3.0
avg return on 3 trajectories of agent15: -3.0
avg return on 3 trajectories of agent16: -3.0
avg return on 3 trajectories of agent17: -3.0
avg return on 3 trajectories of agent18: -3.0
avg return on 3 trajectories of agent19: -3.0
avg cum rews: -3.0, std: 0.0
the best agent: 19, best agent cum rewards: -3.0
37
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.024930722421790473
avg return on 3 trajectories of agent0: -2.6666666666666665
avg return on 3 trajectories of agent1: -2.6666666666666665
avg return on 3 trajectories of agent2: -2.3333333333333335
avg return on 3 trajectories of agent3: -2.3333333333333335
avg return on 3 trajectories of agent4: -3.0
avg return on 3 trajectories of agent5: -3.0
avg return on 3 trajectories of agent6: -3.0
avg return on 3 trajectories of agent7: -3.0
avg return on 3 trajectories of agent8: -2.6666666666666665
avg return on 3 trajectories of agent9: -2.6666666666666665
avg return on 3 trajectories of agent10: -2.6666666666666665
avg return on 3 trajectories of agent11: -2.6666666666666665
avg return on 3 trajectories of agent12: -2.6666666666666665
avg return on 3 trajectories of agent13: -2.6666666666666665
avg return on 3 trajectories of agent14: -2.3333333333333335
avg return on 3 trajectories of agent15: -2.3333333333333335
avg return on 3 trajectories of agent16: -2.6666666666666665
avg return on 3 trajectories of agent17: -2.6666666666666665
avg return on 3 trajectories of agent18: -2.3333333333333335
avg return on 3 trajectories of agent19: -2.6666666666666665
avg cum rews: -2.6499999999999995, std: 0.22298480267099416
the best agent: 18, best agent cum rewards: -2.3333333333333335
38
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.025867262395400055
avg return on 3 trajectories of agent0: -2.6666666666666665
avg return on 3 trajectories of agent1: -3.0
avg return on 3 trajectories of agent2: -3.0
avg return on 3 trajectories of agent3: -2.6666666666666665
avg return on 3 trajectories of agent4: -2.6666666666666665
avg return on 3 trajectories of agent5: -2.3333333333333335
avg return on 3 trajectories of agent6: -2.3333333333333335
avg return on 3 trajectories of agent7: -2.3333333333333335
avg return on 3 trajectories of agent8: -2.6666666666666665
avg return on 3 trajectories of agent9: -3.0
avg return on 3 trajectories of agent10: -2.6666666666666665
avg return on 3 trajectories of agent11: -2.6666666666666665
avg return on 3 trajectories of agent12: -2.3333333333333335
avg return on 3 trajectories of agent13: -2.3333333333333335
avg return on 3 trajectories of agent14: -2.3333333333333335
avg return on 3 trajectories of agent15: -2.3333333333333335
avg return on 3 trajectories of agent16: -2.6666666666666665
avg return on 3 trajectories of agent17: -2.6666666666666665
avg return on 3 trajectories of agent18: -2.3333333333333335
avg return on 3 trajectories of agent19: -2.3333333333333335
avg cum rews: -2.5666666666666664, std: 0.2380476142847616
the best agent: 19, best agent cum rewards: -2.3333333333333335
39
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.025311767595373798
avg return on 3 trajectories of agent0: -2.3333333333333335
avg return on 3 trajectories of agent1: -2.3333333333333335
avg return on 3 trajectories of agent2: -2.6666666666666665
avg return on 3 trajectories of agent3: -2.6666666666666665
avg return on 3 trajectories of agent4: -2.3333333333333335
avg return on 3 trajectories of agent5: -2.3333333333333335
avg return on 3 trajectories of agent6: -2.3333333333333335
avg return on 3 trajectories of agent7: -2.6666666666666665
avg return on 3 trajectories of agent8: -2.0
avg return on 3 trajectories of agent9: -2.0
avg return on 3 trajectories of agent10: -2.3333333333333335
avg return on 3 trajectories of agent11: -2.3333333333333335
avg return on 3 trajectories of agent12: -2.3333333333333335
avg return on 3 trajectories of agent13: -2.3333333333333335
avg return on 3 trajectories of agent14: -2.6666666666666665
avg return on 3 trajectories of agent15: -2.6666666666666665
avg return on 3 trajectories of agent16: -2.3333333333333335
avg return on 3 trajectories of agent17: -2.3333333333333335
avg return on 3 trajectories of agent18: -2.6666666666666665
avg return on 3 trajectories of agent19: -2.6666666666666665
avg cum rews: -2.4166666666666665, std: 0.20749832663314546
the best agent: 8, best agent cum rewards: -2.0
40
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02397028964256479
avg return on 3 trajectories of agent0: -2.0
avg return on 3 trajectories of agent1: -2.3333333333333335
avg return on 3 trajectories of agent2: -2.3333333333333335
avg return on 3 trajectories of agent3: -2.3333333333333335
avg return on 3 trajectories of agent4: -2.0
avg return on 3 trajectories of agent5: -2.0
avg return on 3 trajectories of agent6: -2.0
avg return on 3 trajectories of agent7: -2.0
avg return on 3 trajectories of agent8: -2.0
avg return on 3 trajectories of agent9: -2.0
avg return on 3 trajectories of agent10: -2.0
avg return on 3 trajectories of agent11: -2.0
avg return on 3 trajectories of agent12: -2.0
avg return on 3 trajectories of agent13: -2.0
avg return on 3 trajectories of agent14: -2.0
avg return on 3 trajectories of agent15: -2.0
avg return on 3 trajectories of agent16: -2.0
avg return on 3 trajectories of agent17: -2.0
avg return on 3 trajectories of agent18: -2.0
avg return on 3 trajectories of agent19: -2.0
avg cum rews: -2.05, std: 0.11902380714238091
the best agent: 19, best agent cum rewards: -2.0
41
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02457665243989434
avg return on 3 trajectories of agent0: -2.0
avg return on 3 trajectories of agent1: -2.0
avg return on 3 trajectories of agent2: -2.0
avg return on 3 trajectories of agent3: -2.3333333333333335
avg return on 3 trajectories of agent4: -2.0
avg return on 3 trajectories of agent5: -2.0
avg return on 3 trajectories of agent6: -2.0
avg return on 3 trajectories of agent7: -2.0
avg return on 3 trajectories of agent8: -2.0
avg return on 3 trajectories of agent9: -2.0
avg return on 3 trajectories of agent10: -2.0
avg return on 3 trajectories of agent11: -2.0
avg return on 3 trajectories of agent12: -2.0
avg return on 3 trajectories of agent13: -2.0
avg return on 3 trajectories of agent14: -2.0
avg return on 3 trajectories of agent15: -2.0
avg return on 3 trajectories of agent16: -2.0
avg return on 3 trajectories of agent17: -2.0
avg return on 3 trajectories of agent18: -2.0
avg return on 3 trajectories of agent19: -2.0
avg cum rews: -2.0166666666666666, std: 0.07264831572567793
the best agent: 19, best agent cum rewards: -2.0
42
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.023698371981064052
avg return on 3 trajectories of agent0: -2.0
avg return on 3 trajectories of agent1: -2.0
avg return on 3 trajectories of agent2: -2.0
avg return on 3 trajectories of agent3: -2.0
avg return on 3 trajectories of agent4: -2.0
avg return on 3 trajectories of agent5: -2.0
avg return on 3 trajectories of agent6: -2.0
avg return on 3 trajectories of agent7: -2.0
avg return on 3 trajectories of agent8: -2.0
avg return on 3 trajectories of agent9: -2.0
avg return on 3 trajectories of agent10: -2.0
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -2.0
avg return on 3 trajectories of agent13: -2.0
avg return on 3 trajectories of agent14: -2.0
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -2.0
avg return on 3 trajectories of agent17: -2.0
avg return on 3 trajectories of agent18: -2.0
avg return on 3 trajectories of agent19: -2.0
avg cum rews: -1.9666666666666668, std: 0.09999999999999996
the best agent: 11, best agent cum rewards: -1.6666666666666667
43
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.025398508554770393
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -2.0
avg return on 3 trajectories of agent10: -2.0
avg return on 3 trajectories of agent11: -2.0
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -2.0
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -2.0
avg cum rews: -1.75, std: 0.1443375672974064
the best agent: 18, best agent cum rewards: -1.6666666666666667
44
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02201429577043297
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -2.0
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -2.0
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.7, std: 0.09999999999999996
the best agent: 19, best agent cum rewards: -1.6666666666666667
45
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.0257794659297358
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -2.0
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6833333333333331, std: 0.07264831572567787
the best agent: 19, best agent cum rewards: -1.6666666666666667
46
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.019878208680834904
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -2.0
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6833333333333331, std: 0.07264831572567787
the best agent: 19, best agent cum rewards: -1.6666666666666667
47
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.019483368185974945
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -2.0
avg return on 3 trajectories of agent11: -2.0
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.7, std: 0.09999999999999996
the best agent: 19, best agent cum rewards: -1.6666666666666667
48
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.023937395175614214
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -2.0
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6833333333333331, std: 0.07264831572567787
the best agent: 19, best agent cum rewards: -1.6666666666666667
49
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02457357807473609
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
50
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02453591402099453
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -2.0
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6833333333333331, std: 0.07264831572567787
the best agent: 19, best agent cum rewards: -1.6666666666666667
51
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.024457421083995422
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
52
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.020167838738277037
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -2.0
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6833333333333331, std: 0.07264831572567787
the best agent: 19, best agent cum rewards: -1.6666666666666667
53
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.021122082412522288
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -2.0
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6833333333333331, std: 0.07264831572567787
the best agent: 19, best agent cum rewards: -1.6666666666666667
54
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.023408742933926023
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -2.0
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6833333333333331, std: 0.07264831572567787
the best agent: 19, best agent cum rewards: -1.6666666666666667
55
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.020879875931499713
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -2.0
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -2.0
avg return on 3 trajectories of agent19: -2.0
avg cum rews: -1.7166666666666668, std: 0.11902380714238081
the best agent: 16, best agent cum rewards: -1.6666666666666667
56
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02284382693433188
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
57
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.021463500195186298
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
58
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.021015029741336958
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
59
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.021269630870066773
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
60
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02284590039255299
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
61
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.019944799786056986
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
62
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02296336894623509
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
63
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02464440695302095
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
64
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.020024755355162932
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
65
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.022251227508384618
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
66
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02266738850649333
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
67
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.021244572976326103
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -2.0
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6833333333333331, std: 0.07264831572567787
the best agent: 19, best agent cum rewards: -1.6666666666666667
68
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.019769528955686778
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
69
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02231627254926151
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
70
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.022376211634013318
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -2.0
avg return on 3 trajectories of agent3: -2.0
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -2.0
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.7166666666666668, std: 0.1190238071423808
the best agent: 19, best agent cum rewards: -1.6666666666666667
71
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02265877143815813
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
72
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.020095444738912772
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
73
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.024753248433620645
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
74
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.022187291688386405
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
75
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.021050445511176994
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
76
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.021564439398619434
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
77
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.01868425258115388
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
78
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.01999878545401441
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
79
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.019980172704530997
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
80
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.018846868035570705
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
81
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.019837045581757425
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
82
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.023223412639588624
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
83
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.020506614465217864
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
84
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.018737939967344304
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
85
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.023013151686456568
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
86
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.021643039909679786
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
87
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.021325809629819146
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
88
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.01893937364960077
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
89
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.023285505601973025
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
90
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.022803885448355397
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
91
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02343491877143124
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
92
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.01804882032112705
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
93
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.025087406438015474
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
94
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.022185993019940953
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
95
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02235160007831809
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
96
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.021061641003158237
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
Average distance of random agents to nearest neighbors: [0.017710420958562494, 0.020859460664031142, 0.023388083684381576, 0.02816908020745252, 0.022676409441297993, 0.031358012476222726, 0.027563763520831508, 0.028053835567248026, 0.026506795000441185, 0.02622065071155314, 0.023756987735174494, 0.025207309469282894, 0.027854786886491095, 0.02776704077588426, 0.02833635987254679, 0.022248129854409274, 0.02481040600905219, 0.025148636363643638, 0.021247084942505247, 0.02289757924058524, 0.02489084401210515, 0.023564419448061917, 0.025576117420754486, 0.02607832554991204, 0.02854021527271148, 0.027678258203400995, 0.027822585340344746, 0.025916629227222432, 0.025810135360792956, 0.026075135497006918, 0.026021160973582015, 0.024888972053705462, 0.026641928865816546, 0.024617305014721563, 0.025290862070049262, 0.025920773441129925, 0.024930722421790473, 0.025867262395400055, 0.025311767595373798, 0.02397028964256479, 0.02457665243989434, 0.023698371981064052, 0.025398508554770393, 0.02201429577043297, 0.0257794659297358, 0.019878208680834904, 0.019483368185974945, 0.023937395175614214, 0.02457357807473609, 0.02453591402099453, 0.024457421083995422, 0.020167838738277037, 0.021122082412522288, 0.023408742933926023, 0.020879875931499713, 0.02284382693433188, 0.021463500195186298, 0.021015029741336958, 0.021269630870066773, 0.02284590039255299, 0.019944799786056986, 0.02296336894623509, 0.02464440695302095, 0.020024755355162932, 0.022251227508384618, 0.02266738850649333, 0.021244572976326103, 0.019769528955686778, 0.02231627254926151, 0.022376211634013318, 0.02265877143815813, 0.020095444738912772, 0.024753248433620645, 0.022187291688386405, 0.021050445511176994, 0.021564439398619434, 0.01868425258115388, 0.01999878545401441, 0.019980172704530997, 0.018846868035570705, 0.019837045581757425, 0.023223412639588624, 0.020506614465217864, 0.018737939967344304, 0.023013151686456568, 0.021643039909679786, 0.021325809629819146, 0.01893937364960077, 0.023285505601973025, 0.022803885448355397, 0.02343491877143124, 0.01804882032112705, 0.025087406438015474, 0.022185993019940953, 0.02235160007831809, 0.021061641003158237]
Time taken for each iteration: [20.4633150100708, 35.68935799598694, 50.89489960670471, 66.2735755443573, 87.00123643875122, 101.88924956321716, 116.9304506778717, 137.36260533332825, 152.78185391426086, 167.95110297203064, 182.90337204933167, 198.09589433670044, 213.5046956539154, 234.26531887054443, 255.33551263809204, 271.26765537261963, 286.8964366912842, 306.79964995384216, 326.86890268325806, 347.8802704811096, 363.28266882896423, 378.7655076980591, 399.5856478214264, 415.05496311187744, 436.0656404495239, 457.17197155952454, 478.0117325782776, 493.3999078273773, 508.9995188713074, 524.4375758171082, 544.1631753444672, 559.4756634235382, 580.3499557971954, 599.7909319400787, 620.5071880817413, 635.6193354129791, 650.8475284576416, 671.8388199806213, 692.7847790718079, 713.6636819839478, 733.3169448375702, 748.6207804679871, 769.6955528259277, 784.9397428035736, 800.0201671123505, 815.136753320694, 830.2060086727142, 845.315896987915, 860.5156135559082, 881.0627286434174, 896.119437456131, 911.2329957485199, 931.9259557723999, 947.0729553699493, 967.8749620914459, 987.5285050868988, 1002.7465264797211, 1022.3896765708923, 1043.189280986786, 1058.3847107887268, 1073.5798738002777, 1088.8411087989807, 1104.025348186493, 1119.3234090805054, 1138.8382666110992, 1159.4224345684052, 1174.62637424469, 1194.45689868927, 1215.955097436905, 1231.9283664226532, 1254.682357788086, 1276.1424963474274, 1292.5201921463013, 1313.3120288848877, 1334.184294462204, 1350.3355567455292, 1366.4911963939667, 1382.7364902496338, 1398.8327612876892, 1414.8840255737305, 1437.3434987068176, 1453.4003562927246, 1474.3360600471497, 1490.5392606258392, 1506.698114156723, 1528.5367119312286, 1544.2958092689514, 1564.6195323467255, 1580.1507182121277, 1595.7500212192535, 1611.3874859809875, 1626.978343486786, 1647.2694780826569, 1662.7547690868378, 1677.9832646846771, 1693.2165739536285]
