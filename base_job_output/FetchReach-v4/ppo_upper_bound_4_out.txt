No devices were found
Setting seed -  3
---------------------------------
Environment created
Box(-1.0, 1.0, (4,), float32) Box(-inf, inf, (16,), float64)
Starting training from scratch
Starting evaluation
1
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02099328483658995
avg return on 3 trajectories of agent0: -50.0
avg return on 3 trajectories of agent1: -50.0
avg return on 3 trajectories of agent2: -50.0
avg return on 3 trajectories of agent3: -50.0
avg return on 3 trajectories of agent4: -50.0
avg return on 3 trajectories of agent5: -50.0
avg return on 3 trajectories of agent6: -50.0
avg return on 3 trajectories of agent7: -50.0
avg return on 3 trajectories of agent8: -50.0
avg return on 3 trajectories of agent9: -50.0
avg return on 3 trajectories of agent10: -50.0
avg return on 3 trajectories of agent11: -50.0
avg return on 3 trajectories of agent12: -50.0
avg return on 3 trajectories of agent13: -50.0
avg return on 3 trajectories of agent14: -50.0
avg return on 3 trajectories of agent15: -50.0
avg return on 3 trajectories of agent16: -50.0
avg return on 3 trajectories of agent17: -50.0
avg return on 3 trajectories of agent18: -50.0
avg return on 3 trajectories of agent19: -50.0
avg cum rews: -50.0, std: 0.0
the best agent: 19, best agent cum rewards: -50.0
2
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.026400765629796246
avg return on 3 trajectories of agent0: -42.666666666666664
avg return on 3 trajectories of agent1: -42.333333333333336
avg return on 3 trajectories of agent2: -42.333333333333336
avg return on 3 trajectories of agent3: -43.0
avg return on 3 trajectories of agent4: -42.666666666666664
avg return on 3 trajectories of agent5: -42.333333333333336
avg return on 3 trajectories of agent6: -42.0
avg return on 3 trajectories of agent7: -42.0
avg return on 3 trajectories of agent8: -42.666666666666664
avg return on 3 trajectories of agent9: -43.666666666666664
avg return on 3 trajectories of agent10: -44.333333333333336
avg return on 3 trajectories of agent11: -45.333333333333336
avg return on 3 trajectories of agent12: -43.666666666666664
avg return on 3 trajectories of agent13: -44.333333333333336
avg return on 3 trajectories of agent14: -46.0
avg return on 3 trajectories of agent15: -47.333333333333336
avg return on 3 trajectories of agent16: -42.333333333333336
avg return on 3 trajectories of agent17: -43.0
avg return on 3 trajectories of agent18: -43.666666666666664
avg return on 3 trajectories of agent19: -44.666666666666664
avg cum rews: -43.516666666666666, std: 1.4082100537759117
the best agent: 7, best agent cum rewards: -42.0
3
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.025249391549132354
avg return on 3 trajectories of agent0: -50.0
avg return on 3 trajectories of agent1: -50.0
avg return on 3 trajectories of agent2: -50.0
avg return on 3 trajectories of agent3: -50.0
avg return on 3 trajectories of agent4: -50.0
avg return on 3 trajectories of agent5: -50.0
avg return on 3 trajectories of agent6: -50.0
avg return on 3 trajectories of agent7: -50.0
avg return on 3 trajectories of agent8: -50.0
avg return on 3 trajectories of agent9: -50.0
avg return on 3 trajectories of agent10: -50.0
avg return on 3 trajectories of agent11: -50.0
avg return on 3 trajectories of agent12: -50.0
avg return on 3 trajectories of agent13: -50.0
avg return on 3 trajectories of agent14: -50.0
avg return on 3 trajectories of agent15: -50.0
avg return on 3 trajectories of agent16: -50.0
avg return on 3 trajectories of agent17: -50.0
avg return on 3 trajectories of agent18: -50.0
avg return on 3 trajectories of agent19: -50.0
avg cum rews: -50.0, std: 0.0
the best agent: 19, best agent cum rewards: -50.0
4
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.029887785885413964
avg return on 3 trajectories of agent0: -50.0
avg return on 3 trajectories of agent1: -50.0
avg return on 3 trajectories of agent2: -50.0
avg return on 3 trajectories of agent3: -50.0
avg return on 3 trajectories of agent4: -50.0
avg return on 3 trajectories of agent5: -50.0
avg return on 3 trajectories of agent6: -50.0
avg return on 3 trajectories of agent7: -50.0
avg return on 3 trajectories of agent8: -50.0
avg return on 3 trajectories of agent9: -50.0
avg return on 3 trajectories of agent10: -50.0
avg return on 3 trajectories of agent11: -50.0
avg return on 3 trajectories of agent12: -50.0
avg return on 3 trajectories of agent13: -50.0
avg return on 3 trajectories of agent14: -50.0
avg return on 3 trajectories of agent15: -50.0
avg return on 3 trajectories of agent16: -50.0
avg return on 3 trajectories of agent17: -50.0
avg return on 3 trajectories of agent18: -50.0
avg return on 3 trajectories of agent19: -50.0
avg cum rews: -50.0, std: 0.0
the best agent: 19, best agent cum rewards: -50.0
5
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.025407386520527965
avg return on 3 trajectories of agent0: -50.0
avg return on 3 trajectories of agent1: -50.0
avg return on 3 trajectories of agent2: -50.0
avg return on 3 trajectories of agent3: -50.0
avg return on 3 trajectories of agent4: -50.0
avg return on 3 trajectories of agent5: -50.0
avg return on 3 trajectories of agent6: -50.0
avg return on 3 trajectories of agent7: -50.0
avg return on 3 trajectories of agent8: -50.0
avg return on 3 trajectories of agent9: -50.0
avg return on 3 trajectories of agent10: -50.0
avg return on 3 trajectories of agent11: -50.0
avg return on 3 trajectories of agent12: -50.0
avg return on 3 trajectories of agent13: -50.0
avg return on 3 trajectories of agent14: -50.0
avg return on 3 trajectories of agent15: -50.0
avg return on 3 trajectories of agent16: -50.0
avg return on 3 trajectories of agent17: -50.0
avg return on 3 trajectories of agent18: -50.0
avg return on 3 trajectories of agent19: -50.0
avg cum rews: -50.0, std: 0.0
the best agent: 19, best agent cum rewards: -50.0
6
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02697388311241372
avg return on 3 trajectories of agent0: -50.0
avg return on 3 trajectories of agent1: -50.0
avg return on 3 trajectories of agent2: -50.0
avg return on 3 trajectories of agent3: -50.0
avg return on 3 trajectories of agent4: -50.0
avg return on 3 trajectories of agent5: -50.0
avg return on 3 trajectories of agent6: -50.0
avg return on 3 trajectories of agent7: -50.0
avg return on 3 trajectories of agent8: -50.0
avg return on 3 trajectories of agent9: -50.0
avg return on 3 trajectories of agent10: -50.0
avg return on 3 trajectories of agent11: -50.0
avg return on 3 trajectories of agent12: -50.0
avg return on 3 trajectories of agent13: -50.0
avg return on 3 trajectories of agent14: -50.0
avg return on 3 trajectories of agent15: -50.0
avg return on 3 trajectories of agent16: -50.0
avg return on 3 trajectories of agent17: -50.0
avg return on 3 trajectories of agent18: -50.0
avg return on 3 trajectories of agent19: -50.0
avg cum rews: -50.0, std: 0.0
the best agent: 19, best agent cum rewards: -50.0
7
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.025462376665666243
avg return on 3 trajectories of agent0: -50.0
avg return on 3 trajectories of agent1: -50.0
avg return on 3 trajectories of agent2: -50.0
avg return on 3 trajectories of agent3: -50.0
avg return on 3 trajectories of agent4: -50.0
avg return on 3 trajectories of agent5: -50.0
avg return on 3 trajectories of agent6: -50.0
avg return on 3 trajectories of agent7: -50.0
avg return on 3 trajectories of agent8: -50.0
avg return on 3 trajectories of agent9: -50.0
avg return on 3 trajectories of agent10: -50.0
avg return on 3 trajectories of agent11: -50.0
avg return on 3 trajectories of agent12: -50.0
avg return on 3 trajectories of agent13: -50.0
avg return on 3 trajectories of agent14: -50.0
avg return on 3 trajectories of agent15: -50.0
avg return on 3 trajectories of agent16: -50.0
avg return on 3 trajectories of agent17: -50.0
avg return on 3 trajectories of agent18: -50.0
avg return on 3 trajectories of agent19: -50.0
avg cum rews: -50.0, std: 0.0
the best agent: 19, best agent cum rewards: -50.0
8
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.024439250803478266
avg return on 3 trajectories of agent0: -50.0
avg return on 3 trajectories of agent1: -50.0
avg return on 3 trajectories of agent2: -50.0
avg return on 3 trajectories of agent3: -50.0
avg return on 3 trajectories of agent4: -50.0
avg return on 3 trajectories of agent5: -50.0
avg return on 3 trajectories of agent6: -50.0
avg return on 3 trajectories of agent7: -50.0
avg return on 3 trajectories of agent8: -50.0
avg return on 3 trajectories of agent9: -50.0
avg return on 3 trajectories of agent10: -50.0
avg return on 3 trajectories of agent11: -50.0
avg return on 3 trajectories of agent12: -50.0
avg return on 3 trajectories of agent13: -50.0
avg return on 3 trajectories of agent14: -50.0
avg return on 3 trajectories of agent15: -50.0
avg return on 3 trajectories of agent16: -50.0
avg return on 3 trajectories of agent17: -50.0
avg return on 3 trajectories of agent18: -50.0
avg return on 3 trajectories of agent19: -50.0
avg cum rews: -50.0, std: 0.0
the best agent: 19, best agent cum rewards: -50.0
9
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.027861593061571488
avg return on 3 trajectories of agent0: -50.0
avg return on 3 trajectories of agent1: -50.0
avg return on 3 trajectories of agent2: -50.0
avg return on 3 trajectories of agent3: -50.0
avg return on 3 trajectories of agent4: -50.0
avg return on 3 trajectories of agent5: -50.0
avg return on 3 trajectories of agent6: -50.0
avg return on 3 trajectories of agent7: -50.0
avg return on 3 trajectories of agent8: -50.0
avg return on 3 trajectories of agent9: -50.0
avg return on 3 trajectories of agent10: -50.0
avg return on 3 trajectories of agent11: -50.0
avg return on 3 trajectories of agent12: -50.0
avg return on 3 trajectories of agent13: -50.0
avg return on 3 trajectories of agent14: -50.0
avg return on 3 trajectories of agent15: -50.0
avg return on 3 trajectories of agent16: -50.0
avg return on 3 trajectories of agent17: -50.0
avg return on 3 trajectories of agent18: -50.0
avg return on 3 trajectories of agent19: -50.0
avg cum rews: -50.0, std: 0.0
the best agent: 19, best agent cum rewards: -50.0
10
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.020675675079667975
avg return on 3 trajectories of agent0: -50.0
avg return on 3 trajectories of agent1: -50.0
avg return on 3 trajectories of agent2: -50.0
avg return on 3 trajectories of agent3: -50.0
avg return on 3 trajectories of agent4: -50.0
avg return on 3 trajectories of agent5: -50.0
avg return on 3 trajectories of agent6: -50.0
avg return on 3 trajectories of agent7: -50.0
avg return on 3 trajectories of agent8: -50.0
avg return on 3 trajectories of agent9: -50.0
avg return on 3 trajectories of agent10: -50.0
avg return on 3 trajectories of agent11: -50.0
avg return on 3 trajectories of agent12: -50.0
avg return on 3 trajectories of agent13: -50.0
avg return on 3 trajectories of agent14: -50.0
avg return on 3 trajectories of agent15: -50.0
avg return on 3 trajectories of agent16: -50.0
avg return on 3 trajectories of agent17: -50.0
avg return on 3 trajectories of agent18: -50.0
avg return on 3 trajectories of agent19: -50.0
avg cum rews: -50.0, std: 0.0
the best agent: 19, best agent cum rewards: -50.0
11
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.0291693592110722
avg return on 3 trajectories of agent0: -50.0
avg return on 3 trajectories of agent1: -50.0
avg return on 3 trajectories of agent2: -50.0
avg return on 3 trajectories of agent3: -50.0
avg return on 3 trajectories of agent4: -50.0
avg return on 3 trajectories of agent5: -50.0
avg return on 3 trajectories of agent6: -50.0
avg return on 3 trajectories of agent7: -50.0
avg return on 3 trajectories of agent8: -50.0
avg return on 3 trajectories of agent9: -50.0
avg return on 3 trajectories of agent10: -50.0
avg return on 3 trajectories of agent11: -50.0
avg return on 3 trajectories of agent12: -50.0
avg return on 3 trajectories of agent13: -50.0
avg return on 3 trajectories of agent14: -50.0
avg return on 3 trajectories of agent15: -50.0
avg return on 3 trajectories of agent16: -50.0
avg return on 3 trajectories of agent17: -50.0
avg return on 3 trajectories of agent18: -50.0
avg return on 3 trajectories of agent19: -50.0
avg cum rews: -50.0, std: 0.0
the best agent: 19, best agent cum rewards: -50.0
12
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.026340150433869135
avg return on 3 trajectories of agent0: -50.0
avg return on 3 trajectories of agent1: -50.0
avg return on 3 trajectories of agent2: -50.0
avg return on 3 trajectories of agent3: -50.0
avg return on 3 trajectories of agent4: -50.0
avg return on 3 trajectories of agent5: -50.0
avg return on 3 trajectories of agent6: -50.0
avg return on 3 trajectories of agent7: -50.0
avg return on 3 trajectories of agent8: -50.0
avg return on 3 trajectories of agent9: -50.0
avg return on 3 trajectories of agent10: -50.0
avg return on 3 trajectories of agent11: -50.0
avg return on 3 trajectories of agent12: -50.0
avg return on 3 trajectories of agent13: -50.0
avg return on 3 trajectories of agent14: -50.0
avg return on 3 trajectories of agent15: -50.0
avg return on 3 trajectories of agent16: -50.0
avg return on 3 trajectories of agent17: -50.0
avg return on 3 trajectories of agent18: -50.0
avg return on 3 trajectories of agent19: -50.0
avg cum rews: -50.0, std: 0.0
the best agent: 19, best agent cum rewards: -50.0
13
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.022816287593677403
avg return on 3 trajectories of agent0: -50.0
avg return on 3 trajectories of agent1: -50.0
avg return on 3 trajectories of agent2: -50.0
avg return on 3 trajectories of agent3: -50.0
avg return on 3 trajectories of agent4: -50.0
avg return on 3 trajectories of agent5: -50.0
avg return on 3 trajectories of agent6: -50.0
avg return on 3 trajectories of agent7: -50.0
avg return on 3 trajectories of agent8: -50.0
avg return on 3 trajectories of agent9: -50.0
avg return on 3 trajectories of agent10: -50.0
avg return on 3 trajectories of agent11: -50.0
avg return on 3 trajectories of agent12: -50.0
avg return on 3 trajectories of agent13: -50.0
avg return on 3 trajectories of agent14: -50.0
avg return on 3 trajectories of agent15: -50.0
avg return on 3 trajectories of agent16: -50.0
avg return on 3 trajectories of agent17: -50.0
avg return on 3 trajectories of agent18: -50.0
avg return on 3 trajectories of agent19: -50.0
avg cum rews: -50.0, std: 0.0
the best agent: 19, best agent cum rewards: -50.0
14
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.025879785710164343
avg return on 3 trajectories of agent0: -50.0
avg return on 3 trajectories of agent1: -50.0
avg return on 3 trajectories of agent2: -50.0
avg return on 3 trajectories of agent3: -50.0
avg return on 3 trajectories of agent4: -50.0
avg return on 3 trajectories of agent5: -50.0
avg return on 3 trajectories of agent6: -50.0
avg return on 3 trajectories of agent7: -50.0
avg return on 3 trajectories of agent8: -50.0
avg return on 3 trajectories of agent9: -50.0
avg return on 3 trajectories of agent10: -50.0
avg return on 3 trajectories of agent11: -50.0
avg return on 3 trajectories of agent12: -50.0
avg return on 3 trajectories of agent13: -50.0
avg return on 3 trajectories of agent14: -46.333333333333336
avg return on 3 trajectories of agent15: -42.666666666666664
avg return on 3 trajectories of agent16: -50.0
avg return on 3 trajectories of agent17: -50.0
avg return on 3 trajectories of agent18: -50.0
avg return on 3 trajectories of agent19: -50.0
avg cum rews: -49.45, std: 1.748888535931067
the best agent: 15, best agent cum rewards: -42.666666666666664
15
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02431120674814218
avg return on 3 trajectories of agent0: -32.666666666666664
avg return on 3 trajectories of agent1: -39.333333333333336
avg return on 3 trajectories of agent2: -39.0
avg return on 3 trajectories of agent3: -35.333333333333336
avg return on 3 trajectories of agent4: -50.0
avg return on 3 trajectories of agent5: -50.0
avg return on 3 trajectories of agent6: -50.0
avg return on 3 trajectories of agent7: -50.0
avg return on 3 trajectories of agent8: -36.666666666666664
avg return on 3 trajectories of agent9: -39.0
avg return on 3 trajectories of agent10: -43.333333333333336
avg return on 3 trajectories of agent11: -43.333333333333336
avg return on 3 trajectories of agent12: -36.333333333333336
avg return on 3 trajectories of agent13: -29.333333333333332
avg return on 3 trajectories of agent14: -30.0
avg return on 3 trajectories of agent15: -41.0
avg return on 3 trajectories of agent16: -43.0
avg return on 3 trajectories of agent17: -39.0
avg return on 3 trajectories of agent18: -37.666666666666664
avg return on 3 trajectories of agent19: -42.333333333333336
avg cum rews: -40.36666666666667, std: 6.15530484848458
the best agent: 13, best agent cum rewards: -29.333333333333332
16
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.023961608640143787
avg return on 3 trajectories of agent0: -43.333333333333336
avg return on 3 trajectories of agent1: -50.0
avg return on 3 trajectories of agent2: -50.0
avg return on 3 trajectories of agent3: -50.0
avg return on 3 trajectories of agent4: -45.666666666666664
avg return on 3 trajectories of agent5: -46.333333333333336
avg return on 3 trajectories of agent6: -50.0
avg return on 3 trajectories of agent7: -50.0
avg return on 3 trajectories of agent8: -44.333333333333336
avg return on 3 trajectories of agent9: -47.666666666666664
avg return on 3 trajectories of agent10: -44.333333333333336
avg return on 3 trajectories of agent11: -42.333333333333336
avg return on 3 trajectories of agent12: -45.0
avg return on 3 trajectories of agent13: -43.666666666666664
avg return on 3 trajectories of agent14: -36.333333333333336
avg return on 3 trajectories of agent15: -32.333333333333336
avg return on 3 trajectories of agent16: -50.0
avg return on 3 trajectories of agent17: -44.0
avg return on 3 trajectories of agent18: -36.333333333333336
avg return on 3 trajectories of agent19: -32.333333333333336
avg cum rews: -44.2, std: 5.617828762075255
the best agent: 19, best agent cum rewards: -32.333333333333336
17
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.025553772003510906
avg return on 3 trajectories of agent0: -50.0
avg return on 3 trajectories of agent1: -50.0
avg return on 3 trajectories of agent2: -50.0
avg return on 3 trajectories of agent3: -50.0
avg return on 3 trajectories of agent4: -50.0
avg return on 3 trajectories of agent5: -50.0
avg return on 3 trajectories of agent6: -50.0
avg return on 3 trajectories of agent7: -50.0
avg return on 3 trajectories of agent8: -50.0
avg return on 3 trajectories of agent9: -46.333333333333336
avg return on 3 trajectories of agent10: -43.0
avg return on 3 trajectories of agent11: -43.0
avg return on 3 trajectories of agent12: -50.0
avg return on 3 trajectories of agent13: -50.0
avg return on 3 trajectories of agent14: -50.0
avg return on 3 trajectories of agent15: -50.0
avg return on 3 trajectories of agent16: -43.333333333333336
avg return on 3 trajectories of agent17: -50.0
avg return on 3 trajectories of agent18: -50.0
avg return on 3 trajectories of agent19: -50.0
avg cum rews: -48.78333333333334, std: 2.512800562453508
the best agent: 11, best agent cum rewards: -43.0
18
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.022750882594338738
avg return on 3 trajectories of agent0: -50.0
avg return on 3 trajectories of agent1: -47.0
avg return on 3 trajectories of agent2: -46.333333333333336
avg return on 3 trajectories of agent3: -44.0
avg return on 3 trajectories of agent4: -49.0
avg return on 3 trajectories of agent5: -46.666666666666664
avg return on 3 trajectories of agent6: -46.0
avg return on 3 trajectories of agent7: -46.0
avg return on 3 trajectories of agent8: -50.0
avg return on 3 trajectories of agent9: -50.0
avg return on 3 trajectories of agent10: -50.0
avg return on 3 trajectories of agent11: -50.0
avg return on 3 trajectories of agent12: -46.333333333333336
avg return on 3 trajectories of agent13: -46.0
avg return on 3 trajectories of agent14: -45.666666666666664
avg return on 3 trajectories of agent15: -45.666666666666664
avg return on 3 trajectories of agent16: -47.333333333333336
avg return on 3 trajectories of agent17: -45.666666666666664
avg return on 3 trajectories of agent18: -45.0
avg return on 3 trajectories of agent19: -44.666666666666664
avg cum rews: -47.06666666666667, std: 1.959591794226543
the best agent: 3, best agent cum rewards: -44.0
19
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.026599702550392783
avg return on 3 trajectories of agent0: -47.0
avg return on 3 trajectories of agent1: -46.333333333333336
avg return on 3 trajectories of agent2: -46.333333333333336
avg return on 3 trajectories of agent3: -46.0
avg return on 3 trajectories of agent4: -45.333333333333336
avg return on 3 trajectories of agent5: -41.333333333333336
avg return on 3 trajectories of agent6: -40.666666666666664
avg return on 3 trajectories of agent7: -41.0
avg return on 3 trajectories of agent8: -45.666666666666664
avg return on 3 trajectories of agent9: -46.0
avg return on 3 trajectories of agent10: -46.666666666666664
avg return on 3 trajectories of agent11: -50.0
avg return on 3 trajectories of agent12: -45.666666666666664
avg return on 3 trajectories of agent13: -46.0
avg return on 3 trajectories of agent14: -46.666666666666664
avg return on 3 trajectories of agent15: -47.666666666666664
avg return on 3 trajectories of agent16: -43.333333333333336
avg return on 3 trajectories of agent17: -46.666666666666664
avg return on 3 trajectories of agent18: -48.0
avg return on 3 trajectories of agent19: -50.0
avg cum rews: -45.81666666666667, std: 2.48657506533697
the best agent: 6, best agent cum rewards: -40.666666666666664
20
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.023336512351132856
avg return on 3 trajectories of agent0: -41.666666666666664
avg return on 3 trajectories of agent1: -37.666666666666664
avg return on 3 trajectories of agent2: -31.666666666666668
avg return on 3 trajectories of agent3: -26.0
avg return on 3 trajectories of agent4: -38.333333333333336
avg return on 3 trajectories of agent5: -35.0
avg return on 3 trajectories of agent6: -31.666666666666668
avg return on 3 trajectories of agent7: -31.666666666666668
avg return on 3 trajectories of agent8: -41.0
avg return on 3 trajectories of agent9: -38.333333333333336
avg return on 3 trajectories of agent10: -34.0
avg return on 3 trajectories of agent11: -29.666666666666668
avg return on 3 trajectories of agent12: -31.0
avg return on 3 trajectories of agent13: -29.0
avg return on 3 trajectories of agent14: -27.333333333333332
avg return on 3 trajectories of agent15: -24.666666666666668
avg return on 3 trajectories of agent16: -34.0
avg return on 3 trajectories of agent17: -30.0
avg return on 3 trajectories of agent18: -17.666666666666668
avg return on 3 trajectories of agent19: -14.666666666666666
avg cum rews: -31.25, std: 6.818174242420033
the best agent: 19, best agent cum rewards: -14.666666666666666
21
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02599606174081679
avg return on 3 trajectories of agent0: -14.0
avg return on 3 trajectories of agent1: -20.0
avg return on 3 trajectories of agent2: -34.666666666666664
avg return on 3 trajectories of agent3: -49.0
avg return on 3 trajectories of agent4: -16.0
avg return on 3 trajectories of agent5: -18.666666666666668
avg return on 3 trajectories of agent6: -31.666666666666668
avg return on 3 trajectories of agent7: -50.0
avg return on 3 trajectories of agent8: -14.0
avg return on 3 trajectories of agent9: -14.666666666666666
avg return on 3 trajectories of agent10: -16.666666666666668
avg return on 3 trajectories of agent11: -20.0
avg return on 3 trajectories of agent12: -12.666666666666666
avg return on 3 trajectories of agent13: -10.666666666666666
avg return on 3 trajectories of agent14: -14.333333333333334
avg return on 3 trajectories of agent15: -29.0
avg return on 3 trajectories of agent16: -13.333333333333334
avg return on 3 trajectories of agent17: -11.0
avg return on 3 trajectories of agent18: -9.333333333333334
avg return on 3 trajectories of agent19: -19.0
avg cum rews: -20.93333333333333, std: 11.615411218625788
the best agent: 18, best agent cum rewards: -9.333333333333334
22
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02791843649886421
avg return on 3 trajectories of agent0: -9.0
avg return on 3 trajectories of agent1: -8.333333333333334
avg return on 3 trajectories of agent2: -13.0
avg return on 3 trajectories of agent3: -20.0
avg return on 3 trajectories of agent4: -9.333333333333334
avg return on 3 trajectories of agent5: -8.666666666666666
avg return on 3 trajectories of agent6: -8.333333333333334
avg return on 3 trajectories of agent7: -16.0
avg return on 3 trajectories of agent8: -9.333333333333334
avg return on 3 trajectories of agent9: -11.0
avg return on 3 trajectories of agent10: -12.666666666666666
avg return on 3 trajectories of agent11: -22.666666666666668
avg return on 3 trajectories of agent12: -8.0
avg return on 3 trajectories of agent13: -7.666666666666667
avg return on 3 trajectories of agent14: -20.333333333333332
avg return on 3 trajectories of agent15: -31.666666666666668
avg return on 3 trajectories of agent16: -8.333333333333334
avg return on 3 trajectories of agent17: -17.0
avg return on 3 trajectories of agent18: -29.666666666666668
avg return on 3 trajectories of agent19: -37.333333333333336
avg cum rews: -15.416666666666668, std: 8.681317744316111
the best agent: 13, best agent cum rewards: -7.666666666666667
23
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.025435084998468534
avg return on 3 trajectories of agent0: -8.0
avg return on 3 trajectories of agent1: -9.333333333333334
avg return on 3 trajectories of agent2: -12.666666666666666
avg return on 3 trajectories of agent3: -28.0
avg return on 3 trajectories of agent4: -8.0
avg return on 3 trajectories of agent5: -8.333333333333334
avg return on 3 trajectories of agent6: -9.0
avg return on 3 trajectories of agent7: -11.0
avg return on 3 trajectories of agent8: -7.666666666666667
avg return on 3 trajectories of agent9: -8.666666666666666
avg return on 3 trajectories of agent10: -28.666666666666668
avg return on 3 trajectories of agent11: -33.0
avg return on 3 trajectories of agent12: -7.666666666666667
avg return on 3 trajectories of agent13: -8.0
avg return on 3 trajectories of agent14: -8.333333333333334
avg return on 3 trajectories of agent15: -9.333333333333334
avg return on 3 trajectories of agent16: -8.0
avg return on 3 trajectories of agent17: -8.666666666666666
avg return on 3 trajectories of agent18: -9.333333333333334
avg return on 3 trajectories of agent19: -11.0
avg cum rews: -12.133333333333335, std: 7.608766873372671
the best agent: 8, best agent cum rewards: -7.666666666666667
24
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.023875562447055042
avg return on 3 trajectories of agent0: -8.0
avg return on 3 trajectories of agent1: -7.666666666666667
avg return on 3 trajectories of agent2: -6.666666666666667
avg return on 3 trajectories of agent3: -6.333333333333333
avg return on 3 trajectories of agent4: -8.0
avg return on 3 trajectories of agent5: -7.666666666666667
avg return on 3 trajectories of agent6: -7.666666666666667
avg return on 3 trajectories of agent7: -7.333333333333333
avg return on 3 trajectories of agent8: -8.333333333333334
avg return on 3 trajectories of agent9: -14.333333333333334
avg return on 3 trajectories of agent10: -19.666666666666668
avg return on 3 trajectories of agent11: -26.333333333333332
avg return on 3 trajectories of agent12: -7.333333333333333
avg return on 3 trajectories of agent13: -7.0
avg return on 3 trajectories of agent14: -6.666666666666667
avg return on 3 trajectories of agent15: -6.333333333333333
avg return on 3 trajectories of agent16: -8.0
avg return on 3 trajectories of agent17: -7.0
avg return on 3 trajectories of agent18: -6.0
avg return on 3 trajectories of agent19: -6.0
avg cum rews: -9.116666666666667, std: 5.039042016538902
the best agent: 19, best agent cum rewards: -6.0
25
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.0249648521318408
avg return on 3 trajectories of agent0: -6.333333333333333
avg return on 3 trajectories of agent1: -6.333333333333333
avg return on 3 trajectories of agent2: -6.0
avg return on 3 trajectories of agent3: -24.0
avg return on 3 trajectories of agent4: -6.333333333333333
avg return on 3 trajectories of agent5: -6.333333333333333
avg return on 3 trajectories of agent6: -6.333333333333333
avg return on 3 trajectories of agent7: -6.333333333333333
avg return on 3 trajectories of agent8: -6.333333333333333
avg return on 3 trajectories of agent9: -6.333333333333333
avg return on 3 trajectories of agent10: -6.666666666666667
avg return on 3 trajectories of agent11: -6.666666666666667
avg return on 3 trajectories of agent12: -6.333333333333333
avg return on 3 trajectories of agent13: -6.333333333333333
avg return on 3 trajectories of agent14: -6.333333333333333
avg return on 3 trajectories of agent15: -6.666666666666667
avg return on 3 trajectories of agent16: -6.333333333333333
avg return on 3 trajectories of agent17: -6.333333333333333
avg return on 3 trajectories of agent18: -6.333333333333333
avg return on 3 trajectories of agent19: -6.666666666666667
avg cum rews: -7.2666666666666675, std: 3.8421637422450163
the best agent: 2, best agent cum rewards: -6.0
26
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.023280641199259766
avg return on 3 trajectories of agent0: -6.333333333333333
avg return on 3 trajectories of agent1: -7.0
avg return on 3 trajectories of agent2: -8.0
avg return on 3 trajectories of agent3: -31.0
avg return on 3 trajectories of agent4: -7.0
avg return on 3 trajectories of agent5: -7.333333333333333
avg return on 3 trajectories of agent6: -8.0
avg return on 3 trajectories of agent7: -9.333333333333334
avg return on 3 trajectories of agent8: -6.0
avg return on 3 trajectories of agent9: -6.0
avg return on 3 trajectories of agent10: -6.0
avg return on 3 trajectories of agent11: -6.333333333333333
avg return on 3 trajectories of agent12: -6.0
avg return on 3 trajectories of agent13: -6.333333333333333
avg return on 3 trajectories of agent14: -6.666666666666667
avg return on 3 trajectories of agent15: -6.666666666666667
avg return on 3 trajectories of agent16: -6.333333333333333
avg return on 3 trajectories of agent17: -6.0
avg return on 3 trajectories of agent18: -6.0
avg return on 3 trajectories of agent19: -5.666666666666667
avg cum rews: -7.9, std: 5.371840156470282
the best agent: 19, best agent cum rewards: -5.666666666666667
27
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02637813549705701
avg return on 3 trajectories of agent0: -5.333333333333333
avg return on 3 trajectories of agent1: -5.333333333333333
avg return on 3 trajectories of agent2: -5.333333333333333
avg return on 3 trajectories of agent3: -5.0
avg return on 3 trajectories of agent4: -6.0
avg return on 3 trajectories of agent5: -6.0
avg return on 3 trajectories of agent6: -5.666666666666667
avg return on 3 trajectories of agent7: -5.666666666666667
avg return on 3 trajectories of agent8: -5.333333333333333
avg return on 3 trajectories of agent9: -5.666666666666667
avg return on 3 trajectories of agent10: -6.0
avg return on 3 trajectories of agent11: -6.666666666666667
avg return on 3 trajectories of agent12: -5.333333333333333
avg return on 3 trajectories of agent13: -5.0
avg return on 3 trajectories of agent14: -5.333333333333333
avg return on 3 trajectories of agent15: -16.333333333333332
avg return on 3 trajectories of agent16: -5.333333333333333
avg return on 3 trajectories of agent17: -5.0
avg return on 3 trajectories of agent18: -5.333333333333333
avg return on 3 trajectories of agent19: -5.666666666666667
avg cum rews: -6.066666666666666, std: 2.388863048955855
the best agent: 17, best agent cum rewards: -5.0
28
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02543089928448088
avg return on 3 trajectories of agent0: -6.0
avg return on 3 trajectories of agent1: -6.666666666666667
avg return on 3 trajectories of agent2: -7.666666666666667
avg return on 3 trajectories of agent3: -10.666666666666666
avg return on 3 trajectories of agent4: -6.0
avg return on 3 trajectories of agent5: -6.333333333333333
avg return on 3 trajectories of agent6: -6.666666666666667
avg return on 3 trajectories of agent7: -7.333333333333333
avg return on 3 trajectories of agent8: -5.333333333333333
avg return on 3 trajectories of agent9: -5.0
avg return on 3 trajectories of agent10: -4.333333333333333
avg return on 3 trajectories of agent11: -4.333333333333333
avg return on 3 trajectories of agent12: -5.666666666666667
avg return on 3 trajectories of agent13: -6.666666666666667
avg return on 3 trajectories of agent14: -8.666666666666666
avg return on 3 trajectories of agent15: -26.333333333333332
avg return on 3 trajectories of agent16: -5.333333333333333
avg return on 3 trajectories of agent17: -6.0
avg return on 3 trajectories of agent18: -6.666666666666667
avg return on 3 trajectories of agent19: -7.666666666666667
avg cum rews: -7.466666666666666, std: 4.561188928825953
the best agent: 11, best agent cum rewards: -4.333333333333333
29
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.0233684434017685
avg return on 3 trajectories of agent0: -5.0
avg return on 3 trajectories of agent1: -5.0
avg return on 3 trajectories of agent2: -5.666666666666667
avg return on 3 trajectories of agent3: -6.666666666666667
avg return on 3 trajectories of agent4: -4.333333333333333
avg return on 3 trajectories of agent5: -4.666666666666667
avg return on 3 trajectories of agent6: -4.333333333333333
avg return on 3 trajectories of agent7: -4.333333333333333
avg return on 3 trajectories of agent8: -4.333333333333333
avg return on 3 trajectories of agent9: -4.333333333333333
avg return on 3 trajectories of agent10: -4.333333333333333
avg return on 3 trajectories of agent11: -4.666666666666667
avg return on 3 trajectories of agent12: -4.333333333333333
avg return on 3 trajectories of agent13: -4.333333333333333
avg return on 3 trajectories of agent14: -4.0
avg return on 3 trajectories of agent15: -4.0
avg return on 3 trajectories of agent16: -4.333333333333333
avg return on 3 trajectories of agent17: -4.333333333333333
avg return on 3 trajectories of agent18: -4.0
avg return on 3 trajectories of agent19: -4.0
avg cum rews: -4.549999999999999, std: 0.626054665699765
the best agent: 19, best agent cum rewards: -4.0
30
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.027519742777103583
avg return on 3 trajectories of agent0: -4.333333333333333
avg return on 3 trajectories of agent1: -4.666666666666667
avg return on 3 trajectories of agent2: -5.333333333333333
avg return on 3 trajectories of agent3: -6.666666666666667
avg return on 3 trajectories of agent4: -4.0
avg return on 3 trajectories of agent5: -4.666666666666667
avg return on 3 trajectories of agent6: -5.333333333333333
avg return on 3 trajectories of agent7: -7.0
avg return on 3 trajectories of agent8: -4.0
avg return on 3 trajectories of agent9: -3.6666666666666665
avg return on 3 trajectories of agent10: -4.0
avg return on 3 trajectories of agent11: -4.0
avg return on 3 trajectories of agent12: -4.0
avg return on 3 trajectories of agent13: -4.0
avg return on 3 trajectories of agent14: -3.6666666666666665
avg return on 3 trajectories of agent15: -3.6666666666666665
avg return on 3 trajectories of agent16: -4.0
avg return on 3 trajectories of agent17: -5.0
avg return on 3 trajectories of agent18: -5.0
avg return on 3 trajectories of agent19: -5.666666666666667
avg cum rews: -4.633333333333334, std: 0.9422196016735048
the best agent: 14, best agent cum rewards: -3.6666666666666665
31
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.025426840108886045
avg return on 3 trajectories of agent0: -4.0
avg return on 3 trajectories of agent1: -4.0
avg return on 3 trajectories of agent2: -4.0
avg return on 3 trajectories of agent3: -4.333333333333333
avg return on 3 trajectories of agent4: -4.0
avg return on 3 trajectories of agent5: -4.0
avg return on 3 trajectories of agent6: -3.3333333333333335
avg return on 3 trajectories of agent7: -3.3333333333333335
avg return on 3 trajectories of agent8: -3.6666666666666665
avg return on 3 trajectories of agent9: -3.3333333333333335
avg return on 3 trajectories of agent10: -3.0
avg return on 3 trajectories of agent11: -3.0
avg return on 3 trajectories of agent12: -4.0
avg return on 3 trajectories of agent13: -4.333333333333333
avg return on 3 trajectories of agent14: -6.0
avg return on 3 trajectories of agent15: -36.333333333333336
avg return on 3 trajectories of agent16: -3.6666666666666665
avg return on 3 trajectories of agent17: -4.333333333333333
avg return on 3 trajectories of agent18: -5.666666666666667
avg return on 3 trajectories of agent19: -10.333333333333334
avg cum rews: -5.933333333333334, std: 7.146560944491646
the best agent: 11, best agent cum rewards: -3.0
32
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.024266867665938052
avg return on 3 trajectories of agent0: -3.0
avg return on 3 trajectories of agent1: -3.0
avg return on 3 trajectories of agent2: -3.0
avg return on 3 trajectories of agent3: -3.0
avg return on 3 trajectories of agent4: -3.0
avg return on 3 trajectories of agent5: -3.3333333333333335
avg return on 3 trajectories of agent6: -3.6666666666666665
avg return on 3 trajectories of agent7: -4.0
avg return on 3 trajectories of agent8: -3.0
avg return on 3 trajectories of agent9: -3.0
avg return on 3 trajectories of agent10: -3.0
avg return on 3 trajectories of agent11: -3.0
avg return on 3 trajectories of agent12: -3.0
avg return on 3 trajectories of agent13: -3.0
avg return on 3 trajectories of agent14: -3.0
avg return on 3 trajectories of agent15: -3.3333333333333335
avg return on 3 trajectories of agent16: -3.0
avg return on 3 trajectories of agent17: -3.0
avg return on 3 trajectories of agent18: -3.0
avg return on 3 trajectories of agent19: -3.3333333333333335
avg cum rews: -3.1333333333333337, std: 0.26666666666666666
the best agent: 18, best agent cum rewards: -3.0
33
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02496786313975692
avg return on 3 trajectories of agent0: -3.0
avg return on 3 trajectories of agent1: -3.0
avg return on 3 trajectories of agent2: -3.0
avg return on 3 trajectories of agent3: -3.0
avg return on 3 trajectories of agent4: -2.6666666666666665
avg return on 3 trajectories of agent5: -2.3333333333333335
avg return on 3 trajectories of agent6: -2.3333333333333335
avg return on 3 trajectories of agent7: -2.3333333333333335
avg return on 3 trajectories of agent8: -3.0
avg return on 3 trajectories of agent9: -3.0
avg return on 3 trajectories of agent10: -3.3333333333333335
avg return on 3 trajectories of agent11: -4.0
avg return on 3 trajectories of agent12: -2.6666666666666665
avg return on 3 trajectories of agent13: -3.0
avg return on 3 trajectories of agent14: -3.0
avg return on 3 trajectories of agent15: -3.3333333333333335
avg return on 3 trajectories of agent16: -2.6666666666666665
avg return on 3 trajectories of agent17: -2.6666666666666665
avg return on 3 trajectories of agent18: -3.0
avg return on 3 trajectories of agent19: -3.3333333333333335
avg cum rews: -2.933333333333333, std: 0.38873012632302
the best agent: 5, best agent cum rewards: -2.3333333333333335
34
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02528081385766463
avg return on 3 trajectories of agent0: -3.0
avg return on 3 trajectories of agent1: -3.0
avg return on 3 trajectories of agent2: -3.0
avg return on 3 trajectories of agent3: -3.0
avg return on 3 trajectories of agent4: -3.0
avg return on 3 trajectories of agent5: -3.0
avg return on 3 trajectories of agent6: -3.0
avg return on 3 trajectories of agent7: -3.0
avg return on 3 trajectories of agent8: -2.3333333333333335
avg return on 3 trajectories of agent9: -2.3333333333333335
avg return on 3 trajectories of agent10: -2.3333333333333335
avg return on 3 trajectories of agent11: -2.3333333333333335
avg return on 3 trajectories of agent12: -2.3333333333333335
avg return on 3 trajectories of agent13: -2.3333333333333335
avg return on 3 trajectories of agent14: -2.6666666666666665
avg return on 3 trajectories of agent15: -2.6666666666666665
avg return on 3 trajectories of agent16: -2.3333333333333335
avg return on 3 trajectories of agent17: -3.0
avg return on 3 trajectories of agent18: -2.6666666666666665
avg return on 3 trajectories of agent19: -2.6666666666666665
avg cum rews: -2.7, std: 0.29627314724385295
the best agent: 16, best agent cum rewards: -2.3333333333333335
35
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02771658571855063
avg return on 3 trajectories of agent0: -2.6666666666666665
avg return on 3 trajectories of agent1: -3.0
avg return on 3 trajectories of agent2: -3.0
avg return on 3 trajectories of agent3: -3.3333333333333335
avg return on 3 trajectories of agent4: -2.3333333333333335
avg return on 3 trajectories of agent5: -2.3333333333333335
avg return on 3 trajectories of agent6: -2.3333333333333335
avg return on 3 trajectories of agent7: -2.3333333333333335
avg return on 3 trajectories of agent8: -2.3333333333333335
avg return on 3 trajectories of agent9: -2.0
avg return on 3 trajectories of agent10: -2.0
avg return on 3 trajectories of agent11: -2.0
avg return on 3 trajectories of agent12: -2.0
avg return on 3 trajectories of agent13: -2.0
avg return on 3 trajectories of agent14: -2.0
avg return on 3 trajectories of agent15: -2.3333333333333335
avg return on 3 trajectories of agent16: -2.0
avg return on 3 trajectories of agent17: -2.3333333333333335
avg return on 3 trajectories of agent18: -2.3333333333333335
avg return on 3 trajectories of agent19: -2.3333333333333335
avg cum rews: -2.3500000000000005, std: 0.3723051317281446
the best agent: 16, best agent cum rewards: -2.0
36
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.025660266734708653
avg return on 3 trajectories of agent0: -2.0
avg return on 3 trajectories of agent1: -2.0
avg return on 3 trajectories of agent2: -2.0
avg return on 3 trajectories of agent3: -2.0
avg return on 3 trajectories of agent4: -2.3333333333333335
avg return on 3 trajectories of agent5: -2.0
avg return on 3 trajectories of agent6: -2.0
avg return on 3 trajectories of agent7: -2.0
avg return on 3 trajectories of agent8: -2.3333333333333335
avg return on 3 trajectories of agent9: -2.3333333333333335
avg return on 3 trajectories of agent10: -2.3333333333333335
avg return on 3 trajectories of agent11: -2.3333333333333335
avg return on 3 trajectories of agent12: -2.0
avg return on 3 trajectories of agent13: -2.0
avg return on 3 trajectories of agent14: -2.0
avg return on 3 trajectories of agent15: -2.0
avg return on 3 trajectories of agent16: -2.0
avg return on 3 trajectories of agent17: -2.3333333333333335
avg return on 3 trajectories of agent18: -2.3333333333333335
avg return on 3 trajectories of agent19: -2.3333333333333335
avg cum rews: -2.1333333333333337, std: 0.16329931618554527
the best agent: 16, best agent cum rewards: -2.0
37
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.025611100529976262
avg return on 3 trajectories of agent0: -2.0
avg return on 3 trajectories of agent1: -2.0
avg return on 3 trajectories of agent2: -2.0
avg return on 3 trajectories of agent3: -2.0
avg return on 3 trajectories of agent4: -2.0
avg return on 3 trajectories of agent5: -2.0
avg return on 3 trajectories of agent6: -2.0
avg return on 3 trajectories of agent7: -2.0
avg return on 3 trajectories of agent8: -2.0
avg return on 3 trajectories of agent9: -2.0
avg return on 3 trajectories of agent10: -2.0
avg return on 3 trajectories of agent11: -2.0
avg return on 3 trajectories of agent12: -2.0
avg return on 3 trajectories of agent13: -2.0
avg return on 3 trajectories of agent14: -2.3333333333333335
avg return on 3 trajectories of agent15: -2.3333333333333335
avg return on 3 trajectories of agent16: -2.0
avg return on 3 trajectories of agent17: -2.0
avg return on 3 trajectories of agent18: -2.0
avg return on 3 trajectories of agent19: -2.0
avg cum rews: -2.0333333333333337, std: 0.10000000000000006
the best agent: 19, best agent cum rewards: -2.0
38
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02352794239537114
avg return on 3 trajectories of agent0: -2.0
avg return on 3 trajectories of agent1: -2.0
avg return on 3 trajectories of agent2: -2.0
avg return on 3 trajectories of agent3: -2.0
avg return on 3 trajectories of agent4: -2.0
avg return on 3 trajectories of agent5: -2.0
avg return on 3 trajectories of agent6: -2.0
avg return on 3 trajectories of agent7: -2.0
avg return on 3 trajectories of agent8: -2.0
avg return on 3 trajectories of agent9: -2.0
avg return on 3 trajectories of agent10: -2.0
avg return on 3 trajectories of agent11: -2.3333333333333335
avg return on 3 trajectories of agent12: -2.0
avg return on 3 trajectories of agent13: -2.0
avg return on 3 trajectories of agent14: -2.0
avg return on 3 trajectories of agent15: -2.0
avg return on 3 trajectories of agent16: -2.0
avg return on 3 trajectories of agent17: -2.0
avg return on 3 trajectories of agent18: -2.0
avg return on 3 trajectories of agent19: -2.0
avg cum rews: -2.0166666666666666, std: 0.07264831572567793
the best agent: 19, best agent cum rewards: -2.0
39
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02529697382937774
avg return on 3 trajectories of agent0: -2.0
avg return on 3 trajectories of agent1: -2.0
avg return on 3 trajectories of agent2: -2.0
avg return on 3 trajectories of agent3: -2.0
avg return on 3 trajectories of agent4: -2.0
avg return on 3 trajectories of agent5: -2.0
avg return on 3 trajectories of agent6: -2.0
avg return on 3 trajectories of agent7: -2.0
avg return on 3 trajectories of agent8: -2.0
avg return on 3 trajectories of agent9: -2.0
avg return on 3 trajectories of agent10: -2.0
avg return on 3 trajectories of agent11: -2.0
avg return on 3 trajectories of agent12: -2.0
avg return on 3 trajectories of agent13: -2.0
avg return on 3 trajectories of agent14: -2.0
avg return on 3 trajectories of agent15: -2.0
avg return on 3 trajectories of agent16: -2.0
avg return on 3 trajectories of agent17: -2.0
avg return on 3 trajectories of agent18: -2.0
avg return on 3 trajectories of agent19: -2.0
avg cum rews: -2.0, std: 0.0
the best agent: 19, best agent cum rewards: -2.0
40
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.026129780050538415
avg return on 3 trajectories of agent0: -2.0
avg return on 3 trajectories of agent1: -2.0
avg return on 3 trajectories of agent2: -2.0
avg return on 3 trajectories of agent3: -2.0
avg return on 3 trajectories of agent4: -2.0
avg return on 3 trajectories of agent5: -2.0
avg return on 3 trajectories of agent6: -2.0
avg return on 3 trajectories of agent7: -2.0
avg return on 3 trajectories of agent8: -2.0
avg return on 3 trajectories of agent9: -2.0
avg return on 3 trajectories of agent10: -2.0
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -2.0
avg return on 3 trajectories of agent13: -2.0
avg return on 3 trajectories of agent14: -2.0
avg return on 3 trajectories of agent15: -2.0
avg return on 3 trajectories of agent16: -2.0
avg return on 3 trajectories of agent17: -2.0
avg return on 3 trajectories of agent18: -2.0
avg return on 3 trajectories of agent19: -2.0
avg cum rews: -1.9833333333333336, std: 0.07264831572567787
the best agent: 11, best agent cum rewards: -1.6666666666666667
41
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.022575717797820645
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -2.0
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6833333333333331, std: 0.07264831572567787
the best agent: 19, best agent cum rewards: -1.6666666666666667
42
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.0200363404216665
avg return on 3 trajectories of agent0: -2.0
avg return on 3 trajectories of agent1: -2.0
avg return on 3 trajectories of agent2: -2.0
avg return on 3 trajectories of agent3: -2.0
avg return on 3 trajectories of agent4: -2.0
avg return on 3 trajectories of agent5: -2.0
avg return on 3 trajectories of agent6: -2.0
avg return on 3 trajectories of agent7: -2.0
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -2.0
avg return on 3 trajectories of agent13: -2.0
avg return on 3 trajectories of agent14: -2.0
avg return on 3 trajectories of agent15: -2.0
avg return on 3 trajectories of agent16: -2.0
avg return on 3 trajectories of agent17: -2.0
avg return on 3 trajectories of agent18: -2.0
avg return on 3 trajectories of agent19: -2.0
avg cum rews: -1.9333333333333336, std: 0.1333333333333333
the best agent: 11, best agent cum rewards: -1.6666666666666667
43
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.021218850059541633
avg return on 3 trajectories of agent0: -2.0
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -2.0
avg return on 3 trajectories of agent5: -2.0
avg return on 3 trajectories of agent6: -2.0
avg return on 3 trajectories of agent7: -2.3333333333333335
avg return on 3 trajectories of agent8: -2.0
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -2.0
avg return on 3 trajectories of agent13: -2.0
avg return on 3 trajectories of agent14: -2.0
avg return on 3 trajectories of agent15: -2.0
avg return on 3 trajectories of agent16: -2.0
avg return on 3 trajectories of agent17: -2.0
avg return on 3 trajectories of agent18: -2.0
avg return on 3 trajectories of agent19: -2.0
avg cum rews: -1.9166666666666667, std: 0.17873008824606013
the best agent: 2, best agent cum rewards: -1.6666666666666667
44
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02604144737170545
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -2.0
avg return on 3 trajectories of agent11: -2.0
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.7, std: 0.09999999999999996
the best agent: 19, best agent cum rewards: -1.6666666666666667
45
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.022637089773316178
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
46
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.020967230668374935
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -2.0
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6833333333333331, std: 0.07264831572567787
the best agent: 19, best agent cum rewards: -1.6666666666666667
47
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.025068054656435766
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -2.0
avg return on 3 trajectories of agent15: -2.0
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.7, std: 0.09999999999999996
the best agent: 19, best agent cum rewards: -1.6666666666666667
48
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.024616020318551538
avg return on 3 trajectories of agent0: -2.0
avg return on 3 trajectories of agent1: -2.0
avg return on 3 trajectories of agent2: -2.0
avg return on 3 trajectories of agent3: -2.3333333333333335
avg return on 3 trajectories of agent4: -2.0
avg return on 3 trajectories of agent5: -2.0
avg return on 3 trajectories of agent6: -2.0
avg return on 3 trajectories of agent7: -2.0
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.8166666666666664, std: 0.19649710204252657
the best agent: 19, best agent cum rewards: -1.6666666666666667
49
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.021230834129195332
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -2.0
avg return on 3 trajectories of agent3: -2.0
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -2.0
avg return on 3 trajectories of agent19: -2.0
avg cum rews: -1.7333333333333336, std: 0.1333333333333333
the best agent: 16, best agent cum rewards: -1.6666666666666667
50
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.020157294117307663
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
51
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.01953547043279799
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
52
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.018988483458236775
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
53
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.024225299580245975
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
54
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02042951385764782
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
55
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.020572824846035908
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
56
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.020062512393387133
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
57
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.0212356858226496
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -2.0
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -2.0
avg cum rews: -1.7, std: 0.09999999999999998
the best agent: 18, best agent cum rewards: -1.6666666666666667
58
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.020816349398185944
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -2.0
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6833333333333331, std: 0.07264831572567787
the best agent: 19, best agent cum rewards: -1.6666666666666667
59
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.0235826943657095
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
60
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02019294750156037
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
61
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02195705424101302
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
62
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.023713313821937997
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -2.0
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6833333333333331, std: 0.07264831572567787
the best agent: 19, best agent cum rewards: -1.6666666666666667
63
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02049079019415068
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -2.0
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6833333333333331, std: 0.07264831572567787
the best agent: 19, best agent cum rewards: -1.6666666666666667
64
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.021271683990717005
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -2.0
avg return on 3 trajectories of agent15: -2.0
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -2.0
avg return on 3 trajectories of agent19: -2.0
avg cum rews: -1.7333333333333336, std: 0.1333333333333333
the best agent: 16, best agent cum rewards: -1.6666666666666667
65
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.022916461535428263
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -2.0
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -2.0
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.7, std: 0.09999999999999996
the best agent: 19, best agent cum rewards: -1.6666666666666667
66
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.020276770288992843
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
67
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02360899058381433
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
68
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.019307354887067453
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
69
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.0223949709529828
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
70
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.01956769145676073
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
71
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.019778776739865327
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
72
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.0202636435403699
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -2.0
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -2.0
avg return on 3 trajectories of agent7: -2.0
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.7166666666666668, std: 0.11902380714238081
the best agent: 19, best agent cum rewards: -1.6666666666666667
73
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.019481018619848144
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -2.0
avg return on 3 trajectories of agent11: -2.0
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.7, std: 0.09999999999999996
the best agent: 19, best agent cum rewards: -1.6666666666666667
74
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.017647408414074025
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
75
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.023417226045436935
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
76
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02125710668031283
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
77
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.020286581069502752
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
78
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.020833267503635546
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
79
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.019262934938851953
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
80
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.024464018065861237
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
81
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.020495375471544
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
82
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.024774449039726344
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -2.0
avg cum rews: -1.6833333333333336, std: 0.07264831572567787
the best agent: 18, best agent cum rewards: -1.6666666666666667
83
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.019221658252518335
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -2.0
avg return on 3 trajectories of agent15: -2.3333333333333335
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -2.0
avg return on 3 trajectories of agent19: -2.3333333333333335
avg cum rews: -1.7666666666666668, std: 0.21343747458109497
the best agent: 16, best agent cum rewards: -1.6666666666666667
84
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.022058105746970466
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
85
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.023542097348008547
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -2.0
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6833333333333331, std: 0.07264831572567787
the best agent: 19, best agent cum rewards: -1.6666666666666667
86
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.023425668739088516
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
87
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02026936071258301
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
88
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.01929451108539467
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -2.0
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6833333333333331, std: 0.07264831572567787
the best agent: 19, best agent cum rewards: -1.6666666666666667
89
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02017028384149271
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -2.0
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -2.0
avg return on 3 trajectories of agent19: -2.0
avg cum rews: -1.7166666666666668, std: 0.11902380714238081
the best agent: 16, best agent cum rewards: -1.6666666666666667
90
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.01901023905014719
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -2.0
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -2.0
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -2.0
avg return on 3 trajectories of agent19: -2.0
avg cum rews: -1.7333333333333336, std: 0.1333333333333333
the best agent: 16, best agent cum rewards: -1.6666666666666667
91
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.018765451300721284
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
92
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.022369455442582363
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -2.0
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6833333333333331, std: 0.07264831572567787
the best agent: 19, best agent cum rewards: -1.6666666666666667
93
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.020706347784626288
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
94
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.01957721619435135
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
95
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.018690046608806365
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
96
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.021510334120692226
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
Average distance of random agents to nearest neighbors: [0.02099328483658995, 0.026400765629796246, 0.025249391549132354, 0.029887785885413964, 0.025407386520527965, 0.02697388311241372, 0.025462376665666243, 0.024439250803478266, 0.027861593061571488, 0.020675675079667975, 0.0291693592110722, 0.026340150433869135, 0.022816287593677403, 0.025879785710164343, 0.02431120674814218, 0.023961608640143787, 0.025553772003510906, 0.022750882594338738, 0.026599702550392783, 0.023336512351132856, 0.02599606174081679, 0.02791843649886421, 0.025435084998468534, 0.023875562447055042, 0.0249648521318408, 0.023280641199259766, 0.02637813549705701, 0.02543089928448088, 0.0233684434017685, 0.027519742777103583, 0.025426840108886045, 0.024266867665938052, 0.02496786313975692, 0.02528081385766463, 0.02771658571855063, 0.025660266734708653, 0.025611100529976262, 0.02352794239537114, 0.02529697382937774, 0.026129780050538415, 0.022575717797820645, 0.0200363404216665, 0.021218850059541633, 0.02604144737170545, 0.022637089773316178, 0.020967230668374935, 0.025068054656435766, 0.024616020318551538, 0.021230834129195332, 0.020157294117307663, 0.01953547043279799, 0.018988483458236775, 0.024225299580245975, 0.02042951385764782, 0.020572824846035908, 0.020062512393387133, 0.0212356858226496, 0.020816349398185944, 0.0235826943657095, 0.02019294750156037, 0.02195705424101302, 0.023713313821937997, 0.02049079019415068, 0.021271683990717005, 0.022916461535428263, 0.020276770288992843, 0.02360899058381433, 0.019307354887067453, 0.0223949709529828, 0.01956769145676073, 0.019778776739865327, 0.0202636435403699, 0.019481018619848144, 0.017647408414074025, 0.023417226045436935, 0.02125710668031283, 0.020286581069502752, 0.020833267503635546, 0.019262934938851953, 0.024464018065861237, 0.020495375471544, 0.024774449039726344, 0.019221658252518335, 0.022058105746970466, 0.023542097348008547, 0.023425668739088516, 0.02026936071258301, 0.01929451108539467, 0.02017028384149271, 0.01901023905014719, 0.018765451300721284, 0.022369455442582363, 0.020706347784626288, 0.01957721619435135, 0.018690046608806365, 0.021510334120692226]
Time taken for each iteration: [20.314310550689697, 35.40169405937195, 50.615636587142944, 66.06211566925049, 81.12721228599548, 96.50161862373352, 112.13271689414978, 128.03112149238586, 143.27100348472595, 158.54511189460754, 173.91982698440552, 189.21028542518616, 204.4888744354248, 219.65495896339417, 239.10859203338623, 259.5095965862274, 274.5681359767914, 295.4698152542114, 310.5533528327942, 329.77622866630554, 350.3097128868103, 365.4583775997162, 384.7606317996979, 399.85743284225464, 415.04962825775146, 430.1443700790405, 445.2778732776642, 465.8557333946228, 481.1668276786804, 496.2835214138031, 511.40761852264404, 532.1199684143066, 547.2083864212036, 566.4104256629944, 585.6812012195587, 606.4389407634735, 625.8655369281769, 646.5619313716888, 665.8809978961945, 680.9829299449921, 700.4332447052002, 719.8924732208252, 739.39568567276, 758.89506483078, 778.5622138977051, 799.272926568985, 820.0142107009888, 835.1735696792603, 855.8897566795349, 870.9680483341217, 886.1761484146118, 901.1825580596924, 916.2500350475311, 936.9888150691986, 952.2967820167542, 971.6325612068176, 990.8930361270905, 1005.9637377262115, 1026.351324081421, 1046.8874006271362, 1061.9653096199036, 1077.107073545456, 1092.5213572978973, 1113.1839003562927, 1133.9464831352234, 1154.7483658790588, 1170.2743566036224, 1191.729393005371, 1214.319603919983, 1237.367947101593, 1259.9915437698364, 1276.1847252845764, 1292.384526014328, 1314.8806371688843, 1337.3227791786194, 1359.5875289440155, 1382.0695536136627, 1398.1352529525757, 1420.4565165042877, 1441.303521156311, 1462.2028152942657, 1484.2377154827118, 1499.6014513969421, 1521.0443859100342, 1541.0985362529755, 1562.5060534477234, 1577.8927652835846, 1597.844719171524, 1619.3928582668304, 1634.8435883522034, 1649.9871008396149, 1669.5046014785767, 1684.479027748108, 1704.8693525791168, 1725.2661294937134, 1740.1122508049011]
