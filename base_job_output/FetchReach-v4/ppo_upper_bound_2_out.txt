No devices were found
Setting seed -  1
---------------------------------
Environment created
Box(-1.0, 1.0, (4,), float32) Box(-inf, inf, (16,), float64)
Starting training from scratch
Starting evaluation
1
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.018532178181020847
avg return on 3 trajectories of agent0: -50.0
avg return on 3 trajectories of agent1: -50.0
avg return on 3 trajectories of agent2: -50.0
avg return on 3 trajectories of agent3: -50.0
avg return on 3 trajectories of agent4: -50.0
avg return on 3 trajectories of agent5: -50.0
avg return on 3 trajectories of agent6: -50.0
avg return on 3 trajectories of agent7: -50.0
avg return on 3 trajectories of agent8: -50.0
avg return on 3 trajectories of agent9: -50.0
avg return on 3 trajectories of agent10: -50.0
avg return on 3 trajectories of agent11: -50.0
avg return on 3 trajectories of agent12: -50.0
avg return on 3 trajectories of agent13: -50.0
avg return on 3 trajectories of agent14: -50.0
avg return on 3 trajectories of agent15: -50.0
avg return on 3 trajectories of agent16: -50.0
avg return on 3 trajectories of agent17: -50.0
avg return on 3 trajectories of agent18: -50.0
avg return on 3 trajectories of agent19: -50.0
avg cum rews: -50.0, std: 0.0
the best agent: 19, best agent cum rewards: -50.0
2
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02722416738894808
avg return on 3 trajectories of agent0: -50.0
avg return on 3 trajectories of agent1: -50.0
avg return on 3 trajectories of agent2: -50.0
avg return on 3 trajectories of agent3: -50.0
avg return on 3 trajectories of agent4: -50.0
avg return on 3 trajectories of agent5: -50.0
avg return on 3 trajectories of agent6: -50.0
avg return on 3 trajectories of agent7: -50.0
avg return on 3 trajectories of agent8: -50.0
avg return on 3 trajectories of agent9: -50.0
avg return on 3 trajectories of agent10: -50.0
avg return on 3 trajectories of agent11: -50.0
avg return on 3 trajectories of agent12: -50.0
avg return on 3 trajectories of agent13: -50.0
avg return on 3 trajectories of agent14: -50.0
avg return on 3 trajectories of agent15: -50.0
avg return on 3 trajectories of agent16: -50.0
avg return on 3 trajectories of agent17: -50.0
avg return on 3 trajectories of agent18: -50.0
avg return on 3 trajectories of agent19: -50.0
avg cum rews: -50.0, std: 0.0
the best agent: 19, best agent cum rewards: -50.0
3
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02991712158578646
avg return on 3 trajectories of agent0: -50.0
avg return on 3 trajectories of agent1: -50.0
avg return on 3 trajectories of agent2: -50.0
avg return on 3 trajectories of agent3: -50.0
avg return on 3 trajectories of agent4: -50.0
avg return on 3 trajectories of agent5: -50.0
avg return on 3 trajectories of agent6: -50.0
avg return on 3 trajectories of agent7: -50.0
avg return on 3 trajectories of agent8: -50.0
avg return on 3 trajectories of agent9: -50.0
avg return on 3 trajectories of agent10: -50.0
avg return on 3 trajectories of agent11: -50.0
avg return on 3 trajectories of agent12: -50.0
avg return on 3 trajectories of agent13: -50.0
avg return on 3 trajectories of agent14: -50.0
avg return on 3 trajectories of agent15: -50.0
avg return on 3 trajectories of agent16: -50.0
avg return on 3 trajectories of agent17: -50.0
avg return on 3 trajectories of agent18: -50.0
avg return on 3 trajectories of agent19: -50.0
avg cum rews: -50.0, std: 0.0
the best agent: 19, best agent cum rewards: -50.0
4
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.030810076823461707
avg return on 3 trajectories of agent0: -47.0
avg return on 3 trajectories of agent1: -48.333333333333336
avg return on 3 trajectories of agent2: -50.0
avg return on 3 trajectories of agent3: -50.0
avg return on 3 trajectories of agent4: -50.0
avg return on 3 trajectories of agent5: -50.0
avg return on 3 trajectories of agent6: -50.0
avg return on 3 trajectories of agent7: -50.0
avg return on 3 trajectories of agent8: -45.666666666666664
avg return on 3 trajectories of agent9: -45.0
avg return on 3 trajectories of agent10: -44.333333333333336
avg return on 3 trajectories of agent11: -44.333333333333336
avg return on 3 trajectories of agent12: -45.666666666666664
avg return on 3 trajectories of agent13: -44.666666666666664
avg return on 3 trajectories of agent14: -44.333333333333336
avg return on 3 trajectories of agent15: -43.666666666666664
avg return on 3 trajectories of agent16: -47.0
avg return on 3 trajectories of agent17: -50.0
avg return on 3 trajectories of agent18: -50.0
avg return on 3 trajectories of agent19: -50.0
avg cum rews: -47.5, std: 2.482158558817529
the best agent: 15, best agent cum rewards: -43.666666666666664
5
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.022985713132880746
avg return on 3 trajectories of agent0: -50.0
avg return on 3 trajectories of agent1: -50.0
avg return on 3 trajectories of agent2: -50.0
avg return on 3 trajectories of agent3: -50.0
avg return on 3 trajectories of agent4: -50.0
avg return on 3 trajectories of agent5: -50.0
avg return on 3 trajectories of agent6: -50.0
avg return on 3 trajectories of agent7: -50.0
avg return on 3 trajectories of agent8: -50.0
avg return on 3 trajectories of agent9: -50.0
avg return on 3 trajectories of agent10: -50.0
avg return on 3 trajectories of agent11: -50.0
avg return on 3 trajectories of agent12: -50.0
avg return on 3 trajectories of agent13: -50.0
avg return on 3 trajectories of agent14: -50.0
avg return on 3 trajectories of agent15: -50.0
avg return on 3 trajectories of agent16: -50.0
avg return on 3 trajectories of agent17: -50.0
avg return on 3 trajectories of agent18: -50.0
avg return on 3 trajectories of agent19: -50.0
avg cum rews: -50.0, std: 0.0
the best agent: 19, best agent cum rewards: -50.0
6
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.022828952885817648
avg return on 3 trajectories of agent0: -50.0
avg return on 3 trajectories of agent1: -50.0
avg return on 3 trajectories of agent2: -50.0
avg return on 3 trajectories of agent3: -50.0
avg return on 3 trajectories of agent4: -50.0
avg return on 3 trajectories of agent5: -50.0
avg return on 3 trajectories of agent6: -50.0
avg return on 3 trajectories of agent7: -50.0
avg return on 3 trajectories of agent8: -50.0
avg return on 3 trajectories of agent9: -50.0
avg return on 3 trajectories of agent10: -50.0
avg return on 3 trajectories of agent11: -50.0
avg return on 3 trajectories of agent12: -50.0
avg return on 3 trajectories of agent13: -50.0
avg return on 3 trajectories of agent14: -50.0
avg return on 3 trajectories of agent15: -50.0
avg return on 3 trajectories of agent16: -50.0
avg return on 3 trajectories of agent17: -50.0
avg return on 3 trajectories of agent18: -50.0
avg return on 3 trajectories of agent19: -50.0
avg cum rews: -50.0, std: 0.0
the best agent: 19, best agent cum rewards: -50.0
7
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.026847429361652502
avg return on 3 trajectories of agent0: -50.0
avg return on 3 trajectories of agent1: -50.0
avg return on 3 trajectories of agent2: -50.0
avg return on 3 trajectories of agent3: -50.0
avg return on 3 trajectories of agent4: -50.0
avg return on 3 trajectories of agent5: -50.0
avg return on 3 trajectories of agent6: -50.0
avg return on 3 trajectories of agent7: -50.0
avg return on 3 trajectories of agent8: -50.0
avg return on 3 trajectories of agent9: -50.0
avg return on 3 trajectories of agent10: -50.0
avg return on 3 trajectories of agent11: -50.0
avg return on 3 trajectories of agent12: -50.0
avg return on 3 trajectories of agent13: -50.0
avg return on 3 trajectories of agent14: -50.0
avg return on 3 trajectories of agent15: -50.0
avg return on 3 trajectories of agent16: -50.0
avg return on 3 trajectories of agent17: -50.0
avg return on 3 trajectories of agent18: -50.0
avg return on 3 trajectories of agent19: -50.0
avg cum rews: -50.0, std: 0.0
the best agent: 19, best agent cum rewards: -50.0
8
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02831515752094031
avg return on 3 trajectories of agent0: -50.0
avg return on 3 trajectories of agent1: -50.0
avg return on 3 trajectories of agent2: -50.0
avg return on 3 trajectories of agent3: -50.0
avg return on 3 trajectories of agent4: -50.0
avg return on 3 trajectories of agent5: -50.0
avg return on 3 trajectories of agent6: -47.333333333333336
avg return on 3 trajectories of agent7: -46.0
avg return on 3 trajectories of agent8: -50.0
avg return on 3 trajectories of agent9: -50.0
avg return on 3 trajectories of agent10: -50.0
avg return on 3 trajectories of agent11: -50.0
avg return on 3 trajectories of agent12: -50.0
avg return on 3 trajectories of agent13: -50.0
avg return on 3 trajectories of agent14: -50.0
avg return on 3 trajectories of agent15: -50.0
avg return on 3 trajectories of agent16: -50.0
avg return on 3 trajectories of agent17: -45.666666666666664
avg return on 3 trajectories of agent18: -45.333333333333336
avg return on 3 trajectories of agent19: -45.666666666666664
avg cum rews: -49.0, std: 1.766981104093143
the best agent: 18, best agent cum rewards: -45.333333333333336
9
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.019872513960974794
avg return on 3 trajectories of agent0: -50.0
avg return on 3 trajectories of agent1: -50.0
avg return on 3 trajectories of agent2: -50.0
avg return on 3 trajectories of agent3: -50.0
avg return on 3 trajectories of agent4: -50.0
avg return on 3 trajectories of agent5: -50.0
avg return on 3 trajectories of agent6: -50.0
avg return on 3 trajectories of agent7: -50.0
avg return on 3 trajectories of agent8: -50.0
avg return on 3 trajectories of agent9: -50.0
avg return on 3 trajectories of agent10: -50.0
avg return on 3 trajectories of agent11: -50.0
avg return on 3 trajectories of agent12: -50.0
avg return on 3 trajectories of agent13: -50.0
avg return on 3 trajectories of agent14: -50.0
avg return on 3 trajectories of agent15: -50.0
avg return on 3 trajectories of agent16: -50.0
avg return on 3 trajectories of agent17: -50.0
avg return on 3 trajectories of agent18: -50.0
avg return on 3 trajectories of agent19: -50.0
avg cum rews: -50.0, std: 0.0
the best agent: 19, best agent cum rewards: -50.0
10
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.021849936237682086
avg return on 3 trajectories of agent0: -50.0
avg return on 3 trajectories of agent1: -50.0
avg return on 3 trajectories of agent2: -50.0
avg return on 3 trajectories of agent3: -50.0
avg return on 3 trajectories of agent4: -50.0
avg return on 3 trajectories of agent5: -50.0
avg return on 3 trajectories of agent6: -50.0
avg return on 3 trajectories of agent7: -50.0
avg return on 3 trajectories of agent8: -50.0
avg return on 3 trajectories of agent9: -50.0
avg return on 3 trajectories of agent10: -50.0
avg return on 3 trajectories of agent11: -50.0
avg return on 3 trajectories of agent12: -50.0
avg return on 3 trajectories of agent13: -50.0
avg return on 3 trajectories of agent14: -50.0
avg return on 3 trajectories of agent15: -50.0
avg return on 3 trajectories of agent16: -50.0
avg return on 3 trajectories of agent17: -50.0
avg return on 3 trajectories of agent18: -50.0
avg return on 3 trajectories of agent19: -50.0
avg cum rews: -50.0, std: 0.0
the best agent: 19, best agent cum rewards: -50.0
11
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.024882383604929816
avg return on 3 trajectories of agent0: -50.0
avg return on 3 trajectories of agent1: -50.0
avg return on 3 trajectories of agent2: -50.0
avg return on 3 trajectories of agent3: -50.0
avg return on 3 trajectories of agent4: -50.0
avg return on 3 trajectories of agent5: -50.0
avg return on 3 trajectories of agent6: -50.0
avg return on 3 trajectories of agent7: -50.0
avg return on 3 trajectories of agent8: -50.0
avg return on 3 trajectories of agent9: -50.0
avg return on 3 trajectories of agent10: -50.0
avg return on 3 trajectories of agent11: -50.0
avg return on 3 trajectories of agent12: -50.0
avg return on 3 trajectories of agent13: -50.0
avg return on 3 trajectories of agent14: -50.0
avg return on 3 trajectories of agent15: -50.0
avg return on 3 trajectories of agent16: -50.0
avg return on 3 trajectories of agent17: -50.0
avg return on 3 trajectories of agent18: -50.0
avg return on 3 trajectories of agent19: -50.0
avg cum rews: -50.0, std: 0.0
the best agent: 19, best agent cum rewards: -50.0
12
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.028105334191700422
avg return on 3 trajectories of agent0: -50.0
avg return on 3 trajectories of agent1: -50.0
avg return on 3 trajectories of agent2: -50.0
avg return on 3 trajectories of agent3: -50.0
avg return on 3 trajectories of agent4: -49.333333333333336
avg return on 3 trajectories of agent5: -50.0
avg return on 3 trajectories of agent6: -50.0
avg return on 3 trajectories of agent7: -50.0
avg return on 3 trajectories of agent8: -48.666666666666664
avg return on 3 trajectories of agent9: -50.0
avg return on 3 trajectories of agent10: -50.0
avg return on 3 trajectories of agent11: -50.0
avg return on 3 trajectories of agent12: -50.0
avg return on 3 trajectories of agent13: -50.0
avg return on 3 trajectories of agent14: -50.0
avg return on 3 trajectories of agent15: -50.0
avg return on 3 trajectories of agent16: -50.0
avg return on 3 trajectories of agent17: -50.0
avg return on 3 trajectories of agent18: -50.0
avg return on 3 trajectories of agent19: -50.0
avg cum rews: -49.9, std: 0.3179797338056488
the best agent: 8, best agent cum rewards: -48.666666666666664
13
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.026537398179594017
avg return on 3 trajectories of agent0: -28.333333333333332
avg return on 3 trajectories of agent1: -30.666666666666668
avg return on 3 trajectories of agent2: -33.333333333333336
avg return on 3 trajectories of agent3: -42.333333333333336
avg return on 3 trajectories of agent4: -28.333333333333332
avg return on 3 trajectories of agent5: -29.0
avg return on 3 trajectories of agent6: -30.333333333333332
avg return on 3 trajectories of agent7: -32.0
avg return on 3 trajectories of agent8: -28.0
avg return on 3 trajectories of agent9: -28.333333333333332
avg return on 3 trajectories of agent10: -29.666666666666668
avg return on 3 trajectories of agent11: -45.666666666666664
avg return on 3 trajectories of agent12: -29.666666666666668
avg return on 3 trajectories of agent13: -30.0
avg return on 3 trajectories of agent14: -38.666666666666664
avg return on 3 trajectories of agent15: -41.666666666666664
avg return on 3 trajectories of agent16: -29.0
avg return on 3 trajectories of agent17: -28.333333333333332
avg return on 3 trajectories of agent18: -34.666666666666664
avg return on 3 trajectories of agent19: -39.666666666666664
avg cum rews: -32.88333333333333, std: 5.434739081951302
the best agent: 8, best agent cum rewards: -28.0
14
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.024481187581502185
avg return on 3 trajectories of agent0: -50.0
avg return on 3 trajectories of agent1: -50.0
avg return on 3 trajectories of agent2: -50.0
avg return on 3 trajectories of agent3: -50.0
avg return on 3 trajectories of agent4: -50.0
avg return on 3 trajectories of agent5: -50.0
avg return on 3 trajectories of agent6: -50.0
avg return on 3 trajectories of agent7: -50.0
avg return on 3 trajectories of agent8: -47.666666666666664
avg return on 3 trajectories of agent9: -50.0
avg return on 3 trajectories of agent10: -50.0
avg return on 3 trajectories of agent11: -50.0
avg return on 3 trajectories of agent12: -37.333333333333336
avg return on 3 trajectories of agent13: -48.333333333333336
avg return on 3 trajectories of agent14: -50.0
avg return on 3 trajectories of agent15: -50.0
avg return on 3 trajectories of agent16: -34.0
avg return on 3 trajectories of agent17: -30.333333333333332
avg return on 3 trajectories of agent18: -33.0
avg return on 3 trajectories of agent19: -40.333333333333336
avg cum rews: -46.05, std: 6.640176537144509
the best agent: 17, best agent cum rewards: -30.333333333333332
15
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.026358253474993563
avg return on 3 trajectories of agent0: -50.0
avg return on 3 trajectories of agent1: -39.666666666666664
avg return on 3 trajectories of agent2: -44.666666666666664
avg return on 3 trajectories of agent3: -50.0
avg return on 3 trajectories of agent4: -50.0
avg return on 3 trajectories of agent5: -50.0
avg return on 3 trajectories of agent6: -50.0
avg return on 3 trajectories of agent7: -50.0
avg return on 3 trajectories of agent8: -39.0
avg return on 3 trajectories of agent9: -50.0
avg return on 3 trajectories of agent10: -50.0
avg return on 3 trajectories of agent11: -50.0
avg return on 3 trajectories of agent12: -50.0
avg return on 3 trajectories of agent13: -50.0
avg return on 3 trajectories of agent14: -50.0
avg return on 3 trajectories of agent15: -50.0
avg return on 3 trajectories of agent16: -50.0
avg return on 3 trajectories of agent17: -50.0
avg return on 3 trajectories of agent18: -50.0
avg return on 3 trajectories of agent19: -50.0
avg cum rews: -48.666666666666664, std: 3.3216461782274966
the best agent: 8, best agent cum rewards: -39.0
16
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.026028778774185767
avg return on 3 trajectories of agent0: -50.0
avg return on 3 trajectories of agent1: -50.0
avg return on 3 trajectories of agent2: -38.666666666666664
avg return on 3 trajectories of agent3: -38.0
avg return on 3 trajectories of agent4: -50.0
avg return on 3 trajectories of agent5: -50.0
avg return on 3 trajectories of agent6: -50.0
avg return on 3 trajectories of agent7: -50.0
avg return on 3 trajectories of agent8: -50.0
avg return on 3 trajectories of agent9: -50.0
avg return on 3 trajectories of agent10: -50.0
avg return on 3 trajectories of agent11: -50.0
avg return on 3 trajectories of agent12: -50.0
avg return on 3 trajectories of agent13: -50.0
avg return on 3 trajectories of agent14: -50.0
avg return on 3 trajectories of agent15: -50.0
avg return on 3 trajectories of agent16: -50.0
avg return on 3 trajectories of agent17: -50.0
avg return on 3 trajectories of agent18: -50.0
avg return on 3 trajectories of agent19: -50.0
avg cum rews: -48.83333333333333, std: 3.501586941818111
the best agent: 3, best agent cum rewards: -38.0
17
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.026268041873786098
avg return on 3 trajectories of agent0: -26.666666666666668
avg return on 3 trajectories of agent1: -29.333333333333332
avg return on 3 trajectories of agent2: -36.666666666666664
avg return on 3 trajectories of agent3: -41.666666666666664
avg return on 3 trajectories of agent4: -27.333333333333332
avg return on 3 trajectories of agent5: -27.333333333333332
avg return on 3 trajectories of agent6: -27.333333333333332
avg return on 3 trajectories of agent7: -27.333333333333332
avg return on 3 trajectories of agent8: -26.333333333333332
avg return on 3 trajectories of agent9: -26.0
avg return on 3 trajectories of agent10: -25.333333333333332
avg return on 3 trajectories of agent11: -24.666666666666668
avg return on 3 trajectories of agent12: -27.333333333333332
avg return on 3 trajectories of agent13: -43.0
avg return on 3 trajectories of agent14: -50.0
avg return on 3 trajectories of agent15: -50.0
avg return on 3 trajectories of agent16: -26.666666666666668
avg return on 3 trajectories of agent17: -38.666666666666664
avg return on 3 trajectories of agent18: -50.0
avg return on 3 trajectories of agent19: -50.0
avg cum rews: -34.08333333333333, std: 9.563167188053688
the best agent: 11, best agent cum rewards: -24.666666666666668
18
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02808735855018608
avg return on 3 trajectories of agent0: -50.0
avg return on 3 trajectories of agent1: -50.0
avg return on 3 trajectories of agent2: -50.0
avg return on 3 trajectories of agent3: -50.0
avg return on 3 trajectories of agent4: -50.0
avg return on 3 trajectories of agent5: -50.0
avg return on 3 trajectories of agent6: -50.0
avg return on 3 trajectories of agent7: -41.666666666666664
avg return on 3 trajectories of agent8: -50.0
avg return on 3 trajectories of agent9: -50.0
avg return on 3 trajectories of agent10: -50.0
avg return on 3 trajectories of agent11: -50.0
avg return on 3 trajectories of agent12: -50.0
avg return on 3 trajectories of agent13: -38.666666666666664
avg return on 3 trajectories of agent14: -30.0
avg return on 3 trajectories of agent15: -29.333333333333332
avg return on 3 trajectories of agent16: -50.0
avg return on 3 trajectories of agent17: -48.0
avg return on 3 trajectories of agent18: -45.0
avg return on 3 trajectories of agent19: -43.333333333333336
avg cum rews: -46.3, std: 6.421232142059827
the best agent: 15, best agent cum rewards: -29.333333333333332
19
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.027285162445184148
avg return on 3 trajectories of agent0: -46.333333333333336
avg return on 3 trajectories of agent1: -43.0
avg return on 3 trajectories of agent2: -41.333333333333336
avg return on 3 trajectories of agent3: -40.333333333333336
avg return on 3 trajectories of agent4: -44.333333333333336
avg return on 3 trajectories of agent5: -38.333333333333336
avg return on 3 trajectories of agent6: -30.333333333333332
avg return on 3 trajectories of agent7: -24.333333333333332
avg return on 3 trajectories of agent8: -38.0
avg return on 3 trajectories of agent9: -38.0
avg return on 3 trajectories of agent10: -39.333333333333336
avg return on 3 trajectories of agent11: -40.0
avg return on 3 trajectories of agent12: -32.333333333333336
avg return on 3 trajectories of agent13: -40.333333333333336
avg return on 3 trajectories of agent14: -45.0
avg return on 3 trajectories of agent15: -48.666666666666664
avg return on 3 trajectories of agent16: -28.333333333333332
avg return on 3 trajectories of agent17: -29.333333333333332
avg return on 3 trajectories of agent18: -33.666666666666664
avg return on 3 trajectories of agent19: -38.666666666666664
avg cum rews: -38.0, std: 6.287553843374492
the best agent: 7, best agent cum rewards: -24.333333333333332
20
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.024289079603539245
avg return on 3 trajectories of agent0: -28.0
avg return on 3 trajectories of agent1: -29.333333333333332
avg return on 3 trajectories of agent2: -38.0
avg return on 3 trajectories of agent3: -37.333333333333336
avg return on 3 trajectories of agent4: -29.333333333333332
avg return on 3 trajectories of agent5: -29.666666666666668
avg return on 3 trajectories of agent6: -32.0
avg return on 3 trajectories of agent7: -50.0
avg return on 3 trajectories of agent8: -27.333333333333332
avg return on 3 trajectories of agent9: -28.0
avg return on 3 trajectories of agent10: -27.333333333333332
avg return on 3 trajectories of agent11: -30.333333333333332
avg return on 3 trajectories of agent12: -26.0
avg return on 3 trajectories of agent13: -21.0
avg return on 3 trajectories of agent14: -14.0
avg return on 3 trajectories of agent15: -13.666666666666666
avg return on 3 trajectories of agent16: -26.333333333333332
avg return on 3 trajectories of agent17: -26.0
avg return on 3 trajectories of agent18: -26.0
avg return on 3 trajectories of agent19: -26.333333333333332
avg cum rews: -28.3, std: 7.6353709070934395
the best agent: 15, best agent cum rewards: -13.666666666666666
21
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02606050392020326
avg return on 3 trajectories of agent0: -11.666666666666666
avg return on 3 trajectories of agent1: -11.666666666666666
avg return on 3 trajectories of agent2: -22.333333333333332
avg return on 3 trajectories of agent3: -37.0
avg return on 3 trajectories of agent4: -12.333333333333334
avg return on 3 trajectories of agent5: -12.666666666666666
avg return on 3 trajectories of agent6: -24.666666666666668
avg return on 3 trajectories of agent7: -39.666666666666664
avg return on 3 trajectories of agent8: -13.333333333333334
avg return on 3 trajectories of agent9: -39.666666666666664
avg return on 3 trajectories of agent10: -48.0
avg return on 3 trajectories of agent11: -50.0
avg return on 3 trajectories of agent12: -10.333333333333334
avg return on 3 trajectories of agent13: -10.333333333333334
avg return on 3 trajectories of agent14: -11.666666666666666
avg return on 3 trajectories of agent15: -43.666666666666664
avg return on 3 trajectories of agent16: -10.333333333333334
avg return on 3 trajectories of agent17: -10.333333333333334
avg return on 3 trajectories of agent18: -11.0
avg return on 3 trajectories of agent19: -18.333333333333332
avg cum rews: -22.449999999999996, std: 14.206913418786252
the best agent: 16, best agent cum rewards: -10.333333333333334
22
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.025276450644443744
avg return on 3 trajectories of agent0: -10.666666666666666
avg return on 3 trajectories of agent1: -10.333333333333334
avg return on 3 trajectories of agent2: -10.0
avg return on 3 trajectories of agent3: -10.333333333333334
avg return on 3 trajectories of agent4: -10.666666666666666
avg return on 3 trajectories of agent5: -11.0
avg return on 3 trajectories of agent6: -12.333333333333334
avg return on 3 trajectories of agent7: -15.666666666666666
avg return on 3 trajectories of agent8: -10.0
avg return on 3 trajectories of agent9: -10.0
avg return on 3 trajectories of agent10: -11.0
avg return on 3 trajectories of agent11: -13.666666666666666
avg return on 3 trajectories of agent12: -10.0
avg return on 3 trajectories of agent13: -10.666666666666666
avg return on 3 trajectories of agent14: -25.0
avg return on 3 trajectories of agent15: -50.0
avg return on 3 trajectories of agent16: -10.0
avg return on 3 trajectories of agent17: -11.333333333333334
avg return on 3 trajectories of agent18: -50.0
avg return on 3 trajectories of agent19: -50.0
avg cum rews: -17.633333333333333, std: 13.992815616911733
the best agent: 16, best agent cum rewards: -10.0
23
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.025902303117815207
avg return on 3 trajectories of agent0: -8.333333333333334
avg return on 3 trajectories of agent1: -9.333333333333334
avg return on 3 trajectories of agent2: -11.333333333333334
avg return on 3 trajectories of agent3: -50.0
avg return on 3 trajectories of agent4: -8.666666666666666
avg return on 3 trajectories of agent5: -8.666666666666666
avg return on 3 trajectories of agent6: -8.666666666666666
avg return on 3 trajectories of agent7: -8.333333333333334
avg return on 3 trajectories of agent8: -8.333333333333334
avg return on 3 trajectories of agent9: -8.333333333333334
avg return on 3 trajectories of agent10: -8.0
avg return on 3 trajectories of agent11: -8.333333333333334
avg return on 3 trajectories of agent12: -8.333333333333334
avg return on 3 trajectories of agent13: -8.666666666666666
avg return on 3 trajectories of agent14: -20.0
avg return on 3 trajectories of agent15: -36.333333333333336
avg return on 3 trajectories of agent16: -8.0
avg return on 3 trajectories of agent17: -8.333333333333334
avg return on 3 trajectories of agent18: -9.333333333333334
avg return on 3 trajectories of agent19: -19.666666666666668
avg cum rews: -13.250000000000004, std: 10.753746117309799
the best agent: 16, best agent cum rewards: -8.0
24
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02663676042393312
avg return on 3 trajectories of agent0: -6.666666666666667
avg return on 3 trajectories of agent1: -7.0
avg return on 3 trajectories of agent2: -7.0
avg return on 3 trajectories of agent3: -7.333333333333333
avg return on 3 trajectories of agent4: -6.666666666666667
avg return on 3 trajectories of agent5: -7.333333333333333
avg return on 3 trajectories of agent6: -7.333333333333333
avg return on 3 trajectories of agent7: -8.0
avg return on 3 trajectories of agent8: -6.333333333333333
avg return on 3 trajectories of agent9: -7.0
avg return on 3 trajectories of agent10: -8.0
avg return on 3 trajectories of agent11: -19.0
avg return on 3 trajectories of agent12: -7.0
avg return on 3 trajectories of agent13: -8.333333333333334
avg return on 3 trajectories of agent14: -28.666666666666668
avg return on 3 trajectories of agent15: -45.0
avg return on 3 trajectories of agent16: -6.666666666666667
avg return on 3 trajectories of agent17: -7.333333333333333
avg return on 3 trajectories of agent18: -12.666666666666666
avg return on 3 trajectories of agent19: -39.0
avg cum rews: -12.616666666666667, std: 11.1526155377711
the best agent: 8, best agent cum rewards: -6.333333333333333
25
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02685767942155881
avg return on 3 trajectories of agent0: -6.0
avg return on 3 trajectories of agent1: -6.0
avg return on 3 trajectories of agent2: -5.666666666666667
avg return on 3 trajectories of agent3: -6.333333333333333
avg return on 3 trajectories of agent4: -6.0
avg return on 3 trajectories of agent5: -6.0
avg return on 3 trajectories of agent6: -5.666666666666667
avg return on 3 trajectories of agent7: -6.333333333333333
avg return on 3 trajectories of agent8: -6.0
avg return on 3 trajectories of agent9: -7.333333333333333
avg return on 3 trajectories of agent10: -12.333333333333334
avg return on 3 trajectories of agent11: -45.666666666666664
avg return on 3 trajectories of agent12: -5.333333333333333
avg return on 3 trajectories of agent13: -5.666666666666667
avg return on 3 trajectories of agent14: -5.666666666666667
avg return on 3 trajectories of agent15: -6.0
avg return on 3 trajectories of agent16: -5.333333333333333
avg return on 3 trajectories of agent17: -5.333333333333333
avg return on 3 trajectories of agent18: -5.666666666666667
avg return on 3 trajectories of agent19: -6.333333333333333
avg cum rews: -8.233333333333334, std: 8.711486669908872
the best agent: 16, best agent cum rewards: -5.333333333333333
26
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.025814309199253215
avg return on 3 trajectories of agent0: -5.333333333333333
avg return on 3 trajectories of agent1: -5.333333333333333
avg return on 3 trajectories of agent2: -5.333333333333333
avg return on 3 trajectories of agent3: -5.333333333333333
avg return on 3 trajectories of agent4: -5.333333333333333
avg return on 3 trajectories of agent5: -5.333333333333333
avg return on 3 trajectories of agent6: -5.666666666666667
avg return on 3 trajectories of agent7: -7.333333333333333
avg return on 3 trajectories of agent8: -5.333333333333333
avg return on 3 trajectories of agent9: -5.333333333333333
avg return on 3 trajectories of agent10: -5.333333333333333
avg return on 3 trajectories of agent11: -5.666666666666667
avg return on 3 trajectories of agent12: -5.333333333333333
avg return on 3 trajectories of agent13: -6.0
avg return on 3 trajectories of agent14: -22.0
avg return on 3 trajectories of agent15: -47.666666666666664
avg return on 3 trajectories of agent16: -5.0
avg return on 3 trajectories of agent17: -5.666666666666667
avg return on 3 trajectories of agent18: -22.0
avg return on 3 trajectories of agent19: -50.0
avg cum rews: -11.516666666666667, std: 13.384682372855258
the best agent: 16, best agent cum rewards: -5.0
27
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.022636525299433205
avg return on 3 trajectories of agent0: -4.666666666666667
avg return on 3 trajectories of agent1: -4.333333333333333
avg return on 3 trajectories of agent2: -5.0
avg return on 3 trajectories of agent3: -5.666666666666667
avg return on 3 trajectories of agent4: -5.0
avg return on 3 trajectories of agent5: -4.333333333333333
avg return on 3 trajectories of agent6: -4.666666666666667
avg return on 3 trajectories of agent7: -4.666666666666667
avg return on 3 trajectories of agent8: -4.666666666666667
avg return on 3 trajectories of agent9: -4.666666666666667
avg return on 3 trajectories of agent10: -5.0
avg return on 3 trajectories of agent11: -6.0
avg return on 3 trajectories of agent12: -4.0
avg return on 3 trajectories of agent13: -4.333333333333333
avg return on 3 trajectories of agent14: -4.666666666666667
avg return on 3 trajectories of agent15: -5.333333333333333
avg return on 3 trajectories of agent16: -4.333333333333333
avg return on 3 trajectories of agent17: -4.333333333333333
avg return on 3 trajectories of agent18: -4.666666666666667
avg return on 3 trajectories of agent19: -5.666666666666667
avg cum rews: -4.8, std: 0.5099019513592786
the best agent: 12, best agent cum rewards: -4.0
28
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.024406146408234314
avg return on 3 trajectories of agent0: -4.0
avg return on 3 trajectories of agent1: -3.6666666666666665
avg return on 3 trajectories of agent2: -4.0
avg return on 3 trajectories of agent3: -4.333333333333333
avg return on 3 trajectories of agent4: -4.0
avg return on 3 trajectories of agent5: -4.0
avg return on 3 trajectories of agent6: -4.0
avg return on 3 trajectories of agent7: -4.0
avg return on 3 trajectories of agent8: -4.0
avg return on 3 trajectories of agent9: -4.0
avg return on 3 trajectories of agent10: -4.0
avg return on 3 trajectories of agent11: -4.333333333333333
avg return on 3 trajectories of agent12: -4.0
avg return on 3 trajectories of agent13: -3.6666666666666665
avg return on 3 trajectories of agent14: -3.6666666666666665
avg return on 3 trajectories of agent15: -4.0
avg return on 3 trajectories of agent16: -4.0
avg return on 3 trajectories of agent17: -3.6666666666666665
avg return on 3 trajectories of agent18: -3.6666666666666665
avg return on 3 trajectories of agent19: -4.0
avg cum rews: -3.95, std: 0.19075871903765995
the best agent: 18, best agent cum rewards: -3.6666666666666665
29
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02721232319507767
avg return on 3 trajectories of agent0: -3.3333333333333335
avg return on 3 trajectories of agent1: -3.6666666666666665
avg return on 3 trajectories of agent2: -4.333333333333333
avg return on 3 trajectories of agent3: -6.333333333333333
avg return on 3 trajectories of agent4: -3.3333333333333335
avg return on 3 trajectories of agent5: -3.6666666666666665
avg return on 3 trajectories of agent6: -3.6666666666666665
avg return on 3 trajectories of agent7: -3.6666666666666665
avg return on 3 trajectories of agent8: -3.3333333333333335
avg return on 3 trajectories of agent9: -3.3333333333333335
avg return on 3 trajectories of agent10: -3.6666666666666665
avg return on 3 trajectories of agent11: -5.0
avg return on 3 trajectories of agent12: -3.3333333333333335
avg return on 3 trajectories of agent13: -3.3333333333333335
avg return on 3 trajectories of agent14: -3.3333333333333335
avg return on 3 trajectories of agent15: -3.0
avg return on 3 trajectories of agent16: -3.6666666666666665
avg return on 3 trajectories of agent17: -3.6666666666666665
avg return on 3 trajectories of agent18: -3.6666666666666665
avg return on 3 trajectories of agent19: -4.0
avg cum rews: -3.766666666666667, std: 0.7234178138070234
the best agent: 15, best agent cum rewards: -3.0
30
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.023878544382615934
avg return on 3 trajectories of agent0: -3.0
avg return on 3 trajectories of agent1: -3.3333333333333335
avg return on 3 trajectories of agent2: -3.3333333333333335
avg return on 3 trajectories of agent3: -3.3333333333333335
avg return on 3 trajectories of agent4: -3.0
avg return on 3 trajectories of agent5: -3.0
avg return on 3 trajectories of agent6: -3.0
avg return on 3 trajectories of agent7: -3.3333333333333335
avg return on 3 trajectories of agent8: -3.0
avg return on 3 trajectories of agent9: -3.0
avg return on 3 trajectories of agent10: -3.0
avg return on 3 trajectories of agent11: -3.0
avg return on 3 trajectories of agent12: -2.6666666666666665
avg return on 3 trajectories of agent13: -3.0
avg return on 3 trajectories of agent14: -3.3333333333333335
avg return on 3 trajectories of agent15: -3.3333333333333335
avg return on 3 trajectories of agent16: -3.0
avg return on 3 trajectories of agent17: -3.0
avg return on 3 trajectories of agent18: -3.3333333333333335
avg return on 3 trajectories of agent19: -3.6666666666666665
avg cum rews: -3.1333333333333333, std: 0.22110831935702668
the best agent: 12, best agent cum rewards: -2.6666666666666665
31
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.025278000757428642
avg return on 3 trajectories of agent0: -2.6666666666666665
avg return on 3 trajectories of agent1: -3.0
avg return on 3 trajectories of agent2: -3.0
avg return on 3 trajectories of agent3: -2.6666666666666665
avg return on 3 trajectories of agent4: -2.6666666666666665
avg return on 3 trajectories of agent5: -3.0
avg return on 3 trajectories of agent6: -3.0
avg return on 3 trajectories of agent7: -3.0
avg return on 3 trajectories of agent8: -2.6666666666666665
avg return on 3 trajectories of agent9: -3.0
avg return on 3 trajectories of agent10: -3.0
avg return on 3 trajectories of agent11: -3.0
avg return on 3 trajectories of agent12: -2.6666666666666665
avg return on 3 trajectories of agent13: -2.6666666666666665
avg return on 3 trajectories of agent14: -2.6666666666666665
avg return on 3 trajectories of agent15: -2.6666666666666665
avg return on 3 trajectories of agent16: -2.6666666666666665
avg return on 3 trajectories of agent17: -2.6666666666666665
avg return on 3 trajectories of agent18: -2.6666666666666665
avg return on 3 trajectories of agent19: -2.6666666666666665
avg cum rews: -2.7999999999999994, std: 0.16329931618554527
the best agent: 19, best agent cum rewards: -2.6666666666666665
32
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.023874445743214297
avg return on 3 trajectories of agent0: -2.6666666666666665
avg return on 3 trajectories of agent1: -2.6666666666666665
avg return on 3 trajectories of agent2: -2.6666666666666665
avg return on 3 trajectories of agent3: -2.6666666666666665
avg return on 3 trajectories of agent4: -2.6666666666666665
avg return on 3 trajectories of agent5: -2.6666666666666665
avg return on 3 trajectories of agent6: -2.6666666666666665
avg return on 3 trajectories of agent7: -2.6666666666666665
avg return on 3 trajectories of agent8: -2.6666666666666665
avg return on 3 trajectories of agent9: -2.6666666666666665
avg return on 3 trajectories of agent10: -2.3333333333333335
avg return on 3 trajectories of agent11: -2.6666666666666665
avg return on 3 trajectories of agent12: -2.6666666666666665
avg return on 3 trajectories of agent13: -2.6666666666666665
avg return on 3 trajectories of agent14: -2.3333333333333335
avg return on 3 trajectories of agent15: -2.3333333333333335
avg return on 3 trajectories of agent16: -2.6666666666666665
avg return on 3 trajectories of agent17: -2.6666666666666665
avg return on 3 trajectories of agent18: -2.3333333333333335
avg return on 3 trajectories of agent19: -2.3333333333333335
avg cum rews: -2.583333333333333, std: 0.14433756729740632
the best agent: 19, best agent cum rewards: -2.3333333333333335
33
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.024684425332229955
avg return on 3 trajectories of agent0: -2.3333333333333335
avg return on 3 trajectories of agent1: -2.0
avg return on 3 trajectories of agent2: -2.0
avg return on 3 trajectories of agent3: -2.0
avg return on 3 trajectories of agent4: -2.3333333333333335
avg return on 3 trajectories of agent5: -2.3333333333333335
avg return on 3 trajectories of agent6: -2.3333333333333335
avg return on 3 trajectories of agent7: -2.6666666666666665
avg return on 3 trajectories of agent8: -2.0
avg return on 3 trajectories of agent9: -2.3333333333333335
avg return on 3 trajectories of agent10: -2.3333333333333335
avg return on 3 trajectories of agent11: -2.3333333333333335
avg return on 3 trajectories of agent12: -2.0
avg return on 3 trajectories of agent13: -2.0
avg return on 3 trajectories of agent14: -2.0
avg return on 3 trajectories of agent15: -2.0
avg return on 3 trajectories of agent16: -2.0
avg return on 3 trajectories of agent17: -2.0
avg return on 3 trajectories of agent18: -2.0
avg return on 3 trajectories of agent19: -2.0
avg cum rews: -2.15, std: 0.19649710204252663
the best agent: 19, best agent cum rewards: -2.0
34
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.0247225216182891
avg return on 3 trajectories of agent0: -2.0
avg return on 3 trajectories of agent1: -2.0
avg return on 3 trajectories of agent2: -2.0
avg return on 3 trajectories of agent3: -2.0
avg return on 3 trajectories of agent4: -2.0
avg return on 3 trajectories of agent5: -2.0
avg return on 3 trajectories of agent6: -2.0
avg return on 3 trajectories of agent7: -2.0
avg return on 3 trajectories of agent8: -2.0
avg return on 3 trajectories of agent9: -2.0
avg return on 3 trajectories of agent10: -2.0
avg return on 3 trajectories of agent11: -2.0
avg return on 3 trajectories of agent12: -2.0
avg return on 3 trajectories of agent13: -2.0
avg return on 3 trajectories of agent14: -2.0
avg return on 3 trajectories of agent15: -2.0
avg return on 3 trajectories of agent16: -2.0
avg return on 3 trajectories of agent17: -2.0
avg return on 3 trajectories of agent18: -2.0
avg return on 3 trajectories of agent19: -2.0
avg cum rews: -2.0, std: 0.0
the best agent: 19, best agent cum rewards: -2.0
35
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.022330363979416852
avg return on 3 trajectories of agent0: -2.0
avg return on 3 trajectories of agent1: -2.0
avg return on 3 trajectories of agent2: -2.0
avg return on 3 trajectories of agent3: -2.0
avg return on 3 trajectories of agent4: -2.0
avg return on 3 trajectories of agent5: -2.0
avg return on 3 trajectories of agent6: -2.0
avg return on 3 trajectories of agent7: -2.0
avg return on 3 trajectories of agent8: -2.0
avg return on 3 trajectories of agent9: -2.0
avg return on 3 trajectories of agent10: -2.0
avg return on 3 trajectories of agent11: -2.0
avg return on 3 trajectories of agent12: -2.0
avg return on 3 trajectories of agent13: -2.0
avg return on 3 trajectories of agent14: -2.0
avg return on 3 trajectories of agent15: -2.0
avg return on 3 trajectories of agent16: -2.0
avg return on 3 trajectories of agent17: -2.0
avg return on 3 trajectories of agent18: -2.0
avg return on 3 trajectories of agent19: -2.0
avg cum rews: -2.0, std: 0.0
the best agent: 19, best agent cum rewards: -2.0
36
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02265276051953677
avg return on 3 trajectories of agent0: -2.0
avg return on 3 trajectories of agent1: -2.0
avg return on 3 trajectories of agent2: -2.0
avg return on 3 trajectories of agent3: -2.0
avg return on 3 trajectories of agent4: -2.0
avg return on 3 trajectories of agent5: -2.0
avg return on 3 trajectories of agent6: -2.0
avg return on 3 trajectories of agent7: -2.0
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -2.0
avg return on 3 trajectories of agent10: -2.0
avg return on 3 trajectories of agent11: -2.0
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -2.0
avg return on 3 trajectories of agent18: -2.0
avg return on 3 trajectories of agent19: -2.0
avg cum rews: -1.9, std: 0.15275252316519464
the best agent: 16, best agent cum rewards: -1.6666666666666667
37
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02261389353840835
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -2.0
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -2.0
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -2.0
avg return on 3 trajectories of agent15: -2.0
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -2.0
avg return on 3 trajectories of agent19: -2.0
avg cum rews: -1.7666666666666668, std: 0.15275252316519464
the best agent: 16, best agent cum rewards: -1.6666666666666667
38
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02214730579565959
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -2.0
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -2.0
avg return on 3 trajectories of agent7: -2.0
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -2.0
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -2.0
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -2.0
avg cum rews: -1.7666666666666668, std: 0.15275252316519464
the best agent: 18, best agent cum rewards: -1.6666666666666667
39
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02207598756828258
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -2.0
avg return on 3 trajectories of agent3: -2.3333333333333335
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -2.0
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -2.0
avg return on 3 trajectories of agent11: -2.0
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.7666666666666664, std: 0.18559214542766736
the best agent: 19, best agent cum rewards: -1.6666666666666667
40
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02109655278365987
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -2.0
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6833333333333331, std: 0.07264831572567787
the best agent: 19, best agent cum rewards: -1.6666666666666667
41
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.022780965047682337
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -2.3333333333333335
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -2.3333333333333335
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -2.0
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.75, std: 0.20749832663314555
the best agent: 19, best agent cum rewards: -1.6666666666666667
42
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.021059113434246737
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -2.3333333333333335
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.7, std: 0.14529663145135582
the best agent: 19, best agent cum rewards: -1.6666666666666667
43
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.022617668775328066
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -2.0
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6833333333333331, std: 0.07264831572567787
the best agent: 19, best agent cum rewards: -1.6666666666666667
44
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.021986940560567055
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -2.0
avg return on 3 trajectories of agent11: -2.0
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.7, std: 0.09999999999999996
the best agent: 19, best agent cum rewards: -1.6666666666666667
45
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.01793553707573594
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -2.0
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -2.0
avg return on 3 trajectories of agent11: -2.0
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -2.0
avg cum rews: -1.7333333333333336, std: 0.1333333333333333
the best agent: 18, best agent cum rewards: -1.6666666666666667
46
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02135031177842391
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -2.3333333333333335
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -2.0
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.7166666666666668, std: 0.1589898669028243
the best agent: 19, best agent cum rewards: -1.6666666666666667
47
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.023027840507791286
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -2.0
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -2.0
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.7, std: 0.09999999999999996
the best agent: 19, best agent cum rewards: -1.6666666666666667
48
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.022956305359076192
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -2.0
avg return on 3 trajectories of agent14: -2.0
avg return on 3 trajectories of agent15: -2.0
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.7166666666666668, std: 0.1190238071423808
the best agent: 19, best agent cum rewards: -1.6666666666666667
49
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.024937516756829856
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
50
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.021068572361288167
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -2.0
avg return on 3 trajectories of agent3: -2.3333333333333335
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.7166666666666668, std: 0.1589898669028243
the best agent: 19, best agent cum rewards: -1.6666666666666667
51
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.0194327902882848
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -2.0
avg return on 3 trajectories of agent3: -2.3333333333333335
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -2.0
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -2.6666666666666665
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.7833333333333332, std: 0.2640496586292476
the best agent: 19, best agent cum rewards: -1.6666666666666667
52
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.023041694515633527
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -2.0
avg return on 3 trajectories of agent3: -2.3333333333333335
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.7166666666666668, std: 0.1589898669028243
the best agent: 19, best agent cum rewards: -1.6666666666666667
53
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.023313620619189544
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
54
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.020697071133434053
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -2.3333333333333335
avg return on 3 trajectories of agent2: -2.6666666666666665
avg return on 3 trajectories of agent3: -3.3333333333333335
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -2.0
avg return on 3 trajectories of agent6: -2.3333333333333335
avg return on 3 trajectories of agent7: -2.3333333333333335
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -2.0
avg return on 3 trajectories of agent19: -2.3333333333333335
avg cum rews: -1.9666666666666663, std: 0.44596960534198843
the best agent: 16, best agent cum rewards: -1.6666666666666667
55
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02172495248296887
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -2.0
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -2.0
avg cum rews: -1.7, std: 0.09999999999999998
the best agent: 18, best agent cum rewards: -1.6666666666666667
56
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.019849211509834548
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -2.0
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -2.0
avg return on 3 trajectories of agent6: -2.3333333333333335
avg return on 3 trajectories of agent7: -2.3333333333333335
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -2.0
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.7833333333333332, std: 0.21794494717703367
the best agent: 19, best agent cum rewards: -1.6666666666666667
57
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.01861813037085706
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -2.0
avg return on 3 trajectories of agent2: -2.0
avg return on 3 trajectories of agent3: -2.3333333333333335
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -2.0
avg return on 3 trajectories of agent14: -2.0
avg return on 3 trajectories of agent15: -2.6666666666666665
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -2.0
avg return on 3 trajectories of agent18: -2.0
avg return on 3 trajectories of agent19: -2.3333333333333335
avg cum rews: -1.8833333333333335, std: 0.2843120351538663
the best agent: 16, best agent cum rewards: -1.6666666666666667
58
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02451779161891594
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -2.0
avg return on 3 trajectories of agent10: -2.3333333333333335
avg return on 3 trajectories of agent11: -2.3333333333333335
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.75, std: 0.20749832663314555
the best agent: 19, best agent cum rewards: -1.6666666666666667
59
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02014120158251493
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -2.0
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6833333333333331, std: 0.07264831572567787
the best agent: 19, best agent cum rewards: -1.6666666666666667
60
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.021420971649454428
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -2.0
avg return on 3 trajectories of agent15: -2.0
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -2.0
avg return on 3 trajectories of agent19: -2.0
avg cum rews: -1.7333333333333336, std: 0.1333333333333333
the best agent: 16, best agent cum rewards: -1.6666666666666667
61
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.020503876930381963
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -2.0
avg return on 3 trajectories of agent11: -2.0
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.7, std: 0.09999999999999996
the best agent: 19, best agent cum rewards: -1.6666666666666667
62
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02283908470171396
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
63
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.023015661289101635
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -2.0
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -2.0
avg return on 3 trajectories of agent7: -2.0
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -2.3333333333333335
avg return on 3 trajectories of agent15: -2.3333333333333335
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.7833333333333332, std: 0.21794494717703367
the best agent: 19, best agent cum rewards: -1.6666666666666667
64
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02040214107759488
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -2.0
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6833333333333331, std: 0.07264831572567787
the best agent: 19, best agent cum rewards: -1.6666666666666667
65
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.019871925341180142
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -2.0
avg return on 3 trajectories of agent11: -2.3333333333333335
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.7166666666666668, std: 0.1589898669028243
the best agent: 19, best agent cum rewards: -1.6666666666666667
66
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02025616694900144
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
67
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.020665676866929612
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -2.0
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6833333333333331, std: 0.07264831572567787
the best agent: 19, best agent cum rewards: -1.6666666666666667
68
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.020324876618554692
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
69
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.0189273772750645
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
70
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02074653382087931
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
71
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02301144763951276
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -2.0
avg return on 3 trajectories of agent7: -2.0
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -2.0
avg cum rews: -1.7166666666666668, std: 0.11902380714238081
the best agent: 18, best agent cum rewards: -1.6666666666666667
72
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.023295206780762627
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -2.0
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6833333333333331, std: 0.07264831572567787
the best agent: 19, best agent cum rewards: -1.6666666666666667
73
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.023041396977983294
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -2.0
avg return on 3 trajectories of agent3: -2.0
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -2.0
avg return on 3 trajectories of agent6: -2.0
avg return on 3 trajectories of agent7: -2.0
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -2.0
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.7666666666666664, std: 0.15275252316519464
the best agent: 19, best agent cum rewards: -1.6666666666666667
74
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.020025482436463522
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -2.0
avg return on 3 trajectories of agent11: -2.0
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.7, std: 0.09999999999999996
the best agent: 19, best agent cum rewards: -1.6666666666666667
75
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.019429897918304934
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
76
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.020998992435492993
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
77
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.022873259945598877
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
78
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.0194962617746268
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
79
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.022213530796121667
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -2.0
avg cum rews: -1.6833333333333336, std: 0.07264831572567787
the best agent: 18, best agent cum rewards: -1.6666666666666667
80
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.020882080552992958
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
81
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.01988932372365535
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
82
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02034649719098327
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -2.0
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -2.0
avg return on 3 trajectories of agent19: -2.0
avg cum rews: -1.7166666666666668, std: 0.11902380714238081
the best agent: 16, best agent cum rewards: -1.6666666666666667
83
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.020427554284897016
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
84
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.022080774517292366
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
85
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.023751110095829635
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -2.0
avg return on 3 trajectories of agent15: -2.0
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -2.0
avg cum rews: -1.7166666666666668, std: 0.11902380714238081
the best agent: 18, best agent cum rewards: -1.6666666666666667
86
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.01944773298102792
avg return on 3 trajectories of agent0: -2.0
avg return on 3 trajectories of agent1: -2.0
avg return on 3 trajectories of agent2: -2.0
avg return on 3 trajectories of agent3: -2.0
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -2.0
avg return on 3 trajectories of agent10: -2.0
avg return on 3 trajectories of agent11: -2.0
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.7833333333333332, std: 0.15898986690282424
the best agent: 19, best agent cum rewards: -1.6666666666666667
87
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.019575728519358467
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
88
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.020097899495936017
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
89
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.02140784099423448
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
90
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.018510733128012852
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
91
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.023066060213944632
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
92
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.023255582892257383
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -2.0
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6833333333333331, std: 0.07264831572567787
the best agent: 19, best agent cum rewards: -1.6666666666666667
93
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.023072825531402365
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -2.0
avg return on 3 trajectories of agent3: -2.0
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.7, std: 0.09999999999999996
the best agent: 19, best agent cum rewards: -1.6666666666666667
94
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.021850076652434738
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
95
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.021221414813722264
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
96
---------------------------------
Searching empty space policies
(10, 5512)
(20, 5512)
(20, 5512)
Average distance of agents to nearest neighbors: 0.019925364378954733
avg return on 3 trajectories of agent0: -1.6666666666666667
avg return on 3 trajectories of agent1: -1.6666666666666667
avg return on 3 trajectories of agent2: -1.6666666666666667
avg return on 3 trajectories of agent3: -1.6666666666666667
avg return on 3 trajectories of agent4: -1.6666666666666667
avg return on 3 trajectories of agent5: -1.6666666666666667
avg return on 3 trajectories of agent6: -1.6666666666666667
avg return on 3 trajectories of agent7: -1.6666666666666667
avg return on 3 trajectories of agent8: -1.6666666666666667
avg return on 3 trajectories of agent9: -1.6666666666666667
avg return on 3 trajectories of agent10: -1.6666666666666667
avg return on 3 trajectories of agent11: -1.6666666666666667
avg return on 3 trajectories of agent12: -1.6666666666666667
avg return on 3 trajectories of agent13: -1.6666666666666667
avg return on 3 trajectories of agent14: -1.6666666666666667
avg return on 3 trajectories of agent15: -1.6666666666666667
avg return on 3 trajectories of agent16: -1.6666666666666667
avg return on 3 trajectories of agent17: -1.6666666666666667
avg return on 3 trajectories of agent18: -1.6666666666666667
avg return on 3 trajectories of agent19: -1.6666666666666667
avg cum rews: -1.6666666666666667, std: 0.0
the best agent: 19, best agent cum rewards: -1.6666666666666667
Average distance of random agents to nearest neighbors: [0.018532178181020847, 0.02722416738894808, 0.02991712158578646, 0.030810076823461707, 0.022985713132880746, 0.022828952885817648, 0.026847429361652502, 0.02831515752094031, 0.019872513960974794, 0.021849936237682086, 0.024882383604929816, 0.028105334191700422, 0.026537398179594017, 0.024481187581502185, 0.026358253474993563, 0.026028778774185767, 0.026268041873786098, 0.02808735855018608, 0.027285162445184148, 0.024289079603539245, 0.02606050392020326, 0.025276450644443744, 0.025902303117815207, 0.02663676042393312, 0.02685767942155881, 0.025814309199253215, 0.022636525299433205, 0.024406146408234314, 0.02721232319507767, 0.023878544382615934, 0.025278000757428642, 0.023874445743214297, 0.024684425332229955, 0.0247225216182891, 0.022330363979416852, 0.02265276051953677, 0.02261389353840835, 0.02214730579565959, 0.02207598756828258, 0.02109655278365987, 0.022780965047682337, 0.021059113434246737, 0.022617668775328066, 0.021986940560567055, 0.01793553707573594, 0.02135031177842391, 0.023027840507791286, 0.022956305359076192, 0.024937516756829856, 0.021068572361288167, 0.0194327902882848, 0.023041694515633527, 0.023313620619189544, 0.020697071133434053, 0.02172495248296887, 0.019849211509834548, 0.01861813037085706, 0.02451779161891594, 0.02014120158251493, 0.021420971649454428, 0.020503876930381963, 0.02283908470171396, 0.023015661289101635, 0.02040214107759488, 0.019871925341180142, 0.02025616694900144, 0.020665676866929612, 0.020324876618554692, 0.0189273772750645, 0.02074653382087931, 0.02301144763951276, 0.023295206780762627, 0.023041396977983294, 0.020025482436463522, 0.019429897918304934, 0.020998992435492993, 0.022873259945598877, 0.0194962617746268, 0.022213530796121667, 0.020882080552992958, 0.01988932372365535, 0.02034649719098327, 0.020427554284897016, 0.022080774517292366, 0.023751110095829635, 0.01944773298102792, 0.019575728519358467, 0.020097899495936017, 0.02140784099423448, 0.018510733128012852, 0.023066060213944632, 0.023255582892257383, 0.023072825531402365, 0.021850076652434738, 0.021221414813722264, 0.019925364378954733]
Time taken for each iteration: [19.658007383346558, 34.379777908325195, 49.29201316833496, 64.60963201522827, 79.62968444824219, 98.64455699920654, 113.65903306007385, 134.2825014591217, 149.28972721099854, 164.26051926612854, 179.5177173614502, 199.617290019989, 218.9287564754486, 234.0240502357483, 253.181236743927, 272.3275067806244, 287.18337225914, 302.39248394966125, 322.8383719921112, 337.77149748802185, 352.87546944618225, 367.7663450241089, 388.2063453197479, 403.1645014286041, 418.35353922843933, 438.9311029911041, 453.92921113967896, 474.677463054657, 489.6141173839569, 504.64437079429626, 519.7471601963043, 540.6131293773651, 555.724648475647, 570.8125133514404, 585.8971061706543, 601.0899505615234, 621.3292727470398, 641.6694524288177, 660.8386480808258, 681.6107642650604, 701.0118119716644, 720.4623379707336, 739.8862588405609, 760.7792096138, 775.7777104377747, 795.1190464496613, 815.8277542591095, 830.8224990367889, 845.8028373718262, 860.8205304145813, 875.8931176662445, 891.0156536102295, 905.9425859451294, 926.433779001236, 941.5359425544739, 956.5132048130035, 971.4493777751923, 986.3759605884552, 1001.3651041984558, 1016.5136523246765, 1036.8944199085236, 1051.954487323761, 1067.0759234428406, 1087.47030544281, 1107.9311969280243, 1122.957824230194, 1143.4010682106018, 1162.548680305481, 1177.4754450321198, 1198.1642463207245, 1218.9164271354675, 1240.446459531784, 1256.0166211128235, 1272.1378390789032, 1295.0437178611755, 1311.3697583675385, 1331.8496153354645, 1347.8885962963104, 1368.730702161789, 1389.6737263202667, 1405.7733566761017, 1427.9525666236877, 1450.1413125991821, 1472.3996288776398, 1494.652893781662, 1510.5413722991943, 1532.824863910675, 1554.3312458992004, 1574.329930305481, 1589.7066190242767, 1605.0142848491669, 1624.9901049137115, 1644.8595170974731, 1660.1638810634613, 1675.4919435977936, 1695.380661725998]
