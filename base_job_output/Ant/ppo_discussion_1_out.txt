No devices were found
Setting seed -  0
---------------------------------
Environment created
Box(-1.0, 1.0, (8,), float32) Box(-inf, inf, (105,), float64)
Loading Initial saved model
Model loaded
Starting evaluation
1953
Starting to collect rollouts
Collecting rollouts: 10000/1000000
Collecting rollouts: 20000/1000000
Collecting rollouts: 30000/1000000
Collecting rollouts: 40000/1000000
Collecting rollouts: 50000/1000000
Collecting rollouts: 60000/1000000
Collecting rollouts: 70000/1000000
Collecting rollouts: 80000/1000000
Collecting rollouts: 90000/1000000
Collecting rollouts: 100000/1000000
Collecting rollouts: 110000/1000000
Collecting rollouts: 120000/1000000
Collecting rollouts: 130000/1000000
Collecting rollouts: 140000/1000000
Collecting rollouts: 150000/1000000
Collecting rollouts: 160000/1000000
Collecting rollouts: 170000/1000000
Collecting rollouts: 180000/1000000
Collecting rollouts: 190000/1000000
Collecting rollouts: 200000/1000000
Collecting rollouts: 210000/1000000
Collecting rollouts: 220000/1000000
Collecting rollouts: 230000/1000000
Collecting rollouts: 240000/1000000
Collecting rollouts: 250000/1000000
Collecting rollouts: 260000/1000000
Collecting rollouts: 270000/1000000
Collecting rollouts: 280000/1000000
Collecting rollouts: 290000/1000000
Collecting rollouts: 300000/1000000
Collecting rollouts: 310000/1000000
Collecting rollouts: 320000/1000000
Collecting rollouts: 330000/1000000
Collecting rollouts: 340000/1000000
Collecting rollouts: 350000/1000000
Collecting rollouts: 360000/1000000
Collecting rollouts: 370000/1000000
Collecting rollouts: 380000/1000000
Collecting rollouts: 390000/1000000
Collecting rollouts: 400000/1000000
Collecting rollouts: 410000/1000000
Collecting rollouts: 420000/1000000
Collecting rollouts: 430000/1000000
Collecting rollouts: 440000/1000000
Collecting rollouts: 450000/1000000
Collecting rollouts: 460000/1000000
Collecting rollouts: 470000/1000000
Collecting rollouts: 480000/1000000
Collecting rollouts: 490000/1000000
Collecting rollouts: 500000/1000000
Collecting rollouts: 510000/1000000
Collecting rollouts: 520000/1000000
Collecting rollouts: 530000/1000000
Collecting rollouts: 540000/1000000
Collecting rollouts: 550000/1000000
Collecting rollouts: 560000/1000000
Collecting rollouts: 570000/1000000
Collecting rollouts: 580000/1000000
Collecting rollouts: 590000/1000000
Collecting rollouts: 600000/1000000
Collecting rollouts: 610000/1000000
Collecting rollouts: 620000/1000000
Collecting rollouts: 630000/1000000
Collecting rollouts: 640000/1000000
Collecting rollouts: 650000/1000000
Collecting rollouts: 660000/1000000
Collecting rollouts: 670000/1000000
Collecting rollouts: 680000/1000000
Collecting rollouts: 690000/1000000
Collecting rollouts: 700000/1000000
Collecting rollouts: 710000/1000000
Collecting rollouts: 720000/1000000
Collecting rollouts: 730000/1000000
Collecting rollouts: 740000/1000000
Collecting rollouts: 750000/1000000
Collecting rollouts: 760000/1000000
Collecting rollouts: 770000/1000000
Collecting rollouts: 780000/1000000
Collecting rollouts: 790000/1000000
Collecting rollouts: 800000/1000000
Collecting rollouts: 810000/1000000
Collecting rollouts: 820000/1000000
Collecting rollouts: 830000/1000000
Collecting rollouts: 840000/1000000
Collecting rollouts: 850000/1000000
Collecting rollouts: 860000/1000000
Collecting rollouts: 870000/1000000
Collecting rollouts: 880000/1000000
Collecting rollouts: 890000/1000000
Collecting rollouts: 900000/1000000
Collecting rollouts: 910000/1000000
Collecting rollouts: 920000/1000000
Collecting rollouts: 930000/1000000
Collecting rollouts: 940000/1000000
Collecting rollouts: 950000/1000000
Collecting rollouts: 960000/1000000
Collecting rollouts: 970000/1000000
Collecting rollouts: 980000/1000000
Collecting rollouts: 990000/1000000
Collecting rollouts: 1000000/1000000
Replay buffer size:  (1000000, 1, 105)
Replay buffer saved
---------------------------------
Searching empty space policies
(10, 11472)
(20, 11472)
(20, 11472)
Average distance of agents to nearest neighbors: 0.018323647023760926
Starting 1000 evaluations
avg return on 3 trajectories of agent0: 998.1733000082198
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-11 17:49.19[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-11 17:49.19[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-11 17:49.20[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-11 17:49.20[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-11 17:49.20[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250511174920[0m
[2m2025-05-11 17:49.20[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-11 17:49.41[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511174920: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022277610301971434, 'time_algorithm_update': 0.004875180721282959, 'loss': 1.6274600537642836, 'time_step': 0.007161632776260376, 'init_value': 4.427859783172607}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-11 17:50.02[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511174920: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023188326358795164, 'time_algorithm_update': 0.005062979936599731, 'loss': 2.330035570025444, 'time_step': 0.007443329572677612, 'init_value': 11.999307632446289}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-11 17:50.24[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511174920: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022833082675933836, 'time_algorithm_update': 0.005035712242126465, 'loss': 2.200804533243179, 'time_step': 0.007380067110061645, 'init_value': 19.381134033203125}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-11 17:50.45[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511174920: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002326328992843628, 'time_algorithm_update': 0.005193650722503662, 'loss': 2.0972529781460763, 'time_step': 0.007583697319030761, 'init_value': 25.430789947509766}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-11 17:51.06[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511174920: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00227244234085083, 'time_algorithm_update': 0.004914863109588623, 'loss': 1.942385670542717, 'time_step': 0.007247558355331421, 'init_value': 29.286842346191406}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-11 17:51.28[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511174920: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023263173103332518, 'time_algorithm_update': 0.005059697151184082, 'loss': 1.772482883632183, 'time_step': 0.007447401762008667, 'init_value': 32.62745666503906}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-11 17:51.50[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511174920: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00234099817276001, 'time_algorithm_update': 0.005085299968719483, 'loss': 1.7580883529782296, 'time_step': 0.007487293243408203, 'init_value': 34.88292694091797}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-11 17:52.11[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511174920: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023071553707122803, 'time_algorithm_update': 0.005210813522338867, 'loss': 1.6785459757447243, 'time_step': 0.007581025838851929, 'init_value': 36.321083068847656}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-11 17:52.32[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511174920: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022550251483917237, 'time_algorithm_update': 0.005021037101745606, 'loss': 1.6302710572481156, 'time_step': 0.007335963487625122, 'init_value': 38.51841735839844}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-11 17:52.54[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511174920: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023038823604583742, 'time_algorithm_update': 0.005162089824676514, 'loss': 1.5650519588589669, 'time_step': 0.007528011798858643, 'init_value': 39.57048416137695}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 39.57048416137695
Starting 1000 evaluations
avg return on 3 trajectories of agent1: 1028.6001178089189
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-11 18:09.50[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-11 18:09.50[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-11 18:09.51[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-11 18:09.51[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-11 18:09.51[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250511180951[0m
[2m2025-05-11 18:09.51[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-11 18:10.12[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511180951: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022409920692443848, 'time_algorithm_update': 0.0047742011547088625, 'loss': 1.571294726602733, 'time_step': 0.007071542263031006, 'init_value': 4.6782379150390625}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-11 18:10.33[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511180951: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022973291873931885, 'time_algorithm_update': 0.004889163017272949, 'loss': 2.0573918164372444, 'time_step': 0.007244679450988769, 'init_value': 12.429105758666992}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-11 18:10.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511180951: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00232146692276001, 'time_algorithm_update': 0.005135915517807007, 'loss': 2.1072325381040575, 'time_step': 0.0075189824104309085, 'init_value': 20.035778045654297}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-11 18:11.16[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511180951: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023295884132385255, 'time_algorithm_update': 0.005158965826034546, 'loss': 2.0079829508662224, 'time_step': 0.007550654172897339, 'init_value': 25.970300674438477}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-11 18:11.37[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511180951: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002348634481430054, 'time_algorithm_update': 0.005077440738677979, 'loss': 1.855176687002182, 'time_step': 0.007486742258071899, 'init_value': 30.063499450683594}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-11 18:11.59[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511180951: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002310974359512329, 'time_algorithm_update': 0.005104726552963257, 'loss': 1.7634735414981841, 'time_step': 0.00747677993774414, 'init_value': 33.78512191772461}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-11 18:12.21[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511180951: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002344563007354736, 'time_algorithm_update': 0.005179897785186767, 'loss': 1.6847237738370895, 'time_step': 0.007587279558181763, 'init_value': 35.967079162597656}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-11 18:12.41[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511180951: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002296375036239624, 'time_algorithm_update': 0.0050532913208007815, 'loss': 1.6385057669878007, 'time_step': 0.007410354375839233, 'init_value': 37.591224670410156}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-11 18:13.03[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511180951: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023774144649505616, 'time_algorithm_update': 0.005105637550354004, 'loss': 1.785650622487068, 'time_step': 0.007544484376907349, 'init_value': 39.2791633605957}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-11 18:13.25[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511180951: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002301299810409546, 'time_algorithm_update': 0.005088137865066528, 'loss': 1.5418633351922035, 'time_step': 0.007450268983840942, 'init_value': 41.58517074584961}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.58517074584961
Starting 1000 evaluations
avg return on 3 trajectories of agent2: 1066.413503759441
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-11 18:30.14[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-11 18:30.14[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-11 18:30.16[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-11 18:30.16[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-11 18:30.16[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250511183016[0m
[2m2025-05-11 18:30.16[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-11 18:30.37[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511183016: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022772622108459474, 'time_algorithm_update': 0.005175436496734619, 'loss': 1.5538918967545032, 'time_step': 0.007515471220016479, 'init_value': 4.609389781951904}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-11 18:30.58[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511183016: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002289125680923462, 'time_algorithm_update': 0.004957588911056518, 'loss': 2.200267435669899, 'time_step': 0.007305703401565552, 'init_value': 12.015623092651367}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-11 18:31.19[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511183016: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022511541843414306, 'time_algorithm_update': 0.004930642604827881, 'loss': 2.223238306760788, 'time_step': 0.0072404067516326906, 'init_value': 19.66476821899414}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-11 18:31.40[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511183016: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023085579872131347, 'time_algorithm_update': 0.005075598001480102, 'loss': 2.0976699038147926, 'time_step': 0.007444889068603516, 'init_value': 27.135881423950195}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-11 18:32.02[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511183016: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002305929183959961, 'time_algorithm_update': 0.005153629302978515, 'loss': 1.9826089224219323, 'time_step': 0.00752104663848877, 'init_value': 31.284833908081055}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-11 18:32.23[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511183016: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023345179557800293, 'time_algorithm_update': 0.005148240089416504, 'loss': 1.8074717350006104, 'time_step': 0.007543983221054077, 'init_value': 33.5673828125}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-11 18:32.44[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511183016: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022738425731658935, 'time_algorithm_update': 0.00491339373588562, 'loss': 1.6905352261662483, 'time_step': 0.00724544358253479, 'init_value': 37.10536193847656}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-11 18:33.06[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511183016: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022893218994140623, 'time_algorithm_update': 0.005197380542755127, 'loss': 1.7211173049211501, 'time_step': 0.007548906564712524, 'init_value': 39.577293395996094}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-11 18:33.27[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511183016: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023201682567596436, 'time_algorithm_update': 0.005127439022064209, 'loss': 1.7204436305165292, 'time_step': 0.0075086247920989994, 'init_value': 40.804752349853516}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-11 18:33.48[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511183016: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022531025409698487, 'time_algorithm_update': 0.00505272364616394, 'loss': 1.5302333439588547, 'time_step': 0.0073652338981628415, 'init_value': 41.640846252441406}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.640846252441406
Starting 1000 evaluations
avg return on 3 trajectories of agent3: 1082.9440684166566
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-11 18:50.48[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-11 18:50.48[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-11 18:50.49[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-11 18:50.49[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-11 18:50.49[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250511185049[0m
[2m2025-05-11 18:50.49[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-11 18:51.10[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511185049: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022382588386535645, 'time_algorithm_update': 0.005088260889053345, 'loss': 1.6164947224333883, 'time_step': 0.007387638568878174, 'init_value': 4.6955060958862305}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-11 18:51.31[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511185049: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002315425395965576, 'time_algorithm_update': 0.00497358775138855, 'loss': 2.222785646855831, 'time_step': 0.007349667549133301, 'init_value': 12.177597045898438}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-11 18:51.51[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511185049: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022244400978088377, 'time_algorithm_update': 0.00478150463104248, 'loss': 2.3034428880214692, 'time_step': 0.007063371181488037, 'init_value': 19.728879928588867}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-11 18:52.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511185049: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023600857257843016, 'time_algorithm_update': 0.005246939420700073, 'loss': 2.198597331166267, 'time_step': 0.007670261144638061, 'init_value': 26.12249755859375}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-11 18:52.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511185049: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023654086589813233, 'time_algorithm_update': 0.005307580471038818, 'loss': 1.950946948826313, 'time_step': 0.007736861705780029, 'init_value': 30.62678337097168}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-11 18:52.56[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511185049: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022992708683013917, 'time_algorithm_update': 0.005116983413696289, 'loss': 1.7775000768899918, 'time_step': 0.007478533983230591, 'init_value': 34.59721755981445}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-11 18:53.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511185049: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002282529354095459, 'time_algorithm_update': 0.004886471509933472, 'loss': 1.7742265558242798, 'time_step': 0.007227839231491089, 'init_value': 37.453819274902344}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-11 18:53.39[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511185049: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022929830551147463, 'time_algorithm_update': 0.005301740884780884, 'loss': 1.6526480096578597, 'time_step': 0.0076589035987854005, 'init_value': 39.297908782958984}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-11 18:54.01[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511185049: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002302928686141968, 'time_algorithm_update': 0.005015009403228759, 'loss': 1.6403179916143418, 'time_step': 0.007378504514694214, 'init_value': 40.1234245300293}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-11 18:54.22[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511185049: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002258028745651245, 'time_algorithm_update': 0.004975202083587646, 'loss': 1.5202136927247047, 'time_step': 0.007292824983596802, 'init_value': 40.32747268676758}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.32747268676758
Starting 1000 evaluations
avg return on 3 trajectories of agent4: 1003.3603778819711
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-11 19:11.18[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-11 19:11.18[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-11 19:11.19[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-11 19:11.19[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-11 19:11.19[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250511191119[0m
[2m2025-05-11 19:11.19[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-11 19:11.41[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511191119: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00228045654296875, 'time_algorithm_update': 0.004998129367828369, 'loss': 1.669475034788251, 'time_step': 0.007339390754699707, 'init_value': 4.74329137802124}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-11 19:12.03[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511191119: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023037049770355225, 'time_algorithm_update': 0.005120720863342285, 'loss': 2.2284850462079047, 'time_step': 0.007487234115600586, 'init_value': 11.794353485107422}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-11 19:12.23[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511191119: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002291480779647827, 'time_algorithm_update': 0.004902530193328858, 'loss': 2.047106037199497, 'time_step': 0.007253106117248535, 'init_value': 19.446352005004883}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-11 19:12.45[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511191119: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002350466012954712, 'time_algorithm_update': 0.005134165048599243, 'loss': 2.1614049901366235, 'time_step': 0.007546841621398926, 'init_value': 25.8233699798584}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-11 19:13.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511191119: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002321315288543701, 'time_algorithm_update': 0.005133524894714355, 'loss': 1.9840760373473167, 'time_step': 0.007517130851745606, 'init_value': 30.15936851501465}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-11 19:13.29[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511191119: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023594672679901124, 'time_algorithm_update': 0.005179705619812011, 'loss': 1.8582890295386314, 'time_step': 0.007602807283401489, 'init_value': 33.27596664428711}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-11 19:13.50[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511191119: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022966737747192384, 'time_algorithm_update': 0.004997574806213379, 'loss': 1.7596271634101868, 'time_step': 0.007354381561279297, 'init_value': 36.359073638916016}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-11 19:14.12[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511191119: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002364072561264038, 'time_algorithm_update': 0.005174579620361328, 'loss': 1.6779757077097892, 'time_step': 0.007601567983627319, 'init_value': 37.795433044433594}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-11 19:14.33[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511191119: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023427767753601073, 'time_algorithm_update': 0.005159391164779663, 'loss': 1.6121596760749817, 'time_step': 0.0075644242763519285, 'init_value': 40.3603515625}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-11 19:14.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511191119: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002333574056625366, 'time_algorithm_update': 0.005199892282485962, 'loss': 1.6069969798326493, 'time_step': 0.0075968060493469235, 'init_value': 42.384639739990234}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.384639739990234
Starting 1000 evaluations
avg return on 3 trajectories of agent5: 1066.08614852334
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-11 19:32.11[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-11 19:32.11[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-11 19:32.13[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-11 19:32.13[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-11 19:32.13[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250511193213[0m
[2m2025-05-11 19:32.13[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-11 19:32.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511193213: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002310803413391113, 'time_algorithm_update': 0.0050254642963409426, 'loss': 1.648414844416082, 'time_step': 0.007396550416946411, 'init_value': 4.783167839050293}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-11 19:32.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511193213: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002377022981643677, 'time_algorithm_update': 0.004962507724761963, 'loss': 2.3256411790847777, 'time_step': 0.0073991682529449465, 'init_value': 11.774650573730469}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-11 19:33.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511193213: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00234306263923645, 'time_algorithm_update': 0.005168940544128418, 'loss': 2.1708677075505256, 'time_step': 0.007573484897613525, 'init_value': 19.273874282836914}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-11 19:33.39[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511193213: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023944242000579832, 'time_algorithm_update': 0.005289691686630249, 'loss': 2.047749014079571, 'time_step': 0.007747084140777588, 'init_value': 25.620790481567383}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-11 19:34.00[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511193213: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023183138370513915, 'time_algorithm_update': 0.004957954883575439, 'loss': 1.9113560229539872, 'time_step': 0.007334726333618164, 'init_value': 30.834138870239258}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-11 19:34.22[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511193213: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002373929262161255, 'time_algorithm_update': 0.005017606735229492, 'loss': 1.8688831710219382, 'time_step': 0.007451282501220703, 'init_value': 33.74942398071289}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-11 19:34.44[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511193213: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002389704465866089, 'time_algorithm_update': 0.005254752874374389, 'loss': 1.8093997596502305, 'time_step': 0.007707223892211914, 'init_value': 37.818519592285156}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-11 19:35.06[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511193213: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002349656343460083, 'time_algorithm_update': 0.005353917360305786, 'loss': 1.7532114990353584, 'time_step': 0.007767877817153931, 'init_value': 40.91657257080078}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-11 19:35.27[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511193213: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023200011253356936, 'time_algorithm_update': 0.005014474630355835, 'loss': 1.6557175040245056, 'time_step': 0.007393677234649659, 'init_value': 41.80821990966797}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-11 19:35.48[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511193213: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023146588802337646, 'time_algorithm_update': 0.0049985766410827635, 'loss': 1.7015235590934754, 'time_step': 0.007372735977172851, 'init_value': 43.05146026611328}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 43.05146026611328
Starting 1000 evaluations
avg return on 3 trajectories of agent6: 1104.7022455342124
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-11 19:52.57[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-11 19:52.57[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-11 19:52.59[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-11 19:52.59[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-11 19:52.59[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250511195259[0m
[2m2025-05-11 19:52.59[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-11 19:53.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511195259: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022902712821960447, 'time_algorithm_update': 0.005158039331436157, 'loss': 1.5693257640153169, 'time_step': 0.007510692834854126, 'init_value': 4.190124988555908}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-11 19:53.41[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511195259: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002329629421234131, 'time_algorithm_update': 0.004963014364242554, 'loss': 2.1540243206024168, 'time_step': 0.007351483345031738, 'init_value': 11.08617115020752}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-11 19:54.03[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511195259: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00231391716003418, 'time_algorithm_update': 0.005186241388320923, 'loss': 2.108636256456375, 'time_step': 0.007562219142913818, 'init_value': 18.452558517456055}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-11 19:54.25[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511195259: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023247458934783937, 'time_algorithm_update': 0.005304932355880737, 'loss': 2.0637532398104668, 'time_step': 0.007693339824676513, 'init_value': 25.198158264160156}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-11 19:54.47[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511195259: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023650689125061033, 'time_algorithm_update': 0.005357988119125366, 'loss': 1.9197325369119644, 'time_step': 0.0077884731292724605, 'init_value': 30.165847778320312}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-11 19:55.10[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511195259: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002378845930099487, 'time_algorithm_update': 0.005340196132659912, 'loss': 1.8663606886267663, 'time_step': 0.007784559965133667, 'init_value': 33.72397232055664}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-11 19:55.32[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511195259: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002391306161880493, 'time_algorithm_update': 0.005352935552597046, 'loss': 1.8163020520806312, 'time_step': 0.007810315847396851, 'init_value': 36.55943298339844}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-11 19:55.54[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511195259: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002348270654678345, 'time_algorithm_update': 0.005381335258483886, 'loss': 1.6850681963562966, 'time_step': 0.007794840097427368, 'init_value': 37.69321060180664}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-11 19:56.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511195259: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002383486747741699, 'time_algorithm_update': 0.0054121029376983645, 'loss': 1.782029784142971, 'time_step': 0.007861761569976807, 'init_value': 41.18429946899414}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-11 19:56.39[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511195259: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023562576770782473, 'time_algorithm_update': 0.005339576244354248, 'loss': 1.6557270341515542, 'time_step': 0.007760550975799561, 'init_value': 42.15668487548828}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.15668487548828
Starting 1000 evaluations
avg return on 3 trajectories of agent7: 1120.5479999140641
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-11 20:14.01[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-11 20:14.01[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-11 20:14.02[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-11 20:14.02[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-11 20:14.02[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250511201402[0m
[2m2025-05-11 20:14.02[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-11 20:14.24[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511201402: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022905473709106446, 'time_algorithm_update': 0.005259310960769654, 'loss': 1.4722339324057103, 'time_step': 0.007613517761230469, 'init_value': 4.532479763031006}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-11 20:14.45[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511201402: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023171050548553467, 'time_algorithm_update': 0.004989922523498535, 'loss': 2.295062610626221, 'time_step': 0.007365930318832398, 'init_value': 11.01513671875}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-11 20:15.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511201402: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002280181646347046, 'time_algorithm_update': 0.005025648355484009, 'loss': 2.1667623167037964, 'time_step': 0.00736579155921936, 'init_value': 17.596195220947266}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-11 20:15.29[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511201402: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023560585975646972, 'time_algorithm_update': 0.005270354270935059, 'loss': 2.1148513052463533, 'time_step': 0.007689426422119141, 'init_value': 24.458593368530273}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-11 20:15.51[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511201402: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023199245929718016, 'time_algorithm_update': 0.005408046007156372, 'loss': 1.9350828085541725, 'time_step': 0.007792964696884155, 'init_value': 30.43878936767578}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-11 20:16.12[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511201402: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002302490234375, 'time_algorithm_update': 0.005076378107070923, 'loss': 1.8390545832514762, 'time_step': 0.007438808441162109, 'init_value': 33.072105407714844}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-11 20:16.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511201402: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002330860376358032, 'time_algorithm_update': 0.005058284521102905, 'loss': 1.702549277961254, 'time_step': 0.00744979190826416, 'init_value': 36.21238327026367}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-11 20:16.56[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511201402: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002305757999420166, 'time_algorithm_update': 0.005268203735351563, 'loss': 1.5639135041832923, 'time_step': 0.007636589527130127, 'init_value': 37.30010223388672}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-11 20:17.18[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511201402: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002348629951477051, 'time_algorithm_update': 0.0053151299953460695, 'loss': 1.6207371684312821, 'time_step': 0.007727436780929566, 'init_value': 38.9056282043457}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-11 20:17.39[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511201402: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022960898876190185, 'time_algorithm_update': 0.005095738410949707, 'loss': 1.5752476345300674, 'time_step': 0.007452441930770874, 'init_value': 40.23917007446289}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.23917007446289
Starting 1000 evaluations
avg return on 3 trajectories of agent8: 1012.3338397092489
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-11 20:34.54[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-11 20:34.54[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-11 20:34.55[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-11 20:34.55[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-11 20:34.55[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250511203455[0m
[2m2025-05-11 20:34.55[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-11 20:35.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511203455: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022815523147583006, 'time_algorithm_update': 0.004994380950927735, 'loss': 1.6517741199061275, 'time_step': 0.007335267305374146, 'init_value': 4.58924674987793}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-11 20:35.39[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511203455: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00234602952003479, 'time_algorithm_update': 0.005037102460861206, 'loss': 2.3117662470340727, 'time_step': 0.007443073511123657, 'init_value': 11.683320045471191}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-11 20:36.00[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511203455: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023255910873413088, 'time_algorithm_update': 0.005220670700073243, 'loss': 2.2447237335443497, 'time_step': 0.0076088585853576664, 'init_value': 18.775978088378906}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-11 20:36.22[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511203455: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002378326177597046, 'time_algorithm_update': 0.0052727885246276855, 'loss': 2.140417022049427, 'time_step': 0.00771428918838501, 'init_value': 25.384716033935547}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-11 20:36.44[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511203455: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002357839345932007, 'time_algorithm_update': 0.005126771688461304, 'loss': 2.02809728294611, 'time_step': 0.007545284748077393, 'init_value': 29.178129196166992}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-11 20:37.06[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511203455: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002327481746673584, 'time_algorithm_update': 0.005130771398544311, 'loss': 1.7375309602618219, 'time_step': 0.007518898487091064, 'init_value': 32.11629104614258}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-11 20:37.28[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511203455: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00233528733253479, 'time_algorithm_update': 0.005340821504592895, 'loss': 1.7791147184967995, 'time_step': 0.00773998475074768, 'init_value': 37.20425033569336}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-11 20:37.50[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511203455: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023392460346221924, 'time_algorithm_update': 0.00526514196395874, 'loss': 1.7860690021514893, 'time_step': 0.007667484283447265, 'init_value': 38.414981842041016}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-11 20:38.12[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511203455: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023251762390136717, 'time_algorithm_update': 0.0050743184089660645, 'loss': 1.690652478814125, 'time_step': 0.007459741592407226, 'init_value': 41.185726165771484}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-11 20:38.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511203455: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023598277568817137, 'time_algorithm_update': 0.005180138111114502, 'loss': 1.661220891714096, 'time_step': 0.007600922584533692, 'init_value': 43.34965515136719}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 43.34965515136719
Starting 1000 evaluations
avg return on 3 trajectories of agent9: 1038.1509715187242
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-11 20:55.55[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-11 20:55.55[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-11 20:55.57[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-11 20:55.57[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-11 20:55.57[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250511205557[0m
[2m2025-05-11 20:55.57[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-11 20:56.18[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511205557: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002293895959854126, 'time_algorithm_update': 0.0049674615859985356, 'loss': 1.7001889704093338, 'time_step': 0.007320390939712524, 'init_value': 4.770699501037598}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-11 20:56.40[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511205557: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023594441413879396, 'time_algorithm_update': 0.0052369930744171145, 'loss': 2.134525502026081, 'time_step': 0.007658905267715454, 'init_value': 12.347156524658203}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-11 20:57.02[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511205557: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023381297588348387, 'time_algorithm_update': 0.005234937906265258, 'loss': 2.2799101482629776, 'time_step': 0.007635624647140503, 'init_value': 19.977218627929688}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-11 20:57.24[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511205557: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023666489124298095, 'time_algorithm_update': 0.005110078811645507, 'loss': 2.1083082861304283, 'time_step': 0.007537217378616333, 'init_value': 26.318775177001953}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-11 20:57.45[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511205557: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023099610805511475, 'time_algorithm_update': 0.004930136919021606, 'loss': 1.8736138717532158, 'time_step': 0.007298717498779297, 'init_value': 30.439781188964844}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-11 20:58.08[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511205557: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023766074180603027, 'time_algorithm_update': 0.005300769567489624, 'loss': 1.731867436826229, 'time_step': 0.007740798950195312, 'init_value': 33.501346588134766}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-11 20:58.30[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511205557: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002363067150115967, 'time_algorithm_update': 0.005159664869308472, 'loss': 1.681437674999237, 'time_step': 0.0075842165946960445, 'init_value': 36.350250244140625}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-11 20:58.52[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511205557: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023433420658111573, 'time_algorithm_update': 0.005219213724136353, 'loss': 1.7316908843517302, 'time_step': 0.007625004768371582, 'init_value': 38.45335388183594}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-11 20:59.13[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511205557: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023201980590820312, 'time_algorithm_update': 0.00504323148727417, 'loss': 1.6210486437678338, 'time_step': 0.007423430681228638, 'init_value': 39.72895431518555}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-11 20:59.36[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511205557: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002355459690093994, 'time_algorithm_update': 0.00537900185585022, 'loss': 1.6986591402292253, 'time_step': 0.007799208402633667, 'init_value': 41.012638092041016}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.012638092041016
Starting 1000 evaluations
avg return on 3 trajectories of agent10: 1069.413151745824
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-11 21:16.52[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-11 21:16.52[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-11 21:16.53[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-11 21:16.53[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-11 21:16.53[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250511211653[0m
[2m2025-05-11 21:16.53[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-11 21:17.15[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511211653: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022979612350463867, 'time_algorithm_update': 0.004989578485488892, 'loss': 1.6498534748256206, 'time_step': 0.007347961902618408, 'init_value': 4.440679550170898}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-11 21:17.37[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511211653: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023175437450408936, 'time_algorithm_update': 0.005036444187164307, 'loss': 2.207935806691647, 'time_step': 0.007414839744567871, 'init_value': 11.35891342163086}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-11 21:17.59[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511211653: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023328289985656736, 'time_algorithm_update': 0.005142930269241333, 'loss': 2.1459957904815674, 'time_step': 0.007538587808609009, 'init_value': 19.02121925354004}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-11 21:18.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511211653: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002366130590438843, 'time_algorithm_update': 0.005081380367279053, 'loss': 2.116943986594677, 'time_step': 0.007508845567703247, 'init_value': 25.177734375}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-11 21:18.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511211653: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002334207534790039, 'time_algorithm_update': 0.005206560850143433, 'loss': 1.9685157535672189, 'time_step': 0.007604030370712281, 'init_value': 30.039260864257812}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-11 21:19.04[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511211653: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002377816677093506, 'time_algorithm_update': 0.005148598909378052, 'loss': 1.8288720105290412, 'time_step': 0.0075974113941192625, 'init_value': 34.13242721557617}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-11 21:19.26[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511211653: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023203213214874267, 'time_algorithm_update': 0.005103076696395874, 'loss': 1.7355887382030486, 'time_step': 0.0074859921932220455, 'init_value': 36.48854446411133}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-11 21:19.48[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511211653: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023477845191955567, 'time_algorithm_update': 0.005134455919265747, 'loss': 1.6552072275280953, 'time_step': 0.007545063972473145, 'init_value': 37.39297866821289}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-11 21:20.10[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511211653: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002361260652542114, 'time_algorithm_update': 0.0051970574855804445, 'loss': 1.5495588800311089, 'time_step': 0.007621422529220581, 'init_value': 38.17439270019531}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-11 21:20.32[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511211653: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023493728637695313, 'time_algorithm_update': 0.005223889350891114, 'loss': 1.5584710673093796, 'time_step': 0.00763756251335144, 'init_value': 40.68532943725586}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.68532943725586
Starting 1000 evaluations
avg return on 3 trajectories of agent11: 1097.141499204553
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-11 21:37.52[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-11 21:37.52[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-11 21:37.53[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-11 21:37.53[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-11 21:37.53[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250511213753[0m
[2m2025-05-11 21:37.53[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-11 21:38.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511213753: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022975869178771973, 'time_algorithm_update': 0.0050464413166046145, 'loss': 1.5379402996599674, 'time_step': 0.0074038333892822265, 'init_value': 4.311572551727295}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-11 21:38.36[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511213753: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023214359283447268, 'time_algorithm_update': 0.005147316217422485, 'loss': 2.2102357189655306, 'time_step': 0.007530548810958862, 'init_value': 11.403346061706543}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-11 21:38.58[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511213753: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023454856872558594, 'time_algorithm_update': 0.0052167074680328366, 'loss': 2.1746572651863096, 'time_step': 0.00762511682510376, 'init_value': 18.897924423217773}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-11 21:39.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511213753: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023577759265899657, 'time_algorithm_update': 0.005102952480316162, 'loss': 2.0154213212132452, 'time_step': 0.007521535396575928, 'init_value': 25.156864166259766}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-11 21:39.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511213753: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023484084606170655, 'time_algorithm_update': 0.005245827674865723, 'loss': 2.0172165311574934, 'time_step': 0.0076576838493347165, 'init_value': 29.382373809814453}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-11 21:40.04[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511213753: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023652000427246095, 'time_algorithm_update': 0.005106857061386108, 'loss': 1.7897665799260138, 'time_step': 0.007533849477767945, 'init_value': 32.476844787597656}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-11 21:40.26[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511213753: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00233731746673584, 'time_algorithm_update': 0.005194051742553711, 'loss': 1.8071463629603386, 'time_step': 0.007593319416046142, 'init_value': 34.91776657104492}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-11 21:40.47[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511213753: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002325118064880371, 'time_algorithm_update': 0.005070394039154053, 'loss': 1.7876652091145515, 'time_step': 0.00745642876625061, 'init_value': 37.0209846496582}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-11 21:41.10[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511213753: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002380820989608765, 'time_algorithm_update': 0.005261128902435303, 'loss': 1.5896017392277717, 'time_step': 0.0077050399780273435, 'init_value': 39.9808349609375}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-11 21:41.32[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511213753: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023298976421356203, 'time_algorithm_update': 0.005094102621078491, 'loss': 1.6252257931232452, 'time_step': 0.007484742164611816, 'init_value': 42.04364013671875}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.04364013671875
Starting 1000 evaluations
avg return on 3 trajectories of agent12: 1025.0469169102107
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-11 21:58.49[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-11 21:58.49[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-11 21:58.50[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-11 21:58.50[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-11 21:58.50[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250511215850[0m
[2m2025-05-11 21:58.50[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-11 21:59.12[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511215850: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002316004991531372, 'time_algorithm_update': 0.005027541637420654, 'loss': 1.406785030066967, 'time_step': 0.007403557538986206, 'init_value': 4.948391437530518}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-11 21:59.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511215850: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002365774154663086, 'time_algorithm_update': 0.005236366271972656, 'loss': 2.241667859017849, 'time_step': 0.00766606330871582, 'init_value': 11.611929893493652}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-11 21:59.56[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511215850: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023392865657806397, 'time_algorithm_update': 0.0051517608165740966, 'loss': 2.183108736693859, 'time_step': 0.0075526351928710935, 'init_value': 17.81884765625}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-11 22:00.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511215850: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023296706676483154, 'time_algorithm_update': 0.004969238758087158, 'loss': 2.0262242163419724, 'time_step': 0.007358401298522949, 'init_value': 25.149921417236328}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-11 22:00.39[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511215850: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002370903491973877, 'time_algorithm_update': 0.005150186777114868, 'loss': 1.9546981543898583, 'time_step': 0.007582628011703492, 'init_value': 29.669435501098633}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-11 22:01.01[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511215850: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002357447385787964, 'time_algorithm_update': 0.005295994520187378, 'loss': 1.8125900160074233, 'time_step': 0.007717715501785278, 'init_value': 33.68315887451172}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-11 22:01.23[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511215850: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002378450632095337, 'time_algorithm_update': 0.005149372816085815, 'loss': 1.679687254369259, 'time_step': 0.007589471101760864, 'init_value': 36.1866569519043}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-11 22:01.45[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511215850: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023248825073242186, 'time_algorithm_update': 0.005154816389083862, 'loss': 1.7160549694895744, 'time_step': 0.007541362762451172, 'init_value': 38.206729888916016}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-11 22:02.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511215850: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002326717376708984, 'time_algorithm_update': 0.005147286176681518, 'loss': 1.6264485976099967, 'time_step': 0.007535449028015137, 'init_value': 39.84480285644531}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-11 22:02.29[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511215850: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002403162240982056, 'time_algorithm_update': 0.005224015235900879, 'loss': 1.5469593008160591, 'time_step': 0.007690360069274902, 'init_value': 41.87545394897461}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.87545394897461
Starting 1000 evaluations
avg return on 3 trajectories of agent13: 991.6651051016464
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-11 22:19.55[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-11 22:19.55[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-11 22:19.56[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-11 22:19.56[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-11 22:19.56[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250511221956[0m
[2m2025-05-11 22:19.56[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-11 22:20.18[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511221956: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022923710346221923, 'time_algorithm_update': 0.00498509669303894, 'loss': 1.3999930174797774, 'time_step': 0.007337280511856079, 'init_value': 4.690968990325928}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-11 22:20.40[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511221956: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023573241233825685, 'time_algorithm_update': 0.005077795743942261, 'loss': 2.1916402122974397, 'time_step': 0.007496107816696167, 'init_value': 11.902756690979004}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-11 22:21.02[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511221956: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002314955472946167, 'time_algorithm_update': 0.005123538494110107, 'loss': 2.1514243736863135, 'time_step': 0.007499962329864502, 'init_value': 19.310993194580078}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-11 22:21.24[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511221956: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023378164768218996, 'time_algorithm_update': 0.005272135972976684, 'loss': 1.9453123643398285, 'time_step': 0.007673223018646241, 'init_value': 25.679290771484375}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-11 22:21.46[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511221956: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002348018169403076, 'time_algorithm_update': 0.005046583652496338, 'loss': 1.8834504709243773, 'time_step': 0.00745493221282959, 'init_value': 30.151885986328125}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-11 22:22.08[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511221956: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002321662425994873, 'time_algorithm_update': 0.005127463579177856, 'loss': 1.75909953135252, 'time_step': 0.007510657072067261, 'init_value': 33.248291015625}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-11 22:22.30[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511221956: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002366089344024658, 'time_algorithm_update': 0.005193476915359497, 'loss': 1.699104344725609, 'time_step': 0.0076227464675903325, 'init_value': 35.69526290893555}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-11 22:22.52[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511221956: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023223347663879393, 'time_algorithm_update': 0.00518768048286438, 'loss': 1.6942156838178635, 'time_step': 0.007573015928268432, 'init_value': 37.28633117675781}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-11 22:23.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511221956: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002369579792022705, 'time_algorithm_update': 0.0052337472438812255, 'loss': 1.6356358367204666, 'time_step': 0.0076671669483184815, 'init_value': 39.44819259643555}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-11 22:23.36[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511221956: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002342726230621338, 'time_algorithm_update': 0.005097203969955445, 'loss': 1.6170047239661216, 'time_step': 0.007501746654510498, 'init_value': 40.62785339355469}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.62785339355469
Starting 1000 evaluations
avg return on 3 trajectories of agent14: 959.189129780773
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-11 22:40.55[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-11 22:40.55[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-11 22:40.56[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-11 22:40.56[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-11 22:40.56[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250511224056[0m
[2m2025-05-11 22:40.56[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-11 22:41.18[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511224056: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022930734157562255, 'time_algorithm_update': 0.005128121137619019, 'loss': 1.465589415177703, 'time_step': 0.0074825105667114256, 'init_value': 4.668009281158447}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-11 22:41.40[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511224056: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022945551872253418, 'time_algorithm_update': 0.005196805715560913, 'loss': 2.239024944007397, 'time_step': 0.0075531027317047115, 'init_value': 12.236857414245605}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-11 22:42.02[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511224056: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023032853603363037, 'time_algorithm_update': 0.005174923419952393, 'loss': 2.2242928457260134, 'time_step': 0.007539971828460694, 'init_value': 20.080665588378906}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-11 22:42.24[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511224056: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023717100620269777, 'time_algorithm_update': 0.0051134655475616455, 'loss': 1.9884035924077035, 'time_step': 0.007546347141265869, 'init_value': 25.46031951904297}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-11 22:42.45[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511224056: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002310767412185669, 'time_algorithm_update': 0.005214294910430908, 'loss': 1.8905652374625206, 'time_step': 0.007587728023529053, 'init_value': 29.709333419799805}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-11 22:43.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511224056: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002346510887145996, 'time_algorithm_update': 0.005201942682266235, 'loss': 1.8074716502428054, 'time_step': 0.0076109769344329834, 'init_value': 32.997901916503906}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-11 22:43.29[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511224056: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002310694217681885, 'time_algorithm_update': 0.005185567855834961, 'loss': 1.7733448459506034, 'time_step': 0.007558127403259277, 'init_value': 34.95066833496094}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-11 22:43.51[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511224056: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023251471519470214, 'time_algorithm_update': 0.0051286032199859615, 'loss': 1.6990957903265953, 'time_step': 0.007515338182449341, 'init_value': 37.17600631713867}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-11 22:44.13[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511224056: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002352393388748169, 'time_algorithm_update': 0.0051821329593658445, 'loss': 1.7090330352187157, 'time_step': 0.007597256660461426, 'init_value': 39.69029998779297}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-11 22:44.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511224056: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002308115005493164, 'time_algorithm_update': 0.005172767162322998, 'loss': 1.677969465136528, 'time_step': 0.007542878866195679, 'init_value': 40.27763748168945}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.27763748168945
Starting 1000 evaluations
avg return on 3 trajectories of agent15: 937.6402185608233
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-11 23:01.59[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-11 23:01.59[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-11 23:02.01[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-11 23:02.01[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-11 23:02.01[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250511230201[0m
[2m2025-05-11 23:02.01[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-11 23:02.22[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511230201: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002284640073776245, 'time_algorithm_update': 0.004900555849075317, 'loss': 1.688498903386295, 'time_step': 0.007243337154388428, 'init_value': 4.3983635902404785}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-11 23:02.44[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511230201: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023430774211883544, 'time_algorithm_update': 0.00501396632194519, 'loss': 2.2454656584858896, 'time_step': 0.007417289257049561, 'init_value': 10.550190925598145}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-11 23:03.06[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511230201: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023287320137023925, 'time_algorithm_update': 0.0052658021450042725, 'loss': 2.277373783826828, 'time_step': 0.007658188819885254, 'init_value': 18.409616470336914}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-11 23:03.28[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511230201: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023542335033416746, 'time_algorithm_update': 0.005075123071670532, 'loss': 2.0732517221570017, 'time_step': 0.0074899721145629886, 'init_value': 25.390607833862305}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-11 23:03.50[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511230201: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002340402364730835, 'time_algorithm_update': 0.005147588729858398, 'loss': 1.9597321807742119, 'time_step': 0.007549920082092285, 'init_value': 30.41887092590332}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-11 23:04.11[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511230201: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023203842639923098, 'time_algorithm_update': 0.005007423877716064, 'loss': 1.9395738453269005, 'time_step': 0.007387690305709839, 'init_value': 33.682308197021484}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-11 23:04.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511230201: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0024005661010742187, 'time_algorithm_update': 0.0053709430694580075, 'loss': 1.727233462691307, 'time_step': 0.007837133407592773, 'init_value': 35.75860595703125}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-11 23:04.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511230201: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002320847749710083, 'time_algorithm_update': 0.005052869319915772, 'loss': 1.658756826221943, 'time_step': 0.007434162139892578, 'init_value': 37.43672561645508}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-11 23:05.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511230201: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002344062089920044, 'time_algorithm_update': 0.005241246938705445, 'loss': 1.6870572518706322, 'time_step': 0.007648707389831543, 'init_value': 38.52737808227539}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-11 23:05.39[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511230201: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023610739707946777, 'time_algorithm_update': 0.005133654832839966, 'loss': 1.4816665375828744, 'time_step': 0.007556436538696289, 'init_value': 40.75528335571289}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.75528335571289
Starting 1000 evaluations
avg return on 3 trajectories of agent16: 1027.5330683631864
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-11 23:22.56[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-11 23:22.56[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-11 23:22.58[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-11 23:22.58[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-11 23:22.58[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250511232258[0m
[2m2025-05-11 23:22.58[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-11 23:23.19[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511232258: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022953455448150636, 'time_algorithm_update': 0.005107079267501831, 'loss': 1.7478737902417778, 'time_step': 0.0074640240669250485, 'init_value': 4.47735595703125}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-11 23:23.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511232258: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002304933547973633, 'time_algorithm_update': 0.005027599573135376, 'loss': 2.321564552843571, 'time_step': 0.007393041133880615, 'init_value': 12.0044527053833}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-11 23:24.03[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511232258: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023426086902618407, 'time_algorithm_update': 0.005274985790252686, 'loss': 2.199624116241932, 'time_step': 0.007681337356567383, 'init_value': 19.819198608398438}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-11 23:24.25[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511232258: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023416430950164795, 'time_algorithm_update': 0.004972288846969605, 'loss': 1.992831295967102, 'time_step': 0.00737341594696045, 'init_value': 26.240280151367188}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-11 23:24.47[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511232258: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022969276905059816, 'time_algorithm_update': 0.0050357599258422855, 'loss': 1.8447999776601791, 'time_step': 0.007393121957778931, 'init_value': 30.811725616455078}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-11 23:25.09[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511232258: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023671646118164063, 'time_algorithm_update': 0.005255269765853882, 'loss': 1.6751333057284354, 'time_step': 0.0076859183311462406, 'init_value': 32.34233474731445}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-11 23:25.30[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511232258: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002332770347595215, 'time_algorithm_update': 0.00521929669380188, 'loss': 1.6750172662138938, 'time_step': 0.007615530729293823, 'init_value': 35.541072845458984}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-11 23:25.52[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511232258: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023667354583740237, 'time_algorithm_update': 0.00514975643157959, 'loss': 1.7086089851260184, 'time_step': 0.007579121112823486, 'init_value': 37.779457092285156}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-11 23:26.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511232258: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002339674234390259, 'time_algorithm_update': 0.004963023662567139, 'loss': 1.6074914774298668, 'time_step': 0.007364128828048706, 'init_value': 39.83464050292969}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-11 23:26.36[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511232258: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00232996392250061, 'time_algorithm_update': 0.005268850564956665, 'loss': 1.7009066777825355, 'time_step': 0.007662593126296997, 'init_value': 41.014713287353516}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.014713287353516
Starting 1000 evaluations
avg return on 3 trajectories of agent17: 1007.804761450177
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-11 23:43.59[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-11 23:43.59[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-11 23:44.00[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-11 23:44.00[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-11 23:44.00[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250511234400[0m
[2m2025-05-11 23:44.00[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-11 23:44.22[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511234400: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002321396589279175, 'time_algorithm_update': 0.005077371597290039, 'loss': 1.5521382836177946, 'time_step': 0.007458430767059326, 'init_value': 4.505908012390137}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-11 23:44.44[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511234400: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023261563777923584, 'time_algorithm_update': 0.005074958324432373, 'loss': 2.1709085010290146, 'time_step': 0.007461501359939575, 'init_value': 12.396746635437012}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-11 23:45.06[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511234400: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023796021938323974, 'time_algorithm_update': 0.00530733847618103, 'loss': 2.2845772526860237, 'time_step': 0.007750433921813965, 'init_value': 20.047462463378906}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-11 23:45.28[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511234400: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002369821071624756, 'time_algorithm_update': 0.005124735355377197, 'loss': 2.068933367609978, 'time_step': 0.0075548036098480225, 'init_value': 25.66456413269043}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-11 23:45.50[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511234400: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023538894653320312, 'time_algorithm_update': 0.005196048498153687, 'loss': 1.9092550483345985, 'time_step': 0.007612519264221192, 'init_value': 30.13317108154297}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-11 23:46.12[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511234400: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023957064151763916, 'time_algorithm_update': 0.005281138896942139, 'loss': 1.8130889475941658, 'time_step': 0.007739756345748901, 'init_value': 32.71045684814453}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-11 23:46.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511234400: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00233290696144104, 'time_algorithm_update': 0.00519132399559021, 'loss': 1.6821314157247544, 'time_step': 0.00758632493019104, 'init_value': 36.17013931274414}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-11 23:46.56[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511234400: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023126235008239745, 'time_algorithm_update': 0.005043526649475097, 'loss': 1.5674435147047043, 'time_step': 0.007416163206100464, 'init_value': 38.35432434082031}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-11 23:47.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511234400: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023804192543029784, 'time_algorithm_update': 0.005239774465560913, 'loss': 1.5860990745425225, 'time_step': 0.007683243036270142, 'init_value': 39.89925765991211}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-11 23:47.40[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250511234400: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002351736545562744, 'time_algorithm_update': 0.005286677360534668, 'loss': 1.6906085827350616, 'time_step': 0.007702059745788574, 'init_value': 41.13674545288086}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.13674545288086
Starting 1000 evaluations
avg return on 3 trajectories of agent18: 982.9561879404038
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-12 00:05.04[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-12 00:05.04[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-12 00:05.05[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-12 00:05.05[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-12 00:05.05[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250512000505[0m
[2m2025-05-12 00:05.05[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-12 00:05.27[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512000505: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002317445993423462, 'time_algorithm_update': 0.005222512722015381, 'loss': 1.4207898327335715, 'time_step': 0.007603605508804321, 'init_value': 4.907165050506592}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-12 00:05.49[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512000505: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002319422006607056, 'time_algorithm_update': 0.00506147050857544, 'loss': 2.1658920727968214, 'time_step': 0.007442175626754761, 'init_value': 12.436819076538086}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-12 00:06.11[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512000505: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002331831932067871, 'time_algorithm_update': 0.005185472011566162, 'loss': 2.161167811989784, 'time_step': 0.00758054780960083, 'init_value': 18.674888610839844}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-12 00:06.32[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512000505: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023594470024108885, 'time_algorithm_update': 0.005024449586868286, 'loss': 1.959190167427063, 'time_step': 0.007444361209869385, 'init_value': 24.4118595123291}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-12 00:06.54[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512000505: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002338648319244385, 'time_algorithm_update': 0.005208186388015747, 'loss': 1.9057055807113648, 'time_step': 0.007610979557037353, 'init_value': 28.005102157592773}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-12 00:07.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512000505: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002361485481262207, 'time_algorithm_update': 0.005190813302993774, 'loss': 1.8153869540691376, 'time_step': 0.0076152455806732175, 'init_value': 32.21706008911133}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-12 00:07.39[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512000505: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002346366882324219, 'time_algorithm_update': 0.005263597965240479, 'loss': 1.8240961183309554, 'time_step': 0.007674649715423584, 'init_value': 34.03621292114258}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-12 00:08.00[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512000505: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023183631896972656, 'time_algorithm_update': 0.004974674463272094, 'loss': 1.6660908007621764, 'time_step': 0.0073533222675323485, 'init_value': 37.05341339111328}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-12 00:08.22[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512000505: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0024066355228424072, 'time_algorithm_update': 0.005181296586990357, 'loss': 1.6849232672452927, 'time_step': 0.007651680469512939, 'init_value': 39.08134078979492}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-12 00:08.45[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512000505: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002322521209716797, 'time_algorithm_update': 0.005245276927947998, 'loss': 1.7226966527700425, 'time_step': 0.007631848335266114, 'init_value': 39.51591873168945}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 39.51591873168945
Starting 1000 evaluations
avg return on 3 trajectories of agent19: 960.7971023888499
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-12 00:26.11[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-12 00:26.11[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-12 00:26.12[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-12 00:26.12[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-12 00:26.12[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250512002612[0m
[2m2025-05-12 00:26.12[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-12 00:26.33[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512002612: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023188843727111816, 'time_algorithm_update': 0.005184636831283569, 'loss': 1.6100157845243812, 'time_step': 0.0075661675930023195, 'init_value': 4.394448757171631}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-12 00:26.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512002612: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002320268154144287, 'time_algorithm_update': 0.005080144882202148, 'loss': 2.158399835169315, 'time_step': 0.007461771249771119, 'init_value': 11.091954231262207}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-12 00:27.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512002612: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002302030801773071, 'time_algorithm_update': 0.0049644260406494145, 'loss': 2.3152749078273773, 'time_step': 0.007325629234313965, 'init_value': 18.47830581665039}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-12 00:27.39[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512002612: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002387544870376587, 'time_algorithm_update': 0.00528211236000061, 'loss': 2.1685456106066705, 'time_step': 0.007733610630035401, 'init_value': 25.391021728515625}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-12 00:28.01[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512002612: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002320570945739746, 'time_algorithm_update': 0.005188769340515137, 'loss': 1.9791113456487657, 'time_step': 0.0075718979835510255, 'init_value': 30.37140655517578}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-12 00:28.23[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512002612: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023556127548217775, 'time_algorithm_update': 0.005027342557907105, 'loss': 1.8609730353951455, 'time_step': 0.00744422698020935, 'init_value': 33.21405029296875}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-12 00:28.44[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512002612: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002307124853134155, 'time_algorithm_update': 0.004942915678024292, 'loss': 1.8264083260297774, 'time_step': 0.007309265375137329, 'init_value': 37.100887298583984}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-12 00:29.06[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512002612: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023532588481903075, 'time_algorithm_update': 0.005382161140441894, 'loss': 1.6229587136507033, 'time_step': 0.007800945043563843, 'init_value': 38.238365173339844}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-12 00:29.29[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512002612: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023838236331939697, 'time_algorithm_update': 0.005240469455718994, 'loss': 1.6786150498986243, 'time_step': 0.0076881985664367675, 'init_value': 39.77679443359375}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-12 00:29.50[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512002612: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023146097660064697, 'time_algorithm_update': 0.0050357732772827145, 'loss': 1.570264471948147, 'time_step': 0.007410485744476319, 'init_value': 40.60203552246094}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.60203552246094
ave advantage rew: 41.19264163970947, std: 1.0277362591361772
avg cum rews: 1029.0249857260621, std: 49.947742124703936
Pearson correlation coefficient: 0.27765076077606693
Spearman correlation coefficient: 0.3007518796992481
Kendall Tau correlation coefficient: 0.18947368421052632
the best agent: 7, best agent cum rewards: 1120.5479999140641
1954
Starting to collect rollouts
Collecting rollouts: 10000/1000000
Collecting rollouts: 20000/1000000
Collecting rollouts: 30000/1000000
Collecting rollouts: 40000/1000000
Collecting rollouts: 50000/1000000
Collecting rollouts: 60000/1000000
Collecting rollouts: 70000/1000000
Collecting rollouts: 80000/1000000
Collecting rollouts: 90000/1000000
Collecting rollouts: 100000/1000000
Collecting rollouts: 110000/1000000
Collecting rollouts: 120000/1000000
Collecting rollouts: 130000/1000000
Collecting rollouts: 140000/1000000
Collecting rollouts: 150000/1000000
Collecting rollouts: 160000/1000000
Collecting rollouts: 170000/1000000
Collecting rollouts: 180000/1000000
Collecting rollouts: 190000/1000000
Collecting rollouts: 200000/1000000
Collecting rollouts: 210000/1000000
Collecting rollouts: 220000/1000000
Collecting rollouts: 230000/1000000
Collecting rollouts: 240000/1000000
Collecting rollouts: 250000/1000000
Collecting rollouts: 260000/1000000
Collecting rollouts: 270000/1000000
Collecting rollouts: 280000/1000000
Collecting rollouts: 290000/1000000
Collecting rollouts: 300000/1000000
Collecting rollouts: 310000/1000000
Collecting rollouts: 320000/1000000
Collecting rollouts: 330000/1000000
Collecting rollouts: 340000/1000000
Collecting rollouts: 350000/1000000
Collecting rollouts: 360000/1000000
Collecting rollouts: 370000/1000000
Collecting rollouts: 380000/1000000
Collecting rollouts: 390000/1000000
Collecting rollouts: 400000/1000000
Collecting rollouts: 410000/1000000
Collecting rollouts: 420000/1000000
Collecting rollouts: 430000/1000000
Collecting rollouts: 440000/1000000
Collecting rollouts: 450000/1000000
Collecting rollouts: 460000/1000000
Collecting rollouts: 470000/1000000
Collecting rollouts: 480000/1000000
Collecting rollouts: 490000/1000000
Collecting rollouts: 500000/1000000
Collecting rollouts: 510000/1000000
Collecting rollouts: 520000/1000000
Collecting rollouts: 530000/1000000
Collecting rollouts: 540000/1000000
Collecting rollouts: 550000/1000000
Collecting rollouts: 560000/1000000
Collecting rollouts: 570000/1000000
Collecting rollouts: 580000/1000000
Collecting rollouts: 590000/1000000
Collecting rollouts: 600000/1000000
Collecting rollouts: 610000/1000000
Collecting rollouts: 620000/1000000
Collecting rollouts: 630000/1000000
Collecting rollouts: 640000/1000000
Collecting rollouts: 650000/1000000
Collecting rollouts: 660000/1000000
Collecting rollouts: 670000/1000000
Collecting rollouts: 680000/1000000
Collecting rollouts: 690000/1000000
Collecting rollouts: 700000/1000000
Collecting rollouts: 710000/1000000
Collecting rollouts: 720000/1000000
Collecting rollouts: 730000/1000000
Collecting rollouts: 740000/1000000
Collecting rollouts: 750000/1000000
Collecting rollouts: 760000/1000000
Collecting rollouts: 770000/1000000
Collecting rollouts: 780000/1000000
Collecting rollouts: 790000/1000000
Collecting rollouts: 800000/1000000
Collecting rollouts: 810000/1000000
Collecting rollouts: 820000/1000000
Collecting rollouts: 830000/1000000
Collecting rollouts: 840000/1000000
Collecting rollouts: 850000/1000000
Collecting rollouts: 860000/1000000
Collecting rollouts: 870000/1000000
Collecting rollouts: 880000/1000000
Collecting rollouts: 890000/1000000
Collecting rollouts: 900000/1000000
Collecting rollouts: 910000/1000000
Collecting rollouts: 920000/1000000
Collecting rollouts: 930000/1000000
Collecting rollouts: 940000/1000000
Collecting rollouts: 950000/1000000
Collecting rollouts: 960000/1000000
Collecting rollouts: 970000/1000000
Collecting rollouts: 980000/1000000
Collecting rollouts: 990000/1000000
Collecting rollouts: 1000000/1000000
Replay buffer size:  (1000000, 105)
Replay buffer saved
---------------------------------
Searching empty space policies
(10, 11472)
(20, 11472)
(20, 11472)
Average distance of agents to nearest neighbors: 0.01780672282048433
Starting 1000 evaluations
avg return on 3 trajectories of agent0: 1140.6991131021784
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-12 01:06.50[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-12 01:06.50[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-12 01:06.52[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-12 01:06.52[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-12 01:06.52[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250512010652[0m
[2m2025-05-12 01:06.52[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-12 01:07.13[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512010652: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002311788082122803, 'time_algorithm_update': 0.005135742664337159, 'loss': 1.6382053244784474, 'time_step': 0.007509599924087524, 'init_value': 4.531476974487305}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-12 01:07.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512010652: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023287417888641355, 'time_algorithm_update': 0.005067502737045288, 'loss': 2.1890051976442337, 'time_step': 0.007456845760345459, 'init_value': 11.545334815979004}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-12 01:07.57[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512010652: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023732826709747315, 'time_algorithm_update': 0.005205904006958008, 'loss': 2.0740158012509347, 'time_step': 0.007642055034637451, 'init_value': 18.957672119140625}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-12 01:08.19[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512010652: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023948638439178467, 'time_algorithm_update': 0.005300049066543579, 'loss': 1.9779666418433188, 'time_step': 0.007759654521942138, 'init_value': 25.578832626342773}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-12 01:08.41[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512010652: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002323042392730713, 'time_algorithm_update': 0.005216014146804809, 'loss': 1.8280829517245292, 'time_step': 0.00760157322883606, 'init_value': 29.169986724853516}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-12 01:09.03[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512010652: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002374804735183716, 'time_algorithm_update': 0.005163566350936889, 'loss': 1.9390354478359222, 'time_step': 0.007600889682769775, 'init_value': 32.50493240356445}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-12 01:09.25[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512010652: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002341036081314087, 'time_algorithm_update': 0.0051938571929931645, 'loss': 1.8089084268808364, 'time_step': 0.0075979123115539554, 'init_value': 36.72590255737305}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-12 01:09.47[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512010652: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023513715267181397, 'time_algorithm_update': 0.00532772159576416, 'loss': 1.5733666801452637, 'time_step': 0.007743600845336914, 'init_value': 38.76250076293945}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-12 01:10.08[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512010652: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023770191669464113, 'time_algorithm_update': 0.005089954853057861, 'loss': 1.5661596024632454, 'time_step': 0.007528287649154663, 'init_value': 40.69539260864258}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-12 01:10.30[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512010652: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023378474712371826, 'time_algorithm_update': 0.005137126207351685, 'loss': 1.5634538351297378, 'time_step': 0.007537442207336426, 'init_value': 43.06177520751953}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 43.06177520751953
Starting 1000 evaluations
avg return on 3 trajectories of agent1: 1121.395188022535
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-12 01:27.46[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-12 01:27.46[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-12 01:27.47[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-12 01:27.47[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-12 01:27.47[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250512012747[0m
[2m2025-05-12 01:27.47[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-12 01:28.09[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512012747: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022939543724060057, 'time_algorithm_update': 0.005086045980453491, 'loss': 1.505671579428017, 'time_step': 0.0074412569999694825, 'init_value': 4.970199108123779}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-12 01:28.31[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512012747: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002362393617630005, 'time_algorithm_update': 0.0052239253520965576, 'loss': 2.434277372956276, 'time_step': 0.007650590181350708, 'init_value': 12.308568000793457}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-12 01:28.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512012747: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023225057125091553, 'time_algorithm_update': 0.005111294507980347, 'loss': 2.0692014669179914, 'time_step': 0.007496812105178833, 'init_value': 19.521799087524414}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-12 01:29.15[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512012747: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023229000568389894, 'time_algorithm_update': 0.005149894714355468, 'loss': 2.0566510158777236, 'time_step': 0.0075357422828674315, 'init_value': 25.65514373779297}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-12 01:29.37[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512012747: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002361188173294067, 'time_algorithm_update': 0.005163982152938843, 'loss': 1.8479293411374091, 'time_step': 0.007588429689407349, 'init_value': 30.131458282470703}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-12 01:29.59[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512012747: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023190820217132567, 'time_algorithm_update': 0.005170186042785644, 'loss': 1.7563611602187157, 'time_step': 0.007552157878875732, 'init_value': 34.18647003173828}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-12 01:30.21[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512012747: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002374835729598999, 'time_algorithm_update': 0.0052336685657501224, 'loss': 1.7195520511865616, 'time_step': 0.0076722512245178225, 'init_value': 37.45710754394531}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-12 01:30.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512012747: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023298351764678956, 'time_algorithm_update': 0.005136466741561889, 'loss': 1.6462655239701272, 'time_step': 0.007529414653778076, 'init_value': 40.32789611816406}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-12 01:31.04[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512012747: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023700833320617677, 'time_algorithm_update': 0.005184262752532959, 'loss': 1.7273817055821419, 'time_step': 0.007618225336074829, 'init_value': 43.28429412841797}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-12 01:31.26[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512012747: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002355502367019653, 'time_algorithm_update': 0.005106212139129639, 'loss': 1.5499236931204796, 'time_step': 0.007524236679077149, 'init_value': 43.09306716918945}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 43.09306716918945
Starting 1000 evaluations
avg return on 3 trajectories of agent2: 1118.7421998861792
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-12 01:48.42[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-12 01:48.42[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-12 01:48.44[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-12 01:48.44[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-12 01:48.44[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250512014844[0m
[2m2025-05-12 01:48.44[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-12 01:49.05[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512014844: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023145692348480224, 'time_algorithm_update': 0.005060523509979248, 'loss': 1.4976822044476867, 'time_step': 0.007436608791351319, 'init_value': 4.537801742553711}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-12 01:49.27[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512014844: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023531897068023683, 'time_algorithm_update': 0.005149591445922852, 'loss': 2.194066546857357, 'time_step': 0.007565352916717529, 'init_value': 11.855541229248047}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-12 01:49.49[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512014844: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002322387456893921, 'time_algorithm_update': 0.005149367570877075, 'loss': 2.0919351551532746, 'time_step': 0.007534634828567505, 'init_value': 18.634878158569336}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-12 01:50.11[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512014844: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002359783887863159, 'time_algorithm_update': 0.005269058227539062, 'loss': 1.9549329198598862, 'time_step': 0.007692473888397217, 'init_value': 24.19464111328125}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-12 01:50.33[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512014844: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023566250801086426, 'time_algorithm_update': 0.0052455470561981205, 'loss': 1.8529964448809624, 'time_step': 0.0076665198802948, 'init_value': 28.716609954833984}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-12 01:50.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512014844: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00236996865272522, 'time_algorithm_update': 0.005078081846237183, 'loss': 1.754875759124756, 'time_step': 0.0075099730491638185, 'init_value': 32.903934478759766}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-12 01:51.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512014844: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023521883487701415, 'time_algorithm_update': 0.005248449802398682, 'loss': 1.657391929745674, 'time_step': 0.007666492938995361, 'init_value': 35.96401596069336}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-12 01:51.39[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512014844: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002350873947143555, 'time_algorithm_update': 0.005276428937911987, 'loss': 1.5872697120308876, 'time_step': 0.007691496849060058, 'init_value': 36.89093017578125}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-12 01:52.01[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512014844: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002382162570953369, 'time_algorithm_update': 0.005290671348571778, 'loss': 1.6057590399384498, 'time_step': 0.007737131118774414, 'init_value': 39.917423248291016}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-12 01:52.23[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512014844: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023322415351867674, 'time_algorithm_update': 0.00502119779586792, 'loss': 1.738824213385582, 'time_step': 0.007414192199707031, 'init_value': 42.26290512084961}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.26290512084961
Starting 1000 evaluations
avg return on 3 trajectories of agent3: 1085.9946483739582
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-12 02:09.34[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-12 02:09.34[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-12 02:09.35[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-12 02:09.35[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-12 02:09.35[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250512020935[0m
[2m2025-05-12 02:09.35[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-12 02:09.57[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512020935: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022994349002838136, 'time_algorithm_update': 0.00500285816192627, 'loss': 1.6706580510288478, 'time_step': 0.007362255811691284, 'init_value': 4.723627090454102}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-12 02:10.19[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512020935: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023597810268402098, 'time_algorithm_update': 0.005104799270629883, 'loss': 2.2015627707242964, 'time_step': 0.007527040481567383, 'init_value': 10.937006950378418}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-12 02:10.41[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512020935: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023500075340270998, 'time_algorithm_update': 0.0053132963180542, 'loss': 2.2252951929569242, 'time_step': 0.007727500200271607, 'init_value': 18.655284881591797}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-12 02:11.03[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512020935: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023567280769348146, 'time_algorithm_update': 0.005205847024917602, 'loss': 1.9349742106795311, 'time_step': 0.0076260693073272705, 'init_value': 24.290416717529297}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-12 02:11.25[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512020935: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023568706512451174, 'time_algorithm_update': 0.005188241004943848, 'loss': 1.7755688264966012, 'time_step': 0.007607987880706787, 'init_value': 27.86554718017578}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-12 02:11.47[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512020935: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023294556140899658, 'time_algorithm_update': 0.005139005184173584, 'loss': 1.7056169135570527, 'time_step': 0.007530616760253906, 'init_value': 31.336822509765625}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-12 02:12.09[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512020935: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023533294200897216, 'time_algorithm_update': 0.0052162866592407224, 'loss': 1.6929823554754257, 'time_step': 0.00763336181640625, 'init_value': 34.653133392333984}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-12 02:12.31[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512020935: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023201768398284912, 'time_algorithm_update': 0.00517539119720459, 'loss': 1.6220756124854088, 'time_step': 0.007558241844177246, 'init_value': 37.23122024536133}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-12 02:12.52[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512020935: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023548927307128907, 'time_algorithm_update': 0.0051609835624694825, 'loss': 1.583805795609951, 'time_step': 0.007578216791152954, 'init_value': 38.96640396118164}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-12 02:13.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512020935: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023422982692718505, 'time_algorithm_update': 0.005205905675888062, 'loss': 1.6415105550289153, 'time_step': 0.007611944437026978, 'init_value': 40.993431091308594}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.993431091308594
Starting 1000 evaluations
avg return on 3 trajectories of agent4: 1137.2479719531927
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-12 02:30.35[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-12 02:30.35[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-12 02:30.37[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-12 02:30.37[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-12 02:30.37[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250512023037[0m
[2m2025-05-12 02:30.37[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-12 02:30.58[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512023037: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022861177921295168, 'time_algorithm_update': 0.004931722164154053, 'loss': 1.5762099594846368, 'time_step': 0.007277811527252197, 'init_value': 4.342162132263184}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-12 02:31.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512023037: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023605217933654783, 'time_algorithm_update': 0.005135183095932007, 'loss': 2.2368397580981254, 'time_step': 0.007558579921722412, 'init_value': 11.30275821685791}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-12 02:31.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512023037: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023309528827667237, 'time_algorithm_update': 0.005207111597061157, 'loss': 2.172025423526764, 'time_step': 0.007600624799728393, 'init_value': 18.24099349975586}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-12 02:32.04[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512023037: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023274402618408204, 'time_algorithm_update': 0.005235706567764282, 'loss': 2.038634275019169, 'time_step': 0.007626970052719116, 'init_value': 24.834808349609375}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-12 02:32.26[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512023037: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023554604053497314, 'time_algorithm_update': 0.005140568017959595, 'loss': 1.8013069245815276, 'time_step': 0.007557819366455078, 'init_value': 28.904813766479492}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-12 02:32.48[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512023037: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002345484256744385, 'time_algorithm_update': 0.005192719459533692, 'loss': 1.8721450127959252, 'time_step': 0.007601568937301636, 'init_value': 32.928428649902344}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-12 02:33.10[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512023037: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002367703437805176, 'time_algorithm_update': 0.005133132696151734, 'loss': 1.735461856484413, 'time_step': 0.007562426805496215, 'init_value': 36.77560806274414}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-12 02:33.32[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512023037: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023791055679321287, 'time_algorithm_update': 0.005518070936203003, 'loss': 1.6638357951641083, 'time_step': 0.007964401960372925, 'init_value': 38.51988220214844}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-12 02:33.54[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512023037: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002362834692001343, 'time_algorithm_update': 0.005189656257629394, 'loss': 1.5732087852358818, 'time_step': 0.007615337133407593, 'init_value': 39.908226013183594}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-12 02:34.16[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512023037: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023229000568389894, 'time_algorithm_update': 0.0050968585014343265, 'loss': 1.6013925973773002, 'time_step': 0.007481394052505494, 'init_value': 41.12478256225586}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.12478256225586
Starting 1000 evaluations
avg return on 3 trajectories of agent5: 1116.2573538182712
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-12 02:51.33[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-12 02:51.33[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-12 02:51.35[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-12 02:51.35[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-12 02:51.35[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250512025135[0m
[2m2025-05-12 02:51.35[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-12 02:51.56[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512025135: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002325281620025635, 'time_algorithm_update': 0.005260806083679199, 'loss': 1.5720524826794864, 'time_step': 0.007650522947311401, 'init_value': 4.582615375518799}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-12 02:52.18[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512025135: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022989368438720704, 'time_algorithm_update': 0.004919981956481934, 'loss': 2.090960780143738, 'time_step': 0.007277964830398559, 'init_value': 11.428241729736328}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-12 02:52.40[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512025135: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023502981662750244, 'time_algorithm_update': 0.005326601505279541, 'loss': 2.347364872932434, 'time_step': 0.007741044044494629, 'init_value': 18.83183479309082}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-12 02:53.02[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512025135: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00237906813621521, 'time_algorithm_update': 0.005146673202514648, 'loss': 2.0949483726620675, 'time_step': 0.007587461709976196, 'init_value': 24.831850051879883}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-12 02:53.24[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512025135: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002348365545272827, 'time_algorithm_update': 0.005220960617065429, 'loss': 1.9854701462984086, 'time_step': 0.007632195472717285, 'init_value': 29.79670524597168}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-12 02:53.46[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512025135: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023722243309020996, 'time_algorithm_update': 0.005056537628173828, 'loss': 1.8203891936540604, 'time_step': 0.007489491701126099, 'init_value': 32.26040267944336}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-12 02:54.08[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512025135: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002342828035354614, 'time_algorithm_update': 0.005258590221405029, 'loss': 1.7470112990140916, 'time_step': 0.007665014505386353, 'init_value': 35.715057373046875}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-12 02:54.30[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512025135: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002375624179840088, 'time_algorithm_update': 0.005283041954040528, 'loss': 1.6763156269788742, 'time_step': 0.0077224702835083005, 'init_value': 37.56460189819336}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-12 02:54.52[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512025135: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023630077838897707, 'time_algorithm_update': 0.005121349811553955, 'loss': 1.557002130508423, 'time_step': 0.007546181917190552, 'init_value': 39.79407501220703}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-12 02:55.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512025135: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002329334497451782, 'time_algorithm_update': 0.0051114075183868405, 'loss': 1.5097585527300834, 'time_step': 0.007502195835113526, 'init_value': 40.8404655456543}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.8404655456543
Starting 1000 evaluations
avg return on 3 trajectories of agent6: 1095.6497186455667
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-12 03:12.28[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-12 03:12.28[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-12 03:12.30[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-12 03:12.30[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-12 03:12.30[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250512031230[0m
[2m2025-05-12 03:12.30[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-12 03:12.51[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512031230: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022959434986114502, 'time_algorithm_update': 0.0049058270454406736, 'loss': 1.444713086128235, 'time_step': 0.00726078200340271, 'init_value': 4.644633769989014}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-12 03:13.13[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512031230: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002335791826248169, 'time_algorithm_update': 0.005057489395141602, 'loss': 2.1420720989704134, 'time_step': 0.007454601287841797, 'init_value': 11.633988380432129}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-12 03:13.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512031230: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023415088653564453, 'time_algorithm_update': 0.00522650146484375, 'loss': 2.1101851962208746, 'time_step': 0.007632028579711914, 'init_value': 19.086021423339844}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-12 03:13.57[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512031230: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0024261131286621093, 'time_algorithm_update': 0.005319913864135742, 'loss': 2.0509381202459336, 'time_step': 0.007812875986099243, 'init_value': 25.280235290527344}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-12 03:14.19[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512031230: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023308513164520266, 'time_algorithm_update': 0.005011075258255005, 'loss': 1.8543520426154136, 'time_step': 0.007402428865432739, 'init_value': 29.32047462463379}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-12 03:14.40[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512031230: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023504443168640135, 'time_algorithm_update': 0.005101161003112793, 'loss': 1.7803845230937003, 'time_step': 0.007513587474822998, 'init_value': 32.283206939697266}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-12 03:15.03[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512031230: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00233686900138855, 'time_algorithm_update': 0.005236163854598999, 'loss': 1.665937096297741, 'time_step': 0.007637029647827149, 'init_value': 34.751338958740234}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-12 03:15.25[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512031230: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023796169757843016, 'time_algorithm_update': 0.005190857887268066, 'loss': 1.6353152915239335, 'time_step': 0.00763409423828125, 'init_value': 37.4663200378418}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-12 03:15.46[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512031230: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002353130340576172, 'time_algorithm_update': 0.005031871795654297, 'loss': 1.633741506099701, 'time_step': 0.0074450082778930666, 'init_value': 39.091835021972656}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-12 03:16.08[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512031230: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023472762107849122, 'time_algorithm_update': 0.005216886281967163, 'loss': 1.5631030044555665, 'time_step': 0.007628120899200439, 'init_value': 40.81806182861328}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.81806182861328
Starting 1000 evaluations
avg return on 3 trajectories of agent7: 1045.953939909909
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-12 03:33.23[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-12 03:33.23[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-12 03:33.24[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-12 03:33.24[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-12 03:33.24[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250512033324[0m
[2m2025-05-12 03:33.24[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-12 03:33.46[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512033324: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023113443851470947, 'time_algorithm_update': 0.005021478891372681, 'loss': 1.581586435265839, 'time_step': 0.007393470525741577, 'init_value': 4.339721202850342}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-12 03:34.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512033324: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023499221801757814, 'time_algorithm_update': 0.005089102983474731, 'loss': 2.2965612848997115, 'time_step': 0.0075002810955047605, 'init_value': 11.169981002807617}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-12 03:34.29[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512033324: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023229680061340333, 'time_algorithm_update': 0.005293462038040161, 'loss': 2.1267078934311865, 'time_step': 0.0076808156967163085, 'init_value': 18.321805953979492}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-12 03:34.51[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512033324: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023771326541900633, 'time_algorithm_update': 0.005255792140960693, 'loss': 2.046914383292198, 'time_step': 0.00771324872970581, 'init_value': 24.260082244873047}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-12 03:35.13[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512033324: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023234663009643556, 'time_algorithm_update': 0.005205586194992066, 'loss': 1.8718334605693818, 'time_step': 0.007591406106948853, 'init_value': 28.42906379699707}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-12 03:35.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512033324: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002341322183609009, 'time_algorithm_update': 0.00529975414276123, 'loss': 1.857175128161907, 'time_step': 0.00770492148399353, 'init_value': 31.144468307495117}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-12 03:35.57[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512033324: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023758583068847657, 'time_algorithm_update': 0.005242449760437012, 'loss': 1.7406631762981415, 'time_step': 0.007681396245956421, 'init_value': 35.33423614501953}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-12 03:36.19[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512033324: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023442175388336184, 'time_algorithm_update': 0.005258170127868653, 'loss': 1.675210895895958, 'time_step': 0.007665571928024292, 'init_value': 37.3670539855957}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-12 03:36.41[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512033324: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023636887073516847, 'time_algorithm_update': 0.005031813144683838, 'loss': 1.542307580113411, 'time_step': 0.007456024885177612, 'init_value': 38.34036636352539}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-12 03:37.03[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512033324: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023338046073913573, 'time_algorithm_update': 0.005288323402404785, 'loss': 1.490626565515995, 'time_step': 0.007685391902923584, 'init_value': 39.91944122314453}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 39.91944122314453
Starting 1000 evaluations
avg return on 3 trajectories of agent8: 1142.486789694414
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-12 03:54.20[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-12 03:54.20[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-12 03:54.21[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-12 03:54.21[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-12 03:54.21[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250512035421[0m
[2m2025-05-12 03:54.21[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-12 03:54.43[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512035421: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00234281587600708, 'time_algorithm_update': 0.005160997390747071, 'loss': 1.5021770524978637, 'time_step': 0.007565789937973023, 'init_value': 4.2018961906433105}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-12 03:55.05[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512035421: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023469805717468263, 'time_algorithm_update': 0.0051298847198486324, 'loss': 2.2909483906030657, 'time_step': 0.007539048194885254, 'init_value': 10.793668746948242}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-12 03:55.27[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512035421: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002389748811721802, 'time_algorithm_update': 0.005273088932037353, 'loss': 2.216824855208397, 'time_step': 0.007725886106491089, 'init_value': 18.984201431274414}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-12 03:55.49[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512035421: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023853695392608643, 'time_algorithm_update': 0.005182137727737427, 'loss': 2.1095332483649254, 'time_step': 0.007629073143005371, 'init_value': 25.267162322998047}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-12 03:56.11[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512035421: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023506641387939452, 'time_algorithm_update': 0.005208862781524658, 'loss': 1.8856415489912033, 'time_step': 0.007621724128723145, 'init_value': 29.968109130859375}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-12 03:56.33[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512035421: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0024008493423461914, 'time_algorithm_update': 0.005201162099838257, 'loss': 1.9394216650724412, 'time_step': 0.007664672136306763, 'init_value': 33.15212631225586}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-12 03:56.56[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512035421: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002356424570083618, 'time_algorithm_update': 0.005280701160430909, 'loss': 1.731112454533577, 'time_step': 0.007702173233032227, 'init_value': 36.04328536987305}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-12 03:57.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512035421: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00234757924079895, 'time_algorithm_update': 0.005095655679702759, 'loss': 1.6997733711600305, 'time_step': 0.007504258394241333, 'init_value': 38.02220916748047}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-12 03:57.39[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512035421: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002389596939086914, 'time_algorithm_update': 0.005231048822402954, 'loss': 1.5670380836725235, 'time_step': 0.007683389902114869, 'init_value': 40.35648727416992}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-12 03:58.02[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512035421: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023715088367462158, 'time_algorithm_update': 0.005282054901123047, 'loss': 1.6393746460676193, 'time_step': 0.007717865467071533, 'init_value': 41.195133209228516}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.195133209228516
Starting 1000 evaluations
avg return on 3 trajectories of agent9: 1146.0220273585526
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-12 04:15.17[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-12 04:15.17[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-12 04:15.18[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-12 04:15.18[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-12 04:15.18[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250512041518[0m
[2m2025-05-12 04:15.18[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-12 04:15.40[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512041518: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002314753532409668, 'time_algorithm_update': 0.005073928117752076, 'loss': 1.7320938945561648, 'time_step': 0.0074500198364257815, 'init_value': 4.118131637573242}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-12 04:16.02[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512041518: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023578763008117675, 'time_algorithm_update': 0.005070446968078613, 'loss': 2.1814834918379784, 'time_step': 0.007489893436431885, 'init_value': 11.228365898132324}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-12 04:16.24[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512041518: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023493750095367433, 'time_algorithm_update': 0.005175264120101929, 'loss': 2.221401371836662, 'time_step': 0.0075876591205596925, 'init_value': 18.91358184814453}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-12 04:16.46[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512041518: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002337644815444946, 'time_algorithm_update': 0.005151650905609131, 'loss': 2.0105284938812256, 'time_step': 0.007551740407943725, 'init_value': 24.9777889251709}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-12 04:17.08[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512041518: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002370904207229614, 'time_algorithm_update': 0.005203668832778931, 'loss': 1.8358048090338708, 'time_step': 0.0076376254558563235, 'init_value': 29.09067153930664}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-12 04:17.30[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512041518: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023416171073913574, 'time_algorithm_update': 0.005163703680038452, 'loss': 1.7763001316785811, 'time_step': 0.007567824363708496, 'init_value': 32.25917434692383}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-12 04:17.52[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512041518: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0024007546901702883, 'time_algorithm_update': 0.005271073579788208, 'loss': 1.592816927909851, 'time_step': 0.007736104249954224, 'init_value': 34.97119903564453}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-12 04:18.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512041518: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002338160753250122, 'time_algorithm_update': 0.005115026712417602, 'loss': 1.6690131095051766, 'time_step': 0.007515371322631836, 'init_value': 38.10276412963867}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-12 04:18.36[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512041518: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023749849796295165, 'time_algorithm_update': 0.005149966955184936, 'loss': 1.5560310814976692, 'time_step': 0.007587414741516113, 'init_value': 40.38859176635742}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-12 04:18.58[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512041518: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002370096921920776, 'time_algorithm_update': 0.005050650358200073, 'loss': 1.5490867862701416, 'time_step': 0.007481954574584961, 'init_value': 40.635074615478516}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.635074615478516
Starting 1000 evaluations
avg return on 3 trajectories of agent10: 1158.062043645847
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-12 04:36.17[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-12 04:36.17[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-12 04:36.18[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-12 04:36.18[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-12 04:36.18[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250512043618[0m
[2m2025-05-12 04:36.18[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-12 04:36.40[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512043618: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002279535531997681, 'time_algorithm_update': 0.00489315390586853, 'loss': 1.548793188855052, 'time_step': 0.00723105001449585, 'init_value': 4.514372825622559}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-12 04:37.02[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512043618: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023567678928375245, 'time_algorithm_update': 0.005300809860229492, 'loss': 2.039801592350006, 'time_step': 0.007721765518188477, 'init_value': 11.424346923828125}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-12 04:37.24[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512043618: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002311990737915039, 'time_algorithm_update': 0.00504470944404602, 'loss': 2.2918787427544594, 'time_step': 0.007417251586914062, 'init_value': 19.03204917907715}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-12 04:37.46[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512043618: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023629035949707033, 'time_algorithm_update': 0.0052045114040374756, 'loss': 2.0854586134552955, 'time_step': 0.007630270481109619, 'init_value': 25.85001564025879}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-12 04:38.08[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512043618: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002351963758468628, 'time_algorithm_update': 0.005109177589416504, 'loss': 1.9398540470004082, 'time_step': 0.007521934270858764, 'init_value': 30.217863082885742}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-12 04:38.30[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512043618: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002330678462982178, 'time_algorithm_update': 0.005265784740447998, 'loss': 1.7561152616739273, 'time_step': 0.007660057783126831, 'init_value': 33.89609146118164}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-12 04:38.52[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512043618: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023651304244995115, 'time_algorithm_update': 0.005152311325073242, 'loss': 1.6008824016451835, 'time_step': 0.007578991413116455, 'init_value': 35.354461669921875}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-12 04:39.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512043618: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023156464099884032, 'time_algorithm_update': 0.005120135307312011, 'loss': 1.5472294569611549, 'time_step': 0.0074973955154418945, 'init_value': 38.068321228027344}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-12 04:39.36[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512043618: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023429746627807615, 'time_algorithm_update': 0.005323436975479126, 'loss': 1.6554795252680778, 'time_step': 0.00773076605796814, 'init_value': 39.06532287597656}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-12 04:39.58[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512043618: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002334952116012573, 'time_algorithm_update': 0.005236799001693725, 'loss': 1.5695179023742676, 'time_step': 0.007635768175125122, 'init_value': 40.761329650878906}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.761329650878906
Starting 1000 evaluations
avg return on 3 trajectories of agent11: 1170.8821720753424
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-12 04:57.13[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-12 04:57.13[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-12 04:57.15[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-12 04:57.15[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-12 04:57.15[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250512045715[0m
[2m2025-05-12 04:57.15[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-12 04:57.36[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512045715: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002328277826309204, 'time_algorithm_update': 0.0050280213356018065, 'loss': 1.719666214555502, 'time_step': 0.007417045831680298, 'init_value': 4.223683834075928}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-12 04:57.58[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512045715: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023587777614593507, 'time_algorithm_update': 0.005230997562408447, 'loss': 2.1741902267932893, 'time_step': 0.007653765916824341, 'init_value': 9.961681365966797}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-12 04:58.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512045715: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023816826343536377, 'time_algorithm_update': 0.005074501752853394, 'loss': 2.246844058632851, 'time_step': 0.007517394304275513, 'init_value': 17.259597778320312}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-12 04:58.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512045715: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0024009437561035157, 'time_algorithm_update': 0.005270615816116333, 'loss': 2.2165463529229164, 'time_step': 0.007735567569732666, 'init_value': 24.3040714263916}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-12 04:59.04[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512045715: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023563945293426512, 'time_algorithm_update': 0.005128826379776001, 'loss': 1.9081547884941101, 'time_step': 0.007547538042068482, 'init_value': 29.266780853271484}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-12 04:59.26[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512045715: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002410862684249878, 'time_algorithm_update': 0.0052448689937591554, 'loss': 1.838481717824936, 'time_step': 0.007719878435134888, 'init_value': 33.75556182861328}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-12 04:59.48[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512045715: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002362070083618164, 'time_algorithm_update': 0.0052084908485412595, 'loss': 1.6840480917692184, 'time_step': 0.007633445739746093, 'init_value': 37.29536437988281}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-12 05:00.10[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512045715: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002349475145339966, 'time_algorithm_update': 0.005159995794296265, 'loss': 1.7502008887529372, 'time_step': 0.00757201623916626, 'init_value': 38.61789321899414}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-12 05:00.32[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512045715: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0024062607288360596, 'time_algorithm_update': 0.005224577903747559, 'loss': 1.671368243277073, 'time_step': 0.007694371223449707, 'init_value': 40.493282318115234}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-12 05:00.54[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512045715: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002349960803985596, 'time_algorithm_update': 0.005087470054626465, 'loss': 1.6990335742235183, 'time_step': 0.007499500036239624, 'init_value': 41.75236129760742}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.75236129760742
Starting 1000 evaluations
avg return on 3 trajectories of agent12: 1135.345262692649
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-12 05:18.16[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-12 05:18.16[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-12 05:18.17[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-12 05:18.17[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-12 05:18.17[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250512051817[0m
[2m2025-05-12 05:18.17[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-12 05:18.39[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512051817: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002293993949890137, 'time_algorithm_update': 0.004984689712524414, 'loss': 1.5886396517008543, 'time_step': 0.007338902235031128, 'init_value': 4.410831928253174}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-12 05:19.01[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512051817: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002304866552352905, 'time_algorithm_update': 0.005013468980789184, 'loss': 2.1006982631087303, 'time_step': 0.007379159927368164, 'init_value': 10.65505599975586}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-12 05:19.23[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512051817: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023486180305480955, 'time_algorithm_update': 0.005295002222061157, 'loss': 2.170390848517418, 'time_step': 0.0077082056999206545, 'init_value': 18.36770248413086}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-12 05:19.45[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512051817: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023665804862976073, 'time_algorithm_update': 0.00531390929222107, 'loss': 1.9285975607037544, 'time_step': 0.007744424104690552, 'init_value': 24.5408992767334}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-12 05:20.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512051817: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023409557342529298, 'time_algorithm_update': 0.005168019294738769, 'loss': 1.8581102921366692, 'time_step': 0.0075717844963073735, 'init_value': 29.394887924194336}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-12 05:20.29[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512051817: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023551054000854493, 'time_algorithm_update': 0.0051874170303344725, 'loss': 1.7251871717572211, 'time_step': 0.007605100870132446, 'init_value': 32.350616455078125}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-12 05:20.51[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512051817: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023260529041290285, 'time_algorithm_update': 0.00510345983505249, 'loss': 1.635491002857685, 'time_step': 0.007491315364837646, 'init_value': 35.899600982666016}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-12 05:21.13[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512051817: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023851151466369627, 'time_algorithm_update': 0.005331648111343384, 'loss': 1.603441870868206, 'time_step': 0.007782567739486695, 'init_value': 37.40043640136719}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-12 05:21.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512051817: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023567843437194824, 'time_algorithm_update': 0.005118023633956909, 'loss': 1.5355964703559875, 'time_step': 0.0075367546081542966, 'init_value': 39.13142013549805}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-12 05:21.57[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512051817: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002335273265838623, 'time_algorithm_update': 0.005190619945526123, 'loss': 1.5748095443248749, 'time_step': 0.007589126110076904, 'init_value': 41.032135009765625}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.032135009765625
Starting 1000 evaluations
avg return on 3 trajectories of agent13: 1129.182857247716
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-12 05:39.13[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-12 05:39.13[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-12 05:39.14[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-12 05:39.14[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-12 05:39.14[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250512053914[0m
[2m2025-05-12 05:39.14[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-12 05:39.36[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512053914: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002314481973648071, 'time_algorithm_update': 0.005171673059463501, 'loss': 1.5917413648068905, 'time_step': 0.007550049543380738, 'init_value': 4.530206203460693}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-12 05:39.58[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512053914: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023565313816070557, 'time_algorithm_update': 0.005153358221054077, 'loss': 2.210077054917812, 'time_step': 0.0075721583366394046, 'init_value': 11.845611572265625}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-12 05:40.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512053914: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023463711738586426, 'time_algorithm_update': 0.005236125469207763, 'loss': 2.1230935989022255, 'time_step': 0.007645649909973145, 'init_value': 19.0736026763916}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-12 05:40.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512053914: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023751280307769775, 'time_algorithm_update': 0.005196853399276734, 'loss': 1.923743282198906, 'time_step': 0.0076351256370544435, 'init_value': 26.03704261779785}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-12 05:41.04[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512053914: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002339150905609131, 'time_algorithm_update': 0.005177491426467896, 'loss': 1.7745820476412772, 'time_step': 0.007578822374343872, 'init_value': 30.56044578552246}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-12 05:41.26[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512053914: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023768088817596434, 'time_algorithm_update': 0.00510459303855896, 'loss': 1.7270724437236786, 'time_step': 0.00754265546798706, 'init_value': 32.786865234375}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-12 05:41.48[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512053914: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002372781753540039, 'time_algorithm_update': 0.005267083168029785, 'loss': 1.6338917006850242, 'time_step': 0.00770330262184143, 'init_value': 36.9698486328125}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-12 05:42.10[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512053914: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023411362171173095, 'time_algorithm_update': 0.005246472120285034, 'loss': 1.7036179316043853, 'time_step': 0.007650421619415283, 'init_value': 38.669124603271484}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-12 05:42.32[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512053914: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023869144916534423, 'time_algorithm_update': 0.005163097620010376, 'loss': 1.5968966658115387, 'time_step': 0.007612196683883667, 'init_value': 41.49941635131836}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-12 05:42.54[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512053914: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002335444211959839, 'time_algorithm_update': 0.00506320834159851, 'loss': 1.600991891503334, 'time_step': 0.0074596812725067135, 'init_value': 43.09574890136719}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 43.09574890136719
Starting 1000 evaluations
avg return on 3 trajectories of agent14: 1108.8292782877782
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-12 06:00.06[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-12 06:00.06[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-12 06:00.07[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-12 06:00.07[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-12 06:00.07[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250512060007[0m
[2m2025-05-12 06:00.07[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-12 06:00.28[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512060007: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023083322048187255, 'time_algorithm_update': 0.0050285859107971195, 'loss': 1.5184912581294776, 'time_step': 0.007397927045822143, 'init_value': 4.341669082641602}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-12 06:00.50[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512060007: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002310659646987915, 'time_algorithm_update': 0.0049756581783294675, 'loss': 2.21721776843071, 'time_step': 0.00734585428237915, 'init_value': 11.260601997375488}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-12 06:01.12[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512060007: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023385083675384524, 'time_algorithm_update': 0.005205985546112061, 'loss': 2.104591494858265, 'time_step': 0.00760752010345459, 'init_value': 18.745115280151367}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-12 06:01.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512060007: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002390301465988159, 'time_algorithm_update': 0.0052546758651733395, 'loss': 1.9597191138863563, 'time_step': 0.007708433628082275, 'init_value': 26.16077995300293}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-12 06:01.56[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512060007: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002331352949142456, 'time_algorithm_update': 0.005157437801361084, 'loss': 1.8386992351412774, 'time_step': 0.0075508511066436764, 'init_value': 30.287830352783203}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-12 06:02.18[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512060007: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023739111423492433, 'time_algorithm_update': 0.0051104736328125, 'loss': 1.7696210901141167, 'time_step': 0.007546683311462402, 'init_value': 33.24824142456055}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-12 06:02.40[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512060007: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00236080527305603, 'time_algorithm_update': 0.005315483570098877, 'loss': 1.7101990198493005, 'time_step': 0.0077410354614257815, 'init_value': 35.53319549560547}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-12 06:03.02[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512060007: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023429529666900636, 'time_algorithm_update': 0.005193686485290528, 'loss': 1.5741385061740876, 'time_step': 0.007599542856216431, 'init_value': 37.04021453857422}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-12 06:03.24[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512060007: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002380290746688843, 'time_algorithm_update': 0.005243443250656128, 'loss': 1.5777569143772125, 'time_step': 0.007687088012695313, 'init_value': 38.44408416748047}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-12 06:03.45[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512060007: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002326238393783569, 'time_algorithm_update': 0.005010607004165649, 'loss': 1.601219169318676, 'time_step': 0.007396886825561524, 'init_value': 40.24993133544922}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.24993133544922
Starting 1000 evaluations
avg return on 3 trajectories of agent15: 1096.4599798775148
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-12 06:21.01[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-12 06:21.01[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-12 06:21.02[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-12 06:21.02[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-12 06:21.02[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250512062102[0m
[2m2025-05-12 06:21.02[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-12 06:21.23[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512062102: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002312363147735596, 'time_algorithm_update': 0.004951822519302368, 'loss': 1.6072310998886823, 'time_step': 0.007323596715927124, 'init_value': 4.417461395263672}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-12 06:21.45[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512062102: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023944416046142577, 'time_algorithm_update': 0.005083865880966186, 'loss': 2.1527626651525495, 'time_step': 0.007539778470993042, 'init_value': 11.376253128051758}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-12 06:22.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512062102: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00235897421836853, 'time_algorithm_update': 0.005252916336059571, 'loss': 2.127221177101135, 'time_step': 0.007675785541534424, 'init_value': 18.711193084716797}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-12 06:22.29[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512062102: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002408179998397827, 'time_algorithm_update': 0.005294300556182861, 'loss': 2.02319470512867, 'time_step': 0.007766016483306885, 'init_value': 25.375858306884766}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-12 06:22.51[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512062102: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023355095386505126, 'time_algorithm_update': 0.0050363771915435795, 'loss': 1.9465761120915412, 'time_step': 0.00743229079246521, 'init_value': 29.517990112304688}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-12 06:23.12[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512062102: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002360168218612671, 'time_algorithm_update': 0.0051888759136199955, 'loss': 1.7897561983466148, 'time_step': 0.00761165452003479, 'init_value': 31.658870697021484}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-12 06:23.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512062102: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023785560131073, 'time_algorithm_update': 0.005193268775939942, 'loss': 1.765389466524124, 'time_step': 0.00763451623916626, 'init_value': 34.723602294921875}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-12 06:23.57[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512062102: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023730478286743163, 'time_algorithm_update': 0.005150982141494751, 'loss': 1.6209841358661652, 'time_step': 0.0075864832401275634, 'init_value': 37.590579986572266}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-12 06:24.19[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512062102: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023983850479125978, 'time_algorithm_update': 0.005222431421279907, 'loss': 1.7141424919962882, 'time_step': 0.00768341064453125, 'init_value': 39.94934844970703}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-12 06:24.41[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512062102: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023778982162475587, 'time_algorithm_update': 0.005327412843704224, 'loss': 1.659558324098587, 'time_step': 0.0077701699733734135, 'init_value': 40.1845817565918}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.1845817565918
Starting 1000 evaluations
avg return on 3 trajectories of agent16: 1147.1566062886845
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-12 06:41.58[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-12 06:41.58[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-12 06:41.59[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-12 06:41.59[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-12 06:41.59[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250512064159[0m
[2m2025-05-12 06:41.59[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-12 06:42.21[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512064159: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002310600519180298, 'time_algorithm_update': 0.005080783367156982, 'loss': 1.4324659764766694, 'time_step': 0.007452701330184937, 'init_value': 4.561375141143799}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-12 06:42.43[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512064159: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023933892250061037, 'time_algorithm_update': 0.00530025053024292, 'loss': 2.2188087517619133, 'time_step': 0.0077584669589996335, 'init_value': 11.034414291381836}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-12 06:43.04[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512064159: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023385396003723145, 'time_algorithm_update': 0.005105079174041748, 'loss': 2.161204758286476, 'time_step': 0.007505147695541382, 'init_value': 18.370853424072266}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-12 06:43.26[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512064159: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002382462739944458, 'time_algorithm_update': 0.005174321413040161, 'loss': 2.086232891857624, 'time_step': 0.007619120597839355, 'init_value': 24.67637062072754}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-12 06:43.49[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512064159: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002418567419052124, 'time_algorithm_update': 0.005431674957275391, 'loss': 1.8679366970658302, 'time_step': 0.00791535210609436, 'init_value': 29.01506996154785}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-12 06:44.11[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512064159: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023652670383453368, 'time_algorithm_update': 0.005411804676055908, 'loss': 1.798762786090374, 'time_step': 0.00784251093864441, 'init_value': 33.58110046386719}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-12 06:44.32[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512064159: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023389301300048826, 'time_algorithm_update': 0.005110605955123902, 'loss': 1.7071600435376166, 'time_step': 0.007511218786239624, 'init_value': 36.42369842529297}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-12 06:44.54[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512064159: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002347282886505127, 'time_algorithm_update': 0.00519433045387268, 'loss': 1.714891263127327, 'time_step': 0.007604424238204956, 'init_value': 38.39982604980469}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-12 06:45.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512064159: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002395440101623535, 'time_algorithm_update': 0.00519957160949707, 'loss': 1.7124479652643203, 'time_step': 0.00765739893913269, 'init_value': 39.33743667602539}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-12 06:45.39[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512064159: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002392359972000122, 'time_algorithm_update': 0.0054068567752838135, 'loss': 1.5326235674619675, 'time_step': 0.007864168643951416, 'init_value': 40.9795036315918}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.9795036315918
Starting 1000 evaluations
avg return on 3 trajectories of agent17: 1138.0930584556456
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-12 07:02.58[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-12 07:02.58[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-12 07:02.59[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-12 07:02.59[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-12 07:02.59[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250512070259[0m
[2m2025-05-12 07:02.59[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-12 07:03.21[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512070259: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002293945550918579, 'time_algorithm_update': 0.004941977500915527, 'loss': 1.5603125149235129, 'time_step': 0.007294930219650268, 'init_value': 4.275733947753906}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-12 07:03.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512070259: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023642261028289794, 'time_algorithm_update': 0.005029386043548584, 'loss': 2.1598888956308366, 'time_step': 0.007453805923461914, 'init_value': 10.571538925170898}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-12 07:04.04[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512070259: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023361876010894777, 'time_algorithm_update': 0.005208051204681397, 'loss': 2.1979438282847403, 'time_step': 0.007607115983963013, 'init_value': 18.853961944580078}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-12 07:04.26[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512070259: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002388378858566284, 'time_algorithm_update': 0.005256469488143921, 'loss': 2.0015396648049353, 'time_step': 0.00770839262008667, 'init_value': 25.82187843322754}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-12 07:04.48[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512070259: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023426992893218995, 'time_algorithm_update': 0.0051222162246704105, 'loss': 1.8582920657396316, 'time_step': 0.007525814056396484, 'init_value': 29.2291259765625}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-12 07:05.10[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512070259: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002349799871444702, 'time_algorithm_update': 0.0051459712982177734, 'loss': 1.834225004851818, 'time_step': 0.007557345628738403, 'init_value': 32.56901550292969}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-12 07:05.32[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512070259: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023917601108551026, 'time_algorithm_update': 0.0052719306945800785, 'loss': 1.6241470277905463, 'time_step': 0.007726814270019531, 'init_value': 36.17740249633789}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-12 07:05.54[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512070259: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023544921875, 'time_algorithm_update': 0.005193612813949585, 'loss': 1.7103199937939644, 'time_step': 0.007610485315322876, 'init_value': 38.505130767822266}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-12 07:06.16[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512070259: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00238743782043457, 'time_algorithm_update': 0.005149333238601684, 'loss': 1.6067362342476845, 'time_step': 0.007598996162414551, 'init_value': 40.6004524230957}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-12 07:06.38[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512070259: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002360074281692505, 'time_algorithm_update': 0.0052405686378479005, 'loss': 1.677050391793251, 'time_step': 0.007664201498031617, 'init_value': 43.480411529541016}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 43.480411529541016
Starting 1000 evaluations
avg return on 3 trajectories of agent18: 1121.6279846273692
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-12 07:23.56[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-12 07:23.56[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-12 07:23.57[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-12 07:23.57[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-12 07:23.57[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250512072357[0m
[2m2025-05-12 07:23.57[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-12 07:24.19[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512072357: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023484015464782714, 'time_algorithm_update': 0.005155825853347778, 'loss': 1.5406358159929514, 'time_step': 0.0075660560131073, 'init_value': 4.328294277191162}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-12 07:24.41[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512072357: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023574376106262206, 'time_algorithm_update': 0.005158832311630249, 'loss': 2.238445607662201, 'time_step': 0.007579114675521851, 'init_value': 11.278788566589355}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-12 07:25.03[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512072357: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00236946439743042, 'time_algorithm_update': 0.005073286533355713, 'loss': 2.247571346759796, 'time_step': 0.007503438234329224, 'init_value': 18.834205627441406}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-12 07:25.25[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512072357: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002391343355178833, 'time_algorithm_update': 0.005194153070449829, 'loss': 2.015313894927502, 'time_step': 0.007647388935089111, 'init_value': 24.630889892578125}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-12 07:25.47[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512072357: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002370968818664551, 'time_algorithm_update': 0.005298430919647217, 'loss': 1.8463716649413109, 'time_step': 0.007733491659164429, 'init_value': 29.2276668548584}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-12 07:26.09[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512072357: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023929030895233155, 'time_algorithm_update': 0.005192884683609009, 'loss': 1.8203475925922394, 'time_step': 0.007648756504058838, 'init_value': 32.99245834350586}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-12 07:26.31[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512072357: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023274705410003664, 'time_algorithm_update': 0.004968055486679077, 'loss': 1.7049600052833558, 'time_step': 0.007355652332305908, 'init_value': 34.943180084228516}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-12 07:26.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512072357: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002367036819458008, 'time_algorithm_update': 0.005207975387573242, 'loss': 1.6320836952924729, 'time_step': 0.007637860774993896, 'init_value': 38.30781173706055}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-12 07:27.15[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512072357: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00240838623046875, 'time_algorithm_update': 0.005354859590530395, 'loss': 1.6192881216406823, 'time_step': 0.007828147888183593, 'init_value': 41.035831451416016}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-12 07:27.37[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512072357: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002372443914413452, 'time_algorithm_update': 0.005217176914215088, 'loss': 1.695728641986847, 'time_step': 0.007652773141860962, 'init_value': 43.78849792480469}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 43.78849792480469
Starting 1000 evaluations
avg return on 3 trajectories of agent19: 1119.0801671758475
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-12 07:44.53[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-12 07:44.53[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-12 07:44.55[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-12 07:44.55[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-12 07:44.55[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250512074455[0m
[2m2025-05-12 07:44.55[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-12 07:45.16[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512074455: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023106486797332764, 'time_algorithm_update': 0.005144416332244873, 'loss': 1.705580395065248, 'time_step': 0.007517271757125855, 'init_value': 4.152687072753906}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-12 07:45.38[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512074455: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002350075960159302, 'time_algorithm_update': 0.005020487785339356, 'loss': 2.0759289265871046, 'time_step': 0.0074307632446289065, 'init_value': 10.747989654541016}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-12 07:46.00[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512074455: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002338941812515259, 'time_algorithm_update': 0.005207668066024781, 'loss': 2.1703695995807646, 'time_step': 0.007610256910324097, 'init_value': 18.274362564086914}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-12 07:46.22[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512074455: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002368624687194824, 'time_algorithm_update': 0.005266184568405151, 'loss': 1.948188560128212, 'time_step': 0.007698690414428711, 'init_value': 24.965320587158203}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-12 07:46.44[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512074455: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023414289951324465, 'time_algorithm_update': 0.0052400572299957275, 'loss': 1.9306999897360801, 'time_step': 0.007645161867141724, 'init_value': 29.477258682250977}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-12 07:47.06[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512074455: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002371540307998657, 'time_algorithm_update': 0.00505437159538269, 'loss': 1.8259377366304397, 'time_step': 0.007486701488494873, 'init_value': 32.745121002197266}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-12 07:47.28[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512074455: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023704268932342528, 'time_algorithm_update': 0.005308071851730347, 'loss': 1.611241117477417, 'time_step': 0.0077428631782531735, 'init_value': 35.49147033691406}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-12 07:47.50[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512074455: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002335892915725708, 'time_algorithm_update': 0.005122699499130249, 'loss': 1.6916929605603217, 'time_step': 0.0075199449062347415, 'init_value': 38.57074737548828}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-12 07:48.12[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512074455: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023747737407684324, 'time_algorithm_update': 0.005243969202041626, 'loss': 1.633633023917675, 'time_step': 0.007682536363601685, 'init_value': 40.32929611206055}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-12 07:48.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512074455: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002333280324935913, 'time_algorithm_update': 0.005106500148773193, 'loss': 1.7142350791692733, 'time_step': 0.007500994682312012, 'init_value': 42.21745300292969}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.21745300292969
ave advantage rew: 41.57430458068848, std: 1.155373833165407
avg cum rews: 1123.7584180569575, std: 27.36846640064049
Pearson correlation coefficient: 0.3279418889840751
Spearman correlation coefficient: 0.29022556390977444
Kendall Tau correlation coefficient: 0.2105263157894737
the best agent: 11, best agent cum rewards: 1170.8821720753424
1955
Starting to collect rollouts
Collecting rollouts: 10000/1000000
Collecting rollouts: 20000/1000000
Collecting rollouts: 30000/1000000
Collecting rollouts: 40000/1000000
Collecting rollouts: 50000/1000000
Collecting rollouts: 60000/1000000
Collecting rollouts: 70000/1000000
Collecting rollouts: 80000/1000000
Collecting rollouts: 90000/1000000
Collecting rollouts: 100000/1000000
Collecting rollouts: 110000/1000000
Collecting rollouts: 120000/1000000
Collecting rollouts: 130000/1000000
Collecting rollouts: 140000/1000000
Collecting rollouts: 150000/1000000
Collecting rollouts: 160000/1000000
Collecting rollouts: 170000/1000000
Collecting rollouts: 180000/1000000
Collecting rollouts: 190000/1000000
Collecting rollouts: 200000/1000000
Collecting rollouts: 210000/1000000
Collecting rollouts: 220000/1000000
Collecting rollouts: 230000/1000000
Collecting rollouts: 240000/1000000
Collecting rollouts: 250000/1000000
Collecting rollouts: 260000/1000000
Collecting rollouts: 270000/1000000
Collecting rollouts: 280000/1000000
Collecting rollouts: 290000/1000000
Collecting rollouts: 300000/1000000
Collecting rollouts: 310000/1000000
Collecting rollouts: 320000/1000000
Collecting rollouts: 330000/1000000
Collecting rollouts: 340000/1000000
Collecting rollouts: 350000/1000000
Collecting rollouts: 360000/1000000
Collecting rollouts: 370000/1000000
Collecting rollouts: 380000/1000000
Collecting rollouts: 390000/1000000
Collecting rollouts: 400000/1000000
Collecting rollouts: 410000/1000000
Collecting rollouts: 420000/1000000
Collecting rollouts: 430000/1000000
Collecting rollouts: 440000/1000000
Collecting rollouts: 450000/1000000
Collecting rollouts: 460000/1000000
Collecting rollouts: 470000/1000000
Collecting rollouts: 480000/1000000
Collecting rollouts: 490000/1000000
Collecting rollouts: 500000/1000000
Collecting rollouts: 510000/1000000
Collecting rollouts: 520000/1000000
Collecting rollouts: 530000/1000000
Collecting rollouts: 540000/1000000
Collecting rollouts: 550000/1000000
Collecting rollouts: 560000/1000000
Collecting rollouts: 570000/1000000
Collecting rollouts: 580000/1000000
Collecting rollouts: 590000/1000000
Collecting rollouts: 600000/1000000
Collecting rollouts: 610000/1000000
Collecting rollouts: 620000/1000000
Collecting rollouts: 630000/1000000
Collecting rollouts: 640000/1000000
Collecting rollouts: 650000/1000000
Collecting rollouts: 660000/1000000
Collecting rollouts: 670000/1000000
Collecting rollouts: 680000/1000000
Collecting rollouts: 690000/1000000
Collecting rollouts: 700000/1000000
Collecting rollouts: 710000/1000000
Collecting rollouts: 720000/1000000
Collecting rollouts: 730000/1000000
Collecting rollouts: 740000/1000000
Collecting rollouts: 750000/1000000
Collecting rollouts: 760000/1000000
Collecting rollouts: 770000/1000000
Collecting rollouts: 780000/1000000
Collecting rollouts: 790000/1000000
Collecting rollouts: 800000/1000000
Collecting rollouts: 810000/1000000
Collecting rollouts: 820000/1000000
Collecting rollouts: 830000/1000000
Collecting rollouts: 840000/1000000
Collecting rollouts: 850000/1000000
Collecting rollouts: 860000/1000000
Collecting rollouts: 870000/1000000
Collecting rollouts: 880000/1000000
Collecting rollouts: 890000/1000000
Collecting rollouts: 900000/1000000
Collecting rollouts: 910000/1000000
Collecting rollouts: 920000/1000000
Collecting rollouts: 930000/1000000
Collecting rollouts: 940000/1000000
Collecting rollouts: 950000/1000000
Collecting rollouts: 960000/1000000
Collecting rollouts: 970000/1000000
Collecting rollouts: 980000/1000000
Collecting rollouts: 990000/1000000
Collecting rollouts: 1000000/1000000
Replay buffer size:  (1000000, 105)
Replay buffer saved
---------------------------------
Searching empty space policies
(10, 11472)
(20, 11472)
(20, 11472)
Average distance of agents to nearest neighbors: 0.018559519126874455
Starting 1000 evaluations
avg return on 3 trajectories of agent0: 1194.4796839635806
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-12 08:26.00[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-12 08:26.00[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-12 08:26.01[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-12 08:26.01[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-12 08:26.01[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250512082601[0m
[2m2025-05-12 08:26.01[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-12 08:26.22[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512082601: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023342235088348387, 'time_algorithm_update': 0.005041763544082641, 'loss': 1.6265312831401826, 'time_step': 0.007437437534332275, 'init_value': 4.587740898132324}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-12 08:26.45[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512082601: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00241444730758667, 'time_algorithm_update': 0.00513246488571167, 'loss': 2.135000801384449, 'time_step': 0.007610188484191894, 'init_value': 11.947196960449219}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-12 08:27.06[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512082601: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023602988719940185, 'time_algorithm_update': 0.005152448415756226, 'loss': 2.2247620255351066, 'time_step': 0.007574826717376709, 'init_value': 18.990367889404297}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-12 08:27.28[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512082601: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023708653450012205, 'time_algorithm_update': 0.005181213617324829, 'loss': 2.0467580611109732, 'time_step': 0.007614733219146729, 'init_value': 25.069459915161133}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-12 08:27.50[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512082601: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00236857533454895, 'time_algorithm_update': 0.005011769771575927, 'loss': 1.9041929514408111, 'time_step': 0.007440467357635498, 'init_value': 29.945953369140625}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-12 08:28.12[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512082601: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023741624355316164, 'time_algorithm_update': 0.0051662917137145995, 'loss': 1.8571206687688828, 'time_step': 0.007602841854095459, 'init_value': 33.666587829589844}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-12 08:28.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512082601: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0024077601432800294, 'time_algorithm_update': 0.0050596179962158205, 'loss': 1.7412260918021203, 'time_step': 0.007528881549835205, 'init_value': 36.12312698364258}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-12 08:28.56[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512082601: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002381910800933838, 'time_algorithm_update': 0.005265851259231567, 'loss': 1.6772315031290055, 'time_step': 0.007712026119232177, 'init_value': 37.95357894897461}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-12 08:29.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512082601: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023755879402160645, 'time_algorithm_update': 0.005004393815994263, 'loss': 1.5618834417462348, 'time_step': 0.007440351009368897, 'init_value': 39.20387649536133}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-12 08:29.39[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512082601: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023987898826599123, 'time_algorithm_update': 0.00517183780670166, 'loss': 1.5896187866330147, 'time_step': 0.007632899045944214, 'init_value': 40.2735710144043}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.2735710144043
Starting 1000 evaluations
avg return on 3 trajectories of agent1: 1168.3811075795545
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-12 08:46.45[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-12 08:46.45[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-12 08:46.47[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-12 08:46.47[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-12 08:46.47[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250512084647[0m
[2m2025-05-12 08:46.47[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-12 08:47.08[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512084647: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023323962688446046, 'time_algorithm_update': 0.0049597184658050535, 'loss': 1.7019627054482698, 'time_step': 0.007351707220077514, 'init_value': 4.218172073364258}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-12 08:47.30[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512084647: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0024082558155059815, 'time_algorithm_update': 0.005116383790969849, 'loss': 2.1798581728339195, 'time_step': 0.007587098836898803, 'init_value': 10.18770694732666}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-12 08:47.51[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512084647: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023201639652252197, 'time_algorithm_update': 0.0048623402118682865, 'loss': 2.0933717784285544, 'time_step': 0.007241313934326172, 'init_value': 17.537206649780273}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-12 08:48.13[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512084647: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002424014091491699, 'time_algorithm_update': 0.005309720993041992, 'loss': 2.0841481153965, 'time_step': 0.007799119472503662, 'init_value': 23.741865158081055}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-12 08:48.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512084647: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002347703218460083, 'time_algorithm_update': 0.004989216804504395, 'loss': 1.9662036160230636, 'time_step': 0.007397274255752564, 'init_value': 28.00372886657715}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-12 08:48.56[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512084647: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00236926531791687, 'time_algorithm_update': 0.005201816558837891, 'loss': 1.7711324167847633, 'time_step': 0.007634461641311646, 'init_value': 31.66875648498535}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-12 08:49.18[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512084647: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023880188465118407, 'time_algorithm_update': 0.00507192587852478, 'loss': 1.7684289836883544, 'time_step': 0.007540156602859497, 'init_value': 34.37043762207031}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-12 08:49.41[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512084647: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002389777660369873, 'time_algorithm_update': 0.005299556732177735, 'loss': 1.6800445611476897, 'time_step': 0.007753942489624023, 'init_value': 36.881099700927734}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-12 08:50.02[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512084647: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002379633903503418, 'time_algorithm_update': 0.004974618434906006, 'loss': 1.6392188130021095, 'time_step': 0.007414633512496948, 'init_value': 38.580989837646484}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-12 08:50.23[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512084647: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023573696613311767, 'time_algorithm_update': 0.00511904501914978, 'loss': 1.5161395635604857, 'time_step': 0.007538836240768432, 'init_value': 40.005340576171875}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.005340576171875
Starting 1000 evaluations
avg return on 3 trajectories of agent2: 1144.25747300248
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-12 09:07.30[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-12 09:07.30[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-12 09:07.32[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-12 09:07.32[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-12 09:07.32[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250512090732[0m
[2m2025-05-12 09:07.32[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-12 09:07.54[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512090732: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002314410924911499, 'time_algorithm_update': 0.005049315452575684, 'loss': 1.686121712639928, 'time_step': 0.00742517375946045, 'init_value': 4.325835227966309}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-12 09:08.15[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512090732: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002322514533996582, 'time_algorithm_update': 0.005087449312210083, 'loss': 2.223816652059555, 'time_step': 0.0074715371131896975, 'init_value': 11.166998863220215}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-12 09:08.37[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512090732: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023156256675720215, 'time_algorithm_update': 0.005026841878890991, 'loss': 2.1551812692284584, 'time_step': 0.007403485059738159, 'init_value': 17.80226707458496}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-12 09:08.59[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512090732: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023964142799377443, 'time_algorithm_update': 0.005150625228881836, 'loss': 2.084425990819931, 'time_step': 0.007609182119369507, 'init_value': 24.711288452148438}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-12 09:09.21[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512090732: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002328433275222778, 'time_algorithm_update': 0.005043958425521851, 'loss': 1.8674072914719582, 'time_step': 0.00743358039855957, 'init_value': 29.70477867126465}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-12 09:09.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512090732: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023752076625823976, 'time_algorithm_update': 0.005247401237487793, 'loss': 1.7707358992099762, 'time_step': 0.007686381101608276, 'init_value': 34.270381927490234}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-12 09:10.04[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512090732: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023270163536071777, 'time_algorithm_update': 0.005022971153259277, 'loss': 1.8486257634162904, 'time_step': 0.007410826206207276, 'init_value': 35.15639114379883}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-12 09:10.26[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512090732: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023912353515625, 'time_algorithm_update': 0.0052150883674621585, 'loss': 1.7148827019929886, 'time_step': 0.007669976472854614, 'init_value': 36.88962936401367}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-12 09:10.48[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512090732: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023648929595947265, 'time_algorithm_update': 0.005131130933761597, 'loss': 1.623985664665699, 'time_step': 0.007557636022567749, 'init_value': 39.11920166015625}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-12 09:11.10[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512090732: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023393774032592772, 'time_algorithm_update': 0.005110924482345581, 'loss': 1.6062709270715714, 'time_step': 0.007512503623962402, 'init_value': 40.65254592895508}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.65254592895508
Starting 1000 evaluations
avg return on 3 trajectories of agent3: 1112.1893629993256
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-12 09:28.09[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-12 09:28.09[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-12 09:28.10[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-12 09:28.10[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-12 09:28.10[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250512092810[0m
[2m2025-05-12 09:28.10[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-12 09:28.32[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512092810: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023122496604919434, 'time_algorithm_update': 0.005006845712661743, 'loss': 1.605863479219377, 'time_step': 0.007379678010940552, 'init_value': 4.985299110412598}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-12 09:28.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512092810: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002346554756164551, 'time_algorithm_update': 0.005009991407394409, 'loss': 2.2536896017193793, 'time_step': 0.00741758131980896, 'init_value': 11.812422752380371}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-12 09:29.15[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512092810: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002340756177902222, 'time_algorithm_update': 0.005088529109954834, 'loss': 2.2341077615618707, 'time_step': 0.007491308927536011, 'init_value': 19.82594871520996}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-12 09:29.37[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512092810: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0024040844440460203, 'time_algorithm_update': 0.005192432641983032, 'loss': 1.9529348365664483, 'time_step': 0.007659793615341187, 'init_value': 25.519084930419922}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-12 09:29.59[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512092810: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023335182666778566, 'time_algorithm_update': 0.00497470474243164, 'loss': 1.8059284202456474, 'time_step': 0.0073685159683227535, 'init_value': 29.079919815063477}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-12 09:30.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512092810: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023792009353637697, 'time_algorithm_update': 0.005062058925628662, 'loss': 1.83679058355093, 'time_step': 0.007502913475036621, 'init_value': 33.28199768066406}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-12 09:30.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512092810: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023468706607818603, 'time_algorithm_update': 0.005090299367904663, 'loss': 1.7835993876457215, 'time_step': 0.007499594688415528, 'init_value': 35.66525650024414}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-12 09:31.04[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512092810: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002390395164489746, 'time_algorithm_update': 0.005216063022613526, 'loss': 1.5532775024175645, 'time_step': 0.0076702418327331545, 'init_value': 37.54052734375}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-12 09:31.26[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512092810: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023708484172821043, 'time_algorithm_update': 0.005080836772918701, 'loss': 1.6916767761707305, 'time_step': 0.007513609409332276, 'init_value': 39.92580795288086}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-12 09:31.48[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512092810: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023384718894958498, 'time_algorithm_update': 0.004988187789916992, 'loss': 1.5864292042255401, 'time_step': 0.007387595891952515, 'init_value': 41.00083923339844}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.00083923339844
Starting 1000 evaluations
avg return on 3 trajectories of agent4: 1198.9181723553015
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-12 09:48.57[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-12 09:48.57[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-12 09:48.58[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-12 09:48.58[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-12 09:48.58[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250512094858[0m
[2m2025-05-12 09:48.58[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-12 09:49.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512094858: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023103580474853514, 'time_algorithm_update': 0.00487098240852356, 'loss': 1.7294838917329907, 'time_step': 0.007240274906158447, 'init_value': 5.051967144012451}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-12 09:49.41[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512094858: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023876914978027343, 'time_algorithm_update': 0.005042632102966308, 'loss': 2.3125159360170366, 'time_step': 0.007492114782333374, 'init_value': 11.80929183959961}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-12 09:50.03[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512094858: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002289116144180298, 'time_algorithm_update': 0.004774246215820312, 'loss': 2.190818918168545, 'time_step': 0.007121087551116944, 'init_value': 18.540639877319336}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-12 09:50.25[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512094858: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002390796661376953, 'time_algorithm_update': 0.005299705982208252, 'loss': 2.1057798399329184, 'time_step': 0.007754862308502197, 'init_value': 25.4928035736084}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-12 09:50.47[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512094858: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023918204307556154, 'time_algorithm_update': 0.005101046800613403, 'loss': 1.9359499300718308, 'time_step': 0.007553895473480224, 'init_value': 30.437166213989258}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-12 09:51.09[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512094858: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023469126224517824, 'time_algorithm_update': 0.005009690046310425, 'loss': 1.744697695016861, 'time_step': 0.007417407274246216, 'init_value': 33.48811340332031}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-12 09:51.30[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512094858: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023337135314941406, 'time_algorithm_update': 0.005057729959487915, 'loss': 1.6539164927601815, 'time_step': 0.00745283317565918, 'init_value': 35.5606575012207}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-12 09:51.52[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512094858: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023458733558654786, 'time_algorithm_update': 0.005266082763671875, 'loss': 1.6018591657876968, 'time_step': 0.0076761188507080075, 'init_value': 37.50075912475586}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-12 09:52.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512094858: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023931632041931153, 'time_algorithm_update': 0.005089724063873291, 'loss': 1.6262690474390984, 'time_step': 0.007544894695281982, 'init_value': 40.29192352294922}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-12 09:52.36[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512094858: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002384634256362915, 'time_algorithm_update': 0.005064216613769532, 'loss': 1.600267291367054, 'time_step': 0.0075120642185211185, 'init_value': 41.60459518432617}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.60459518432617
Starting 1000 evaluations
avg return on 3 trajectories of agent5: 1170.2965436948189
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-12 10:09.37[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-12 10:09.37[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-12 10:09.39[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-12 10:09.39[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-12 10:09.39[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250512100939[0m
[2m2025-05-12 10:09.39[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-12 10:10.00[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512100939: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002305891275405884, 'time_algorithm_update': 0.004843319654464722, 'loss': 1.5932685465067624, 'time_step': 0.007207122802734375, 'init_value': 4.31108283996582}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-12 10:10.22[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512100939: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023862202167510985, 'time_algorithm_update': 0.005146860599517822, 'loss': 2.254423995912075, 'time_step': 0.007595797061920166, 'init_value': 11.06215763092041}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-12 10:10.44[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512100939: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00236901068687439, 'time_algorithm_update': 0.0050742428302764896, 'loss': 2.1761051974892616, 'time_step': 0.0075050780773162845, 'init_value': 18.669307708740234}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-12 10:11.06[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512100939: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0024087815284729005, 'time_algorithm_update': 0.00522481369972229, 'loss': 2.075274515211582, 'time_step': 0.00769657826423645, 'init_value': 25.77318572998047}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-12 10:11.28[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512100939: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023325912952423095, 'time_algorithm_update': 0.005105194807052613, 'loss': 1.971646271467209, 'time_step': 0.007498859882354736, 'init_value': 30.751619338989258}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-12 10:11.50[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512100939: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0024217162132263185, 'time_algorithm_update': 0.005253771781921387, 'loss': 1.8097970681190492, 'time_step': 0.007739645957946777, 'init_value': 34.86077880859375}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-12 10:12.12[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512100939: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002370785713195801, 'time_algorithm_update': 0.004962702274322509, 'loss': 1.6858407948613168, 'time_step': 0.007393063306808472, 'init_value': 37.4482307434082}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-12 10:12.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512100939: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023856115341186522, 'time_algorithm_update': 0.0052531142234802245, 'loss': 1.5676905713677407, 'time_step': 0.007702589988708496, 'init_value': 39.481109619140625}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-12 10:12.56[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512100939: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0024027104377746583, 'time_algorithm_update': 0.005075955629348755, 'loss': 1.6251215611696244, 'time_step': 0.007539918184280395, 'init_value': 40.49629211425781}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-12 10:13.18[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512100939: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002367058515548706, 'time_algorithm_update': 0.005232041597366333, 'loss': 1.5593544977307319, 'time_step': 0.0076628212928771975, 'init_value': 42.30184555053711}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.30184555053711
Starting 1000 evaluations
avg return on 3 trajectories of agent6: 1147.4275533410087
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-12 10:30.25[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-12 10:30.25[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-12 10:30.27[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-12 10:30.27[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-12 10:30.27[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250512103027[0m
[2m2025-05-12 10:30.27[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-12 10:30.48[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512103027: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002305027484893799, 'time_algorithm_update': 0.004949815273284912, 'loss': 1.8404738848507405, 'time_step': 0.007314761638641357, 'init_value': 4.769697666168213}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-12 10:31.09[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512103027: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00232173490524292, 'time_algorithm_update': 0.004994540691375732, 'loss': 2.3382458750009536, 'time_step': 0.007376655817031861, 'init_value': 11.616463661193848}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-12 10:31.32[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512103027: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002341625690460205, 'time_algorithm_update': 0.005272153854370117, 'loss': 2.2352608105540277, 'time_step': 0.007677842617034912, 'init_value': 18.691436767578125}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-12 10:31.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512103027: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002381875038146973, 'time_algorithm_update': 0.005244230270385742, 'loss': 2.0072595962285997, 'time_step': 0.007689299345016479, 'init_value': 25.737600326538086}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-12 10:32.15[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512103027: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023278880119323732, 'time_algorithm_update': 0.005095129489898682, 'loss': 1.9291924264431, 'time_step': 0.007484169483184815, 'init_value': 30.963821411132812}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-12 10:32.37[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512103027: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002362204074859619, 'time_algorithm_update': 0.005004831314086914, 'loss': 1.777263808488846, 'time_step': 0.007427202463150024, 'init_value': 32.992618560791016}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-12 10:32.59[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512103027: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023599135875701904, 'time_algorithm_update': 0.005337230682373047, 'loss': 1.6722679003477097, 'time_step': 0.007761954545974731, 'init_value': 36.70732498168945}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-12 10:33.21[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512103027: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023410656452178954, 'time_algorithm_update': 0.00521474289894104, 'loss': 1.6435341742038727, 'time_step': 0.00761892580986023, 'init_value': 37.764320373535156}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-12 10:33.43[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512103027: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023340115547180176, 'time_algorithm_update': 0.004921316146850586, 'loss': 1.6635538793206215, 'time_step': 0.007314198255538941, 'init_value': 39.7367057800293}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-12 10:34.05[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512103027: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002340059757232666, 'time_algorithm_update': 0.005188608884811401, 'loss': 1.5781367559432984, 'time_step': 0.007591425657272339, 'init_value': 42.13869094848633}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.13869094848633
Starting 1000 evaluations
avg return on 3 trajectories of agent7: 1120.4794054328968
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-12 10:51.11[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-12 10:51.11[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-12 10:51.12[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-12 10:51.13[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-12 10:51.13[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250512105113[0m
[2m2025-05-12 10:51.13[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-12 10:51.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512105113: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023076372146606447, 'time_algorithm_update': 0.004958233118057251, 'loss': 1.6993231012821197, 'time_step': 0.007326417446136475, 'init_value': 4.337727069854736}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-12 10:51.56[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512105113: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023461511135101317, 'time_algorithm_update': 0.005106787443161011, 'loss': 2.4247028942108155, 'time_step': 0.00751605772972107, 'init_value': 11.274388313293457}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-12 10:52.18[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512105113: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023557553291320803, 'time_algorithm_update': 0.005142065286636352, 'loss': 2.0812806371450425, 'time_step': 0.0075604584217071535, 'init_value': 18.70364761352539}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-12 10:52.40[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512105113: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023131239414215087, 'time_algorithm_update': 0.004910308599472046, 'loss': 1.9926961405873298, 'time_step': 0.007283002614974976, 'init_value': 24.918453216552734}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-12 10:53.01[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512105113: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002379551410675049, 'time_algorithm_update': 0.005008311748504639, 'loss': 1.8996225476264954, 'time_step': 0.007448661327362061, 'init_value': 31.080997467041016}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-12 10:53.24[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512105113: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023734533786773683, 'time_algorithm_update': 0.005235134363174438, 'loss': 1.9836044299602509, 'time_step': 0.007672777652740478, 'init_value': 34.22311782836914}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-12 10:53.46[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512105113: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023994159698486326, 'time_algorithm_update': 0.005213011503219605, 'loss': 1.7035084307789803, 'time_step': 0.007675939083099366, 'init_value': 36.7897834777832}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-12 10:54.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512105113: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023347582817077636, 'time_algorithm_update': 0.005001127004623413, 'loss': 1.6121572458148004, 'time_step': 0.007396765470504761, 'init_value': 37.84473419189453}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-12 10:54.29[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512105113: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002379005670547485, 'time_algorithm_update': 0.0052242703437805176, 'loss': 1.6695825112462044, 'time_step': 0.007666987180709839, 'init_value': 38.52539825439453}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-12 10:54.52[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512105113: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0024090218544006348, 'time_algorithm_update': 0.005243170738220215, 'loss': 1.5585949615836143, 'time_step': 0.007716482400894165, 'init_value': 40.223873138427734}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.223873138427734
Starting 1000 evaluations
avg return on 3 trajectories of agent8: 1201.8342936803017
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-12 11:11.56[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-12 11:11.56[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-12 11:11.57[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-12 11:11.57[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-12 11:11.57[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250512111157[0m
[2m2025-05-12 11:11.57[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-12 11:12.19[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512111157: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023132386207580565, 'time_algorithm_update': 0.004997758388519287, 'loss': 1.5750577879622578, 'time_step': 0.007371557950973511, 'init_value': 4.4661688804626465}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-12 11:12.41[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512111157: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023985824584960938, 'time_algorithm_update': 0.005127351284027099, 'loss': 2.3450175671577456, 'time_step': 0.00758815050125122, 'init_value': 11.573659896850586}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-12 11:13.03[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512111157: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023437843322753906, 'time_algorithm_update': 0.005143889665603638, 'loss': 2.2234434672594072, 'time_step': 0.007550318241119385, 'init_value': 19.027254104614258}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-12 11:13.24[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512111157: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022865803241729735, 'time_algorithm_update': 0.004821936845779419, 'loss': 2.039184497952461, 'time_step': 0.007166542530059814, 'init_value': 24.847850799560547}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-12 11:13.46[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512111157: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002355856418609619, 'time_algorithm_update': 0.005326880216598511, 'loss': 1.9327768141031265, 'time_step': 0.007747559547424316, 'init_value': 30.485143661499023}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-12 11:14.09[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512111157: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023597333431243897, 'time_algorithm_update': 0.005177740573883057, 'loss': 1.8584294632673264, 'time_step': 0.007599993228912354, 'init_value': 33.33122253417969}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-12 11:14.30[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512111157: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002391824007034302, 'time_algorithm_update': 0.005218093872070313, 'loss': 1.7578420357108115, 'time_step': 0.007673890590667725, 'init_value': 36.389469146728516}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-12 11:14.51[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512111157: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002310936212539673, 'time_algorithm_update': 0.004823128700256348, 'loss': 1.782725986301899, 'time_step': 0.007193516969680786, 'init_value': 39.506290435791016}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-12 11:15.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512111157: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0024137043952941893, 'time_algorithm_update': 0.005332574367523193, 'loss': 1.6978369345664979, 'time_step': 0.007811769723892212, 'init_value': 41.98338317871094}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-12 11:15.36[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512111157: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002352961540222168, 'time_algorithm_update': 0.005242059707641602, 'loss': 1.611233317911625, 'time_step': 0.00765867018699646, 'init_value': 44.915794372558594}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 44.915794372558594
Starting 1000 evaluations
avg return on 3 trajectories of agent9: 1196.320753572781
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-12 11:32.54[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-12 11:32.54[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-12 11:32.55[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-12 11:32.55[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-12 11:32.55[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250512113255[0m
[2m2025-05-12 11:32.55[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-12 11:33.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512113255: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023370540142059327, 'time_algorithm_update': 0.004983213901519776, 'loss': 1.6346602710410953, 'time_step': 0.007380733728408814, 'init_value': 5.0142974853515625}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-12 11:33.39[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512113255: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002411271333694458, 'time_algorithm_update': 0.0051139483451843265, 'loss': 2.193631632447243, 'time_step': 0.007588204860687256, 'init_value': 11.990728378295898}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-12 11:34.00[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512113255: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002332296133041382, 'time_algorithm_update': 0.004880906343460083, 'loss': 2.1929669317603113, 'time_step': 0.007272399187088012, 'init_value': 18.282337188720703}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-12 11:34.22[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512113255: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023968408107757568, 'time_algorithm_update': 0.005098354339599609, 'loss': 2.006183537185192, 'time_step': 0.0075570249557495115, 'init_value': 24.43144989013672}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-12 11:34.44[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512113255: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002402822971343994, 'time_algorithm_update': 0.005181807279586792, 'loss': 1.9930886704921722, 'time_step': 0.007648394823074341, 'init_value': 28.26314353942871}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-12 11:35.06[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512113255: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002372941493988037, 'time_algorithm_update': 0.005043310165405273, 'loss': 1.7803727925419808, 'time_step': 0.007478138208389282, 'init_value': 32.9719123840332}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-12 11:35.28[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512113255: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002397560119628906, 'time_algorithm_update': 0.004959882974624634, 'loss': 1.7351454372406006, 'time_step': 0.007418189287185669, 'init_value': 34.56468963623047}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-12 11:35.50[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512113255: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023613295555114746, 'time_algorithm_update': 0.0050577189922332766, 'loss': 1.6325134345293044, 'time_step': 0.007481043338775635, 'init_value': 36.99837875366211}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-12 11:36.12[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512113255: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002402194023132324, 'time_algorithm_update': 0.005214876890182495, 'loss': 1.5459539315104485, 'time_step': 0.007681241750717163, 'init_value': 39.555843353271484}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-12 11:36.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512113255: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0024046988487243653, 'time_algorithm_update': 0.005115925312042236, 'loss': 1.5098787637352944, 'time_step': 0.007583329439163208, 'init_value': 40.48316192626953}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.48316192626953
Starting 1000 evaluations
avg return on 3 trajectories of agent10: 1197.2311519136904
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-12 11:53.44[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-12 11:53.44[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-12 11:53.46[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-12 11:53.46[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-12 11:53.46[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250512115346[0m
[2m2025-05-12 11:53.46[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-12 11:54.08[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512115346: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023090555667877196, 'time_algorithm_update': 0.00504260516166687, 'loss': 1.5792429079040884, 'time_step': 0.00741324782371521, 'init_value': 4.767525672912598}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-12 11:54.30[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512115346: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023279035091400145, 'time_algorithm_update': 0.005183162689208984, 'loss': 2.2540423480272294, 'time_step': 0.0075823266506195065, 'init_value': 11.756400108337402}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-12 11:54.51[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512115346: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002315408229827881, 'time_algorithm_update': 0.004922199249267578, 'loss': 2.1982429447770118, 'time_step': 0.00729674243927002, 'init_value': 19.82014274597168}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-12 11:55.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512115346: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002383404016494751, 'time_algorithm_update': 0.005147818565368652, 'loss': 1.9799206349253655, 'time_step': 0.0075931308269500735, 'init_value': 26.054906845092773}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-12 11:55.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512115346: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002350696325302124, 'time_algorithm_update': 0.0050261027812957765, 'loss': 1.8233988575935365, 'time_step': 0.007437455415725708, 'init_value': 31.029762268066406}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-12 11:55.57[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512115346: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023493149280548096, 'time_algorithm_update': 0.005244900941848755, 'loss': 1.7517117067575454, 'time_step': 0.007657856225967407, 'init_value': 34.986351013183594}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-12 11:56.19[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512115346: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002372854471206665, 'time_algorithm_update': 0.005084120988845825, 'loss': 1.7430866737365722, 'time_step': 0.007518404245376587, 'init_value': 37.33595657348633}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-12 11:56.41[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512115346: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023472135066986083, 'time_algorithm_update': 0.005252147674560547, 'loss': 1.8065749638080597, 'time_step': 0.007663131237030029, 'init_value': 39.60478973388672}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-12 11:57.03[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512115346: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023432202339172363, 'time_algorithm_update': 0.00511833667755127, 'loss': 1.6064278483390808, 'time_step': 0.007523902893066406, 'init_value': 40.14866256713867}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-12 11:57.25[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512115346: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023762142658233644, 'time_algorithm_update': 0.005227566242218018, 'loss': 1.5794545270204543, 'time_step': 0.007667313575744629, 'init_value': 41.7071647644043}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.7071647644043
Starting 1000 evaluations
avg return on 3 trajectories of agent11: 1198.3672321890042
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-12 12:14.25[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-12 12:14.25[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-12 12:14.27[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-12 12:14.27[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-12 12:14.27[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250512121427[0m
[2m2025-05-12 12:14.27[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-12 12:14.48[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512121427: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022883598804473875, 'time_algorithm_update': 0.004964917898178101, 'loss': 1.1767663612142205, 'time_step': 0.007313590049743652, 'init_value': 4.52821159362793}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-12 12:15.10[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512121427: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023220009803771972, 'time_algorithm_update': 0.004966864347457886, 'loss': 2.0714947019219396, 'time_step': 0.007349268198013305, 'init_value': 11.752577781677246}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-12 12:15.31[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512121427: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023207905292510988, 'time_algorithm_update': 0.005111073970794678, 'loss': 2.2124911521077157, 'time_step': 0.0074943344593048095, 'init_value': 18.989765167236328}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-12 12:15.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512121427: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002327575922012329, 'time_algorithm_update': 0.005079124927520752, 'loss': 2.0098551079034803, 'time_step': 0.00746867823600769, 'init_value': 25.8328800201416}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-12 12:16.15[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512121427: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023907372951507567, 'time_algorithm_update': 0.005217914342880249, 'loss': 1.8199427284002303, 'time_step': 0.007672291278839111, 'init_value': 29.737682342529297}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-12 12:16.37[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512121427: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002321598768234253, 'time_algorithm_update': 0.005021362066268921, 'loss': 1.7146608074307441, 'time_step': 0.00740378737449646, 'init_value': 32.65037155151367}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-12 12:16.59[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512121427: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023567051887512206, 'time_algorithm_update': 0.005024470090866089, 'loss': 1.5816929638385773, 'time_step': 0.007443012475967408, 'init_value': 34.90594482421875}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-12 12:17.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512121427: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023374943733215333, 'time_algorithm_update': 0.005111712694168091, 'loss': 1.5950615507364274, 'time_step': 0.007511050701141358, 'init_value': 36.839019775390625}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-12 12:17.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512121427: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023730716705322266, 'time_algorithm_update': 0.005201296091079712, 'loss': 1.5926631631851196, 'time_step': 0.007637702465057373, 'init_value': 38.96907424926758}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-12 12:18.04[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512121427: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002320662260055542, 'time_algorithm_update': 0.004927053213119507, 'loss': 1.5690063620209693, 'time_step': 0.007307163953781128, 'init_value': 42.3460807800293}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.3460807800293
Starting 1000 evaluations
avg return on 3 trajectories of agent12: 1205.0580723506562
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-12 12:35.02[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-12 12:35.02[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-12 12:35.03[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-12 12:35.03[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-12 12:35.03[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250512123503[0m
[2m2025-05-12 12:35.03[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-12 12:35.24[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512123503: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002277658462524414, 'time_algorithm_update': 0.004901713132858277, 'loss': 1.5321090203523635, 'time_step': 0.007238089323043823, 'init_value': 4.8250322341918945}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-12 12:35.45[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512123503: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002235527276992798, 'time_algorithm_update': 0.004677260160446167, 'loss': 2.224471789419651, 'time_step': 0.0069694027900695805, 'init_value': 11.45952320098877}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-12 12:36.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512123503: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023519296646118165, 'time_algorithm_update': 0.005141807317733765, 'loss': 2.108389237165451, 'time_step': 0.007555502414703369, 'init_value': 19.40786361694336}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-12 12:36.29[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512123503: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023665382862091064, 'time_algorithm_update': 0.00517660140991211, 'loss': 1.9880029585957528, 'time_step': 0.007605995416641235, 'init_value': 25.240928649902344}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-12 12:36.50[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512123503: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022861063480377197, 'time_algorithm_update': 0.00491738224029541, 'loss': 1.8214763311743736, 'time_step': 0.007262174844741821, 'init_value': 30.083694458007812}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-12 12:37.11[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512123503: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022924997806549074, 'time_algorithm_update': 0.004809866189956665, 'loss': 1.7559910134673118, 'time_step': 0.007160322427749634, 'init_value': 32.821510314941406}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-12 12:37.33[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512123503: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023339738845825197, 'time_algorithm_update': 0.005192155361175537, 'loss': 1.7599041536450386, 'time_step': 0.007588836431503296, 'init_value': 35.91019058227539}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-12 12:37.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512123503: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002362668752670288, 'time_algorithm_update': 0.005146710634231567, 'loss': 1.6981940116882324, 'time_step': 0.007571075439453125, 'init_value': 38.16952133178711}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-12 12:38.15[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512123503: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023097734451293945, 'time_algorithm_update': 0.004923745632171631, 'loss': 1.643805878996849, 'time_step': 0.0072924203872680666, 'init_value': 40.555931091308594}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-12 12:38.37[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512123503: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002306124210357666, 'time_algorithm_update': 0.00493623423576355, 'loss': 1.6045526113510131, 'time_step': 0.007301738023757934, 'init_value': 41.50119400024414}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.50119400024414
Starting 1000 evaluations
avg return on 3 trajectories of agent13: 1206.9446311081228
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-12 12:55.29[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-12 12:55.29[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-12 12:55.31[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-12 12:55.31[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-12 12:55.31[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250512125531[0m
[2m2025-05-12 12:55.31[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-12 12:55.51[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512125531: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022772395610809325, 'time_algorithm_update': 0.004838023900985718, 'loss': 1.4906501761749387, 'time_step': 0.007174165487289429, 'init_value': 4.603304386138916}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-12 12:56.13[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512125531: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023058195114135744, 'time_algorithm_update': 0.005047518491744995, 'loss': 2.247966453552246, 'time_step': 0.007414886236190796, 'init_value': 12.01706600189209}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-12 12:56.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512125531: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023224680423736574, 'time_algorithm_update': 0.0051426842212677, 'loss': 2.169632476747036, 'time_step': 0.007526841163635254, 'init_value': 18.882001876831055}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-12 12:56.56[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512125531: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002302357912063599, 'time_algorithm_update': 0.004929713487625122, 'loss': 2.0555065029859545, 'time_step': 0.007290922403335572, 'init_value': 25.07651138305664}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-12 12:57.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512125531: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002308790683746338, 'time_algorithm_update': 0.005018378973007202, 'loss': 1.790369214117527, 'time_step': 0.007387642860412598, 'init_value': 29.333316802978516}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-12 12:57.39[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512125531: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002375360727310181, 'time_algorithm_update': 0.005134135007858276, 'loss': 1.719564701318741, 'time_step': 0.007571929216384888, 'init_value': 32.61355972290039}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-12 12:58.01[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512125531: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023310141563415527, 'time_algorithm_update': 0.005130139827728272, 'loss': 1.7096516574621201, 'time_step': 0.007523040533065796, 'init_value': 33.77811050415039}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-12 12:58.22[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512125531: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023007910251617433, 'time_algorithm_update': 0.004922764301300049, 'loss': 1.6888662858605386, 'time_step': 0.007283143281936646, 'init_value': 35.371917724609375}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-12 12:58.44[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512125531: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023524587154388427, 'time_algorithm_update': 0.005180124044418335, 'loss': 1.6864863409996034, 'time_step': 0.007595437526702881, 'init_value': 38.51736068725586}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-12 12:59.06[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512125531: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023259291648864747, 'time_algorithm_update': 0.005085224390029907, 'loss': 1.616916730761528, 'time_step': 0.007473036289215088, 'init_value': 40.73896789550781}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.73896789550781
Starting 1000 evaluations
avg return on 3 trajectories of agent14: 1204.6420801687232
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-12 13:15.53[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-12 13:15.53[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-12 13:15.54[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-12 13:15.54[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-12 13:15.54[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250512131554[0m
[2m2025-05-12 13:15.54[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-12 13:16.15[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512131554: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022605633735656738, 'time_algorithm_update': 0.004879875659942627, 'loss': 1.5046689006015659, 'time_step': 0.007199373722076416, 'init_value': 4.557119369506836}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-12 13:16.36[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512131554: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023397905826568603, 'time_algorithm_update': 0.005007225751876831, 'loss': 2.1836040850877763, 'time_step': 0.007407732009887695, 'init_value': 11.136393547058105}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-12 13:16.58[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512131554: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022746288776397706, 'time_algorithm_update': 0.00491257905960083, 'loss': 2.19184647500515, 'time_step': 0.007246929407119751, 'init_value': 18.335464477539062}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-12 13:17.19[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512131554: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023143641948699953, 'time_algorithm_update': 0.004981550931930542, 'loss': 2.234926774978638, 'time_step': 0.0073562033176422115, 'init_value': 26.08392333984375}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-12 13:17.41[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512131554: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022982757091522216, 'time_algorithm_update': 0.0051132128238677976, 'loss': 1.9577961434125901, 'time_step': 0.007473756551742553, 'init_value': 30.324491500854492}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-12 13:18.02[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512131554: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002298337697982788, 'time_algorithm_update': 0.0048251328468322755, 'loss': 1.8247749226093293, 'time_step': 0.007182045936584473, 'init_value': 33.439571380615234}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-12 13:18.24[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512131554: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023353209495544434, 'time_algorithm_update': 0.005024914741516113, 'loss': 1.7794873408079148, 'time_step': 0.007420362234115601, 'init_value': 35.92399215698242}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-12 13:18.45[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512131554: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002311586141586304, 'time_algorithm_update': 0.005078027009963989, 'loss': 1.5839231197237968, 'time_step': 0.007451427936553955, 'init_value': 37.2079963684082}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-12 13:19.06[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512131554: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022992537021636963, 'time_algorithm_update': 0.005130689620971679, 'loss': 1.6219414544701576, 'time_step': 0.007492178916931152, 'init_value': 39.029056549072266}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-12 13:19.28[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512131554: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022801361083984377, 'time_algorithm_update': 0.004837862491607666, 'loss': 1.6527457887530326, 'time_step': 0.007176453828811645, 'init_value': 41.587249755859375}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.587249755859375
Starting 1000 evaluations
avg return on 3 trajectories of agent15: 1203.8922566909173
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-12 13:36.21[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-12 13:36.21[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-12 13:36.22[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-12 13:36.22[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-12 13:36.22[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250512133622[0m
[2m2025-05-12 13:36.22[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-12 13:36.43[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512133622: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002250846862792969, 'time_algorithm_update': 0.004797229051589966, 'loss': 1.4548813882395626, 'time_step': 0.007106173992156983, 'init_value': 4.685396194458008}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-12 13:37.05[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512133622: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023362610340118407, 'time_algorithm_update': 0.005127279281616211, 'loss': 2.235456737220287, 'time_step': 0.007525651693344116, 'init_value': 11.585200309753418}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-12 13:37.26[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512133622: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002293226718902588, 'time_algorithm_update': 0.005036872148513794, 'loss': 2.234114868402481, 'time_step': 0.007391638278961181, 'init_value': 19.01629066467285}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-12 13:37.47[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512133622: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023392295837402345, 'time_algorithm_update': 0.004980839729309082, 'loss': 2.0986193377375604, 'time_step': 0.007380582809448242, 'init_value': 26.03749656677246}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-12 13:38.08[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512133622: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002236037015914917, 'time_algorithm_update': 0.004754085302352906, 'loss': 1.92458412450552, 'time_step': 0.007047263622283936, 'init_value': 30.9025821685791}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-12 13:38.30[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512133622: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002342751979827881, 'time_algorithm_update': 0.005066236734390259, 'loss': 1.7494728385806084, 'time_step': 0.007470481157302857, 'init_value': 32.46245574951172}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-12 13:38.52[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512133622: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022904064655303955, 'time_algorithm_update': 0.004980185031890869, 'loss': 1.730283112347126, 'time_step': 0.00733095121383667, 'init_value': 35.84819412231445}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-12 13:39.12[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512133622: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023020293712615967, 'time_algorithm_update': 0.00507929539680481, 'loss': 1.5873677721619606, 'time_step': 0.007443026781082153, 'init_value': 37.914432525634766}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-12 13:39.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512133622: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002317359924316406, 'time_algorithm_update': 0.004939918518066406, 'loss': 1.565545769572258, 'time_step': 0.00731665849685669, 'init_value': 39.51871871948242}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-12 13:39.56[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512133622: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022892990112304687, 'time_algorithm_update': 0.004972700357437134, 'loss': 1.5107606404423715, 'time_step': 0.007322724103927612, 'init_value': 41.67251205444336}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.67251205444336
Starting 1000 evaluations
avg return on 3 trajectories of agent16: 1204.5498145780323
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-12 13:56.46[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-12 13:56.46[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-12 13:56.47[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-12 13:56.47[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-12 13:56.47[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250512135647[0m
[2m2025-05-12 13:56.47[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-12 13:57.09[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512135647: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022481632232666015, 'time_algorithm_update': 0.004849276065826416, 'loss': 1.629106005348265, 'time_step': 0.007156152725219727, 'init_value': 4.18549108505249}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-12 13:57.30[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512135647: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022803077697753906, 'time_algorithm_update': 0.0049825568199157715, 'loss': 2.1966581844687463, 'time_step': 0.0073235886096954346, 'init_value': 11.297807693481445}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-12 13:57.51[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512135647: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002296408653259277, 'time_algorithm_update': 0.005022504806518555, 'loss': 2.088482502937317, 'time_step': 0.0073802309036254884, 'init_value': 17.98029899597168}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-12 13:58.12[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512135647: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022781331539154055, 'time_algorithm_update': 0.004907643079757691, 'loss': 2.024528143465519, 'time_step': 0.0072457194328308105, 'init_value': 25.42656898498535}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-12 13:58.33[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512135647: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002347658395767212, 'time_algorithm_update': 0.0050030767917633055, 'loss': 1.8646338552832604, 'time_step': 0.007411550045013428, 'init_value': 29.031503677368164}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-12 13:58.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512135647: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023010611534118653, 'time_algorithm_update': 0.0051216230392456055, 'loss': 1.876957675933838, 'time_step': 0.007484952211380005, 'init_value': 31.18109893798828}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-12 13:59.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512135647: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002331078052520752, 'time_algorithm_update': 0.005084113836288452, 'loss': 1.6741304691433907, 'time_step': 0.00747714900970459, 'init_value': 34.560401916503906}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-12 13:59.38[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512135647: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022652249336242674, 'time_algorithm_update': 0.004846297264099121, 'loss': 1.705166519343853, 'time_step': 0.007170508146286011, 'init_value': 36.33081817626953}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-12 13:59.59[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512135647: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022916488647460936, 'time_algorithm_update': 0.005034080505371094, 'loss': 1.70955808198452, 'time_step': 0.007386790752410889, 'init_value': 37.528289794921875}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-12 14:00.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512135647: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022925097942352295, 'time_algorithm_update': 0.00502251935005188, 'loss': 1.6349668381214142, 'time_step': 0.007376202344894409, 'init_value': 39.28871154785156}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 39.28871154785156
Starting 1000 evaluations
avg return on 3 trajectories of agent17: 1213.272687366884
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-12 14:17.11[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-12 14:17.11[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-12 14:17.12[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-12 14:17.12[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-12 14:17.12[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250512141712[0m
[2m2025-05-12 14:17.12[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-12 14:17.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512141712: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00227586030960083, 'time_algorithm_update': 0.004989108085632324, 'loss': 1.7277761682122945, 'time_step': 0.007325412273406983, 'init_value': 4.424922943115234}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-12 14:17.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512141712: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002301348686218262, 'time_algorithm_update': 0.00500081729888916, 'loss': 2.0466831130385397, 'time_step': 0.00736287784576416, 'init_value': 11.818483352661133}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-12 14:18.16[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512141712: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022799067497253417, 'time_algorithm_update': 0.004896123409271241, 'loss': 2.2977786604762076, 'time_step': 0.007235490798950196, 'init_value': 18.7441463470459}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-12 14:18.37[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512141712: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023164892196655272, 'time_algorithm_update': 0.004990694999694824, 'loss': 1.9926253546476365, 'time_step': 0.007367282629013061, 'init_value': 24.987180709838867}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-12 14:18.59[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512141712: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002327561378479004, 'time_algorithm_update': 0.00511667799949646, 'loss': 1.9055350900888444, 'time_step': 0.007506782293319702, 'init_value': 30.21883201599121}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-12 14:19.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512141712: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002336187839508057, 'time_algorithm_update': 0.005015065908432007, 'loss': 1.7968353412151337, 'time_step': 0.007411897420883179, 'init_value': 33.218570709228516}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-12 14:19.41[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512141712: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002290090084075928, 'time_algorithm_update': 0.004936902523040771, 'loss': 1.6813837950229644, 'time_step': 0.007287317514419555, 'init_value': 35.33412170410156}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-12 14:20.03[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512141712: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023672828674316405, 'time_algorithm_update': 0.005057025671005249, 'loss': 1.610579748570919, 'time_step': 0.007485609769821167, 'init_value': 36.04403305053711}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-12 14:20.25[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512141712: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023301870822906496, 'time_algorithm_update': 0.005095706701278686, 'loss': 1.696293281674385, 'time_step': 0.0074882652759552006, 'init_value': 38.39314651489258}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-12 14:20.46[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512141712: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002308336019515991, 'time_algorithm_update': 0.005021665334701538, 'loss': 1.5292271406650544, 'time_step': 0.007390813589096069, 'init_value': 40.837432861328125}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.837432861328125
Starting 1000 evaluations
avg return on 3 trajectories of agent18: 1218.7015550615652
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-12 14:37.36[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-12 14:37.36[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-12 14:37.37[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-12 14:37.37[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-12 14:37.37[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250512143737[0m
[2m2025-05-12 14:37.37[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-12 14:37.59[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512143737: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022781856060028077, 'time_algorithm_update': 0.004986826658248901, 'loss': 1.6162684967592358, 'time_step': 0.007325534582138062, 'init_value': 5.044200897216797}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-12 14:38.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512143737: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00237504243850708, 'time_algorithm_update': 0.004992838382720947, 'loss': 2.3754826259613036, 'time_step': 0.007428496599197388, 'init_value': 12.43835735321045}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-12 14:38.41[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512143737: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00231376051902771, 'time_algorithm_update': 0.00506136441230774, 'loss': 2.071244328022003, 'time_step': 0.007436759233474731, 'init_value': 20.397397994995117}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-12 14:39.02[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512143737: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022861404418945313, 'time_algorithm_update': 0.004752702236175537, 'loss': 2.0345749791264534, 'time_step': 0.00709628963470459, 'init_value': 25.921520233154297}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-12 14:39.24[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512143737: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023638548851013185, 'time_algorithm_update': 0.005204816579818725, 'loss': 1.8422772997617722, 'time_step': 0.007632766962051392, 'init_value': 30.09169578552246}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-12 14:39.45[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512143737: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023166823387146, 'time_algorithm_update': 0.005033392906188965, 'loss': 1.819836143374443, 'time_step': 0.007410922050476074, 'init_value': 33.99454116821289}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-12 14:40.06[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512143737: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023490602970123293, 'time_algorithm_update': 0.005078481674194336, 'loss': 1.7963682041168212, 'time_step': 0.007489227056503296, 'init_value': 36.00845718383789}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-12 14:40.28[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512143737: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022462384700775145, 'time_algorithm_update': 0.0047853984832763674, 'loss': 1.6201267397403718, 'time_step': 0.007088838338851928, 'init_value': 37.6878776550293}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-12 14:40.49[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512143737: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023528099060058593, 'time_algorithm_update': 0.005189287900924683, 'loss': 1.728456779539585, 'time_step': 0.0076055660247802736, 'init_value': 40.471805572509766}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-12 14:41.11[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512143737: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00231699538230896, 'time_algorithm_update': 0.005058651447296143, 'loss': 1.531637303173542, 'time_step': 0.007440818071365356, 'init_value': 41.74799728393555}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.74799728393555
Starting 1000 evaluations
avg return on 3 trajectories of agent19: 1221.7145868328428
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-12 14:58.04[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-12 14:58.04[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-12 14:58.06[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-12 14:58.06[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-12 14:58.06[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250512145806[0m
[2m2025-05-12 14:58.06[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-12 14:58.27[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512145806: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002278984069824219, 'time_algorithm_update': 0.005082963466644287, 'loss': 1.63161606002599, 'time_step': 0.007423663854598999, 'init_value': 4.422918796539307}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-12 14:58.48[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512145806: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023536431789398194, 'time_algorithm_update': 0.005034311056137085, 'loss': 2.1957845532894136, 'time_step': 0.007449421644210815, 'init_value': 11.466297149658203}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-12 14:59.09[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512145806: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022247228622436525, 'time_algorithm_update': 0.004756819486618042, 'loss': 2.1412443110346793, 'time_step': 0.007038346529006958, 'init_value': 19.887083053588867}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-12 14:59.31[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512145806: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023316178321838377, 'time_algorithm_update': 0.005060713052749634, 'loss': 2.051350538790226, 'time_step': 0.007453297853469849, 'init_value': 26.564146041870117}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-12 14:59.52[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512145806: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002282928228378296, 'time_algorithm_update': 0.005041499614715576, 'loss': 1.8367850984930991, 'time_step': 0.007385121345520019, 'init_value': 30.520029067993164}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-12 15:00.13[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512145806: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023330302238464356, 'time_algorithm_update': 0.00501951003074646, 'loss': 1.7513417859077454, 'time_step': 0.007412843227386475, 'init_value': 33.829200744628906}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-12 15:00.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512145806: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022812771797180178, 'time_algorithm_update': 0.004764705657958984, 'loss': 1.662961984694004, 'time_step': 0.007103227853775025, 'init_value': 34.65595626831055}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-12 15:00.56[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512145806: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023140213489532472, 'time_algorithm_update': 0.005176793813705444, 'loss': 1.5181608377695084, 'time_step': 0.0075538563728332515, 'init_value': 37.1051025390625}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-12 15:01.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512145806: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023236746788024903, 'time_algorithm_update': 0.005030514717102051, 'loss': 1.5673937579393387, 'time_step': 0.007415029048919677, 'init_value': 38.32933044433594}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-12 15:01.38[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512145806: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022927241325378417, 'time_algorithm_update': 0.004937777757644654, 'loss': 1.4651848943829537, 'time_step': 0.007290035247802734, 'init_value': 39.90059280395508}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 39.90059280395508
ave advantage rew: 41.24640808105469, std: 1.1860637146045183
avg cum rews: 1186.4479208941245, std: 31.065835204090092
Pearson correlation coefficient: 0.10209822334091717
Spearman correlation coefficient: 0.015037593984962405
Kendall Tau correlation coefficient: 0.0
the best agent: 19, best agent cum rewards: 1221.7145868328428
1956
Starting to collect rollouts
Collecting rollouts: 10000/1000000
Collecting rollouts: 20000/1000000
Collecting rollouts: 30000/1000000
Collecting rollouts: 40000/1000000
Collecting rollouts: 50000/1000000
Collecting rollouts: 60000/1000000
Collecting rollouts: 70000/1000000
Collecting rollouts: 80000/1000000
Collecting rollouts: 90000/1000000
Collecting rollouts: 100000/1000000
Collecting rollouts: 110000/1000000
Collecting rollouts: 120000/1000000
Collecting rollouts: 130000/1000000
Collecting rollouts: 140000/1000000
Collecting rollouts: 150000/1000000
Collecting rollouts: 160000/1000000
Collecting rollouts: 170000/1000000
Collecting rollouts: 180000/1000000
Collecting rollouts: 190000/1000000
Collecting rollouts: 200000/1000000
Collecting rollouts: 210000/1000000
Collecting rollouts: 220000/1000000
Collecting rollouts: 230000/1000000
Collecting rollouts: 240000/1000000
Collecting rollouts: 250000/1000000
Collecting rollouts: 260000/1000000
Collecting rollouts: 270000/1000000
Collecting rollouts: 280000/1000000
Collecting rollouts: 290000/1000000
Collecting rollouts: 300000/1000000
Collecting rollouts: 310000/1000000
Collecting rollouts: 320000/1000000
Collecting rollouts: 330000/1000000
Collecting rollouts: 340000/1000000
Collecting rollouts: 350000/1000000
Collecting rollouts: 360000/1000000
Collecting rollouts: 370000/1000000
Collecting rollouts: 380000/1000000
Collecting rollouts: 390000/1000000
Collecting rollouts: 400000/1000000
Collecting rollouts: 410000/1000000
Collecting rollouts: 420000/1000000
Collecting rollouts: 430000/1000000
Collecting rollouts: 440000/1000000
Collecting rollouts: 450000/1000000
Collecting rollouts: 460000/1000000
Collecting rollouts: 470000/1000000
Collecting rollouts: 480000/1000000
Collecting rollouts: 490000/1000000
Collecting rollouts: 500000/1000000
Collecting rollouts: 510000/1000000
Collecting rollouts: 520000/1000000
Collecting rollouts: 530000/1000000
Collecting rollouts: 540000/1000000
Collecting rollouts: 550000/1000000
Collecting rollouts: 560000/1000000
Collecting rollouts: 570000/1000000
Collecting rollouts: 580000/1000000
Collecting rollouts: 590000/1000000
Collecting rollouts: 600000/1000000
Collecting rollouts: 610000/1000000
Collecting rollouts: 620000/1000000
Collecting rollouts: 630000/1000000
Collecting rollouts: 640000/1000000
Collecting rollouts: 650000/1000000
Collecting rollouts: 660000/1000000
Collecting rollouts: 670000/1000000
Collecting rollouts: 680000/1000000
Collecting rollouts: 690000/1000000
Collecting rollouts: 700000/1000000
Collecting rollouts: 710000/1000000
Collecting rollouts: 720000/1000000
Collecting rollouts: 730000/1000000
Collecting rollouts: 740000/1000000
Collecting rollouts: 750000/1000000
Collecting rollouts: 760000/1000000
Collecting rollouts: 770000/1000000
Collecting rollouts: 780000/1000000
Collecting rollouts: 790000/1000000
Collecting rollouts: 800000/1000000
Collecting rollouts: 810000/1000000
Collecting rollouts: 820000/1000000
Collecting rollouts: 830000/1000000
Collecting rollouts: 840000/1000000
Collecting rollouts: 850000/1000000
Collecting rollouts: 860000/1000000
Collecting rollouts: 870000/1000000
Collecting rollouts: 880000/1000000
Collecting rollouts: 890000/1000000
Collecting rollouts: 900000/1000000
Collecting rollouts: 910000/1000000
Collecting rollouts: 920000/1000000
Collecting rollouts: 930000/1000000
Collecting rollouts: 940000/1000000
Collecting rollouts: 950000/1000000
Collecting rollouts: 960000/1000000
Collecting rollouts: 970000/1000000
Collecting rollouts: 980000/1000000
Collecting rollouts: 990000/1000000
Collecting rollouts: 1000000/1000000
Replay buffer size:  (1000000, 105)
Replay buffer saved
---------------------------------
Searching empty space policies
(10, 11472)
(20, 11472)
(20, 11472)
Average distance of agents to nearest neighbors: 0.018119785551107322
Starting 1000 evaluations
avg return on 3 trajectories of agent0: 1227.0638996378532
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-12 15:38.18[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-12 15:38.18[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-12 15:38.20[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-12 15:38.20[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-12 15:38.20[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250512153820[0m
[2m2025-05-12 15:38.20[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-12 15:38.40[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512153820: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022373344898223876, 'time_algorithm_update': 0.0047002797126770015, 'loss': 1.4557222881391645, 'time_step': 0.006994229078292846, 'init_value': 4.4615583419799805}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-12 15:39.02[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512153820: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00236889910697937, 'time_algorithm_update': 0.005091280698776245, 'loss': 2.29936279463768, 'time_step': 0.007521912813186645, 'init_value': 10.807249069213867}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-12 15:39.24[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512153820: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002301969528198242, 'time_algorithm_update': 0.005031407117843628, 'loss': 2.318612871825695, 'time_step': 0.007395299434661865, 'init_value': 18.34804344177246}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-12 15:39.45[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512153820: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023130362033843993, 'time_algorithm_update': 0.005220091819763183, 'loss': 2.0612281022667887, 'time_step': 0.007596082210540771, 'init_value': 24.490808486938477}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-12 15:40.06[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512153820: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023377583026885987, 'time_algorithm_update': 0.004807646036148071, 'loss': 1.9043717148303985, 'time_step': 0.007202682495117188, 'init_value': 29.588165283203125}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-12 15:40.28[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512153820: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023401079177856445, 'time_algorithm_update': 0.0050937337875366214, 'loss': 1.7685537712574004, 'time_step': 0.007495204210281372, 'init_value': 32.84041976928711}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-12 15:40.50[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512153820: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023618032932281492, 'time_algorithm_update': 0.005095165491104126, 'loss': 1.6272541099190712, 'time_step': 0.0075185315608978275, 'init_value': 35.66550827026367}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-12 15:41.11[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512153820: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023162698745727538, 'time_algorithm_update': 0.005031525611877441, 'loss': 1.552040786087513, 'time_step': 0.007408336162567138, 'init_value': 36.9964714050293}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-12 15:41.33[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512153820: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002294911861419678, 'time_algorithm_update': 0.004853093385696411, 'loss': 1.5682187558412553, 'time_step': 0.007205317974090577, 'init_value': 38.637516021728516}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-12 15:41.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512153820: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002384931564331055, 'time_algorithm_update': 0.005292114973068238, 'loss': 1.6036919732689858, 'time_step': 0.007740647792816162, 'init_value': 40.4602165222168}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.4602165222168
Starting 1000 evaluations
avg return on 3 trajectories of agent1: 1234.0530935809375
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-12 15:58.43[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-12 15:58.43[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-12 15:58.44[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-12 15:58.44[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-12 15:58.44[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250512155844[0m
[2m2025-05-12 15:58.44[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-12 15:59.05[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512155844: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022727618217468263, 'time_algorithm_update': 0.004910673141479492, 'loss': 1.6709080295935272, 'time_step': 0.007242497444152832, 'init_value': 4.317180633544922}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-12 15:59.26[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512155844: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022962942123413085, 'time_algorithm_update': 0.004906241178512573, 'loss': 2.3108362548947334, 'time_step': 0.00726152515411377, 'init_value': 11.589287757873535}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-12 15:59.48[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512155844: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022795617580413817, 'time_algorithm_update': 0.004967406034469605, 'loss': 2.2437296746373177, 'time_step': 0.007306407690048217, 'init_value': 18.991004943847656}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-12 16:00.10[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512155844: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002372162103652954, 'time_algorithm_update': 0.005228716373443604, 'loss': 2.101079834282398, 'time_step': 0.007664024353027344, 'init_value': 25.579986572265625}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-12 16:00.31[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512155844: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002282170534133911, 'time_algorithm_update': 0.0050132105350494385, 'loss': 1.9487361952662468, 'time_step': 0.007355705261230468, 'init_value': 30.43488311767578}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-12 16:00.52[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512155844: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002255295753479004, 'time_algorithm_update': 0.004895470380783081, 'loss': 1.8652693858742715, 'time_step': 0.007209267854690552, 'init_value': 33.497554779052734}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-12 16:01.13[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512155844: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023274762630462647, 'time_algorithm_update': 0.005061020135879516, 'loss': 1.7149218727350235, 'time_step': 0.007449285268783569, 'init_value': 36.184593200683594}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-12 16:01.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512155844: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022936553955078126, 'time_algorithm_update': 0.005094053745269775, 'loss': 1.6381323704719544, 'time_step': 0.007448757648468017, 'init_value': 39.46297836303711}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-12 16:01.56[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512155844: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023433704376220705, 'time_algorithm_update': 0.005119870662689209, 'loss': 1.7083035559654236, 'time_step': 0.007524535179138183, 'init_value': 41.6905517578125}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-12 16:02.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512155844: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002292850732803345, 'time_algorithm_update': 0.004987594604492188, 'loss': 1.6374192460179329, 'time_step': 0.007340393543243408, 'init_value': 42.7188606262207}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.7188606262207
Starting 1000 evaluations
avg return on 3 trajectories of agent2: 1243.1068558969068
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-12 16:19.06[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-12 16:19.06[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-12 16:19.07[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-12 16:19.07[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-12 16:19.07[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250512161907[0m
[2m2025-05-12 16:19.07[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-12 16:19.28[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512161907: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002276890754699707, 'time_algorithm_update': 0.004965098857879638, 'loss': 1.6631315727159381, 'time_step': 0.0073018019199371335, 'init_value': 4.091832160949707}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-12 16:19.50[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512161907: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002334378957748413, 'time_algorithm_update': 0.005014644384384155, 'loss': 2.3127589110136033, 'time_step': 0.007409862041473389, 'init_value': 10.320273399353027}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-12 16:20.11[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512161907: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022945709228515626, 'time_algorithm_update': 0.00497203516960144, 'loss': 2.2178809535503388, 'time_step': 0.00732716703414917, 'init_value': 17.663288116455078}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-12 16:20.32[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512161907: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023513343334197996, 'time_algorithm_update': 0.005063321113586426, 'loss': 2.1316732281446455, 'time_step': 0.0074752717018127446, 'init_value': 25.17990493774414}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-12 16:20.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512161907: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022679557800292967, 'time_algorithm_update': 0.004746603488922119, 'loss': 1.8816262800693513, 'time_step': 0.007071273565292358, 'init_value': 29.805192947387695}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-12 16:21.15[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512161907: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002300550699234009, 'time_algorithm_update': 0.0050407381057739255, 'loss': 1.7045474477410316, 'time_step': 0.007401925325393677, 'init_value': 33.972251892089844}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-12 16:21.36[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512161907: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023411622047424317, 'time_algorithm_update': 0.004990687131881714, 'loss': 1.7252313372492791, 'time_step': 0.007392219543457031, 'init_value': 36.19108581542969}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-12 16:21.57[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512161907: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002305072069168091, 'time_algorithm_update': 0.005205651760101318, 'loss': 1.5998803797960282, 'time_step': 0.007573486089706421, 'init_value': 37.17414474487305}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-12 16:22.19[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512161907: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023195741176605224, 'time_algorithm_update': 0.004894245147705078, 'loss': 1.5679460546374322, 'time_step': 0.007272707223892212, 'init_value': 39.59897994995117}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-12 16:22.40[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512161907: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023130006790161133, 'time_algorithm_update': 0.0050189712047576905, 'loss': 1.5261012057662011, 'time_step': 0.007392513036727905, 'init_value': 41.111228942871094}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.111228942871094
Starting 1000 evaluations
avg return on 3 trajectories of agent3: 1249.8634734707753
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-12 16:39.30[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-12 16:39.30[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-12 16:39.31[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-12 16:39.31[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-12 16:39.31[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250512163931[0m
[2m2025-05-12 16:39.31[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-12 16:39.52[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512163931: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022583045959472655, 'time_algorithm_update': 0.004908915281295776, 'loss': 1.7281154048740863, 'time_step': 0.007226902961730957, 'init_value': 4.171840667724609}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-12 16:40.13[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512163931: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002243846893310547, 'time_algorithm_update': 0.004760205507278442, 'loss': 2.2739529074430465, 'time_step': 0.0070614492893219, 'init_value': 11.49714183807373}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-12 16:40.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512163931: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023021371364593504, 'time_algorithm_update': 0.0051528956890106205, 'loss': 2.289412096261978, 'time_step': 0.007518484115600586, 'init_value': 18.932769775390625}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-12 16:40.56[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512163931: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002277979373931885, 'time_algorithm_update': 0.004961900711059571, 'loss': 1.9840012001991272, 'time_step': 0.007299946069717407, 'init_value': 24.3295955657959}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-12 16:41.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512163931: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002268059253692627, 'time_algorithm_update': 0.005006258249282837, 'loss': 1.8673366709947585, 'time_step': 0.007335545301437378, 'init_value': 30.06328773498535}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-12 16:41.38[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512163931: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022964301109313964, 'time_algorithm_update': 0.004951730251312256, 'loss': 1.7692941045165063, 'time_step': 0.0073079953193664554, 'init_value': 33.25213623046875}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-12 16:42.00[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512163931: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023107528686523438, 'time_algorithm_update': 0.005216837882995606, 'loss': 1.750947848021984, 'time_step': 0.007591017723083496, 'init_value': 35.75361633300781}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-12 16:42.21[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512163931: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022655792236328126, 'time_algorithm_update': 0.004784837961196899, 'loss': 1.6580387935042382, 'time_step': 0.007107846975326538, 'init_value': 38.132511138916016}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-12 16:42.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512163931: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023142476081848143, 'time_algorithm_update': 0.005015381336212158, 'loss': 1.5938266596794128, 'time_step': 0.007389943599700927, 'init_value': 39.806209564208984}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-12 16:43.04[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512163931: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022835831642150878, 'time_algorithm_update': 0.005058311462402344, 'loss': 1.5780179153680802, 'time_step': 0.00740292763710022, 'init_value': 41.74687576293945}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.74687576293945
Starting 1000 evaluations
avg return on 3 trajectories of agent4: 1229.0438438348226
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-12 16:59.54[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-12 16:59.54[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-12 16:59.55[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-12 16:59.55[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-12 16:59.55[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250512165955[0m
[2m2025-05-12 16:59.55[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-12 17:00.16[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512165955: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002254753589630127, 'time_algorithm_update': 0.004881362438201905, 'loss': 1.6026874525994061, 'time_step': 0.007195477247238159, 'init_value': 4.138893127441406}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-12 17:00.38[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512165955: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00229669189453125, 'time_algorithm_update': 0.0050030038356781, 'loss': 2.0993336582779882, 'time_step': 0.0073610591888427735, 'init_value': 10.674653053283691}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-12 17:00.59[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512165955: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022529566287994383, 'time_algorithm_update': 0.004839757204055786, 'loss': 2.196187791109085, 'time_step': 0.0071512770652771, 'init_value': 18.42853355407715}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-12 17:01.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512165955: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002325284242630005, 'time_algorithm_update': 0.0051125075817108154, 'loss': 2.0367824918031694, 'time_step': 0.007499362468719482, 'init_value': 23.590316772460938}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-12 17:01.41[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512165955: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002256781578063965, 'time_algorithm_update': 0.004843856334686279, 'loss': 1.8785307785272598, 'time_step': 0.007158833026885986, 'init_value': 28.601093292236328}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-12 17:02.03[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512165955: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023353688716888426, 'time_algorithm_update': 0.00519524598121643, 'loss': 1.9160525107979773, 'time_step': 0.007593727588653564, 'init_value': 31.951738357543945}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-12 17:02.24[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512165955: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022035222053527832, 'time_algorithm_update': 0.004662423133850097, 'loss': 1.7279847158193589, 'time_step': 0.006922240972518921, 'init_value': 35.863121032714844}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-12 17:02.45[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512165955: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022891104221343995, 'time_algorithm_update': 0.005195667505264282, 'loss': 1.6509693027734758, 'time_step': 0.00754834270477295, 'init_value': 37.082733154296875}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-12 17:03.06[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512165955: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002255664110183716, 'time_algorithm_update': 0.0048500230312347415, 'loss': 1.6231403144001961, 'time_step': 0.007164194583892823, 'init_value': 39.3414192199707}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-12 17:03.28[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512165955: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002300471544265747, 'time_algorithm_update': 0.005141499280929565, 'loss': 1.6537832065820695, 'time_step': 0.0075047268867492675, 'init_value': 39.95993423461914}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 39.95993423461914
Starting 1000 evaluations
avg return on 3 trajectories of agent5: 1235.1139410595
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-12 17:20.14[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-12 17:20.14[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-12 17:20.15[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-12 17:20.15[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-12 17:20.15[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250512172015[0m
[2m2025-05-12 17:20.15[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-12 17:20.37[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512172015: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00226568865776062, 'time_algorithm_update': 0.005122941255569458, 'loss': 1.6026557338535785, 'time_step': 0.007451004028320313, 'init_value': 4.833911895751953}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-12 17:20.58[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512172015: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002274536371231079, 'time_algorithm_update': 0.0048171901702880856, 'loss': 2.134150371193886, 'time_step': 0.0071502914428710936, 'init_value': 12.49346923828125}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-12 17:21.19[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512172015: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022373528480529787, 'time_algorithm_update': 0.004827794313430786, 'loss': 2.1646786482334135, 'time_step': 0.007123513460159302, 'init_value': 19.316099166870117}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-12 17:21.40[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512172015: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022790586948394777, 'time_algorithm_update': 0.004992146730422973, 'loss': 2.062040213227272, 'time_step': 0.0073314368724823, 'init_value': 25.03384017944336}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-12 17:22.02[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512172015: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002273710012435913, 'time_algorithm_update': 0.005255980730056763, 'loss': 1.882274067401886, 'time_step': 0.007593660593032837, 'init_value': 30.090255737304688}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-12 17:22.22[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512172015: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022328333854675295, 'time_algorithm_update': 0.004724948644638061, 'loss': 1.8060741507411002, 'time_step': 0.007014771699905395, 'init_value': 33.36857223510742}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-12 17:22.44[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512172015: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00228564453125, 'time_algorithm_update': 0.004917100667953491, 'loss': 1.5895341416597366, 'time_step': 0.0072617075443267825, 'init_value': 35.27824783325195}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-12 17:23.05[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512172015: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022955963611602783, 'time_algorithm_update': 0.004991796493530274, 'loss': 1.5072201311588287, 'time_step': 0.007347914457321167, 'init_value': 36.97002410888672}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-12 17:23.26[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512172015: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023357086181640626, 'time_algorithm_update': 0.005230215787887574, 'loss': 1.5172022926211357, 'time_step': 0.0076300201416015625, 'init_value': 39.06439971923828}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-12 17:23.47[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512172015: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002225855827331543, 'time_algorithm_update': 0.004783918380737304, 'loss': 1.538377481341362, 'time_step': 0.007067026138305664, 'init_value': 41.063411712646484}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.063411712646484
Starting 1000 evaluations
avg return on 3 trajectories of agent6: 1241.7469024861996
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-12 17:40.33[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-12 17:40.33[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-12 17:40.34[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-12 17:40.34[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-12 17:40.34[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250512174034[0m
[2m2025-05-12 17:40.34[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-12 17:40.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512174034: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002270538330078125, 'time_algorithm_update': 0.004855751276016235, 'loss': 1.4807538327723742, 'time_step': 0.007184582233428955, 'init_value': 4.618783473968506}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-12 17:41.16[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512174034: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022914416790008546, 'time_algorithm_update': 0.004862899541854858, 'loss': 2.2452517682909967, 'time_step': 0.007213457584381104, 'init_value': 11.729637145996094}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-12 17:41.38[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512174034: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023277094364166258, 'time_algorithm_update': 0.005123008728027343, 'loss': 2.138888016819954, 'time_step': 0.007512906312942505, 'init_value': 19.75691795349121}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-12 17:41.59[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512174034: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023257746696472167, 'time_algorithm_update': 0.004979649305343628, 'loss': 2.0943244463801385, 'time_step': 0.007364862680435181, 'init_value': 25.46056365966797}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-12 17:42.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512174034: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022707977294921873, 'time_algorithm_update': 0.004822142124176025, 'loss': 1.9357777705192567, 'time_step': 0.007150850772857666, 'init_value': 30.252531051635742}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-12 17:42.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512174034: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002349794387817383, 'time_algorithm_update': 0.005032384634017944, 'loss': 1.7596565868258476, 'time_step': 0.007443067073822022, 'init_value': 33.44780349731445}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-12 17:43.03[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512174034: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023266074657440185, 'time_algorithm_update': 0.0050675241947174075, 'loss': 1.6957966713309287, 'time_step': 0.007455755472183228, 'init_value': 36.06830596923828}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-12 17:43.25[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512174034: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023730599880218504, 'time_algorithm_update': 0.005040868520736695, 'loss': 1.6476036632657052, 'time_step': 0.007475823640823364, 'init_value': 38.61296081542969}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-12 17:43.46[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512174034: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022914602756500244, 'time_algorithm_update': 0.004950932502746582, 'loss': 1.67806909263134, 'time_step': 0.007302603483200073, 'init_value': 40.18754196166992}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-12 17:44.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512174034: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023250203132629396, 'time_algorithm_update': 0.005048328638076782, 'loss': 1.4684531770944595, 'time_step': 0.007434677124023437, 'init_value': 42.54643249511719}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.54643249511719
Starting 1000 evaluations
avg return on 3 trajectories of agent7: 1251.205250484828
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-12 18:00.54[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-12 18:00.54[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-12 18:00.55[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-12 18:00.55[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-12 18:00.55[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250512180055[0m
[2m2025-05-12 18:00.55[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-12 18:01.16[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512180055: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002268397092819214, 'time_algorithm_update': 0.004924267530441284, 'loss': 1.5522638820111752, 'time_step': 0.007251958847045898, 'init_value': 4.378977298736572}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-12 18:01.38[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512180055: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002318467140197754, 'time_algorithm_update': 0.005212502002716064, 'loss': 2.281685927927494, 'time_step': 0.007594612360000611, 'init_value': 11.20631217956543}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-12 18:01.59[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512180055: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00228682804107666, 'time_algorithm_update': 0.005070122718811035, 'loss': 2.139603572547436, 'time_step': 0.007417772769927979, 'init_value': 18.34544563293457}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-12 18:02.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512180055: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022914278507232665, 'time_algorithm_update': 0.004929714679718018, 'loss': 2.02951049721241, 'time_step': 0.0072798244953155514, 'init_value': 25.773876190185547}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-12 18:02.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512180055: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023101942539215086, 'time_algorithm_update': 0.005062422037124634, 'loss': 1.8721508378386498, 'time_step': 0.007433401346206665, 'init_value': 30.090044021606445}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-12 18:03.04[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512180055: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002343475580215454, 'time_algorithm_update': 0.005200675249099731, 'loss': 1.677176463663578, 'time_step': 0.007606566667556763, 'init_value': 33.801631927490234}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-12 18:03.25[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512180055: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022441723346710205, 'time_algorithm_update': 0.0048834261894226075, 'loss': 1.6884196796417237, 'time_step': 0.007186054706573486, 'init_value': 36.40358352661133}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-12 18:03.45[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512180055: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002290402889251709, 'time_algorithm_update': 0.005072965860366822, 'loss': 1.6858835542201995, 'time_step': 0.007423551082611084, 'init_value': 38.99708557128906}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-12 18:04.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512180055: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002328421115875244, 'time_algorithm_update': 0.005224152088165283, 'loss': 1.5655545399188995, 'time_step': 0.007615230083465576, 'init_value': 39.757225036621094}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-12 18:04.29[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512180055: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023091912269592287, 'time_algorithm_update': 0.005227776527404785, 'loss': 1.49431203687191, 'time_step': 0.0075996811389923095, 'init_value': 41.07862091064453}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.07862091064453
Starting 1000 evaluations
avg return on 3 trajectories of agent8: 1230.553322000063
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-12 18:21.17[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-12 18:21.17[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-12 18:21.19[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-12 18:21.19[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-12 18:21.19[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250512182119[0m
[2m2025-05-12 18:21.19[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-12 18:21.40[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512182119: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002269050359725952, 'time_algorithm_update': 0.0050893819332122805, 'loss': 1.5181094817519187, 'time_step': 0.007420214414596557, 'init_value': 4.594123363494873}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-12 18:22.01[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512182119: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002288511276245117, 'time_algorithm_update': 0.004872680902481079, 'loss': 2.239837259590626, 'time_step': 0.007219555616378784, 'init_value': 11.457359313964844}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-12 18:22.22[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512182119: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002265958309173584, 'time_algorithm_update': 0.005013076305389405, 'loss': 2.180984932422638, 'time_step': 0.007338874816894532, 'init_value': 19.447111129760742}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-12 18:22.44[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512182119: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002331127405166626, 'time_algorithm_update': 0.005096033334732055, 'loss': 2.029664393603802, 'time_step': 0.007488602876663208, 'init_value': 24.486534118652344}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-12 18:23.05[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512182119: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022818703651428223, 'time_algorithm_update': 0.00497764778137207, 'loss': 1.8129109311699867, 'time_step': 0.007319090843200683, 'init_value': 30.181934356689453}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-12 18:23.26[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512182119: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022343246936798095, 'time_algorithm_update': 0.004817544460296631, 'loss': 1.790385892689228, 'time_step': 0.007109457731246948, 'init_value': 33.182533264160156}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-12 18:23.48[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512182119: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023419601917266846, 'time_algorithm_update': 0.005116177320480347, 'loss': 1.7357810447216033, 'time_step': 0.007518993139266968, 'init_value': 36.40044403076172}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-12 18:24.09[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512182119: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002288861036300659, 'time_algorithm_update': 0.005213040590286255, 'loss': 1.627880557537079, 'time_step': 0.007564624309539795, 'init_value': 37.53866958618164}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-12 18:24.31[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512182119: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002318716049194336, 'time_algorithm_update': 0.004963353872299194, 'loss': 1.6375516431927681, 'time_step': 0.007342371702194214, 'init_value': 39.09394454956055}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-12 18:24.51[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512182119: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022225210666656494, 'time_algorithm_update': 0.00480898642539978, 'loss': 1.527881717979908, 'time_step': 0.007089069843292236, 'init_value': 42.19351577758789}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.19351577758789
Starting 1000 evaluations
avg return on 3 trajectories of agent9: 1240.0473880771162
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-12 18:41.44[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-12 18:41.44[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-12 18:41.46[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-12 18:41.46[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-12 18:41.46[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250512184146[0m
[2m2025-05-12 18:41.46[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-12 18:42.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512184146: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002242480754852295, 'time_algorithm_update': 0.004922787427902222, 'loss': 1.9041722548305988, 'time_step': 0.007224630832672119, 'init_value': 4.5439605712890625}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-12 18:42.28[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512184146: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002270084381103516, 'time_algorithm_update': 0.004867366313934326, 'loss': 2.4422040823102, 'time_step': 0.007196649074554444, 'init_value': 11.072901725769043}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-12 18:42.50[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512184146: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022983901500701906, 'time_algorithm_update': 0.0050909752845764164, 'loss': 2.0940245805382727, 'time_step': 0.007451470375061035, 'init_value': 19.137849807739258}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-12 18:43.11[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512184146: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023070509433746338, 'time_algorithm_update': 0.004951760530471801, 'loss': 2.022058040857315, 'time_step': 0.007318676471710205, 'init_value': 26.27672576904297}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-12 18:43.32[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512184146: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002274638891220093, 'time_algorithm_update': 0.004953554153442383, 'loss': 1.822249798297882, 'time_step': 0.007288091659545899, 'init_value': 31.056575775146484}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-12 18:43.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512184146: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002299361228942871, 'time_algorithm_update': 0.004872658967971802, 'loss': 1.6510847496390342, 'time_step': 0.007230650901794433, 'init_value': 32.363441467285156}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-12 18:44.15[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512184146: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023059778213500976, 'time_algorithm_update': 0.005197593688964844, 'loss': 1.6536033608317375, 'time_step': 0.00756718111038208, 'init_value': 35.018619537353516}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-12 18:44.36[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512184146: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002285184144973755, 'time_algorithm_update': 0.0049609549045562746, 'loss': 1.4703599091768265, 'time_step': 0.00730562162399292, 'init_value': 37.613773345947266}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-12 18:44.57[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512184146: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002311715841293335, 'time_algorithm_update': 0.004992925643920899, 'loss': 1.4860041788220406, 'time_step': 0.007364496469497681, 'init_value': 39.361785888671875}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-12 18:45.19[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512184146: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00228627610206604, 'time_algorithm_update': 0.0050283725261688235, 'loss': 1.5575857696533204, 'time_step': 0.007374778509140014, 'init_value': 43.33185577392578}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 43.33185577392578
Starting 1000 evaluations
avg return on 3 trajectories of agent10: 1254.067130884214
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-12 19:02.09[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-12 19:02.09[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-12 19:02.10[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-12 19:02.10[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-12 19:02.10[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250512190210[0m
[2m2025-05-12 19:02.10[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-12 19:02.31[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512190210: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022701058387756346, 'time_algorithm_update': 0.004927356481552124, 'loss': 1.5473984388262034, 'time_step': 0.007256603717803955, 'init_value': 4.484647750854492}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-12 19:02.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512190210: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002291538953781128, 'time_algorithm_update': 0.005075268983840943, 'loss': 2.182715711414814, 'time_step': 0.0074278988838195805, 'init_value': 11.408349990844727}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-12 19:03.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512190210: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023468284606933594, 'time_algorithm_update': 0.005026519060134888, 'loss': 2.1924293329715727, 'time_step': 0.007434295654296875, 'init_value': 18.655685424804688}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-12 19:03.36[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512190210: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002286365509033203, 'time_algorithm_update': 0.004928142070770264, 'loss': 2.0347338527441026, 'time_step': 0.007273682832717896, 'init_value': 23.690406799316406}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-12 19:03.57[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512190210: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002296645164489746, 'time_algorithm_update': 0.005082885026931763, 'loss': 1.8598714298009873, 'time_step': 0.007440847873687744, 'init_value': 28.538070678710938}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-12 19:04.19[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512190210: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023247129917144775, 'time_algorithm_update': 0.004930347204208374, 'loss': 1.7785581293702126, 'time_step': 0.0073148891925811765, 'init_value': 32.5783805847168}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-12 19:04.40[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512190210: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002258174180984497, 'time_algorithm_update': 0.004871548175811768, 'loss': 1.6941484611034394, 'time_step': 0.007188636779785157, 'init_value': 35.223182678222656}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-12 19:05.01[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512190210: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002303252935409546, 'time_algorithm_update': 0.004981864929199218, 'loss': 1.5574898235201835, 'time_step': 0.0073456354141235355, 'init_value': 37.80610275268555}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-12 19:05.23[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512190210: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023165757656097414, 'time_algorithm_update': 0.005217456340789795, 'loss': 1.4616668708324432, 'time_step': 0.007596724748611451, 'init_value': 39.396018981933594}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-12 19:05.45[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512190210: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002345799922943115, 'time_algorithm_update': 0.005096804618835449, 'loss': 1.5352847962379454, 'time_step': 0.00750460410118103, 'init_value': 40.876617431640625}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.876617431640625
Starting 1000 evaluations
avg return on 3 trajectories of agent11: 1267.7306406933412
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-12 19:22.30[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-12 19:22.30[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-12 19:22.31[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-12 19:22.31[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-12 19:22.31[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250512192231[0m
[2m2025-05-12 19:22.31[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-12 19:22.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512192231: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00224131178855896, 'time_algorithm_update': 0.0049024813175201415, 'loss': 1.8532581103369594, 'time_step': 0.007202567815780639, 'init_value': 4.273976802825928}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-12 19:23.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512192231: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022958080768585203, 'time_algorithm_update': 0.00497489333152771, 'loss': 2.287462746798992, 'time_step': 0.007331221103668213, 'init_value': 11.437460899353027}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-12 19:23.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512192231: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002231631278991699, 'time_algorithm_update': 0.004838150262832641, 'loss': 2.2515730361938475, 'time_step': 0.007127284288406372, 'init_value': 19.672536849975586}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-12 19:23.56[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512192231: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002293123960494995, 'time_algorithm_update': 0.005136989831924439, 'loss': 1.9225492516756058, 'time_step': 0.007491937875747681, 'init_value': 25.53099822998047}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-12 19:24.18[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512192231: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022864387035369874, 'time_algorithm_update': 0.005073643684387207, 'loss': 1.857233366727829, 'time_step': 0.007421401500701905, 'init_value': 30.276065826416016}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-12 19:24.39[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512192231: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022709498405456543, 'time_algorithm_update': 0.004874442100524902, 'loss': 1.7945759937167167, 'time_step': 0.007204294681549072, 'init_value': 33.36103057861328}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-12 19:25.00[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512192231: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002299414873123169, 'time_algorithm_update': 0.004786556482315064, 'loss': 1.761268926024437, 'time_step': 0.00714331316947937, 'init_value': 36.04404067993164}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-12 19:25.22[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512192231: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002295902967453003, 'time_algorithm_update': 0.005084504604339599, 'loss': 1.6456635876893997, 'time_step': 0.007441445112228394, 'init_value': 36.82094955444336}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-12 19:25.44[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512192231: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023434557914733885, 'time_algorithm_update': 0.0051760122776031495, 'loss': 1.5678211259245873, 'time_step': 0.007582489252090454, 'init_value': 39.191341400146484}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-12 19:26.05[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512192231: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002245915174484253, 'time_algorithm_update': 0.0048081398010253905, 'loss': 1.5936976869106292, 'time_step': 0.007111677408218384, 'init_value': 41.33195114135742}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.33195114135742
Starting 1000 evaluations
avg return on 3 trajectories of agent12: 1230.573915553906
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-12 19:42.58[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-12 19:42.58[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-12 19:42.59[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-12 19:42.59[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-12 19:42.59[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250512194259[0m
[2m2025-05-12 19:42.59[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-12 19:43.21[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512194259: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002288995981216431, 'time_algorithm_update': 0.004940911531448365, 'loss': 1.571758211016655, 'time_step': 0.007288980722427368, 'init_value': 4.572012424468994}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-12 19:43.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512194259: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022997348308563233, 'time_algorithm_update': 0.00484722900390625, 'loss': 2.3495849534273145, 'time_step': 0.007204797029495239, 'init_value': 11.528399467468262}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-12 19:44.04[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512194259: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002319988965988159, 'time_algorithm_update': 0.005050448894500732, 'loss': 2.3258106432557106, 'time_step': 0.007430700778961181, 'init_value': 19.28233528137207}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-12 19:44.25[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512194259: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002334350109100342, 'time_algorithm_update': 0.005054114818572998, 'loss': 2.043654996931553, 'time_step': 0.007449023723602295, 'init_value': 25.929285049438477}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-12 19:44.46[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512194259: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023283746242523193, 'time_algorithm_update': 0.005074964046478271, 'loss': 1.8285224834680558, 'time_step': 0.007464313268661499, 'init_value': 30.3349609375}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-12 19:45.08[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512194259: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002330690622329712, 'time_algorithm_update': 0.004973473787307739, 'loss': 1.8044375039935112, 'time_step': 0.007363411426544189, 'init_value': 32.66079330444336}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-12 19:45.30[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512194259: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023267560005187987, 'time_algorithm_update': 0.0050324292182922364, 'loss': 1.6389099253416062, 'time_step': 0.00741970157623291, 'init_value': 35.284297943115234}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-12 19:45.51[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512194259: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002295836925506592, 'time_algorithm_update': 0.0050440549850463865, 'loss': 1.6112562748789787, 'time_step': 0.007400561571121216, 'init_value': 38.07684326171875}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-12 19:46.12[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512194259: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002271437406539917, 'time_algorithm_update': 0.004854675769805908, 'loss': 1.6224839084148408, 'time_step': 0.007183774709701538, 'init_value': 40.86018371582031}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-12 19:46.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512194259: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002323253393173218, 'time_algorithm_update': 0.005088550806045532, 'loss': 1.550061862051487, 'time_step': 0.0074727869033813475, 'init_value': 42.37980270385742}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.37980270385742
Starting 1000 evaluations
avg return on 3 trajectories of agent13: 1213.009068454071
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-12 20:03.23[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-12 20:03.23[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-12 20:03.24[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-12 20:03.24[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-12 20:03.24[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250512200324[0m
[2m2025-05-12 20:03.24[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-12 20:03.45[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512200324: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022141046524047853, 'time_algorithm_update': 0.004707094430923462, 'loss': 1.5593028666377067, 'time_step': 0.006977622747421265, 'init_value': 4.53606653213501}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-12 20:04.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512200324: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002291658878326416, 'time_algorithm_update': 0.00510609769821167, 'loss': 2.167726478934288, 'time_step': 0.007459923028945923, 'init_value': 11.611225128173828}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-12 20:04.29[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512200324: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023227832317352297, 'time_algorithm_update': 0.005000573873519897, 'loss': 2.1648275746703147, 'time_step': 0.007384263753890992, 'init_value': 19.4870662689209}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-12 20:04.49[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512200324: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023110251426696777, 'time_algorithm_update': 0.004939037322998047, 'loss': 2.0615405453443527, 'time_step': 0.007309478998184204, 'init_value': 26.760072708129883}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-12 20:05.11[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512200324: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022425401210784913, 'time_algorithm_update': 0.0048456301689147946, 'loss': 1.929069144308567, 'time_step': 0.007146672964096069, 'init_value': 30.85703468322754}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-12 20:05.33[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512200324: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023339128494262694, 'time_algorithm_update': 0.005146820545196534, 'loss': 1.7672793698310851, 'time_step': 0.007543383598327636, 'init_value': 34.286808013916016}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-12 20:05.54[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512200324: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022950379848480223, 'time_algorithm_update': 0.004998884201049805, 'loss': 1.7630281096696854, 'time_step': 0.007353893756866455, 'init_value': 36.953670501708984}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-12 20:06.15[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512200324: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022534828186035155, 'time_algorithm_update': 0.004816374063491821, 'loss': 1.6582515277266503, 'time_step': 0.007127356052398681, 'init_value': 38.76283645629883}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-12 20:06.37[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512200324: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002305872917175293, 'time_algorithm_update': 0.0050647611618041995, 'loss': 1.5687476187944411, 'time_step': 0.0074318284988403325, 'init_value': 40.375823974609375}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-12 20:06.59[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512200324: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002293467044830322, 'time_algorithm_update': 0.005179061889648438, 'loss': 1.609458798468113, 'time_step': 0.00753462815284729, 'init_value': 41.870330810546875}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.870330810546875
Starting 1000 evaluations
avg return on 3 trajectories of agent14: 1174.783266006118
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-12 20:23.42[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-12 20:23.42[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-12 20:23.43[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-12 20:23.43[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-12 20:23.43[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250512202343[0m
[2m2025-05-12 20:23.43[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-12 20:24.05[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512202343: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022697556018829346, 'time_algorithm_update': 0.004927228927612304, 'loss': 1.5573322495371102, 'time_step': 0.007256940126419067, 'init_value': 4.763568878173828}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-12 20:24.27[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512202343: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022760066986083983, 'time_algorithm_update': 0.004941808462142944, 'loss': 2.2847071877717973, 'time_step': 0.007278401374816895, 'init_value': 11.509928703308105}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-12 20:24.48[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512202343: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002291081428527832, 'time_algorithm_update': 0.004924917936325073, 'loss': 2.135669008612633, 'time_step': 0.007276036262512207, 'init_value': 18.395143508911133}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-12 20:25.09[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512202343: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002333757400512695, 'time_algorithm_update': 0.005146003007888794, 'loss': 2.1201116802692415, 'time_step': 0.007541293859481811, 'init_value': 25.342933654785156}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-12 20:25.31[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512202343: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002300299644470215, 'time_algorithm_update': 0.005089936017990113, 'loss': 1.931966580748558, 'time_step': 0.0074520504474639895, 'init_value': 30.037147521972656}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-12 20:25.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512202343: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023131487369537356, 'time_algorithm_update': 0.0050056583881378175, 'loss': 1.7393562082648277, 'time_step': 0.007379942655563355, 'init_value': 33.143043518066406}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-12 20:26.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512202343: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002275132656097412, 'time_algorithm_update': 0.005005964756011963, 'loss': 1.6333084887862206, 'time_step': 0.0073415920734405515, 'init_value': 36.05721664428711}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-12 20:26.36[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512202343: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002327826976776123, 'time_algorithm_update': 0.0049970090389251706, 'loss': 1.605920376598835, 'time_step': 0.0073848309516906735, 'init_value': 38.85635757446289}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-12 20:26.58[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512202343: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023500292301177977, 'time_algorithm_update': 0.005158572196960449, 'loss': 1.557927420258522, 'time_step': 0.007571091175079345, 'init_value': 40.67652893066406}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-12 20:27.19[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512202343: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022886435985565185, 'time_algorithm_update': 0.005064751386642456, 'loss': 1.5409705542325973, 'time_step': 0.007414848566055298, 'init_value': 42.93693923950195}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.93693923950195
Starting 1000 evaluations
avg return on 3 trajectories of agent15: 1094.2704304755343
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-12 20:44.08[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-12 20:44.08[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-12 20:44.10[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-12 20:44.10[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-12 20:44.10[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250512204410[0m
[2m2025-05-12 20:44.10[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-12 20:44.30[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512204410: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022681412696838378, 'time_algorithm_update': 0.005070274353027344, 'loss': 1.4892440195679664, 'time_step': 0.0074002258777618405, 'init_value': 4.409785270690918}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-12 20:44.51[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512204410: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002245185136795044, 'time_algorithm_update': 0.004719012975692749, 'loss': 2.213262667775154, 'time_step': 0.007021353483200073, 'init_value': 12.315074920654297}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-12 20:45.13[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512204410: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002272184133529663, 'time_algorithm_update': 0.004981762886047363, 'loss': 2.237648949623108, 'time_step': 0.0073138587474822995, 'init_value': 19.3206729888916}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-12 20:45.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512204410: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022965891361236574, 'time_algorithm_update': 0.005160766363143921, 'loss': 1.9242658807635307, 'time_step': 0.007519863367080689, 'init_value': 24.728086471557617}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-12 20:45.56[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512204410: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023131983280181884, 'time_algorithm_update': 0.005072061777114868, 'loss': 1.7875621765851974, 'time_step': 0.007446308374404907, 'init_value': 29.407808303833008}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-12 20:46.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512204410: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022089536190032957, 'time_algorithm_update': 0.004721773624420166, 'loss': 1.739685642182827, 'time_step': 0.006987017631530762, 'init_value': 33.632080078125}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-12 20:46.40[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512204410: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023530259132385255, 'time_algorithm_update': 0.004987243413925171, 'loss': 1.5670949361324311, 'time_step': 0.0074005436897277834, 'init_value': 35.37617111206055}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-12 20:47.01[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512204410: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002295055866241455, 'time_algorithm_update': 0.005190391063690186, 'loss': 1.5801154718995094, 'time_step': 0.00754828691482544, 'init_value': 37.54782485961914}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-12 20:47.22[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512204410: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023229947090148925, 'time_algorithm_update': 0.0049918899536132814, 'loss': 1.5877571986317636, 'time_step': 0.007375205278396606, 'init_value': 39.44750213623047}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-12 20:47.43[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512204410: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002227332353591919, 'time_algorithm_update': 0.004804275751113892, 'loss': 1.6208379080295563, 'time_step': 0.007089004755020141, 'init_value': 40.910789489746094}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.910789489746094
Starting 1000 evaluations
avg return on 3 trajectories of agent16: 1233.0680344584105
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-12 21:04.30[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-12 21:04.30[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-12 21:04.31[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-12 21:04.31[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-12 21:04.31[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250512210431[0m
[2m2025-05-12 21:04.31[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-12 21:04.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512210431: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022504093647003173, 'time_algorithm_update': 0.004884429931640625, 'loss': 1.6080028365701438, 'time_step': 0.007193482398986816, 'init_value': 4.39810037612915}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-12 21:05.13[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512210431: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002277048349380493, 'time_algorithm_update': 0.004866803646087646, 'loss': 2.213287613630295, 'time_step': 0.00720282506942749, 'init_value': 11.567580223083496}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-12 21:05.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512210431: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002323731184005737, 'time_algorithm_update': 0.0050827345848083495, 'loss': 2.049871191382408, 'time_step': 0.007468542098999023, 'init_value': 18.488872528076172}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-12 21:05.57[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512210431: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022971003055572508, 'time_algorithm_update': 0.004859095096588135, 'loss': 2.0258964685201644, 'time_step': 0.007214900255203247, 'init_value': 25.009328842163086}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-12 21:06.18[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512210431: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022867870330810546, 'time_algorithm_update': 0.004925138473510742, 'loss': 1.8485905228853226, 'time_step': 0.0072721574306488035, 'init_value': 29.557758331298828}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-12 21:06.40[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512210431: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002369570016860962, 'time_algorithm_update': 0.005026289701461792, 'loss': 1.8032125935554504, 'time_step': 0.00745706295967102, 'init_value': 32.34625244140625}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-12 21:07.01[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512210431: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023102281093597414, 'time_algorithm_update': 0.005137027263641358, 'loss': 1.6919539039134979, 'time_step': 0.007509738206863403, 'init_value': 35.9174690246582}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-12 21:07.23[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512210431: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002272634029388428, 'time_algorithm_update': 0.004884917259216309, 'loss': 1.630988486468792, 'time_step': 0.007216503620147705, 'init_value': 37.42438507080078}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-12 21:07.44[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512210431: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002344180107116699, 'time_algorithm_update': 0.004969286441802979, 'loss': 1.5481480723023415, 'time_step': 0.00737363314628601, 'init_value': 39.902740478515625}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-12 21:08.06[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512210431: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002315861940383911, 'time_algorithm_update': 0.005006711959838867, 'loss': 1.4824979517459869, 'time_step': 0.007383742094039917, 'init_value': 41.100521087646484}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.100521087646484
Starting 1000 evaluations
avg return on 3 trajectories of agent17: 1222.0669627751843
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-12 21:24.56[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-12 21:24.56[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-12 21:24.58[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-12 21:24.58[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-12 21:24.58[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250512212458[0m
[2m2025-05-12 21:24.58[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-12 21:25.18[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512212458: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022108159065246584, 'time_algorithm_update': 0.004673539161682129, 'loss': 1.8102158501818777, 'time_step': 0.006940263986587525, 'init_value': 4.660589218139648}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-12 21:25.40[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512212458: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023442094326019285, 'time_algorithm_update': 0.005186462640762329, 'loss': 2.323950067102909, 'time_step': 0.007594292163848877, 'init_value': 11.196127891540527}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-12 21:26.01[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512212458: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002275500774383545, 'time_algorithm_update': 0.004940551280975342, 'loss': 2.323438405573368, 'time_step': 0.007275479793548584, 'init_value': 18.541385650634766}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-12 21:26.22[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512212458: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022556746006011964, 'time_algorithm_update': 0.004817308902740479, 'loss': 2.0152810764312745, 'time_step': 0.007131461143493652, 'init_value': 25.14628028869629}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-12 21:26.43[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512212458: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022669708728790283, 'time_algorithm_update': 0.004812931776046753, 'loss': 1.8890653987526893, 'time_step': 0.007137487888336182, 'init_value': 28.624736785888672}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-12 21:27.05[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512212458: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002323094606399536, 'time_algorithm_update': 0.005300060510635376, 'loss': 1.8290333270430565, 'time_step': 0.007687771081924438, 'init_value': 31.351722717285156}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-12 21:27.26[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512212458: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023120319843292236, 'time_algorithm_update': 0.0048848257064819335, 'loss': 1.6753680812120437, 'time_step': 0.0072556624412536625, 'init_value': 34.923213958740234}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-12 21:27.47[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512212458: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002274298667907715, 'time_algorithm_update': 0.0048717837333679195, 'loss': 1.6248190731406211, 'time_step': 0.007204493761062622, 'init_value': 36.6923828125}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-12 21:28.09[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512212458: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023333227634429934, 'time_algorithm_update': 0.005014061212539673, 'loss': 1.6012931194901467, 'time_step': 0.00740808629989624, 'init_value': 39.45278549194336}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-12 21:28.31[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512212458: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002315469741821289, 'time_algorithm_update': 0.0052306067943573, 'loss': 1.5468792120814323, 'time_step': 0.007609493732452392, 'init_value': 40.70598220825195}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.70598220825195
Starting 1000 evaluations
avg return on 3 trajectories of agent18: 1205.2507013383201
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-12 21:45.17[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-12 21:45.17[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-12 21:45.18[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-12 21:45.18[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-12 21:45.18[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250512214518[0m
[2m2025-05-12 21:45.18[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-12 21:45.40[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512214518: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002308628559112549, 'time_algorithm_update': 0.005128413915634155, 'loss': 1.8314680714607239, 'time_step': 0.007499238967895508, 'init_value': 4.480113983154297}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-12 21:46.01[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512214518: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002279797077178955, 'time_algorithm_update': 0.004864553451538086, 'loss': 2.345321112811565, 'time_step': 0.00720270037651062, 'init_value': 12.146754264831543}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-12 21:46.22[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512214518: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002289910316467285, 'time_algorithm_update': 0.004944938182830811, 'loss': 2.2417181852459906, 'time_step': 0.007294322729110718, 'init_value': 19.469667434692383}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-12 21:46.44[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512214518: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023542113304138184, 'time_algorithm_update': 0.005023052215576172, 'loss': 2.0735075040459634, 'time_step': 0.007437043190002442, 'init_value': 25.950878143310547}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-12 21:47.05[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512214518: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002302417278289795, 'time_algorithm_update': 0.00511465311050415, 'loss': 1.9935866897106171, 'time_step': 0.0074791028499603274, 'init_value': 31.1898250579834}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-12 21:47.26[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512214518: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002283275365829468, 'time_algorithm_update': 0.004777275085449219, 'loss': 1.7689111567139626, 'time_step': 0.007117583274841309, 'init_value': 33.80763244628906}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-12 21:47.47[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512214518: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023082828521728514, 'time_algorithm_update': 0.0050369324684143065, 'loss': 1.67751443451643, 'time_step': 0.007405938386917115, 'init_value': 35.777767181396484}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-12 21:48.08[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512214518: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022982072830200193, 'time_algorithm_update': 0.00483024787902832, 'loss': 1.5999467973709107, 'time_step': 0.0071867799758911135, 'init_value': 37.312747955322266}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-12 21:48.30[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512214518: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002338245153427124, 'time_algorithm_update': 0.005089013576507568, 'loss': 1.662295113503933, 'time_step': 0.007488341331481934, 'init_value': 39.47966003417969}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-12 21:48.51[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512214518: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022245094776153565, 'time_algorithm_update': 0.004647922277450561, 'loss': 1.5152568351030349, 'time_step': 0.006927596807479858, 'init_value': 41.15339279174805}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.15339279174805
Starting 1000 evaluations
avg return on 3 trajectories of agent19: 1186.2552370876633
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-12 22:05.28[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-12 22:05.28[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-12 22:05.29[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-12 22:05.29[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-12 22:05.29[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250512220529[0m
[2m2025-05-12 22:05.29[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-12 22:05.50[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512220529: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00222919225692749, 'time_algorithm_update': 0.00477589225769043, 'loss': 1.8700646819993854, 'time_step': 0.007062597990036011, 'init_value': 4.555732727050781}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-12 22:06.11[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512220529: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002222397804260254, 'time_algorithm_update': 0.004777099609375, 'loss': 2.2217306511998176, 'time_step': 0.007056233882904053, 'init_value': 10.443427085876465}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-12 22:06.31[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512220529: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022222371101379393, 'time_algorithm_update': 0.00476134729385376, 'loss': 2.2469897601008415, 'time_step': 0.007040903806686401, 'init_value': 18.329633712768555}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-12 22:06.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512220529: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023077964782714845, 'time_algorithm_update': 0.005077167272567749, 'loss': 2.032698083400726, 'time_step': 0.00744700574874878, 'init_value': 24.93229103088379}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-12 22:07.13[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512220529: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002246782064437866, 'time_algorithm_update': 0.004836637258529663, 'loss': 1.8734571607112884, 'time_step': 0.007141731023788452, 'init_value': 29.157766342163086}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-12 22:07.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512220529: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002260768175125122, 'time_algorithm_update': 0.004808223485946656, 'loss': 1.7290873275399208, 'time_step': 0.007127098321914673, 'init_value': 32.841575622558594}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-12 22:07.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512220529: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002237843036651611, 'time_algorithm_update': 0.004840698003768921, 'loss': 1.669598164319992, 'time_step': 0.007136818647384644, 'init_value': 34.40171813964844}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-12 22:08.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512220529: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002322878360748291, 'time_algorithm_update': 0.005035547494888305, 'loss': 1.6501740602254868, 'time_step': 0.007420120000839234, 'init_value': 36.66166687011719}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-12 22:08.37[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512220529: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022319545745849607, 'time_algorithm_update': 0.004773869037628174, 'loss': 1.514291895210743, 'time_step': 0.007063326120376587, 'init_value': 37.98442840576172}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-12 22:08.58[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512220529: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022256548404693604, 'time_algorithm_update': 0.0047754313945770266, 'loss': 1.4852784481048584, 'time_step': 0.007058494806289673, 'init_value': 39.617645263671875}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 39.617645263671875
ave advantage rew: 41.45474624633789, std: 0.9644430327649085
avg cum rews: 1223.1436679127883, std: 36.557431380670195
Pearson correlation coefficient: 0.13114309764844106
Spearman correlation coefficient: 0.1699248120300752
Kendall Tau correlation coefficient: 0.10526315789473685
the best agent: 11, best agent cum rewards: 1267.7306406933412
1957
Starting to collect rollouts
Collecting rollouts: 10000/1000000
Collecting rollouts: 20000/1000000
Collecting rollouts: 30000/1000000
Collecting rollouts: 40000/1000000
Collecting rollouts: 50000/1000000
Collecting rollouts: 60000/1000000
Collecting rollouts: 70000/1000000
Collecting rollouts: 80000/1000000
Collecting rollouts: 90000/1000000
Collecting rollouts: 100000/1000000
Collecting rollouts: 110000/1000000
Collecting rollouts: 120000/1000000
Collecting rollouts: 130000/1000000
Collecting rollouts: 140000/1000000
Collecting rollouts: 150000/1000000
Collecting rollouts: 160000/1000000
Collecting rollouts: 170000/1000000
Collecting rollouts: 180000/1000000
Collecting rollouts: 190000/1000000
Collecting rollouts: 200000/1000000
Collecting rollouts: 210000/1000000
Collecting rollouts: 220000/1000000
Collecting rollouts: 230000/1000000
Collecting rollouts: 240000/1000000
Collecting rollouts: 250000/1000000
Collecting rollouts: 260000/1000000
Collecting rollouts: 270000/1000000
Collecting rollouts: 280000/1000000
Collecting rollouts: 290000/1000000
Collecting rollouts: 300000/1000000
Collecting rollouts: 310000/1000000
Collecting rollouts: 320000/1000000
Collecting rollouts: 330000/1000000
Collecting rollouts: 340000/1000000
Collecting rollouts: 350000/1000000
Collecting rollouts: 360000/1000000
Collecting rollouts: 370000/1000000
Collecting rollouts: 380000/1000000
Collecting rollouts: 390000/1000000
Collecting rollouts: 400000/1000000
Collecting rollouts: 410000/1000000
Collecting rollouts: 420000/1000000
Collecting rollouts: 430000/1000000
Collecting rollouts: 440000/1000000
Collecting rollouts: 450000/1000000
Collecting rollouts: 460000/1000000
Collecting rollouts: 470000/1000000
Collecting rollouts: 480000/1000000
Collecting rollouts: 490000/1000000
Collecting rollouts: 500000/1000000
Collecting rollouts: 510000/1000000
Collecting rollouts: 520000/1000000
Collecting rollouts: 530000/1000000
Collecting rollouts: 540000/1000000
Collecting rollouts: 550000/1000000
Collecting rollouts: 560000/1000000
Collecting rollouts: 570000/1000000
Collecting rollouts: 580000/1000000
Collecting rollouts: 590000/1000000
Collecting rollouts: 600000/1000000
Collecting rollouts: 610000/1000000
Collecting rollouts: 620000/1000000
Collecting rollouts: 630000/1000000
Collecting rollouts: 640000/1000000
Collecting rollouts: 650000/1000000
Collecting rollouts: 660000/1000000
Collecting rollouts: 670000/1000000
Collecting rollouts: 680000/1000000
Collecting rollouts: 690000/1000000
Collecting rollouts: 700000/1000000
Collecting rollouts: 710000/1000000
Collecting rollouts: 720000/1000000
Collecting rollouts: 730000/1000000
Collecting rollouts: 740000/1000000
Collecting rollouts: 750000/1000000
Collecting rollouts: 760000/1000000
Collecting rollouts: 770000/1000000
Collecting rollouts: 780000/1000000
Collecting rollouts: 790000/1000000
Collecting rollouts: 800000/1000000
Collecting rollouts: 810000/1000000
Collecting rollouts: 820000/1000000
Collecting rollouts: 830000/1000000
Collecting rollouts: 840000/1000000
Collecting rollouts: 850000/1000000
Collecting rollouts: 860000/1000000
Collecting rollouts: 870000/1000000
Collecting rollouts: 880000/1000000
Collecting rollouts: 890000/1000000
Collecting rollouts: 900000/1000000
Collecting rollouts: 910000/1000000
Collecting rollouts: 920000/1000000
Collecting rollouts: 930000/1000000
Collecting rollouts: 940000/1000000
Collecting rollouts: 950000/1000000
Collecting rollouts: 960000/1000000
Collecting rollouts: 970000/1000000
Collecting rollouts: 980000/1000000
Collecting rollouts: 990000/1000000
Collecting rollouts: 1000000/1000000
Replay buffer size:  (1000000, 105)
Replay buffer saved
---------------------------------
Searching empty space policies
(10, 11472)
(20, 11472)
(20, 11472)
Average distance of agents to nearest neighbors: 0.01894473488752206
Starting 1000 evaluations
avg return on 3 trajectories of agent0: 1264.2757848907993
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-12 22:44.46[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-12 22:44.46[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-12 22:44.47[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-12 22:44.47[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-12 22:44.47[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250512224447[0m
[2m2025-05-12 22:44.47[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-12 22:45.08[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512224447: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002262904167175293, 'time_algorithm_update': 0.004989713907241821, 'loss': 1.6091901744157076, 'time_step': 0.007312989950180053, 'init_value': 4.486757278442383}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-12 22:45.29[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512224447: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002258711338043213, 'time_algorithm_update': 0.004871861696243286, 'loss': 2.3137045023441316, 'time_step': 0.007189922094345093, 'init_value': 10.558244705200195}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-12 22:45.49[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512224447: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022284657955169676, 'time_algorithm_update': 0.004608712434768677, 'loss': 2.2536860291957854, 'time_step': 0.006892313957214355, 'init_value': 18.122209548950195}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-12 22:46.10[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512224447: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022853066921234132, 'time_algorithm_update': 0.004751852989196777, 'loss': 2.1029001487493515, 'time_step': 0.007094057083129883, 'init_value': 25.48055076599121}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-12 22:46.31[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512224447: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002287809371948242, 'time_algorithm_update': 0.00498506760597229, 'loss': 1.8841070110201836, 'time_step': 0.007333522319793701, 'init_value': 29.159151077270508}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-12 22:46.52[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512224447: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023192148208618165, 'time_algorithm_update': 0.005063966035842895, 'loss': 1.7964782113432884, 'time_step': 0.007444161653518677, 'init_value': 32.216495513916016}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-12 22:47.13[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512224447: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002216949701309204, 'time_algorithm_update': 0.0047144672870635985, 'loss': 1.703421378135681, 'time_step': 0.0069877967834472655, 'init_value': 36.7518196105957}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-12 22:47.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512224447: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022697815895080567, 'time_algorithm_update': 0.004846840381622314, 'loss': 1.6472874571084977, 'time_step': 0.007174631595611572, 'init_value': 38.151241302490234}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-12 22:47.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512224447: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002254451274871826, 'time_algorithm_update': 0.004826217412948608, 'loss': 1.6646308774352074, 'time_step': 0.007139174461364746, 'init_value': 40.44845199584961}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-12 22:48.16[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512224447: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002317451477050781, 'time_algorithm_update': 0.004925410270690918, 'loss': 1.7595760534405709, 'time_step': 0.0073025283813476565, 'init_value': 41.7064323425293}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.7064323425293
Starting 1000 evaluations
avg return on 3 trajectories of agent1: 1248.990629046946
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-12 23:04.51[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-12 23:04.51[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-12 23:04.53[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-12 23:04.53[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-12 23:04.53[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250512230453[0m
[2m2025-05-12 23:04.53[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-12 23:05.13[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512230453: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002233271598815918, 'time_algorithm_update': 0.00483140230178833, 'loss': 1.614913836851716, 'time_step': 0.007122504472732544, 'init_value': 4.414488315582275}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-12 23:05.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512230453: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021634116172790526, 'time_algorithm_update': 0.004557347774505615, 'loss': 2.291364829182625, 'time_step': 0.006774998188018798, 'init_value': 11.352307319641113}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-12 23:05.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512230453: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002314020872116089, 'time_algorithm_update': 0.004990718126296997, 'loss': 2.247919247746468, 'time_step': 0.007364313364028931, 'init_value': 18.52284812927246}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-12 23:06.16[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512230453: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002257248878479004, 'time_algorithm_update': 0.0048959097862243655, 'loss': 1.9753284217715263, 'time_step': 0.00721151328086853, 'init_value': 25.461462020874023}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-12 23:06.36[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512230453: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002305532693862915, 'time_algorithm_update': 0.004935773849487304, 'loss': 1.8417063126564026, 'time_step': 0.007300283193588257, 'init_value': 30.371028900146484}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-12 23:06.57[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512230453: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002250934362411499, 'time_algorithm_update': 0.004756439924240113, 'loss': 1.8206468482017517, 'time_step': 0.007067631006240845, 'init_value': 33.40660858154297}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-12 23:07.18[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512230453: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022749969959259034, 'time_algorithm_update': 0.004973040580749512, 'loss': 1.7079448879361152, 'time_step': 0.007307305574417115, 'init_value': 36.260066986083984}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-12 23:07.39[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512230453: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022540462017059328, 'time_algorithm_update': 0.004953569889068603, 'loss': 1.6176563645601272, 'time_step': 0.007267231225967407, 'init_value': 37.74177932739258}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-12 23:08.00[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512230453: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022301721572875978, 'time_algorithm_update': 0.00482860803604126, 'loss': 1.6269761207699776, 'time_step': 0.007116300106048584, 'init_value': 40.63956832885742}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-12 23:08.21[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512230453: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022717909812927247, 'time_algorithm_update': 0.004819284677505493, 'loss': 1.585365878880024, 'time_step': 0.007148809194564819, 'init_value': 41.49698257446289}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.49698257446289
Starting 1000 evaluations
avg return on 3 trajectories of agent2: 1235.9890408927818
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-12 23:24.59[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-12 23:24.59[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-12 23:25.00[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-12 23:25.00[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-12 23:25.00[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250512232500[0m
[2m2025-05-12 23:25.00[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-12 23:25.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512232500: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002254444599151611, 'time_algorithm_update': 0.0049153432846069335, 'loss': 1.8342498515173793, 'time_step': 0.007228898525238037, 'init_value': 4.560292720794678}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-12 23:25.41[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512232500: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022869734764099123, 'time_algorithm_update': 0.0048332102298736575, 'loss': 2.392560115516186, 'time_step': 0.007178261280059815, 'init_value': 10.790831565856934}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-12 23:26.02[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512232500: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002230766296386719, 'time_algorithm_update': 0.004799087047576905, 'loss': 2.190507533669472, 'time_step': 0.007086788177490234, 'init_value': 18.238040924072266}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-12 23:26.23[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512232500: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022858905792236327, 'time_algorithm_update': 0.004876667022705078, 'loss': 2.091973825752735, 'time_step': 0.007221077680587769, 'init_value': 24.62030029296875}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-12 23:26.44[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512232500: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022782413959503175, 'time_algorithm_update': 0.004914311170578003, 'loss': 1.951481884598732, 'time_step': 0.007251776695251465, 'init_value': 29.304990768432617}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-12 23:27.04[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512232500: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00229181694984436, 'time_algorithm_update': 0.004825373888015747, 'loss': 1.8317361343502998, 'time_step': 0.007174967527389526, 'init_value': 32.4734992980957}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-12 23:27.25[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512232500: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022504019737243654, 'time_algorithm_update': 0.004817967414855957, 'loss': 1.7520118475556374, 'time_step': 0.007126274108886718, 'init_value': 36.76374816894531}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-12 23:27.46[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512232500: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022691013813018798, 'time_algorithm_update': 0.004930167436599731, 'loss': 1.8200176656246185, 'time_step': 0.007258635997772217, 'init_value': 39.026145935058594}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-12 23:28.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512232500: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022956411838531495, 'time_algorithm_update': 0.005003605127334595, 'loss': 1.6517530465126038, 'time_step': 0.007359177827835083, 'init_value': 40.465702056884766}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-12 23:28.28[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512232500: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00228264594078064, 'time_algorithm_update': 0.004737308740615845, 'loss': 1.669535898566246, 'time_step': 0.007076764822006225, 'init_value': 42.56217956542969}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.56217956542969
Starting 1000 evaluations
avg return on 3 trajectories of agent3: 1216.6771135524125
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-12 23:45.06[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-12 23:45.06[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-12 23:45.08[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-12 23:45.08[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-12 23:45.08[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250512234508[0m
[2m2025-05-12 23:45.08[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-12 23:45.28[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512234508: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022317795753479005, 'time_algorithm_update': 0.004834964036941529, 'loss': 1.6700592461302877, 'time_step': 0.007123950958251953, 'init_value': 4.55997371673584}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-12 23:45.49[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512234508: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002263106107711792, 'time_algorithm_update': 0.004955142974853516, 'loss': 2.212214890062809, 'time_step': 0.007278027772903442, 'init_value': 11.159492492675781}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-12 23:46.10[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512234508: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022485690116882326, 'time_algorithm_update': 0.0048298599720001225, 'loss': 2.1900282709002497, 'time_step': 0.00713673996925354, 'init_value': 19.515079498291016}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-12 23:46.31[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512234508: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023139331340789795, 'time_algorithm_update': 0.004858919858932495, 'loss': 2.0011991869211196, 'time_step': 0.007231218814849854, 'init_value': 25.062091827392578}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-12 23:46.52[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512234508: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022571780681610106, 'time_algorithm_update': 0.00484316611289978, 'loss': 1.8855728169679642, 'time_step': 0.007158137559890747, 'init_value': 28.960159301757812}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-12 23:47.12[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512234508: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023212311267852784, 'time_algorithm_update': 0.004903149127960205, 'loss': 1.7675359415411949, 'time_step': 0.007283196210861206, 'init_value': 32.58065414428711}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-12 23:47.33[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512234508: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022946698665618896, 'time_algorithm_update': 0.0049778993129730225, 'loss': 1.7653920137286185, 'time_step': 0.007332371234893799, 'init_value': 35.78739547729492}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-12 23:47.54[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512234508: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002255777835845947, 'time_algorithm_update': 0.004698445320129394, 'loss': 1.6753700390458106, 'time_step': 0.007010592937469483, 'init_value': 36.234039306640625}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-12 23:48.15[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512234508: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022728745937347413, 'time_algorithm_update': 0.004873061895370483, 'loss': 1.5852687078118324, 'time_step': 0.007204442024230957, 'init_value': 38.88180923461914}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-12 23:48.36[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250512234508: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022707488536834715, 'time_algorithm_update': 0.004907289743423462, 'loss': 1.716968454003334, 'time_step': 0.007237107038497925, 'init_value': 41.137847900390625}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.137847900390625
Starting 1000 evaluations
avg return on 3 trajectories of agent4: 1261.9290413420256
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 00:05.24[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 00:05.24[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 00:05.25[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 00:05.25[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 00:05.25[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513000525[0m
[2m2025-05-13 00:05.25[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 00:05.46[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513000525: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022692420482635497, 'time_algorithm_update': 0.004837371826171875, 'loss': 1.6931084601208568, 'time_step': 0.007164843082427978, 'init_value': 4.1601338386535645}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 00:06.08[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513000525: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023130836486816406, 'time_algorithm_update': 0.00490228271484375, 'loss': 2.219994547009468, 'time_step': 0.007274425029754639, 'init_value': 10.535354614257812}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 00:06.29[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513000525: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022684726715087892, 'time_algorithm_update': 0.0048315560817718504, 'loss': 2.322652714073658, 'time_step': 0.007157973527908325, 'init_value': 17.53809356689453}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 00:06.51[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513000525: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023594655990600588, 'time_algorithm_update': 0.005129480123519897, 'loss': 2.133010556936264, 'time_step': 0.007550704002380371, 'init_value': 24.790695190429688}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 00:07.12[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513000525: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023369548320770262, 'time_algorithm_update': 0.004986826419830322, 'loss': 1.9014624696373938, 'time_step': 0.007383412122726441, 'init_value': 29.496116638183594}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 00:07.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513000525: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002305107593536377, 'time_algorithm_update': 0.00497142505645752, 'loss': 1.7779059665203094, 'time_step': 0.007335973024368286, 'init_value': 32.142112731933594}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 00:07.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513000525: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023212935924530028, 'time_algorithm_update': 0.004893800735473633, 'loss': 1.663511552155018, 'time_step': 0.0072739882469177244, 'init_value': 34.53984451293945}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 00:08.16[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513000525: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023133485317230226, 'time_algorithm_update': 0.00507695484161377, 'loss': 1.6348612441420556, 'time_step': 0.007450839281082153, 'init_value': 37.419715881347656}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-13 00:08.38[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513000525: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023653676509857178, 'time_algorithm_update': 0.005052211999893188, 'loss': 1.7089470675587655, 'time_step': 0.007477783203125, 'init_value': 39.302284240722656}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-13 00:08.59[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513000525: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00227085018157959, 'time_algorithm_update': 0.004875905752182007, 'loss': 1.665380782544613, 'time_step': 0.007205147743225098, 'init_value': 40.34233474731445}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.34233474731445
Starting 1000 evaluations
avg return on 3 trajectories of agent5: 1239.8278003038038
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 00:26.06[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 00:26.06[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 00:26.07[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 00:26.07[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 00:26.07[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513002607[0m
[2m2025-05-13 00:26.07[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 00:26.28[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513002607: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002273787021636963, 'time_algorithm_update': 0.004731101989746094, 'loss': 1.538050517514348, 'time_step': 0.007062114953994751, 'init_value': 4.372695446014404}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 00:26.49[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513002607: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023003702163696287, 'time_algorithm_update': 0.004731295824050903, 'loss': 2.443282849431038, 'time_step': 0.007088565111160279, 'init_value': 10.60621452331543}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 00:27.11[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513002607: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023553845882415773, 'time_algorithm_update': 0.0050519294738769534, 'loss': 2.334346388399601, 'time_step': 0.007468699932098389, 'init_value': 17.9537410736084}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 00:27.32[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513002607: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023642199039459228, 'time_algorithm_update': 0.004913665533065796, 'loss': 2.012132598936558, 'time_step': 0.007337619543075561, 'init_value': 24.972963333129883}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 00:27.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513002607: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022989110946655274, 'time_algorithm_update': 0.004816530227661132, 'loss': 1.8666785416007041, 'time_step': 0.0071734988689422605, 'init_value': 29.549131393432617}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 00:28.15[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513002607: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002354980707168579, 'time_algorithm_update': 0.004820313692092896, 'loss': 1.7606750549674035, 'time_step': 0.007233476877212525, 'init_value': 33.23042297363281}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 00:28.36[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513002607: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023448212146759033, 'time_algorithm_update': 0.005054012298583984, 'loss': 1.8291434875130654, 'time_step': 0.007460370779037475, 'init_value': 36.36507797241211}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 00:28.57[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513002607: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023091390132904052, 'time_algorithm_update': 0.004830578088760376, 'loss': 1.630192848443985, 'time_step': 0.007197987556457519, 'init_value': 38.69452667236328}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-13 00:29.18[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513002607: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023585410118103028, 'time_algorithm_update': 0.004816981792449951, 'loss': 1.5611929119825363, 'time_step': 0.007239797353744507, 'init_value': 40.81673812866211}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-13 00:29.40[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513002607: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023462793827056885, 'time_algorithm_update': 0.005013797998428345, 'loss': 1.5964234887361526, 'time_step': 0.00742076587677002, 'init_value': 42.045955657958984}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.045955657958984
Starting 1000 evaluations
avg return on 3 trajectories of agent6: 1220.868503049776
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 00:46.49[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 00:46.49[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 00:46.51[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 00:46.51[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 00:46.51[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513004651[0m
[2m2025-05-13 00:46.51[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 00:47.12[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513004651: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002295325756072998, 'time_algorithm_update': 0.005013865232467651, 'loss': 1.5657561774104833, 'time_step': 0.007370545864105225, 'init_value': 4.550044536590576}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 00:47.32[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513004651: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002268399715423584, 'time_algorithm_update': 0.0045903799533843995, 'loss': 2.3031406285762785, 'time_step': 0.006914999485015869, 'init_value': 10.746194839477539}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 00:47.54[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513004651: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002265259027481079, 'time_algorithm_update': 0.0047678184509277344, 'loss': 2.1698883168101313, 'time_step': 0.0070900051593780515, 'init_value': 17.589765548706055}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 00:48.15[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513004651: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023089370727539063, 'time_algorithm_update': 0.004947654962539673, 'loss': 2.1088408421874045, 'time_step': 0.007316051721572876, 'init_value': 23.884336471557617}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 00:48.37[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513004651: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002360060691833496, 'time_algorithm_update': 0.004985862493515015, 'loss': 1.9008536983728408, 'time_step': 0.007406051397323608, 'init_value': 28.97825050354004}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 00:48.57[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513004651: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022363829612731933, 'time_algorithm_update': 0.00461431884765625, 'loss': 1.8126187422275544, 'time_step': 0.006906304597854614, 'init_value': 33.027400970458984}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 00:49.19[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513004651: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002336419105529785, 'time_algorithm_update': 0.004841592073440552, 'loss': 1.6260234336853028, 'time_step': 0.007235933780670166, 'init_value': 35.56393814086914}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 00:49.40[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513004651: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023035454750061036, 'time_algorithm_update': 0.005238223552703858, 'loss': 1.7843738632202149, 'time_step': 0.007605025291442871, 'init_value': 36.858402252197266}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-13 00:50.01[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513004651: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023261876106262206, 'time_algorithm_update': 0.004785458564758301, 'loss': 1.5861793785095215, 'time_step': 0.007169761180877685, 'init_value': 38.23369598388672}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-13 00:50.22[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513004651: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022533020973205566, 'time_algorithm_update': 0.004639475107192993, 'loss': 1.5217325147986411, 'time_step': 0.006948743581771851, 'init_value': 39.87775421142578}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 39.87775421142578
Starting 1000 evaluations
avg return on 3 trajectories of agent7: 1193.1321531627718
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 01:07.29[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 01:07.29[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 01:07.31[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 01:07.31[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 01:07.31[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513010731[0m
[2m2025-05-13 01:07.31[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 01:07.51[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513010731: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022692105770111084, 'time_algorithm_update': 0.004704218864440918, 'loss': 1.6602605821564793, 'time_step': 0.007030098438262939, 'init_value': 4.421870708465576}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 01:08.13[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513010731: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023937301635742186, 'time_algorithm_update': 0.005031218290328979, 'loss': 2.3695487713217736, 'time_step': 0.007485541105270385, 'init_value': 10.774248123168945}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 01:08.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513010731: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002347597599029541, 'time_algorithm_update': 0.005074217557907105, 'loss': 2.4561865321397782, 'time_step': 0.007482835292816162, 'init_value': 18.164127349853516}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 01:08.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513010731: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022671847343444826, 'time_algorithm_update': 0.004682886600494385, 'loss': 2.057763723611832, 'time_step': 0.007005691289901733, 'init_value': 24.7874698638916}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 01:09.16[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513010731: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022515416145324706, 'time_algorithm_update': 0.004671510457992554, 'loss': 1.918638738811016, 'time_step': 0.006978561162948608, 'init_value': 28.76736831665039}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 01:09.38[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513010731: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002380394697189331, 'time_algorithm_update': 0.005056553602218628, 'loss': 1.8653862511515618, 'time_step': 0.007497671842575073, 'init_value': 32.584449768066406}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 01:10.00[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513010731: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023923935890197753, 'time_algorithm_update': 0.005137231111526489, 'loss': 1.721038050889969, 'time_step': 0.007591432332992554, 'init_value': 35.015380859375}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 01:10.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513010731: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002277775526046753, 'time_algorithm_update': 0.004745038747787475, 'loss': 1.654733802318573, 'time_step': 0.007079499959945679, 'init_value': 37.07802963256836}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-13 01:10.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513010731: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023664581775665284, 'time_algorithm_update': 0.0049284036159515385, 'loss': 1.6044749131202698, 'time_step': 0.007353457689285278, 'init_value': 39.707088470458984}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-13 01:11.04[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513010731: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023610055446624755, 'time_algorithm_update': 0.00519394588470459, 'loss': 1.6086354258656501, 'time_step': 0.007617702722549438, 'init_value': 41.75333786010742}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.75333786010742
Starting 1000 evaluations
avg return on 3 trajectories of agent8: 1260.1436138219894
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 01:28.09[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 01:28.09[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 01:28.10[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 01:28.10[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 01:28.10[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513012810[0m
[2m2025-05-13 01:28.10[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 01:28.31[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513012810: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002305105686187744, 'time_algorithm_update': 0.005029083251953125, 'loss': 1.6854561354145408, 'time_step': 0.007395721912384033, 'init_value': 4.184542655944824}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 01:28.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513012810: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002328266143798828, 'time_algorithm_update': 0.004888203859329224, 'loss': 2.2682862883806227, 'time_step': 0.007275823354721069, 'init_value': 10.713641166687012}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 01:29.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513012810: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023059453964233397, 'time_algorithm_update': 0.004966138124465942, 'loss': 2.311541867673397, 'time_step': 0.0073310317993164065, 'init_value': 18.745708465576172}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 01:29.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513012810: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002292541742324829, 'time_algorithm_update': 0.004706773281097412, 'loss': 2.1708455703258513, 'time_step': 0.0070555419921875, 'init_value': 25.413562774658203}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 01:29.56[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513012810: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023736798763275145, 'time_algorithm_update': 0.005042640447616577, 'loss': 1.8964676696062088, 'time_step': 0.007476778030395508, 'init_value': 29.26694107055664}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 01:30.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513012810: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002279705286026001, 'time_algorithm_update': 0.004863215684890747, 'loss': 1.8244197978377341, 'time_step': 0.0072011837959289554, 'init_value': 32.93571090698242}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 01:30.39[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513012810: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00236665415763855, 'time_algorithm_update': 0.005002300024032593, 'loss': 1.7043431691527366, 'time_step': 0.007429047584533692, 'init_value': 35.76097869873047}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 01:31.00[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513012810: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002302299976348877, 'time_algorithm_update': 0.004921161890029907, 'loss': 1.7135171540975571, 'time_step': 0.007282550573348999, 'init_value': 38.044925689697266}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-13 01:31.22[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513012810: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002346889495849609, 'time_algorithm_update': 0.005029105901718139, 'loss': 1.6145899780988693, 'time_step': 0.0074370458126068115, 'init_value': 39.73637771606445}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-13 01:31.43[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513012810: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023029839992523195, 'time_algorithm_update': 0.004867583990097046, 'loss': 1.704725829720497, 'time_step': 0.007228793621063233, 'init_value': 41.69880676269531}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.69880676269531
Starting 1000 evaluations
avg return on 3 trajectories of agent9: 1293.5374391115379
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 01:48.50[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 01:48.50[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 01:48.52[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 01:48.52[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 01:48.52[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513014852[0m
[2m2025-05-13 01:48.52[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 01:49.13[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513014852: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022891092300415038, 'time_algorithm_update': 0.0049739952087402345, 'loss': 1.6736814056411387, 'time_step': 0.007323651075363159, 'init_value': 4.149158000946045}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 01:49.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513014852: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002268849611282349, 'time_algorithm_update': 0.004720553874969482, 'loss': 2.1158236115574836, 'time_step': 0.007046498775482178, 'init_value': 11.236442565917969}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 01:49.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513014852: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023016083240509034, 'time_algorithm_update': 0.004891699075698853, 'loss': 2.3055783802866934, 'time_step': 0.007253511905670166, 'init_value': 18.86463165283203}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 01:50.16[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513014852: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023254737854003908, 'time_algorithm_update': 0.00487541937828064, 'loss': 2.1118158422708513, 'time_step': 0.007259829521179199, 'init_value': 24.982746124267578}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 01:50.37[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513014852: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002279228448867798, 'time_algorithm_update': 0.004801776885986328, 'loss': 1.9022415002584458, 'time_step': 0.007139631748199463, 'init_value': 30.16594696044922}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 01:50.59[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513014852: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002331531286239624, 'time_algorithm_update': 0.004842354536056519, 'loss': 1.899970476448536, 'time_step': 0.007232701539993286, 'init_value': 33.17837905883789}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 01:51.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513014852: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023037595748901366, 'time_algorithm_update': 0.004831256151199341, 'loss': 1.8665571050047876, 'time_step': 0.0071939613819122315, 'init_value': 35.78441619873047}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 01:51.41[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513014852: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023837273120880125, 'time_algorithm_update': 0.005049553394317627, 'loss': 1.7159180351495742, 'time_step': 0.007495024919509888, 'init_value': 38.17488479614258}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-13 01:52.02[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513014852: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022787024974823, 'time_algorithm_update': 0.004768682241439819, 'loss': 1.7615552879571914, 'time_step': 0.007105308771133423, 'init_value': 40.16746520996094}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-13 01:52.23[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513014852: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023175861835479736, 'time_algorithm_update': 0.005011854887008667, 'loss': 1.6429065952897073, 'time_step': 0.007390542030334473, 'init_value': 41.19466018676758}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.19466018676758
Starting 1000 evaluations
avg return on 3 trajectories of agent10: 1334.136333928094
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 02:09.28[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 02:09.28[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 02:09.30[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 02:09.30[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 02:09.30[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513020930[0m
[2m2025-05-13 02:09.30[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 02:09.51[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513020930: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002316303014755249, 'time_algorithm_update': 0.00500662112236023, 'loss': 1.710726176649332, 'time_step': 0.007383729934692383, 'init_value': 4.303765773773193}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 02:10.12[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513020930: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022974987030029296, 'time_algorithm_update': 0.00470083475112915, 'loss': 2.264689190208912, 'time_step': 0.007054636001586914, 'init_value': 10.89695930480957}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 02:10.33[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513020930: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023029320240020752, 'time_algorithm_update': 0.004816416501998901, 'loss': 2.2706889562010764, 'time_step': 0.007176613807678223, 'init_value': 17.812522888183594}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 02:10.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513020930: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023568239212036135, 'time_algorithm_update': 0.004937885999679565, 'loss': 2.0858240222334863, 'time_step': 0.00735383653640747, 'init_value': 25.01321029663086}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 02:11.16[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513020930: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002346167325973511, 'time_algorithm_update': 0.005099194288253784, 'loss': 2.003485088467598, 'time_step': 0.007506907224655151, 'init_value': 30.247440338134766}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 02:11.37[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513020930: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023570077419281005, 'time_algorithm_update': 0.00495399022102356, 'loss': 1.9173745710253716, 'time_step': 0.0073700034618377685, 'init_value': 33.56721115112305}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 02:11.58[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513020930: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00230346417427063, 'time_algorithm_update': 0.004882388353347779, 'loss': 1.7038442283272743, 'time_step': 0.007243576765060425, 'init_value': 34.785884857177734}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 02:12.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513020930: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023342502117156983, 'time_algorithm_update': 0.0051402530670166015, 'loss': 1.6475596997141837, 'time_step': 0.007536184549331665, 'init_value': 36.65412139892578}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-13 02:12.41[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513020930: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002359550714492798, 'time_algorithm_update': 0.004915121078491211, 'loss': 1.6769295545220375, 'time_step': 0.007333108901977539, 'init_value': 39.35862350463867}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-13 02:13.02[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513020930: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023094773292541503, 'time_algorithm_update': 0.004832547903060913, 'loss': 1.6060660113692284, 'time_step': 0.007199459075927735, 'init_value': 39.86186599731445}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 39.86186599731445
Starting 1000 evaluations
avg return on 3 trajectories of agent11: 1362.6242499505192
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 02:30.05[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 02:30.05[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 02:30.06[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 02:30.06[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 02:30.06[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513023006[0m
[2m2025-05-13 02:30.06[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 02:30.26[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513023006: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022295191287994387, 'time_algorithm_update': 0.004614452600479126, 'loss': 1.684710287325084, 'time_step': 0.006899080038070679, 'init_value': 4.093544006347656}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 02:30.48[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513023006: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002339150667190552, 'time_algorithm_update': 0.0048225345611572264, 'loss': 2.224019146203995, 'time_step': 0.007219257116317749, 'init_value': 10.202271461486816}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 02:31.10[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513023006: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023369460105895994, 'time_algorithm_update': 0.00524132490158081, 'loss': 2.370963611841202, 'time_step': 0.007641507863998413, 'init_value': 16.685379028320312}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 02:31.31[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513023006: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023159329891204836, 'time_algorithm_update': 0.004887676954269409, 'loss': 2.0982384169697763, 'time_step': 0.0072623975276947025, 'init_value': 24.262775421142578}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 02:31.51[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513023006: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022572903633117677, 'time_algorithm_update': 0.0047153313159942626, 'loss': 1.9619647579193116, 'time_step': 0.00702877688407898, 'init_value': 28.457643508911133}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 02:32.13[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513023006: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002337414741516113, 'time_algorithm_update': 0.004853727340698243, 'loss': 1.7468893652558326, 'time_step': 0.007248727321624756, 'init_value': 32.21745681762695}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 02:32.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513023006: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023893272876739503, 'time_algorithm_update': 0.005214202642440796, 'loss': 1.72925386595726, 'time_step': 0.007666106462478638, 'init_value': 34.94772720336914}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 02:32.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513023006: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022939321994781495, 'time_algorithm_update': 0.0048265869617462155, 'loss': 1.7511121643185616, 'time_step': 0.007178253650665283, 'init_value': 36.24192810058594}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-13 02:33.16[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513023006: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022961666584014892, 'time_algorithm_update': 0.004711328983306885, 'loss': 1.6644561461806298, 'time_step': 0.007063642263412475, 'init_value': 39.29456329345703}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-13 02:33.38[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513023006: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023076188564300536, 'time_algorithm_update': 0.004992888212203979, 'loss': 1.6031147049069405, 'time_step': 0.007359391212463379, 'init_value': 41.111236572265625}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.111236572265625
Starting 1000 evaluations
avg return on 3 trajectories of agent12: 1253.0299929988075
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 02:50.48[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 02:50.48[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 02:50.49[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 02:50.49[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 02:50.49[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513025049[0m
[2m2025-05-13 02:50.49[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 02:51.10[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513025049: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002261629581451416, 'time_algorithm_update': 0.004644158601760864, 'loss': 1.6688567925021052, 'time_step': 0.0069624648094177245, 'init_value': 4.608739852905273}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 02:51.31[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513025049: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002311997890472412, 'time_algorithm_update': 0.0049719011783599856, 'loss': 2.380559577524662, 'time_step': 0.007344904661178589, 'init_value': 11.908817291259766}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 02:51.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513025049: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002327000141143799, 'time_algorithm_update': 0.004953613519668579, 'loss': 2.186162365913391, 'time_step': 0.007340529680252075, 'init_value': 19.4536075592041}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 02:52.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513025049: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023657307624816892, 'time_algorithm_update': 0.004942431688308716, 'loss': 2.0472295372486116, 'time_step': 0.00736862301826477, 'init_value': 25.333284378051758}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 02:52.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513025049: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022984161376953124, 'time_algorithm_update': 0.0048082747459411625, 'loss': 1.8722977456450463, 'time_step': 0.0071649630069732665, 'init_value': 29.46915054321289}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 02:52.56[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513025049: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002361445188522339, 'time_algorithm_update': 0.004896384000778198, 'loss': 1.743318688929081, 'time_step': 0.007317399024963379, 'init_value': 32.37776565551758}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 02:53.18[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513025049: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002346614122390747, 'time_algorithm_update': 0.00499850869178772, 'loss': 1.6727127582430839, 'time_step': 0.007405863523483276, 'init_value': 35.2510986328125}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 02:53.39[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513025049: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023906891345977783, 'time_algorithm_update': 0.005101936101913452, 'loss': 1.6532516320347785, 'time_step': 0.007554295301437378, 'init_value': 36.493045806884766}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-13 02:54.01[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513025049: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002319972038269043, 'time_algorithm_update': 0.004981668949127197, 'loss': 1.6575622252225877, 'time_step': 0.007362327337265015, 'init_value': 38.09796142578125}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-13 02:54.22[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513025049: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022794110774993896, 'time_algorithm_update': 0.004749025583267212, 'loss': 1.5269345151782037, 'time_step': 0.007086030006408691, 'init_value': 41.20705032348633}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.20705032348633
Starting 1000 evaluations
avg return on 3 trajectories of agent13: 1242.372238481023
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 03:11.31[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 03:11.31[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 03:11.33[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 03:11.33[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 03:11.33[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513031133[0m
[2m2025-05-13 03:11.33[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 03:11.54[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513031133: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002322709798812866, 'time_algorithm_update': 0.005037765502929687, 'loss': 1.6058447197973729, 'time_step': 0.007421684741973877, 'init_value': 4.542726516723633}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 03:12.16[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513031133: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023609278202056886, 'time_algorithm_update': 0.0049146685600280765, 'loss': 2.2516957331895826, 'time_step': 0.0073343346118927, 'init_value': 10.889015197753906}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 03:12.37[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513031133: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023214452266693115, 'time_algorithm_update': 0.0049185256958007816, 'loss': 2.161867551445961, 'time_step': 0.007299253225326538, 'init_value': 18.19215965270996}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 03:12.58[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513031133: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023389363288879392, 'time_algorithm_update': 0.004852674245834351, 'loss': 2.1344975616931916, 'time_step': 0.007249629974365234, 'init_value': 24.453380584716797}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 03:13.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513031133: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00238796067237854, 'time_algorithm_update': 0.005052650451660156, 'loss': 1.868867073714733, 'time_step': 0.007501609086990356, 'init_value': 28.33548927307129}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 03:13.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513031133: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002329164981842041, 'time_algorithm_update': 0.004896939277648926, 'loss': 1.914660604417324, 'time_step': 0.007285032272338867, 'init_value': 32.881107330322266}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 03:14.02[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513031133: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002309140205383301, 'time_algorithm_update': 0.0048535940647125245, 'loss': 1.7951839530467988, 'time_step': 0.007221060276031494, 'init_value': 34.609092712402344}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 03:14.24[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513031133: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023364036083221434, 'time_algorithm_update': 0.004969541788101196, 'loss': 1.6387767007946967, 'time_step': 0.0073660540580749514, 'init_value': 36.7437744140625}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-13 03:14.46[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513031133: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023825981616973878, 'time_algorithm_update': 0.005018953561782837, 'loss': 1.6255002862215042, 'time_step': 0.007462215423583984, 'init_value': 39.4068489074707}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-13 03:15.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513031133: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002333176851272583, 'time_algorithm_update': 0.0049019033908843995, 'loss': 1.665049269914627, 'time_step': 0.007293903112411499, 'init_value': 40.9525260925293}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.9525260925293
Starting 1000 evaluations
avg return on 3 trajectories of agent14: 1227.3393184880158
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 03:32.15[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 03:32.15[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 03:32.17[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 03:32.17[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 03:32.17[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513033217[0m
[2m2025-05-13 03:32.17[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 03:32.38[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513033217: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022609665393829347, 'time_algorithm_update': 0.004714439630508423, 'loss': 1.5775720443800092, 'time_step': 0.007032745361328125, 'init_value': 4.363030910491943}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 03:32.58[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513033217: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023198795318603517, 'time_algorithm_update': 0.004730540752410889, 'loss': 2.291010933935642, 'time_step': 0.007107690095901489, 'init_value': 10.894745826721191}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 03:33.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513033217: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002327777862548828, 'time_algorithm_update': 0.005019587993621826, 'loss': 2.3686347163319588, 'time_step': 0.007408558130264282, 'init_value': 18.738162994384766}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 03:33.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513033217: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023424530029296873, 'time_algorithm_update': 0.004938636064529419, 'loss': 2.170606245338917, 'time_step': 0.007341900587081909, 'init_value': 24.007360458374023}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 03:34.03[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513033217: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002329216957092285, 'time_algorithm_update': 0.0049676005840301515, 'loss': 1.8822705189585687, 'time_step': 0.007357145309448242, 'init_value': 30.11794662475586}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 03:34.24[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513033217: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002283745765686035, 'time_algorithm_update': 0.0046750249862670895, 'loss': 1.8260361046791076, 'time_step': 0.007015105485916138, 'init_value': 33.40673828125}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 03:34.46[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513033217: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023408067226409913, 'time_algorithm_update': 0.005021228551864624, 'loss': 1.7934539190530776, 'time_step': 0.007423047065734863, 'init_value': 36.2511100769043}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 03:35.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513033217: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00227590274810791, 'time_algorithm_update': 0.004788824081420898, 'loss': 1.8138713750839233, 'time_step': 0.0071227879524230955, 'init_value': 38.534217834472656}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-13 03:35.28[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513033217: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023229382038116456, 'time_algorithm_update': 0.004795099973678589, 'loss': 1.7490443729162217, 'time_step': 0.0071763875484466555, 'init_value': 41.473716735839844}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-13 03:35.49[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513033217: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022764596939086916, 'time_algorithm_update': 0.0047943670749664305, 'loss': 1.6895483875870705, 'time_step': 0.007130493879318237, 'init_value': 42.29185104370117}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.29185104370117
Starting 1000 evaluations
avg return on 3 trajectories of agent15: 1213.4630889550879
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 03:52.56[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 03:52.56[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 03:52.57[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 03:52.57[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 03:52.57[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513035257[0m
[2m2025-05-13 03:52.57[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 03:53.18[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513035257: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022209978103637697, 'time_algorithm_update': 0.004576086759567261, 'loss': 1.7180998556688427, 'time_step': 0.0068517720699310305, 'init_value': 4.341927528381348}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 03:53.39[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513035257: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002352682113647461, 'time_algorithm_update': 0.004950611352920532, 'loss': 2.1551969460248945, 'time_step': 0.007363232135772705, 'init_value': 10.94844913482666}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 03:54.01[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513035257: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002266296625137329, 'time_algorithm_update': 0.004791035413742066, 'loss': 2.22267700445652, 'time_step': 0.00711512565612793, 'init_value': 17.881677627563477}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 03:54.22[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513035257: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023102035522460937, 'time_algorithm_update': 0.005036351203918457, 'loss': 1.9933450634479524, 'time_step': 0.007407602310180664, 'init_value': 24.71475601196289}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 03:54.43[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513035257: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022458016872406008, 'time_algorithm_update': 0.004731405973434449, 'loss': 1.9751871472597122, 'time_step': 0.0070339031219482425, 'init_value': 30.166763305664062}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 03:55.05[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513035257: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023515055179595947, 'time_algorithm_update': 0.005109565019607544, 'loss': 1.8121608350872993, 'time_step': 0.00752315902709961, 'init_value': 33.46099853515625}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 03:55.26[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513035257: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023249502182006838, 'time_algorithm_update': 0.0048915517330169675, 'loss': 1.715659164726734, 'time_step': 0.007275737285614013, 'init_value': 35.20758819580078}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 03:55.47[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513035257: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002302647352218628, 'time_algorithm_update': 0.004882387161254883, 'loss': 1.6593929277062416, 'time_step': 0.007244160413742065, 'init_value': 37.385154724121094}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-13 03:56.08[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513035257: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022928595542907717, 'time_algorithm_update': 0.004730093955993653, 'loss': 1.5646899205446243, 'time_step': 0.007080697059631348, 'init_value': 39.527191162109375}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-13 03:56.30[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513035257: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023161132335662842, 'time_algorithm_update': 0.005018944501876831, 'loss': 1.6520058405399323, 'time_step': 0.007395169734954834, 'init_value': 41.02109146118164}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.02109146118164
Starting 1000 evaluations
avg return on 3 trajectories of agent16: 1253.9925039679529
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 04:13.36[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 04:13.36[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 04:13.37[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 04:13.37[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 04:13.37[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513041337[0m
[2m2025-05-13 04:13.37[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 04:13.59[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513041337: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023055779933929444, 'time_algorithm_update': 0.004994187593460083, 'loss': 1.6391658375039697, 'time_step': 0.007360709190368652, 'init_value': 4.4943037033081055}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 04:14.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513041337: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002354501247406006, 'time_algorithm_update': 0.004880598306655884, 'loss': 2.1682894538640975, 'time_step': 0.007294595003128052, 'init_value': 11.353659629821777}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 04:14.41[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513041337: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00228791069984436, 'time_algorithm_update': 0.004913187742233276, 'loss': 2.2504596999883653, 'time_step': 0.0072599115371704106, 'init_value': 19.176734924316406}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 04:15.02[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513041337: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002299848318099976, 'time_algorithm_update': 0.004757492303848266, 'loss': 2.0321548291444778, 'time_step': 0.007114415407180786, 'init_value': 24.9089298248291}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 04:15.24[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513041337: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023772916793823244, 'time_algorithm_update': 0.004954425096511841, 'loss': 1.9273938509225845, 'time_step': 0.007391636848449707, 'init_value': 29.76095962524414}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 04:15.45[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513041337: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002330716609954834, 'time_algorithm_update': 0.0050210819244384764, 'loss': 1.7639520219564437, 'time_step': 0.007412419319152832, 'init_value': 33.37814712524414}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 04:16.06[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513041337: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022894999980926515, 'time_algorithm_update': 0.004845942497253418, 'loss': 1.7642346485853195, 'time_step': 0.007193554639816285, 'init_value': 35.89027786254883}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 04:16.27[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513041337: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002286980867385864, 'time_algorithm_update': 0.004870598077774048, 'loss': 1.6383006137013436, 'time_step': 0.007216506958007812, 'init_value': 38.08280944824219}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-13 04:16.49[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513041337: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023543362617492675, 'time_algorithm_update': 0.005018297433853149, 'loss': 1.6215252750515938, 'time_step': 0.007433428764343262, 'init_value': 41.093196868896484}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-13 04:17.10[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513041337: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002355382204055786, 'time_algorithm_update': 0.0050169677734375, 'loss': 1.6576255667209625, 'time_step': 0.0074331130981445314, 'init_value': 42.95939254760742}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.95939254760742
Starting 1000 evaluations
avg return on 3 trajectories of agent17: 1258.8320236592479
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 04:34.16[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 04:34.16[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 04:34.18[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 04:34.18[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 04:34.18[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513043418[0m
[2m2025-05-13 04:34.18[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 04:34.39[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513043418: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002295608043670654, 'time_algorithm_update': 0.00483069634437561, 'loss': 1.6027396074235438, 'time_step': 0.007184972286224365, 'init_value': 4.217844486236572}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 04:35.00[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513043418: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002286041736602783, 'time_algorithm_update': 0.004808563470840454, 'loss': 2.1930265763401984, 'time_step': 0.007152825355529785, 'init_value': 11.259543418884277}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 04:35.22[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513043418: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023253860473632813, 'time_algorithm_update': 0.004804595708847046, 'loss': 2.183899458169937, 'time_step': 0.007188009262084961, 'init_value': 18.31182289123535}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 04:35.43[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513043418: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023717207908630373, 'time_algorithm_update': 0.004890056133270264, 'loss': 1.9801921775341034, 'time_step': 0.00732064437866211, 'init_value': 23.572734832763672}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 04:36.04[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513043418: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023411250114440917, 'time_algorithm_update': 0.0050571448802948, 'loss': 1.8926710249781609, 'time_step': 0.007458740949630737, 'init_value': 27.766998291015625}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 04:36.26[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513043418: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002361127853393555, 'time_algorithm_update': 0.0048507719039916995, 'loss': 1.7106719286441803, 'time_step': 0.00727009630203247, 'init_value': 31.20563316345215}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 04:36.47[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513043418: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023324885368347166, 'time_algorithm_update': 0.0049071204662323, 'loss': 1.6837849521040917, 'time_step': 0.007298626899719238, 'init_value': 35.055503845214844}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 04:37.09[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513043418: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023422436714172364, 'time_algorithm_update': 0.004948078870773315, 'loss': 1.737431579530239, 'time_step': 0.00735031509399414, 'init_value': 37.25243377685547}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-13 04:37.30[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513043418: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023832018375396728, 'time_algorithm_update': 0.00497467827796936, 'loss': 1.6710546196699143, 'time_step': 0.007418029546737671, 'init_value': 39.493682861328125}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-13 04:37.51[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513043418: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002308584928512573, 'time_algorithm_update': 0.00485628080368042, 'loss': 1.5255467004179954, 'time_step': 0.007222881317138672, 'init_value': 41.1794319152832}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.1794319152832
Starting 1000 evaluations
avg return on 3 trajectories of agent18: 1266.7144299592942
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 04:54.59[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 04:54.59[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 04:55.00[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 04:55.00[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 04:55.00[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513045500[0m
[2m2025-05-13 04:55.00[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 04:55.21[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513045500: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023162786960601806, 'time_algorithm_update': 0.004922575712203979, 'loss': 1.643698044732213, 'time_step': 0.00729902982711792, 'init_value': 4.573938369750977}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 04:55.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513045500: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002307243585586548, 'time_algorithm_update': 0.0046847484111785884, 'loss': 2.300364343702793, 'time_step': 0.007048656225204467, 'init_value': 11.598347663879395}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 04:56.04[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513045500: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023202879428863526, 'time_algorithm_update': 0.005019608736038208, 'loss': 2.1298245925307273, 'time_step': 0.0074000232219696045, 'init_value': 18.62662124633789}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 04:56.25[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513045500: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002280076265335083, 'time_algorithm_update': 0.004802683115005493, 'loss': 2.0686288533210755, 'time_step': 0.007140505313873291, 'init_value': 24.669639587402344}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 04:56.47[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513045500: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002379981517791748, 'time_algorithm_update': 0.005044561386108398, 'loss': 1.9259845247864724, 'time_step': 0.007485396385192871, 'init_value': 28.1673526763916}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 04:57.08[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513045500: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002272915601730347, 'time_algorithm_update': 0.0047670347690582275, 'loss': 1.8521052328944205, 'time_step': 0.007096588850021362, 'init_value': 31.781286239624023}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 04:57.30[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513045500: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023760521411895752, 'time_algorithm_update': 0.005038812637329102, 'loss': 1.7518624336123467, 'time_step': 0.007475493431091308, 'init_value': 35.206398010253906}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 04:57.51[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513045500: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023323535919189454, 'time_algorithm_update': 0.005053311109542847, 'loss': 1.6396411392688752, 'time_step': 0.00744597864151001, 'init_value': 36.85248947143555}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-13 04:58.12[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513045500: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023580217361450196, 'time_algorithm_update': 0.004940456628799438, 'loss': 1.698223943591118, 'time_step': 0.0073582038879394535, 'init_value': 38.577152252197266}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-13 04:58.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513045500: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022798378467559816, 'time_algorithm_update': 0.004800839900970459, 'loss': 1.5283910197615624, 'time_step': 0.007138397455215454, 'init_value': 40.385032653808594}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.385032653808594
Starting 1000 evaluations
avg return on 3 trajectories of agent19: 1269.4123820118723
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 05:15.39[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 05:15.39[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 05:15.41[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 05:15.41[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 05:15.41[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513051541[0m
[2m2025-05-13 05:15.41[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 05:16.02[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513051541: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002281841039657593, 'time_algorithm_update': 0.004830856800079345, 'loss': 1.6408501814678311, 'time_step': 0.00717060661315918, 'init_value': 4.063248634338379}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 05:16.23[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513051541: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002350149631500244, 'time_algorithm_update': 0.004968050956726074, 'loss': 2.2951797443032267, 'time_step': 0.007384283781051636, 'init_value': 10.71993350982666}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 05:16.44[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513051541: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002303900718688965, 'time_algorithm_update': 0.0048105292320251465, 'loss': 2.238910604774952, 'time_step': 0.0071721868515014645, 'init_value': 18.553218841552734}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 05:17.06[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513051541: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022992541790008546, 'time_algorithm_update': 0.00484614634513855, 'loss': 2.109217845737934, 'time_step': 0.0072029693126678465, 'init_value': 24.928974151611328}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 05:17.27[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513051541: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023192226886749267, 'time_algorithm_update': 0.004945817470550537, 'loss': 1.9409575644731523, 'time_step': 0.007323973417282105, 'init_value': 29.572494506835938}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 05:17.49[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513051541: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023797590732574465, 'time_algorithm_update': 0.005058041334152222, 'loss': 1.7591475296020507, 'time_step': 0.007498621702194214, 'init_value': 32.82582092285156}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 05:18.10[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513051541: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023466570377349855, 'time_algorithm_update': 0.004911967754364014, 'loss': 1.7670806522369384, 'time_step': 0.0073174829483032226, 'init_value': 35.114479064941406}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 05:18.31[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513051541: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022839803695678712, 'time_algorithm_update': 0.004769721269607544, 'loss': 1.676652759194374, 'time_step': 0.007110893964767456, 'init_value': 37.75172805786133}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-13 05:18.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513051541: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023488528728485107, 'time_algorithm_update': 0.004915134191513061, 'loss': 1.7632508480548859, 'time_step': 0.007322911977767944, 'init_value': 39.603050231933594}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-13 05:19.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513051541: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002310210943222046, 'time_algorithm_update': 0.00503744626045227, 'loss': 1.5548986405730247, 'time_step': 0.007407434940338135, 'init_value': 40.69761276245117}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.69761276245117
ave advantage rew: 41.27416915893555, std: 0.8045185724621057
avg cum rews: 1255.8643840787379, std: 38.45751531401766
Pearson correlation coefficient: -0.2927480116482279
Spearman correlation coefficient: -0.3263157894736842
Kendall Tau correlation coefficient: -0.22105263157894736
the best agent: 11, best agent cum rewards: 1362.6242499505192
1958
Starting to collect rollouts
Collecting rollouts: 10000/1000000
Collecting rollouts: 20000/1000000
Collecting rollouts: 30000/1000000
Collecting rollouts: 40000/1000000
Collecting rollouts: 50000/1000000
Collecting rollouts: 60000/1000000
Collecting rollouts: 70000/1000000
Collecting rollouts: 80000/1000000
Collecting rollouts: 90000/1000000
Collecting rollouts: 100000/1000000
Collecting rollouts: 110000/1000000
Collecting rollouts: 120000/1000000
Collecting rollouts: 130000/1000000
Collecting rollouts: 140000/1000000
Collecting rollouts: 150000/1000000
Collecting rollouts: 160000/1000000
Collecting rollouts: 170000/1000000
Collecting rollouts: 180000/1000000
Collecting rollouts: 190000/1000000
Collecting rollouts: 200000/1000000
Collecting rollouts: 210000/1000000
Collecting rollouts: 220000/1000000
Collecting rollouts: 230000/1000000
Collecting rollouts: 240000/1000000
Collecting rollouts: 250000/1000000
Collecting rollouts: 260000/1000000
Collecting rollouts: 270000/1000000
Collecting rollouts: 280000/1000000
Collecting rollouts: 290000/1000000
Collecting rollouts: 300000/1000000
Collecting rollouts: 310000/1000000
Collecting rollouts: 320000/1000000
Collecting rollouts: 330000/1000000
Collecting rollouts: 340000/1000000
Collecting rollouts: 350000/1000000
Collecting rollouts: 360000/1000000
Collecting rollouts: 370000/1000000
Collecting rollouts: 380000/1000000
Collecting rollouts: 390000/1000000
Collecting rollouts: 400000/1000000
Collecting rollouts: 410000/1000000
Collecting rollouts: 420000/1000000
Collecting rollouts: 430000/1000000
Collecting rollouts: 440000/1000000
Collecting rollouts: 450000/1000000
Collecting rollouts: 460000/1000000
Collecting rollouts: 470000/1000000
Collecting rollouts: 480000/1000000
Collecting rollouts: 490000/1000000
Collecting rollouts: 500000/1000000
Collecting rollouts: 510000/1000000
Collecting rollouts: 520000/1000000
Collecting rollouts: 530000/1000000
Collecting rollouts: 540000/1000000
Collecting rollouts: 550000/1000000
Collecting rollouts: 560000/1000000
Collecting rollouts: 570000/1000000
Collecting rollouts: 580000/1000000
Collecting rollouts: 590000/1000000
Collecting rollouts: 600000/1000000
Collecting rollouts: 610000/1000000
Collecting rollouts: 620000/1000000
Collecting rollouts: 630000/1000000
Collecting rollouts: 640000/1000000
Collecting rollouts: 650000/1000000
Collecting rollouts: 660000/1000000
Collecting rollouts: 670000/1000000
Collecting rollouts: 680000/1000000
Collecting rollouts: 690000/1000000
Collecting rollouts: 700000/1000000
Collecting rollouts: 710000/1000000
Collecting rollouts: 720000/1000000
Collecting rollouts: 730000/1000000
Collecting rollouts: 740000/1000000
Collecting rollouts: 750000/1000000
Collecting rollouts: 760000/1000000
Collecting rollouts: 770000/1000000
Collecting rollouts: 780000/1000000
Collecting rollouts: 790000/1000000
Collecting rollouts: 800000/1000000
Collecting rollouts: 810000/1000000
Collecting rollouts: 820000/1000000
Collecting rollouts: 830000/1000000
Collecting rollouts: 840000/1000000
Collecting rollouts: 850000/1000000
Collecting rollouts: 860000/1000000
Collecting rollouts: 870000/1000000
Collecting rollouts: 880000/1000000
Collecting rollouts: 890000/1000000
Collecting rollouts: 900000/1000000
Collecting rollouts: 910000/1000000
Collecting rollouts: 920000/1000000
Collecting rollouts: 930000/1000000
Collecting rollouts: 940000/1000000
Collecting rollouts: 950000/1000000
Collecting rollouts: 960000/1000000
Collecting rollouts: 970000/1000000
Collecting rollouts: 980000/1000000
Collecting rollouts: 990000/1000000
Collecting rollouts: 1000000/1000000
Replay buffer size:  (1000000, 105)
Replay buffer saved
---------------------------------
Searching empty space policies
(10, 11472)
(20, 11472)
(20, 11472)
Average distance of agents to nearest neighbors: 0.01844449888247
Starting 1000 evaluations
avg return on 3 trajectories of agent0: 1371.5898647469128
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 05:56.17[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 05:56.17[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 05:56.18[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 05:56.18[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 05:56.18[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513055618[0m
[2m2025-05-13 05:56.18[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 05:56.39[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513055618: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00234281325340271, 'time_algorithm_update': 0.005016953706741333, 'loss': 1.5502572457939385, 'time_step': 0.0074211938381195065, 'init_value': 4.83690881729126}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 05:57.01[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513055618: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023472793102264403, 'time_algorithm_update': 0.005029537916183472, 'loss': 2.2660107011795043, 'time_step': 0.007438500881195068, 'init_value': 11.524879455566406}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 05:57.21[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513055618: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022626430988311767, 'time_algorithm_update': 0.004665536642074585, 'loss': 2.255629108965397, 'time_step': 0.006984589099884034, 'init_value': 18.67225456237793}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 05:57.43[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513055618: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023306033611297607, 'time_algorithm_update': 0.004794406890869141, 'loss': 2.1985232889056205, 'time_step': 0.007201630592346192, 'init_value': 25.657976150512695}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 05:58.05[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513055618: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023448972702026366, 'time_algorithm_update': 0.0050081582069396976, 'loss': 1.975935954630375, 'time_step': 0.007414214134216309, 'init_value': 30.742238998413086}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 05:58.26[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513055618: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023494558334350587, 'time_algorithm_update': 0.004969106435775757, 'loss': 1.936924885571003, 'time_step': 0.00737955641746521, 'init_value': 34.22039031982422}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 05:58.47[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513055618: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022637736797332763, 'time_algorithm_update': 0.004652392625808716, 'loss': 1.7709976099729539, 'time_step': 0.006972221374511719, 'init_value': 37.27472686767578}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 05:59.08[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513055618: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002388469457626343, 'time_algorithm_update': 0.004984212636947632, 'loss': 1.7833633940815925, 'time_step': 0.007433037042617798, 'init_value': 39.271690368652344}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-13 05:59.31[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513055618: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002392484903335571, 'time_algorithm_update': 0.005043255090713501, 'loss': 1.753890477359295, 'time_step': 0.007496912956237793, 'init_value': 41.583160400390625}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-13 05:59.51[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513055618: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022974205017089844, 'time_algorithm_update': 0.004751291275024414, 'loss': 1.6973994736671447, 'time_step': 0.007106035470962524, 'init_value': 43.402191162109375}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 43.402191162109375
Starting 1000 evaluations
avg return on 3 trajectories of agent1: 1375.3275075036058
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 06:16.48[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 06:16.48[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 06:16.50[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 06:16.50[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 06:16.50[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513061650[0m
[2m2025-05-13 06:16.50[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 06:17.11[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513061650: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022608411312103273, 'time_algorithm_update': 0.0048215374946594235, 'loss': 1.4578190354853868, 'time_step': 0.007140637159347534, 'init_value': 4.3046369552612305}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 06:17.32[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513061650: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002281233787536621, 'time_algorithm_update': 0.004885582685470581, 'loss': 2.3310060354471207, 'time_step': 0.007225574493408203, 'init_value': 10.668896675109863}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 06:17.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513061650: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023028452396392824, 'time_algorithm_update': 0.004911953926086426, 'loss': 2.230967816531658, 'time_step': 0.007273506879806518, 'init_value': 18.834014892578125}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 06:18.15[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513061650: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023459734916687013, 'time_algorithm_update': 0.004840034723281861, 'loss': 2.152979741871357, 'time_step': 0.007243968248367309, 'init_value': 24.041017532348633}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 06:18.36[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513061650: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023060970306396484, 'time_algorithm_update': 0.004978967905044556, 'loss': 1.9819723910689353, 'time_step': 0.00734461236000061, 'init_value': 28.89292335510254}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 06:18.58[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513061650: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002332252264022827, 'time_algorithm_update': 0.004922114133834839, 'loss': 1.7890094578266145, 'time_step': 0.00731410551071167, 'init_value': 31.917129516601562}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 06:19.18[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513061650: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022831499576568604, 'time_algorithm_update': 0.0049321212768554685, 'loss': 1.8164936299324035, 'time_step': 0.0072746741771698, 'init_value': 35.93405532836914}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 06:19.40[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513061650: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002324840784072876, 'time_algorithm_update': 0.004821837425231934, 'loss': 1.7542651414871215, 'time_step': 0.007204330682754516, 'init_value': 38.71186447143555}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-13 06:20.01[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513061650: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002359700918197632, 'time_algorithm_update': 0.005038688898086548, 'loss': 1.5905163613557816, 'time_step': 0.007459233760833741, 'init_value': 40.57447052001953}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-13 06:20.23[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513061650: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023122599124908447, 'time_algorithm_update': 0.004986777782440186, 'loss': 1.671020268201828, 'time_step': 0.007359012365341187, 'init_value': 43.28021240234375}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 43.28021240234375
Starting 1000 evaluations
avg return on 3 trajectories of agent2: 1378.3476237665354
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 06:37.23[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 06:37.23[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 06:37.25[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 06:37.25[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 06:37.25[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513063725[0m
[2m2025-05-13 06:37.25[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 06:37.46[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513063725: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00226267147064209, 'time_algorithm_update': 0.004706417798995972, 'loss': 1.8150344168841839, 'time_step': 0.007026224374771118, 'init_value': 4.230817794799805}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 06:38.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513063725: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023434872627258302, 'time_algorithm_update': 0.004914709806442261, 'loss': 2.403281167805195, 'time_step': 0.007317374229431153, 'init_value': 11.476122856140137}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 06:38.28[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513063725: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023206965923309327, 'time_algorithm_update': 0.004908103704452515, 'loss': 2.3342745534181595, 'time_step': 0.007287683010101319, 'init_value': 19.919042587280273}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 06:38.50[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513063725: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002380475997924805, 'time_algorithm_update': 0.004976626396179199, 'loss': 2.133580234527588, 'time_step': 0.007416976451873779, 'init_value': 24.777477264404297}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 06:39.11[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513063725: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022849223613739013, 'time_algorithm_update': 0.00469942045211792, 'loss': 1.9356756259202956, 'time_step': 0.007040575504302978, 'init_value': 29.18374252319336}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 06:39.32[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513063725: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002368997097015381, 'time_algorithm_update': 0.004919225931167602, 'loss': 1.974309697151184, 'time_step': 0.0073480079174041745, 'init_value': 31.578237533569336}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 06:39.54[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513063725: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023302536010742186, 'time_algorithm_update': 0.004964000463485717, 'loss': 1.8284149667024612, 'time_step': 0.007354721307754517, 'init_value': 34.71868133544922}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 06:40.15[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513063725: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023589739799499514, 'time_algorithm_update': 0.005057699680328369, 'loss': 1.694855430662632, 'time_step': 0.00747806453704834, 'init_value': 36.1998405456543}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-13 06:40.36[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513063725: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023198142051696776, 'time_algorithm_update': 0.004784583330154419, 'loss': 1.667273265004158, 'time_step': 0.007161717653274536, 'init_value': 38.84889221191406}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-13 06:40.57[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513063725: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022908759117126463, 'time_algorithm_update': 0.004746064186096192, 'loss': 1.6284242910146713, 'time_step': 0.007094036102294922, 'init_value': 40.4353141784668}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.4353141784668
Starting 1000 evaluations
avg return on 3 trajectories of agent3: 1367.4704577268985
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 06:57.54[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 06:57.54[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 06:57.55[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 06:57.55[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 06:57.55[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513065755[0m
[2m2025-05-13 06:57.55[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 06:58.15[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513065755: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022388880252838133, 'time_algorithm_update': 0.004569970607757569, 'loss': 1.7253681185543537, 'time_step': 0.006864283800125122, 'init_value': 4.0287604331970215}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 06:58.36[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513065755: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022644715309143065, 'time_algorithm_update': 0.00472448992729187, 'loss': 2.2736899774670603, 'time_step': 0.007045804738998413, 'init_value': 11.087625503540039}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 06:58.58[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513065755: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023594439029693604, 'time_algorithm_update': 0.00511432933807373, 'loss': 2.2675171338915825, 'time_step': 0.007536309957504273, 'init_value': 18.436012268066406}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 06:59.19[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513065755: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002355611801147461, 'time_algorithm_update': 0.004954339027404785, 'loss': 2.0974506632089613, 'time_step': 0.007369808912277222, 'init_value': 25.626331329345703}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 06:59.40[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513065755: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022688813209533693, 'time_algorithm_update': 0.004662637948989868, 'loss': 1.9905366708636283, 'time_step': 0.006987384557723999, 'init_value': 30.725677490234375}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 07:00.01[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513065755: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023210651874542238, 'time_algorithm_update': 0.004792559623718262, 'loss': 1.6809481100440025, 'time_step': 0.007171350002288818, 'init_value': 33.78593063354492}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 07:00.23[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513065755: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00233721399307251, 'time_algorithm_update': 0.0051202671527862545, 'loss': 1.7256974425911904, 'time_step': 0.007519420146942139, 'init_value': 37.020042419433594}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 07:00.44[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513065755: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023132612705230714, 'time_algorithm_update': 0.004915914058685303, 'loss': 1.7384089593291283, 'time_step': 0.007289060592651367, 'init_value': 37.03059005737305}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-13 07:01.05[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513065755: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022511978149414064, 'time_algorithm_update': 0.004681356430053711, 'loss': 1.6784669583439826, 'time_step': 0.006988495588302612, 'init_value': 39.7943000793457}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-13 07:01.26[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513065755: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00234062123298645, 'time_algorithm_update': 0.004947956562042236, 'loss': 1.6001386902332306, 'time_step': 0.007347966909408569, 'init_value': 41.362037658691406}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.362037658691406
Starting 1000 evaluations
avg return on 3 trajectories of agent4: 1375.2784236842106
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 07:18.22[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 07:18.22[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 07:18.23[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 07:18.23[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 07:18.23[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513071823[0m
[2m2025-05-13 07:18.23[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 07:18.44[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513071823: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022543282508850097, 'time_algorithm_update': 0.0047056183815002445, 'loss': 1.7591393110826612, 'time_step': 0.007017072916030884, 'init_value': 4.317245960235596}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 07:19.06[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513071823: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002371124267578125, 'time_algorithm_update': 0.005129494667053223, 'loss': 2.3280378836989404, 'time_step': 0.007564925432205201, 'init_value': 11.20955753326416}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 07:19.27[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513071823: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002249647617340088, 'time_algorithm_update': 0.004736049890518189, 'loss': 2.2236067876815797, 'time_step': 0.007042789936065674, 'init_value': 18.10453224182129}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 07:19.47[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513071823: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022495217323303222, 'time_algorithm_update': 0.004678400278091431, 'loss': 2.050045247077942, 'time_step': 0.006984549999237061, 'init_value': 24.872838973999023}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 07:20.09[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513071823: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023359413146972654, 'time_algorithm_update': 0.004920817136764526, 'loss': 1.9358543652296065, 'time_step': 0.007316179275512695, 'init_value': 29.376384735107422}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 07:20.31[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513071823: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023505661487579345, 'time_algorithm_update': 0.005121426582336426, 'loss': 1.752066622555256, 'time_step': 0.007534757137298584, 'init_value': 32.75636672973633}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 07:20.51[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513071823: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022638731002807616, 'time_algorithm_update': 0.004626806497573853, 'loss': 1.7882182932496071, 'time_step': 0.006947135210037232, 'init_value': 35.96672821044922}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 07:21.12[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513071823: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022376594543457033, 'time_algorithm_update': 0.004600084543228149, 'loss': 1.7589020924568177, 'time_step': 0.006893217325210571, 'init_value': 38.00431442260742}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-13 07:21.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513071823: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002314328908920288, 'time_algorithm_update': 0.005059217214584351, 'loss': 1.6423117780089378, 'time_step': 0.007435547590255737, 'init_value': 38.95913314819336}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-13 07:21.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513071823: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023467977046966555, 'time_algorithm_update': 0.0050843749046325685, 'loss': 1.5627713031172752, 'time_step': 0.007493088960647583, 'init_value': 40.94566345214844}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.94566345214844
Starting 1000 evaluations
avg return on 3 trajectories of agent5: 1391.2921492032922
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 07:38.55[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 07:38.55[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 07:38.56[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 07:38.56[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 07:38.56[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513073856[0m
[2m2025-05-13 07:38.56[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 07:39.18[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513073856: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023057496547698973, 'time_algorithm_update': 0.004932422161102295, 'loss': 1.6387566562518479, 'time_step': 0.007297979116439819, 'init_value': 3.8417563438415527}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 07:39.39[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513073856: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002321932554244995, 'time_algorithm_update': 0.0049199059009552, 'loss': 2.3530725882053374, 'time_step': 0.007300779819488525, 'init_value': 10.503279685974121}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 07:40.00[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513073856: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002244534730911255, 'time_algorithm_update': 0.004644783735275268, 'loss': 2.2377755469083787, 'time_step': 0.006944894790649414, 'init_value': 18.134267807006836}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 07:40.22[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513073856: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023440423011779786, 'time_algorithm_update': 0.005039741516113281, 'loss': 2.1092166298627855, 'time_step': 0.007444546222686767, 'init_value': 25.145370483398438}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 07:40.43[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513073856: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002311654090881348, 'time_algorithm_update': 0.0049160470962524416, 'loss': 1.9994528851509095, 'time_step': 0.007286872386932373, 'init_value': 29.761411666870117}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 07:41.04[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513073856: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002391597509384155, 'time_algorithm_update': 0.0049803807735443115, 'loss': 1.8915365899205208, 'time_step': 0.007431935548782348, 'init_value': 32.63523864746094}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 07:41.25[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513073856: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022602453231811525, 'time_algorithm_update': 0.004677190065383911, 'loss': 1.8151985403895379, 'time_step': 0.00699335789680481, 'init_value': 34.81488037109375}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 07:41.47[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513073856: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023816938400268556, 'time_algorithm_update': 0.005048614501953125, 'loss': 1.7318455206155776, 'time_step': 0.007491302251815796, 'init_value': 36.85201644897461}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-13 07:42.09[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513073856: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002311096668243408, 'time_algorithm_update': 0.004937120676040649, 'loss': 1.7239518166184424, 'time_step': 0.00730746841430664, 'init_value': 39.40909194946289}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-13 07:42.30[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513073856: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023151040077209473, 'time_algorithm_update': 0.004872633695602417, 'loss': 1.5775009787082672, 'time_step': 0.007246143579483032, 'init_value': 41.286293029785156}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.286293029785156
Starting 1000 evaluations
avg return on 3 trajectories of agent6: 1382.9498748005917
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 07:59.31[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 07:59.31[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 07:59.32[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 07:59.32[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 07:59.32[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513075932[0m
[2m2025-05-13 07:59.32[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 07:59.52[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513075932: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022103896141052247, 'time_algorithm_update': 0.00452477765083313, 'loss': 1.767719834767282, 'time_step': 0.0067903163433074955, 'init_value': 4.348659038543701}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 08:00.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513075932: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023205623626708985, 'time_algorithm_update': 0.004882039546966553, 'loss': 2.2742951645255087, 'time_step': 0.007262592315673828, 'init_value': 10.832277297973633}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 08:00.36[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513075932: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002318350076675415, 'time_algorithm_update': 0.004969537973403931, 'loss': 2.2044412805438043, 'time_step': 0.007348726987838745, 'init_value': 18.644672393798828}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 08:00.57[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513075932: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023594708442687988, 'time_algorithm_update': 0.004933260679244995, 'loss': 2.105293909072876, 'time_step': 0.007351891040802002, 'init_value': 25.551727294921875}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 08:01.18[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513075932: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022486903667449953, 'time_algorithm_update': 0.004668671131134033, 'loss': 2.0083129412531853, 'time_step': 0.006973574161529541, 'init_value': 31.571378707885742}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 08:01.40[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513075932: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023822202682495116, 'time_algorithm_update': 0.005018372535705567, 'loss': 1.9728980646133423, 'time_step': 0.00746186375617981, 'init_value': 35.07524108886719}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 08:02.01[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513075932: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002307103157043457, 'time_algorithm_update': 0.004909795522689819, 'loss': 1.801306008219719, 'time_step': 0.0072770798206329345, 'init_value': 37.762550354003906}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 08:02.22[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513075932: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023246772289276124, 'time_algorithm_update': 0.004776947259902954, 'loss': 1.6717825596928597, 'time_step': 0.007159442186355591, 'init_value': 40.196388244628906}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-13 08:02.43[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513075932: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022394320964813233, 'time_algorithm_update': 0.004657735824584961, 'loss': 1.8120039510726929, 'time_step': 0.006953076839447021, 'init_value': 42.6158447265625}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-13 08:03.04[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513075932: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002309511661529541, 'time_algorithm_update': 0.005022880077362061, 'loss': 1.7422324260473252, 'time_step': 0.00739323091506958, 'init_value': 43.279685974121094}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 43.279685974121094
Starting 1000 evaluations
avg return on 3 trajectories of agent7: 1365.8907177724448
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 08:20.03[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 08:20.03[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 08:20.05[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 08:20.05[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 08:20.05[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513082005[0m
[2m2025-05-13 08:20.05[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 08:20.26[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513082005: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002263755559921265, 'time_algorithm_update': 0.004731350660324097, 'loss': 1.5448181327879429, 'time_step': 0.007052895784378052, 'init_value': 4.44598388671875}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 08:20.47[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513082005: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002239889144897461, 'time_algorithm_update': 0.004685137033462524, 'loss': 2.239457333803177, 'time_step': 0.006981088638305664, 'init_value': 11.080142974853516}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 08:21.08[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513082005: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023446729183197023, 'time_algorithm_update': 0.004963366985321045, 'loss': 2.2719611107707025, 'time_step': 0.007368318319320679, 'init_value': 17.73333740234375}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 08:21.30[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513082005: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002380931854248047, 'time_algorithm_update': 0.005006672859191895, 'loss': 2.047895119011402, 'time_step': 0.007448415994644165, 'init_value': 24.825244903564453}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 08:21.51[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513082005: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022607626914978025, 'time_algorithm_update': 0.00475324010848999, 'loss': 1.9853152042627336, 'time_step': 0.007071579694747925, 'init_value': 28.8621768951416}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 08:22.12[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513082005: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022932991981506347, 'time_algorithm_update': 0.0047541985511779785, 'loss': 1.817012448310852, 'time_step': 0.007104856491088867, 'init_value': 33.40760803222656}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 08:22.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513082005: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023028433322906496, 'time_algorithm_update': 0.0049588575363159176, 'loss': 1.805159528374672, 'time_step': 0.0073213140964508054, 'init_value': 35.525901794433594}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 08:22.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513082005: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002324188470840454, 'time_algorithm_update': 0.005101262331008911, 'loss': 1.6941716404557228, 'time_step': 0.007487677812576294, 'init_value': 37.16675567626953}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-13 08:23.16[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513082005: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022721078395843506, 'time_algorithm_update': 0.004672272682189942, 'loss': 1.6415826365947723, 'time_step': 0.007000706672668457, 'init_value': 39.28424835205078}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-13 08:23.37[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513082005: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00230696439743042, 'time_algorithm_update': 0.004831373453140259, 'loss': 1.6870737836360932, 'time_step': 0.007196832418441773, 'init_value': 41.51783752441406}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.51783752441406
Starting 1000 evaluations
avg return on 3 trajectories of agent8: 1378.4311158935393
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 08:40.35[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 08:40.35[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 08:40.36[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 08:40.36[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 08:40.36[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513084036[0m
[2m2025-05-13 08:40.36[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 08:40.57[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513084036: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022262554168701173, 'time_algorithm_update': 0.004559940576553344, 'loss': 1.5819883020296692, 'time_step': 0.006841688632965088, 'init_value': 4.548189163208008}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 08:41.19[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513084036: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002329066514968872, 'time_algorithm_update': 0.005013422966003418, 'loss': 2.326335200667381, 'time_step': 0.0074041526317596435, 'init_value': 12.163728713989258}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 08:41.40[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513084036: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002317185878753662, 'time_algorithm_update': 0.004919510841369629, 'loss': 2.401118883550167, 'time_step': 0.007296442031860351, 'init_value': 18.789371490478516}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 08:42.01[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513084036: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023393445014953614, 'time_algorithm_update': 0.004793320894241333, 'loss': 2.0629035605788233, 'time_step': 0.007190321445465088, 'init_value': 25.27845573425293}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 08:42.22[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513084036: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002258661508560181, 'time_algorithm_update': 0.004728531837463379, 'loss': 1.9831877136826515, 'time_step': 0.007044220447540283, 'init_value': 29.35763168334961}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 08:42.44[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513084036: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023903303146362307, 'time_algorithm_update': 0.0051658468246459964, 'loss': 1.835136496245861, 'time_step': 0.007619704723358154, 'init_value': 31.804203033447266}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 08:43.05[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513084036: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023014686107635496, 'time_algorithm_update': 0.004837048768997192, 'loss': 1.8292040178775788, 'time_step': 0.007197245836257935, 'init_value': 34.63978958129883}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 08:43.25[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513084036: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023024168014526367, 'time_algorithm_update': 0.0047815639972686765, 'loss': 1.7654396963119507, 'time_step': 0.007141932487487793, 'init_value': 38.14581298828125}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-13 08:43.47[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513084036: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00227140736579895, 'time_algorithm_update': 0.004723533868789673, 'loss': 1.6915130014419555, 'time_step': 0.0070519354343414305, 'init_value': 39.89352035522461}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-13 08:44.09[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513084036: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002346478462219238, 'time_algorithm_update': 0.005169953346252441, 'loss': 1.7486745775341987, 'time_step': 0.007579632520675659, 'init_value': 41.96227264404297}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.96227264404297
Starting 1000 evaluations
avg return on 3 trajectories of agent9: 1372.4129290735045
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 09:01.10[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 09:01.10[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 09:01.11[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 09:01.11[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 09:01.11[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513090111[0m
[2m2025-05-13 09:01.11[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 09:01.33[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513090111: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023234026432037355, 'time_algorithm_update': 0.004949340105056763, 'loss': 1.6726499215587973, 'time_step': 0.0073329367637634275, 'init_value': 4.493790149688721}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 09:01.54[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513090111: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023732926845550536, 'time_algorithm_update': 0.0048447465896606446, 'loss': 2.2410373978614806, 'time_step': 0.007276240825653076, 'init_value': 10.96920394897461}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 09:02.15[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513090111: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023007686138153075, 'time_algorithm_update': 0.004750813961029053, 'loss': 2.13873460316658, 'time_step': 0.0071083841323852535, 'init_value': 18.164583206176758}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 09:02.37[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513090111: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002398131608963013, 'time_algorithm_update': 0.004936677932739258, 'loss': 2.077218334674835, 'time_step': 0.007394112825393677, 'init_value': 24.14239501953125}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 09:02.58[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513090111: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023615975379943847, 'time_algorithm_update': 0.005122974872589111, 'loss': 1.923213861823082, 'time_step': 0.007546533346176148, 'init_value': 29.359140396118164}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 09:03.19[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513090111: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023136508464813234, 'time_algorithm_update': 0.004781328439712525, 'loss': 1.8478187029361726, 'time_step': 0.007152266979217529, 'init_value': 33.0350341796875}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 09:03.41[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513090111: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023891072273254394, 'time_algorithm_update': 0.004998863935470581, 'loss': 1.7746483949422835, 'time_step': 0.0074470267295837405, 'init_value': 35.90961837768555}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 09:04.02[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513090111: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023391356468200684, 'time_algorithm_update': 0.004922492504119873, 'loss': 1.6475429551005363, 'time_step': 0.007320568799972534, 'init_value': 39.351715087890625}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-13 09:04.24[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513090111: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023798086643218993, 'time_algorithm_update': 0.005116866827011108, 'loss': 1.7054919014573098, 'time_step': 0.0075585911273956296, 'init_value': 40.49437713623047}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-13 09:04.45[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513090111: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002266969919204712, 'time_algorithm_update': 0.004635918617248535, 'loss': 1.7052154775857926, 'time_step': 0.006958213806152344, 'init_value': 41.92396545410156}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.92396545410156
Starting 1000 evaluations
avg return on 3 trajectories of agent10: 1365.89672420462
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 09:21.48[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 09:21.48[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 09:21.49[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 09:21.49[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 09:21.49[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513092149[0m
[2m2025-05-13 09:21.49[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 09:22.11[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513092149: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023082273006439207, 'time_algorithm_update': 0.004993304967880249, 'loss': 1.6457877543196082, 'time_step': 0.00736217999458313, 'init_value': 4.7449846267700195}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 09:22.32[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513092149: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023032195568084717, 'time_algorithm_update': 0.004747666835784912, 'loss': 2.334898626089096, 'time_step': 0.007108583688735962, 'init_value': 12.967964172363281}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 09:22.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513092149: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023076977729797363, 'time_algorithm_update': 0.0047946090698242185, 'loss': 2.1146984308958054, 'time_step': 0.0071598470211029054, 'init_value': 20.591957092285156}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 09:23.15[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513092149: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023103950023651123, 'time_algorithm_update': 0.004842116355895996, 'loss': 2.0207741112709043, 'time_step': 0.007210270881652832, 'init_value': 26.821815490722656}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 09:23.36[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513092149: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0024014511108398436, 'time_algorithm_update': 0.0051766448020935055, 'loss': 1.96717400431633, 'time_step': 0.0076524271965026855, 'init_value': 30.38017463684082}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 09:23.57[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513092149: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023037083148956298, 'time_algorithm_update': 0.004839441776275635, 'loss': 1.9212893012166024, 'time_step': 0.007201629161834717, 'init_value': 33.33327102661133}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 09:24.19[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513092149: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00236416220664978, 'time_algorithm_update': 0.004940744400024414, 'loss': 1.7420849288702012, 'time_step': 0.007364275217056274, 'init_value': 36.828086853027344}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 09:24.40[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513092149: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023117828369140624, 'time_algorithm_update': 0.004861254930496215, 'loss': 1.699493251681328, 'time_step': 0.007231796503067016, 'init_value': 38.371341705322266}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-13 09:25.01[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513092149: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002323169708251953, 'time_algorithm_update': 0.004924911499023438, 'loss': 1.7031782931685449, 'time_step': 0.0073069450855255125, 'init_value': 40.99223327636719}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-13 09:25.23[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513092149: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022995665073394776, 'time_algorithm_update': 0.004821056127548217, 'loss': 1.6588709326386453, 'time_step': 0.007178772687911988, 'init_value': 42.13628387451172}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.13628387451172
Starting 1000 evaluations
avg return on 3 trajectories of agent11: 1353.2371459543779
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 09:42.23[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 09:42.23[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 09:42.25[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 09:42.25[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 09:42.25[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513094225[0m
[2m2025-05-13 09:42.25[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 09:42.45[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513094225: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002253870725631714, 'time_algorithm_update': 0.004716729640960694, 'loss': 1.7530967318341135, 'time_step': 0.0070278079509735105, 'init_value': 4.850808620452881}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 09:43.06[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513094225: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022249560356140136, 'time_algorithm_update': 0.004702667951583863, 'loss': 2.3679901379942896, 'time_step': 0.006984281539916992, 'init_value': 11.9268217086792}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 09:43.28[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513094225: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023402528762817383, 'time_algorithm_update': 0.004936127185821533, 'loss': 2.226730458498001, 'time_step': 0.007336578845977783, 'init_value': 18.926164627075195}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 09:43.49[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513094225: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00233686900138855, 'time_algorithm_update': 0.004975380182266236, 'loss': 2.073731047332287, 'time_step': 0.0073719630241394045, 'init_value': 25.666383743286133}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 09:44.10[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513094225: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022622601985931396, 'time_algorithm_update': 0.004728229999542236, 'loss': 1.9989039815068246, 'time_step': 0.007047382116317749, 'init_value': 30.754812240600586}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 09:44.32[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513094225: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023559582233428954, 'time_algorithm_update': 0.005036515235900879, 'loss': 1.7703047694563865, 'time_step': 0.007453440189361572, 'init_value': 34.39826202392578}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 09:44.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513094225: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022853777408599852, 'time_algorithm_update': 0.004896934747695923, 'loss': 1.775303368628025, 'time_step': 0.007240295171737671, 'init_value': 36.408348083496094}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 09:45.15[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513094225: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002327523946762085, 'time_algorithm_update': 0.005020146608352661, 'loss': 1.6471056396365165, 'time_step': 0.007408484220504761, 'init_value': 38.115806579589844}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-13 09:45.36[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513094225: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002246702432632446, 'time_algorithm_update': 0.004720348358154297, 'loss': 1.6108731151819229, 'time_step': 0.0070232715606689455, 'init_value': 40.50775146484375}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-13 09:45.58[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513094225: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023321986198425295, 'time_algorithm_update': 0.005071115970611572, 'loss': 1.6263806656003, 'time_step': 0.007464561700820923, 'init_value': 41.48111343383789}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.48111343383789
Starting 1000 evaluations
avg return on 3 trajectories of agent12: 1382.5334703056235
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 10:02.58[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 10:02.58[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 10:02.59[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 10:02.59[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 10:02.59[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513100259[0m
[2m2025-05-13 10:02.59[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 10:03.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513100259: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002301279067993164, 'time_algorithm_update': 0.004851516246795654, 'loss': 1.7651216380596162, 'time_step': 0.0072117366790771485, 'init_value': 4.520600318908691}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 10:03.41[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513100259: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002294837951660156, 'time_algorithm_update': 0.004767404317855835, 'loss': 2.2484573792219162, 'time_step': 0.007120085716247559, 'init_value': 11.450028419494629}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 10:04.03[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513100259: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023316779136657714, 'time_algorithm_update': 0.0050324368476867675, 'loss': 2.318031129360199, 'time_step': 0.007424903392791748, 'init_value': 18.440025329589844}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 10:04.24[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513100259: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023004460334777833, 'time_algorithm_update': 0.004808317422866821, 'loss': 2.0635727673768995, 'time_step': 0.00716640043258667, 'init_value': 24.964597702026367}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 10:04.46[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513100259: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023730077743530273, 'time_algorithm_update': 0.005020227909088135, 'loss': 1.9691223492026328, 'time_step': 0.007453460693359375, 'init_value': 29.572324752807617}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 10:05.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513100259: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002295844078063965, 'time_algorithm_update': 0.0048016331195831295, 'loss': 1.7578939775824547, 'time_step': 0.007155451774597168, 'init_value': 32.93910598754883}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 10:05.29[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513100259: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023838882446289063, 'time_algorithm_update': 0.005057975769042968, 'loss': 1.644629747927189, 'time_step': 0.0075034983158111575, 'init_value': 35.538734436035156}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 10:05.50[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513100259: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022928490638732912, 'time_algorithm_update': 0.004806633949279785, 'loss': 1.6159784650802613, 'time_step': 0.0071573231220245365, 'init_value': 37.513668060302734}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-13 10:06.11[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513100259: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023036599159240723, 'time_algorithm_update': 0.004824833393096924, 'loss': 1.5732192628979682, 'time_step': 0.007186996698379517, 'init_value': 39.16155242919922}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-13 10:06.33[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513100259: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023447797298431394, 'time_algorithm_update': 0.004991386413574219, 'loss': 1.526855353832245, 'time_step': 0.00739563250541687, 'init_value': 40.72503662109375}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.72503662109375
Starting 1000 evaluations
avg return on 3 trajectories of agent13: 1369.0187675136506
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 10:23.30[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 10:23.30[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 10:23.31[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 10:23.31[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 10:23.31[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513102331[0m
[2m2025-05-13 10:23.31[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 10:23.52[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513102331: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022376315593719484, 'time_algorithm_update': 0.004648848533630371, 'loss': 1.8380659438297153, 'time_step': 0.006942512989044189, 'init_value': 4.4309282302856445}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 10:24.13[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513102331: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023294744491577147, 'time_algorithm_update': 0.004855546474456787, 'loss': 2.3493037683963776, 'time_step': 0.0072441246509552006, 'init_value': 10.6241455078125}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 10:24.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513102331: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023492488861083984, 'time_algorithm_update': 0.005098982095718384, 'loss': 2.197369027733803, 'time_step': 0.007509913206100464, 'init_value': 18.076465606689453}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 10:24.56[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513102331: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023311154842376707, 'time_algorithm_update': 0.004771136999130249, 'loss': 2.1709138018488883, 'time_step': 0.0071595656871795655, 'init_value': 24.31618309020996}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 10:25.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513102331: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022752716541290284, 'time_algorithm_update': 0.004703802824020386, 'loss': 1.9417927248477935, 'time_step': 0.007035300016403199, 'init_value': 29.306697845458984}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 10:25.39[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513102331: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023453361988067627, 'time_algorithm_update': 0.004976319074630737, 'loss': 1.9192423150539397, 'time_step': 0.007382277011871338, 'init_value': 33.21181106567383}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 10:26.00[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513102331: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023819119930267333, 'time_algorithm_update': 0.005059539794921875, 'loss': 1.7593078662157058, 'time_step': 0.007503200292587281, 'init_value': 34.96611022949219}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 10:26.21[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513102331: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023146822452545165, 'time_algorithm_update': 0.0048975121974945066, 'loss': 1.7526083474755287, 'time_step': 0.007271019220352173, 'init_value': 37.62790298461914}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-13 10:26.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513102331: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022599823474884033, 'time_algorithm_update': 0.004648683309555054, 'loss': 1.6007320147752762, 'time_step': 0.006965055227279663, 'init_value': 39.14516067504883}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-13 10:27.03[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513102331: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023431713581085205, 'time_algorithm_update': 0.004997308254241943, 'loss': 1.801858983695507, 'time_step': 0.007401860237121582, 'init_value': 40.187591552734375}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.187591552734375
Starting 1000 evaluations
avg return on 3 trajectories of agent14: 1346.546326618664
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 10:44.00[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 10:44.00[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 10:44.02[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 10:44.02[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 10:44.02[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513104402[0m
[2m2025-05-13 10:44.02[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 10:44.23[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513104402: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002289988279342651, 'time_algorithm_update': 0.005017307996749878, 'loss': 1.6945080050379038, 'time_step': 0.007368617773056031, 'init_value': 4.312788963317871}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 10:44.44[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513104402: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022877829074859617, 'time_algorithm_update': 0.0048191978931427, 'loss': 2.4108281198740005, 'time_step': 0.0071652884483337405, 'init_value': 11.660122871398926}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 10:45.05[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513104402: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022707414627075196, 'time_algorithm_update': 0.004783272266387939, 'loss': 2.2017480509281158, 'time_step': 0.007111422061920166, 'init_value': 19.08671760559082}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 10:45.26[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513104402: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002335657596588135, 'time_algorithm_update': 0.0048613550662994385, 'loss': 2.0462562728524207, 'time_step': 0.00725571346282959, 'init_value': 25.605289459228516}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 10:45.48[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513104402: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002351940870285034, 'time_algorithm_update': 0.0050434026718139645, 'loss': 1.8515586906671524, 'time_step': 0.007456061840057373, 'init_value': 30.184925079345703}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 10:46.09[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513104402: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002285064220428467, 'time_algorithm_update': 0.004797977924346924, 'loss': 1.8271598896980286, 'time_step': 0.0071409823894500735, 'init_value': 33.068336486816406}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 10:46.30[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513104402: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023160958290100097, 'time_algorithm_update': 0.0048014836311340335, 'loss': 1.8626349259614945, 'time_step': 0.007175704002380371, 'init_value': 35.898223876953125}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 10:46.51[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513104402: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023220682144165037, 'time_algorithm_update': 0.004900994777679443, 'loss': 1.6581475660800933, 'time_step': 0.0072824015617370605, 'init_value': 37.03218078613281}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-13 10:47.13[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513104402: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023401391506195066, 'time_algorithm_update': 0.0050789272785186764, 'loss': 1.665091590821743, 'time_step': 0.007481030225753784, 'init_value': 37.653099060058594}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-13 10:47.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513104402: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002303351402282715, 'time_algorithm_update': 0.004903979539871216, 'loss': 1.5677362721562385, 'time_step': 0.00726624608039856, 'init_value': 41.1124267578125}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.1124267578125
Starting 1000 evaluations
avg return on 3 trajectories of agent15: 1317.200950703241
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 11:04.31[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 11:04.31[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 11:04.33[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 11:04.33[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 11:04.33[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513110433[0m
[2m2025-05-13 11:04.33[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 11:04.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513110433: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022174036502838135, 'time_algorithm_update': 0.004529170989990235, 'loss': 1.7028739193379878, 'time_step': 0.006801403284072876, 'init_value': 4.320945739746094}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 11:05.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513110433: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002301694631576538, 'time_algorithm_update': 0.004734747648239136, 'loss': 2.4312412691116334, 'time_step': 0.007094427108764649, 'init_value': 11.530037879943848}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 11:05.36[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513110433: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002314133405685425, 'time_algorithm_update': 0.004972232103347778, 'loss': 2.1761144635081293, 'time_step': 0.007346816539764404, 'init_value': 19.234546661376953}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 11:05.57[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513110433: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002365577697753906, 'time_algorithm_update': 0.004969987154006958, 'loss': 2.1630747230052947, 'time_step': 0.00739661955833435, 'init_value': 25.73919105529785}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 11:06.18[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513110433: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002264201879501343, 'time_algorithm_update': 0.004681270599365234, 'loss': 1.962479702591896, 'time_step': 0.007001892805099487, 'init_value': 30.013214111328125}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 11:06.39[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513110433: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00233412766456604, 'time_algorithm_update': 0.004806885004043579, 'loss': 1.8776258117556572, 'time_step': 0.007199113130569458, 'init_value': 32.95979690551758}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 11:07.01[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513110433: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023706793785095216, 'time_algorithm_update': 0.004976930856704712, 'loss': 1.7032111028432846, 'time_step': 0.007407530307769776, 'init_value': 36.76206970214844}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 11:07.22[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513110433: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002306853771209717, 'time_algorithm_update': 0.004920481204986572, 'loss': 1.7297931689620019, 'time_step': 0.007286710500717163, 'init_value': 38.728946685791016}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-13 11:07.43[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513110433: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022903947830200193, 'time_algorithm_update': 0.004782642126083374, 'loss': 1.645362473487854, 'time_step': 0.007130875110626221, 'init_value': 40.746788024902344}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-13 11:08.04[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513110433: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002299267053604126, 'time_algorithm_update': 0.004814357042312622, 'loss': 1.5986595967411994, 'time_step': 0.007171497821807861, 'init_value': 42.21516799926758}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.21516799926758
Starting 1000 evaluations
avg return on 3 trajectories of agent16: 1385.5440140393855
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 11:25.01[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 11:25.01[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 11:25.02[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 11:25.02[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 11:25.02[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513112502[0m
[2m2025-05-13 11:25.02[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 11:25.23[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513112502: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022715651988983155, 'time_algorithm_update': 0.004823531627655029, 'loss': 1.738333500660956, 'time_step': 0.0071536459922790525, 'init_value': 4.047211647033691}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 11:25.45[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513112502: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023132848739624025, 'time_algorithm_update': 0.004862078666687012, 'loss': 2.2484835159778593, 'time_step': 0.007234186410903931, 'init_value': 9.973418235778809}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 11:26.06[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513112502: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023258452415466308, 'time_algorithm_update': 0.004982192754745483, 'loss': 2.2186854256987574, 'time_step': 0.007368163108825683, 'init_value': 17.125022888183594}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 11:26.27[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513112502: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022491350173950196, 'time_algorithm_update': 0.004649966239929199, 'loss': 2.096469598531723, 'time_step': 0.0069548628330230716, 'init_value': 23.377683639526367}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 11:26.48[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513112502: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002305973768234253, 'time_algorithm_update': 0.004954769611358643, 'loss': 1.9891330941319465, 'time_step': 0.0073200764656066895, 'init_value': 29.454635620117188}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 11:27.10[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513112502: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023229081630706788, 'time_algorithm_update': 0.004960492372512817, 'loss': 1.893269094824791, 'time_step': 0.007343241214752197, 'init_value': 32.966705322265625}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 11:27.31[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513112502: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023743622303009034, 'time_algorithm_update': 0.0049754538536071775, 'loss': 1.8003674161434173, 'time_step': 0.007410145998001098, 'init_value': 36.03010559082031}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 11:27.52[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513112502: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022137365341186525, 'time_algorithm_update': 0.004584739685058594, 'loss': 1.6886086100935935, 'time_step': 0.006853189468383789, 'init_value': 38.040802001953125}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-13 11:28.13[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513112502: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023522162437438964, 'time_algorithm_update': 0.004982375144958496, 'loss': 1.6620781471133232, 'time_step': 0.007395066261291504, 'init_value': 41.48958206176758}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-13 11:28.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513112502: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002338512420654297, 'time_algorithm_update': 0.005067203283309936, 'loss': 1.7183942301273345, 'time_step': 0.007466380834579468, 'init_value': 43.73322677612305}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 43.73322677612305
Starting 1000 evaluations
avg return on 3 trajectories of agent17: 1379.7139229739805
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 11:45.28[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 11:45.28[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 11:45.30[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 11:45.30[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 11:45.30[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513114530[0m
[2m2025-05-13 11:45.30[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 11:45.50[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513114530: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002205002307891846, 'time_algorithm_update': 0.004626940488815307, 'loss': 1.4481205892339348, 'time_step': 0.006887283325195313, 'init_value': 4.081625461578369}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 11:46.11[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513114530: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022944233417510986, 'time_algorithm_update': 0.004744038581848144, 'loss': 2.328953851163387, 'time_step': 0.007095854997634887, 'init_value': 11.111557960510254}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 11:46.32[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513114530: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022788038253784178, 'time_algorithm_update': 0.0048369414806365965, 'loss': 2.3013582394719125, 'time_step': 0.007173434019088745, 'init_value': 17.93744468688965}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 11:46.54[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513114530: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023413729667663575, 'time_algorithm_update': 0.005138933420181274, 'loss': 2.1114143802523615, 'time_step': 0.007542470216751099, 'init_value': 24.74029541015625}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 11:47.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513114530: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022227301597595216, 'time_algorithm_update': 0.004634248971939087, 'loss': 2.024481131017208, 'time_step': 0.006912145614624023, 'init_value': 31.045654296875}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 11:47.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513114530: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023395142555236816, 'time_algorithm_update': 0.0049604721069335935, 'loss': 1.861965472996235, 'time_step': 0.007359711170196534, 'init_value': 34.08053207397461}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 11:47.57[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513114530: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022935678958892823, 'time_algorithm_update': 0.004858644962310791, 'loss': 1.7866017602682114, 'time_step': 0.007210491895675659, 'init_value': 36.6883430480957}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 11:48.18[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513114530: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002295835018157959, 'time_algorithm_update': 0.005168040752410888, 'loss': 1.7385301853418351, 'time_step': 0.007526123762130737, 'init_value': 38.605133056640625}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-13 11:48.39[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513114530: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023031265735626223, 'time_algorithm_update': 0.004679358720779419, 'loss': 1.7113193753361702, 'time_step': 0.007038738250732422, 'init_value': 39.634361267089844}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-13 11:49.00[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513114530: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002307376146316528, 'time_algorithm_update': 0.004925882339477539, 'loss': 1.732823996782303, 'time_step': 0.007292587518692017, 'init_value': 40.73890686035156}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.73890686035156
Starting 1000 evaluations
avg return on 3 trajectories of agent18: 1368.1028570437827
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 12:05.51[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 12:05.51[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 12:05.52[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 12:05.52[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 12:05.52[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513120552[0m
[2m2025-05-13 12:05.52[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 12:06.13[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513120552: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022806310653686523, 'time_algorithm_update': 0.0048666360378265385, 'loss': 1.6154548319503665, 'time_step': 0.007206285953521728, 'init_value': 4.770684242248535}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 12:06.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513120552: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023218631744384766, 'time_algorithm_update': 0.0047777676582336425, 'loss': 2.3824090009331704, 'time_step': 0.007158159017562866, 'init_value': 11.554510116577148}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 12:06.56[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513120552: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022967915534973142, 'time_algorithm_update': 0.0049536099433898926, 'loss': 2.1647364673018457, 'time_step': 0.007309899091720581, 'init_value': 19.203227996826172}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 12:07.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513120552: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022814049720764162, 'time_algorithm_update': 0.00484635329246521, 'loss': 2.1438992045521736, 'time_step': 0.007186252355575562, 'init_value': 26.83897590637207}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 12:07.38[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513120552: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023276185989379882, 'time_algorithm_update': 0.0048832368850708005, 'loss': 1.9088085693120957, 'time_step': 0.007269460678100586, 'init_value': 30.641435623168945}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 12:08.00[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513120552: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002327460050582886, 'time_algorithm_update': 0.004964397668838501, 'loss': 1.8462345612049103, 'time_step': 0.0073518092632293705, 'init_value': 35.027557373046875}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 12:08.21[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513120552: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023598318099975588, 'time_algorithm_update': 0.005052853584289551, 'loss': 1.718237011909485, 'time_step': 0.007474100112915039, 'init_value': 38.4229736328125}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 12:08.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513120552: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022873589992523195, 'time_algorithm_update': 0.004808282613754273, 'loss': 1.6382953733205796, 'time_step': 0.007153488397598266, 'init_value': 40.26298141479492}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-13 12:09.03[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513120552: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002317189931869507, 'time_algorithm_update': 0.004920890092849731, 'loss': 1.726039839208126, 'time_step': 0.007297335386276245, 'init_value': 41.15375900268555}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-13 12:09.25[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513120552: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002317063093185425, 'time_algorithm_update': 0.005079113960266114, 'loss': 1.5640515057444573, 'time_step': 0.00745773959159851, 'init_value': 42.721405029296875}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.721405029296875
Starting 1000 evaluations
avg return on 3 trajectories of agent19: 1347.2463235728276
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 12:26.20[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 12:26.20[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 12:26.21[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 12:26.21[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 12:26.21[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513122621[0m
[2m2025-05-13 12:26.21[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 12:26.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513122621: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002271514654159546, 'time_algorithm_update': 0.005020032644271851, 'loss': 1.5873811430707574, 'time_step': 0.00735252571105957, 'init_value': 4.39052152633667}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 12:27.03[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513122621: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022291810512542723, 'time_algorithm_update': 0.004631962776184082, 'loss': 2.258171250402927, 'time_step': 0.006916937828063965, 'init_value': 10.391036987304688}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 12:27.24[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513122621: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002334913969039917, 'time_algorithm_update': 0.005174458980560303, 'loss': 2.2786235377788544, 'time_step': 0.00757131576538086, 'init_value': 18.00296974182129}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 12:27.46[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513122621: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023125159740448, 'time_algorithm_update': 0.0048290808200836186, 'loss': 2.1550545766353606, 'time_step': 0.007199508190155029, 'init_value': 23.79769515991211}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 12:28.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513122621: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002298487186431885, 'time_algorithm_update': 0.004872275829315186, 'loss': 2.038500331521034, 'time_step': 0.0072296903133392335, 'init_value': 28.811683654785156}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 12:28.28[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513122621: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00221549654006958, 'time_algorithm_update': 0.004628550767898559, 'loss': 1.9837297078967095, 'time_step': 0.00690003776550293, 'init_value': 31.58771324157715}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 12:28.50[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513122621: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002368690490722656, 'time_algorithm_update': 0.00506563401222229, 'loss': 1.7831487815976144, 'time_step': 0.007494838237762451, 'init_value': 33.9030647277832}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 12:29.11[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513122621: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023141732215881347, 'time_algorithm_update': 0.005038243055343628, 'loss': 1.7614351978898048, 'time_step': 0.007413326263427734, 'init_value': 36.395774841308594}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-13 12:29.32[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513122621: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002289036273956299, 'time_algorithm_update': 0.004709131956100464, 'loss': 1.5880078608393668, 'time_step': 0.0070551269054412846, 'init_value': 38.609493255615234}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-13 12:29.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513122621: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00227732515335083, 'time_algorithm_update': 0.0048058867454528805, 'loss': 1.7024503032565117, 'time_step': 0.007141008377075196, 'init_value': 41.27463150024414}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.27463150024414
ave advantage rew: 41.7860631942749, std: 1.017754851575672
avg cum rews: 1368.7015583550842, std: 16.53327256145364
Pearson correlation coefficient: 0.06702773872648611
Spearman correlation coefficient: 0.03308270676691729
Kendall Tau correlation coefficient: 0.052631578947368425
the best agent: 5, best agent cum rewards: 1391.2921492032922
1959
Starting to collect rollouts
Collecting rollouts: 10000/1000000
Collecting rollouts: 20000/1000000
Collecting rollouts: 30000/1000000
Collecting rollouts: 40000/1000000
Collecting rollouts: 50000/1000000
Collecting rollouts: 60000/1000000
Collecting rollouts: 70000/1000000
Collecting rollouts: 80000/1000000
Collecting rollouts: 90000/1000000
Collecting rollouts: 100000/1000000
Collecting rollouts: 110000/1000000
Collecting rollouts: 120000/1000000
Collecting rollouts: 130000/1000000
Collecting rollouts: 140000/1000000
Collecting rollouts: 150000/1000000
Collecting rollouts: 160000/1000000
Collecting rollouts: 170000/1000000
Collecting rollouts: 180000/1000000
Collecting rollouts: 190000/1000000
Collecting rollouts: 200000/1000000
Collecting rollouts: 210000/1000000
Collecting rollouts: 220000/1000000
Collecting rollouts: 230000/1000000
Collecting rollouts: 240000/1000000
Collecting rollouts: 250000/1000000
Collecting rollouts: 260000/1000000
Collecting rollouts: 270000/1000000
Collecting rollouts: 280000/1000000
Collecting rollouts: 290000/1000000
Collecting rollouts: 300000/1000000
Collecting rollouts: 310000/1000000
Collecting rollouts: 320000/1000000
Collecting rollouts: 330000/1000000
Collecting rollouts: 340000/1000000
Collecting rollouts: 350000/1000000
Collecting rollouts: 360000/1000000
Collecting rollouts: 370000/1000000
Collecting rollouts: 380000/1000000
Collecting rollouts: 390000/1000000
Collecting rollouts: 400000/1000000
Collecting rollouts: 410000/1000000
Collecting rollouts: 420000/1000000
Collecting rollouts: 430000/1000000
Collecting rollouts: 440000/1000000
Collecting rollouts: 450000/1000000
Collecting rollouts: 460000/1000000
Collecting rollouts: 470000/1000000
Collecting rollouts: 480000/1000000
Collecting rollouts: 490000/1000000
Collecting rollouts: 500000/1000000
Collecting rollouts: 510000/1000000
Collecting rollouts: 520000/1000000
Collecting rollouts: 530000/1000000
Collecting rollouts: 540000/1000000
Collecting rollouts: 550000/1000000
Collecting rollouts: 560000/1000000
Collecting rollouts: 570000/1000000
Collecting rollouts: 580000/1000000
Collecting rollouts: 590000/1000000
Collecting rollouts: 600000/1000000
Collecting rollouts: 610000/1000000
Collecting rollouts: 620000/1000000
Collecting rollouts: 630000/1000000
Collecting rollouts: 640000/1000000
Collecting rollouts: 650000/1000000
Collecting rollouts: 660000/1000000
Collecting rollouts: 670000/1000000
Collecting rollouts: 680000/1000000
Collecting rollouts: 690000/1000000
Collecting rollouts: 700000/1000000
Collecting rollouts: 710000/1000000
Collecting rollouts: 720000/1000000
Collecting rollouts: 730000/1000000
Collecting rollouts: 740000/1000000
Collecting rollouts: 750000/1000000
Collecting rollouts: 760000/1000000
Collecting rollouts: 770000/1000000
Collecting rollouts: 780000/1000000
Collecting rollouts: 790000/1000000
Collecting rollouts: 800000/1000000
Collecting rollouts: 810000/1000000
Collecting rollouts: 820000/1000000
Collecting rollouts: 830000/1000000
Collecting rollouts: 840000/1000000
Collecting rollouts: 850000/1000000
Collecting rollouts: 860000/1000000
Collecting rollouts: 870000/1000000
Collecting rollouts: 880000/1000000
Collecting rollouts: 890000/1000000
Collecting rollouts: 900000/1000000
Collecting rollouts: 910000/1000000
Collecting rollouts: 920000/1000000
Collecting rollouts: 930000/1000000
Collecting rollouts: 940000/1000000
Collecting rollouts: 950000/1000000
Collecting rollouts: 960000/1000000
Collecting rollouts: 970000/1000000
Collecting rollouts: 980000/1000000
Collecting rollouts: 990000/1000000
Collecting rollouts: 1000000/1000000
Replay buffer size:  (1000000, 105)
Replay buffer saved
---------------------------------
Searching empty space policies
(10, 11472)
(20, 11472)
(20, 11472)
Average distance of agents to nearest neighbors: 0.0192045654173801
Starting 1000 evaluations
avg return on 3 trajectories of agent0: 1382.3783393859496
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 13:06.45[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 13:06.45[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 13:06.46[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 13:06.46[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 13:06.46[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513130646[0m
[2m2025-05-13 13:06.46[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 13:07.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513130646: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00227028489112854, 'time_algorithm_update': 0.004798239469528199, 'loss': 1.6050201103165747, 'time_step': 0.00712673282623291, 'init_value': 4.698503017425537}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 13:07.28[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513130646: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023210363388061523, 'time_algorithm_update': 0.004767751455307007, 'loss': 2.308212098836899, 'time_step': 0.007146092414855957, 'init_value': 11.384892463684082}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 13:07.50[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513130646: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002303257703781128, 'time_algorithm_update': 0.0049563889503479, 'loss': 2.281330606997013, 'time_step': 0.007318717956542969, 'init_value': 18.87094497680664}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 13:08.11[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513130646: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023568696975708008, 'time_algorithm_update': 0.005062766313552856, 'loss': 2.2283558517098427, 'time_step': 0.007480727195739746, 'init_value': 25.57843017578125}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 13:08.32[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513130646: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022817084789276123, 'time_algorithm_update': 0.004858425378799438, 'loss': 2.035724516093731, 'time_step': 0.007197533130645752, 'init_value': 30.541927337646484}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 13:08.54[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513130646: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00228317928314209, 'time_algorithm_update': 0.00487266731262207, 'loss': 1.8573168100714683, 'time_step': 0.007213560342788697, 'init_value': 33.473907470703125}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 13:09.15[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513130646: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023319573402404785, 'time_algorithm_update': 0.00497523045539856, 'loss': 1.7578945806026458, 'time_step': 0.0073661720752716065, 'init_value': 36.090599060058594}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 13:09.36[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513130646: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002343756675720215, 'time_algorithm_update': 0.005103080749511719, 'loss': 1.6978248242139817, 'time_step': 0.007508632898330689, 'init_value': 38.262508392333984}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-13 13:09.58[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513130646: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023545773029327393, 'time_algorithm_update': 0.004917279958724975, 'loss': 1.7651072319746017, 'time_step': 0.007330765962600708, 'init_value': 40.88203811645508}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-13 13:10.19[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513130646: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023106107711791993, 'time_algorithm_update': 0.004991384744644165, 'loss': 1.6311117874979972, 'time_step': 0.007361192226409912, 'init_value': 42.10231399536133}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.10231399536133
Starting 1000 evaluations
avg return on 3 trajectories of agent1: 1389.052576383371
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 13:27.14[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 13:27.14[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 13:27.15[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 13:27.15[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 13:27.15[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513132715[0m
[2m2025-05-13 13:27.15[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 13:27.36[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513132715: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022763705253601076, 'time_algorithm_update': 0.00485003137588501, 'loss': 1.6801285591199995, 'time_step': 0.007185100555419922, 'init_value': 4.399806022644043}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 13:27.58[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513132715: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002355959892272949, 'time_algorithm_update': 0.0048441228866577144, 'loss': 2.36935280251503, 'time_step': 0.007258916854858398, 'init_value': 10.373916625976562}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 13:28.19[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513132715: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023078219890594483, 'time_algorithm_update': 0.004809000730514526, 'loss': 2.323199645936489, 'time_step': 0.007174758195877075, 'init_value': 18.372913360595703}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 13:28.40[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513132715: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002318552255630493, 'time_algorithm_update': 0.004718267440795899, 'loss': 2.1645021240115168, 'time_step': 0.007093941688537598, 'init_value': 25.02796173095703}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 13:29.01[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513132715: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002300966739654541, 'time_algorithm_update': 0.00490934157371521, 'loss': 1.9652383294701576, 'time_step': 0.007269693613052368, 'init_value': 30.03121566772461}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 13:29.22[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513132715: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002367550611495972, 'time_algorithm_update': 0.004907856941223145, 'loss': 1.7861937772035599, 'time_step': 0.0073358800411224365, 'init_value': 33.218414306640625}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 13:29.44[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513132715: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002339359760284424, 'time_algorithm_update': 0.004958532094955444, 'loss': 1.7923143520355225, 'time_step': 0.007358115434646606, 'init_value': 36.376808166503906}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 13:30.05[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513132715: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002267197370529175, 'time_algorithm_update': 0.004608927965164184, 'loss': 1.7122348619103431, 'time_step': 0.006932459115982056, 'init_value': 39.89581298828125}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-13 13:30.26[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513132715: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00233524227142334, 'time_algorithm_update': 0.004893017768859863, 'loss': 1.6532390318512917, 'time_step': 0.007287431955337525, 'init_value': 42.29010009765625}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-13 13:30.48[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513132715: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022632620334625242, 'time_algorithm_update': 0.004761629581451416, 'loss': 1.7114752231240273, 'time_step': 0.007082925319671631, 'init_value': 44.203060150146484}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 44.203060150146484
Starting 1000 evaluations
avg return on 3 trajectories of agent2: 1385.6612025562385
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 13:47.41[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 13:47.41[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 13:47.43[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 13:47.43[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 13:47.43[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513134743[0m
[2m2025-05-13 13:47.43[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 13:48.03[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513134743: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022721147537231447, 'time_algorithm_update': 0.0048032236099243165, 'loss': 1.5928655908703804, 'time_step': 0.007133380889892578, 'init_value': 4.452875137329102}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 13:48.24[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513134743: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022830595970153808, 'time_algorithm_update': 0.0046712737083435055, 'loss': 2.282278753519058, 'time_step': 0.007011198759078979, 'init_value': 10.477522850036621}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 13:48.45[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513134743: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002296098470687866, 'time_algorithm_update': 0.004849376440048217, 'loss': 2.295540629386902, 'time_step': 0.007204514026641845, 'init_value': 18.148778915405273}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 13:49.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513134743: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023822627067565916, 'time_algorithm_update': 0.0050334794521331785, 'loss': 2.2017477710843085, 'time_step': 0.007477460861206054, 'init_value': 24.72820472717285}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 13:49.28[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513134743: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002265885353088379, 'time_algorithm_update': 0.004730456352233887, 'loss': 1.9529850543737413, 'time_step': 0.0070536725521087645, 'init_value': 28.70207405090332}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 13:49.49[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513134743: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002288559436798096, 'time_algorithm_update': 0.0047730705738067624, 'loss': 1.7755736058950424, 'time_step': 0.007119205951690674, 'init_value': 31.377676010131836}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 13:50.10[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513134743: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002324333906173706, 'time_algorithm_update': 0.004874821424484253, 'loss': 1.741612505197525, 'time_step': 0.007257925271987915, 'init_value': 35.02226257324219}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 13:50.32[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513134743: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023372552394866943, 'time_algorithm_update': 0.005078519105911255, 'loss': 1.7514559932947158, 'time_step': 0.007477670431137085, 'init_value': 37.801029205322266}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-13 13:50.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513134743: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023094863891601563, 'time_algorithm_update': 0.004807946681976319, 'loss': 1.591417892575264, 'time_step': 0.007175797939300537, 'init_value': 39.220340728759766}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-13 13:51.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513134743: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002303788900375366, 'time_algorithm_update': 0.004877749919891357, 'loss': 1.5550727506875992, 'time_step': 0.007239955186843872, 'init_value': 41.51399612426758}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.51399612426758
Starting 1000 evaluations
avg return on 3 trajectories of agent3: 1376.8361512058136
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 14:08.07[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 14:08.07[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 14:08.08[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 14:08.08[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 14:08.08[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513140808[0m
[2m2025-05-13 14:08.08[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 14:08.29[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513140808: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022341368198394774, 'time_algorithm_update': 0.004632339239120483, 'loss': 1.7130528725609184, 'time_step': 0.006922738313674927, 'init_value': 4.342540264129639}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 14:08.50[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513140808: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023319036960601806, 'time_algorithm_update': 0.004827592611312866, 'loss': 2.433508060157299, 'time_step': 0.007218423366546631, 'init_value': 10.989946365356445}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 14:09.11[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513140808: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023013827800750734, 'time_algorithm_update': 0.004973124980926513, 'loss': 2.1708249502182007, 'time_step': 0.007334147930145264, 'init_value': 18.000747680664062}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 14:09.32[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513140808: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002306787967681885, 'time_algorithm_update': 0.004892588138580322, 'loss': 2.091520775139332, 'time_step': 0.007258412837982178, 'init_value': 25.00328254699707}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 14:09.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513140808: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022496562004089356, 'time_algorithm_update': 0.004666812419891357, 'loss': 1.9092955419421196, 'time_step': 0.00697273325920105, 'init_value': 29.20633888244629}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 14:10.15[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513140808: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023350374698638916, 'time_algorithm_update': 0.004921698093414307, 'loss': 1.8171463328003883, 'time_step': 0.0073160362243652344, 'init_value': 33.007652282714844}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 14:10.36[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513140808: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002356447219848633, 'time_algorithm_update': 0.004993171215057373, 'loss': 1.7760407804250717, 'time_step': 0.007409613847732544, 'init_value': 36.577293395996094}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 14:10.57[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513140808: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002314298629760742, 'time_algorithm_update': 0.004878247261047363, 'loss': 1.8334410457611083, 'time_step': 0.00725074052810669, 'init_value': 39.73931121826172}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-13 14:11.19[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513140808: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023293168544769286, 'time_algorithm_update': 0.004847398519515991, 'loss': 1.620022905766964, 'time_step': 0.007234973430633545, 'init_value': 41.450950622558594}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-13 14:11.40[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513140808: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002277305841445923, 'time_algorithm_update': 0.004829113006591797, 'loss': 1.8078728962540627, 'time_step': 0.007164824724197388, 'init_value': 41.921226501464844}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.921226501464844
Starting 1000 evaluations
avg return on 3 trajectories of agent4: 1385.4703370066732
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 14:28.33[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 14:28.33[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 14:28.35[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 14:28.35[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 14:28.35[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513142835[0m
[2m2025-05-13 14:28.35[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 14:28.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513142835: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022671854496002196, 'time_algorithm_update': 0.004736342668533325, 'loss': 1.5455298340469599, 'time_step': 0.007060188055038452, 'init_value': 4.37993860244751}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 14:29.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513142835: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023490314483642577, 'time_algorithm_update': 0.004943006753921509, 'loss': 2.1982810218334197, 'time_step': 0.007351234436035157, 'init_value': 11.548799514770508}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 14:29.38[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513142835: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002304143190383911, 'time_algorithm_update': 0.004853493452072143, 'loss': 2.070247646331787, 'time_step': 0.007215548753738404, 'init_value': 18.440799713134766}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 14:29.59[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513142835: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023435978889465334, 'time_algorithm_update': 0.004975435256958008, 'loss': 2.036673937737942, 'time_step': 0.007378204584121704, 'init_value': 24.80979347229004}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 14:30.21[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513142835: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023114323616027833, 'time_algorithm_update': 0.004905475616455078, 'loss': 1.921261653482914, 'time_step': 0.00727553129196167, 'init_value': 30.067642211914062}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 14:30.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513142835: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002342911720275879, 'time_algorithm_update': 0.00488884973526001, 'loss': 1.8735841024518014, 'time_step': 0.007289434432983398, 'init_value': 33.291954040527344}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 14:31.04[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513142835: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00235100793838501, 'time_algorithm_update': 0.005049777269363403, 'loss': 1.8487097057700157, 'time_step': 0.007461509466171265, 'init_value': 35.79794692993164}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 14:31.25[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513142835: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00229746413230896, 'time_algorithm_update': 0.004903918266296387, 'loss': 1.6694756602048875, 'time_step': 0.007259784936904907, 'init_value': 38.069374084472656}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-13 14:31.46[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513142835: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002377870321273804, 'time_algorithm_update': 0.00506074047088623, 'loss': 1.6267754799723626, 'time_step': 0.007498748540878296, 'init_value': 40.746864318847656}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-13 14:32.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513142835: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022561471462249757, 'time_algorithm_update': 0.004739830255508423, 'loss': 1.7526519175767898, 'time_step': 0.007052006244659424, 'init_value': 42.718875885009766}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.718875885009766
Starting 1000 evaluations
avg return on 3 trajectories of agent5: 1389.7847228694964
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 14:49.02[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 14:49.02[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 14:49.03[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 14:49.03[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 14:49.03[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513144903[0m
[2m2025-05-13 14:49.03[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 14:49.24[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513144903: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002294820785522461, 'time_algorithm_update': 0.004789952039718628, 'loss': 1.8969486737474799, 'time_step': 0.007142731189727783, 'init_value': 4.565858840942383}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 14:49.45[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513144903: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022973670959472656, 'time_algorithm_update': 0.004834387063980102, 'loss': 2.385746946156025, 'time_step': 0.007190398931503296, 'init_value': 11.65119743347168}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 14:50.06[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513144903: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023455088138580322, 'time_algorithm_update': 0.004930179357528686, 'loss': 2.258088891327381, 'time_step': 0.007335663080215454, 'init_value': 19.42313575744629}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 14:50.28[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513144903: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023441762924194336, 'time_algorithm_update': 0.00484639048576355, 'loss': 2.1640088428258895, 'time_step': 0.007248849153518677, 'init_value': 26.800031661987305}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 14:50.48[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513144903: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022554752826690672, 'time_algorithm_update': 0.004645272731781006, 'loss': 1.9296357924342156, 'time_step': 0.006956571340560913, 'init_value': 31.78866195678711}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 14:51.09[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513144903: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023293941020965576, 'time_algorithm_update': 0.005012737035751343, 'loss': 1.7532256402373314, 'time_step': 0.007402767181396484, 'init_value': 34.96983337402344}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 14:51.31[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513144903: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002314382553100586, 'time_algorithm_update': 0.004894858598709107, 'loss': 1.8274026244282722, 'time_step': 0.007268547296524048, 'init_value': 37.747867584228516}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 14:51.52[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513144903: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002304532289505005, 'time_algorithm_update': 0.0049233965873718265, 'loss': 1.6916379553079606, 'time_step': 0.007287123441696167, 'init_value': 39.58249282836914}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-13 14:52.13[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513144903: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002244830369949341, 'time_algorithm_update': 0.004670621871948243, 'loss': 1.6789081581830978, 'time_step': 0.006971590280532837, 'init_value': 41.38505554199219}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-13 14:52.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513144903: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023749921321868897, 'time_algorithm_update': 0.005042320013046265, 'loss': 1.621560992062092, 'time_step': 0.007478497505187988, 'init_value': 42.873817443847656}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.873817443847656
Starting 1000 evaluations
avg return on 3 trajectories of agent6: 1388.3094709182437
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 15:09.29[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 15:09.29[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 15:09.30[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 15:09.30[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 15:09.30[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513150930[0m
[2m2025-05-13 15:09.30[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 15:09.51[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513150930: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022341370582580566, 'time_algorithm_update': 0.0047369029521942135, 'loss': 1.5934828776195646, 'time_step': 0.007027360916137695, 'init_value': 4.719044208526611}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 15:10.12[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513150930: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002306580066680908, 'time_algorithm_update': 0.004718888282775879, 'loss': 2.2249983255267143, 'time_step': 0.007082525014877319, 'init_value': 11.75208854675293}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 15:10.33[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513150930: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023071365356445313, 'time_algorithm_update': 0.0049549899101257325, 'loss': 2.2820330983400345, 'time_step': 0.007321780681610108, 'init_value': 19.724828720092773}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 15:10.54[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513150930: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022691826820373535, 'time_algorithm_update': 0.0048541660308837895, 'loss': 2.095020165503025, 'time_step': 0.007181330919265747, 'init_value': 25.042343139648438}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 15:11.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513150930: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022666373252868653, 'time_algorithm_update': 0.0047121355533599855, 'loss': 1.9220976943969728, 'time_step': 0.007034557819366455, 'init_value': 29.436243057250977}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 15:11.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513150930: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002324577569961548, 'time_algorithm_update': 0.00494938063621521, 'loss': 1.8358312393426894, 'time_step': 0.007332339525222779, 'init_value': 33.37013244628906}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 15:11.57[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513150930: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002333333969116211, 'time_algorithm_update': 0.004973018884658813, 'loss': 1.6399606221914291, 'time_step': 0.007365612506866455, 'init_value': 35.132564544677734}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 15:12.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513150930: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022975044250488283, 'time_algorithm_update': 0.004856199979782105, 'loss': 1.6985008371472359, 'time_step': 0.007212302923202515, 'init_value': 39.3829460144043}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-13 15:12.38[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513150930: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022590503692626954, 'time_algorithm_update': 0.004670969247817993, 'loss': 1.6025997765660287, 'time_step': 0.006986590385437011, 'init_value': 40.848114013671875}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-13 15:13.00[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513150930: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022805047035217283, 'time_algorithm_update': 0.004885134935379029, 'loss': 1.647982513308525, 'time_step': 0.0072238421440124516, 'init_value': 42.02616882324219}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.02616882324219
Starting 1000 evaluations
avg return on 3 trajectories of agent7: 1385.824273646589
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 15:29.48[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 15:29.48[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 15:29.49[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 15:29.49[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 15:29.49[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513152949[0m
[2m2025-05-13 15:29.49[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 15:30.09[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513152949: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022143890857696533, 'time_algorithm_update': 0.004619356393814087, 'loss': 1.7200978002026677, 'time_step': 0.006889710426330567, 'init_value': 4.6088433265686035}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 15:30.30[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513152949: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022330427169799803, 'time_algorithm_update': 0.004563843965530396, 'loss': 2.2779822701215746, 'time_step': 0.006851853370666504, 'init_value': 11.506084442138672}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 15:30.51[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513152949: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022971091270446776, 'time_algorithm_update': 0.004895787000656128, 'loss': 2.1908530975580214, 'time_step': 0.007252284049987793, 'init_value': 18.34056854248047}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 15:31.12[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513152949: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023556010723114014, 'time_algorithm_update': 0.0049951388835906985, 'loss': 2.050116998076439, 'time_step': 0.007411523580551148, 'init_value': 24.12226104736328}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 15:31.33[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513152949: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002255850076675415, 'time_algorithm_update': 0.00472933554649353, 'loss': 1.961098738849163, 'time_step': 0.007042130708694458, 'init_value': 29.313940048217773}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 15:31.54[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513152949: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002328209400177002, 'time_algorithm_update': 0.004771733522415161, 'loss': 1.8223439286351204, 'time_step': 0.0071579525470733645, 'init_value': 32.61290740966797}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 15:32.15[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513152949: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002294907808303833, 'time_algorithm_update': 0.004835643529891968, 'loss': 1.7639508504271508, 'time_step': 0.007189802169799805, 'init_value': 35.76959228515625}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 15:32.37[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513152949: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023938632011413575, 'time_algorithm_update': 0.0049650356769561765, 'loss': 1.796041251540184, 'time_step': 0.0074192736148834225, 'init_value': 38.16316223144531}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-13 15:32.57[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513152949: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002246084213256836, 'time_algorithm_update': 0.004678823709487915, 'loss': 1.6934164924621582, 'time_step': 0.0069816079139709475, 'init_value': 40.53107452392578}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-13 15:33.18[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513152949: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022687251567840576, 'time_algorithm_update': 0.00482729434967041, 'loss': 1.693834295630455, 'time_step': 0.007154244422912598, 'init_value': 43.41777801513672}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 43.41777801513672
Starting 1000 evaluations
avg return on 3 trajectories of agent8: 1383.1503332647706
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 15:50.06[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 15:50.06[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 15:50.07[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 15:50.07[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 15:50.07[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513155007[0m
[2m2025-05-13 15:50.07[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 15:50.29[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513155007: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0025583651065826415, 'time_algorithm_update': 0.004883877754211426, 'loss': 1.6013627690523864, 'time_step': 0.007501395225524903, 'init_value': 4.520148277282715}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 15:50.50[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513155007: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002295210599899292, 'time_algorithm_update': 0.00479498815536499, 'loss': 2.3669073191285133, 'time_step': 0.007148643732070923, 'init_value': 11.494922637939453}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 15:51.11[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513155007: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022724471092224123, 'time_algorithm_update': 0.004842986345291137, 'loss': 2.191485692679882, 'time_step': 0.007173674583435059, 'init_value': 19.67715072631836}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 15:51.32[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513155007: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002242225885391235, 'time_algorithm_update': 0.004743312358856201, 'loss': 2.1307860281467437, 'time_step': 0.007042585372924804, 'init_value': 26.552248001098633}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 15:51.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513155007: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023412210941314696, 'time_algorithm_update': 0.0049227380752563474, 'loss': 1.9957361425757407, 'time_step': 0.007323010206222534, 'init_value': 30.233427047729492}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 15:52.15[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513155007: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023432841300964355, 'time_algorithm_update': 0.005172127246856689, 'loss': 1.8277292140722274, 'time_step': 0.007577554702758789, 'init_value': 33.85297393798828}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 15:52.36[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513155007: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002312345027923584, 'time_algorithm_update': 0.004848204851150513, 'loss': 1.8279939305782318, 'time_step': 0.007219067811965942, 'init_value': 37.48292541503906}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 15:52.57[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513155007: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022879157066345215, 'time_algorithm_update': 0.0049229092597961426, 'loss': 1.8412941319942475, 'time_step': 0.007270203590393066, 'init_value': 40.53734588623047}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-13 15:53.18[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513155007: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002330249547958374, 'time_algorithm_update': 0.00483130931854248, 'loss': 1.7036132380366324, 'time_step': 0.00721946120262146, 'init_value': 42.44913101196289}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-13 15:53.40[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513155007: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002292884111404419, 'time_algorithm_update': 0.004945537805557251, 'loss': 1.7255215750336648, 'time_step': 0.007297887086868286, 'init_value': 42.79137420654297}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.79137420654297
Starting 1000 evaluations
avg return on 3 trajectories of agent9: 1386.195397694508
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 16:10.34[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 16:10.34[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 16:10.35[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 16:10.35[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 16:10.35[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513161035[0m
[2m2025-05-13 16:10.35[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 16:10.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513161035: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002213625431060791, 'time_algorithm_update': 0.004538542747497558, 'loss': 1.603699901431799, 'time_step': 0.006807032823562622, 'init_value': 4.592913627624512}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 16:11.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513161035: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023610119819641113, 'time_algorithm_update': 0.004905943870544434, 'loss': 2.2195612856149673, 'time_step': 0.007326078653335571, 'init_value': 12.09686279296875}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 16:11.38[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513161035: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023080298900604247, 'time_algorithm_update': 0.005001812934875488, 'loss': 2.259664053440094, 'time_step': 0.007370433330535889, 'init_value': 19.792404174804688}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 16:11.59[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513161035: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022991666793823243, 'time_algorithm_update': 0.004763764381408691, 'loss': 2.2025104871988295, 'time_step': 0.007120552778244018, 'init_value': 25.49637794494629}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 16:12.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513161035: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022439866065979003, 'time_algorithm_update': 0.004705532550811768, 'loss': 1.9872640296816826, 'time_step': 0.007006575345993042, 'init_value': 30.218385696411133}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 16:12.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513161035: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002343550205230713, 'time_algorithm_update': 0.004936039686203003, 'loss': 1.7694625593423843, 'time_step': 0.007339348316192627, 'init_value': 32.94449996948242}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 16:13.03[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513161035: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023739609718322753, 'time_algorithm_update': 0.004929712772369385, 'loss': 1.6028964500427245, 'time_step': 0.007363817453384399, 'init_value': 36.05498123168945}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 16:13.24[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513161035: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002272218942642212, 'time_algorithm_update': 0.0047840638160705565, 'loss': 1.7400042377114295, 'time_step': 0.007113812923431396, 'init_value': 37.45691680908203}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-13 16:13.45[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513161035: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023459267616271974, 'time_algorithm_update': 0.0049303138256073, 'loss': 1.6331897116303444, 'time_step': 0.0073360402584075925, 'init_value': 39.43492126464844}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-13 16:14.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513161035: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023303143978118898, 'time_algorithm_update': 0.0049739558696746825, 'loss': 1.596894043624401, 'time_step': 0.007364639520645142, 'init_value': 41.34074020385742}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.34074020385742
Starting 1000 evaluations
avg return on 3 trajectories of agent10: 1379.2545923189662
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 16:30.58[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 16:30.58[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 16:30.59[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 16:30.59[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 16:30.59[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513163059[0m
[2m2025-05-13 16:30.59[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 16:31.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513163059: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022964317798614504, 'time_algorithm_update': 0.005117955684661865, 'loss': 1.6378823110163212, 'time_step': 0.007476478576660156, 'init_value': 4.3576741218566895}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 16:31.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513163059: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002333623170852661, 'time_algorithm_update': 0.004803900241851807, 'loss': 2.248624260902405, 'time_step': 0.007195568323135376, 'init_value': 10.084534645080566}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 16:32.02[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513163059: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002221130847930908, 'time_algorithm_update': 0.004528832197189331, 'loss': 2.3352789869904518, 'time_step': 0.006804560661315918, 'init_value': 18.70098876953125}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 16:32.24[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513163059: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002302149295806885, 'time_algorithm_update': 0.004750222444534302, 'loss': 2.1615705319046974, 'time_step': 0.007109872817993164, 'init_value': 26.57830047607422}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 16:32.45[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513163059: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023198833465576173, 'time_algorithm_update': 0.004914275646209717, 'loss': 2.006396894812584, 'time_step': 0.007294054985046387, 'init_value': 31.497806549072266}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 16:33.06[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513163059: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002323019742965698, 'time_algorithm_update': 0.004875069379806519, 'loss': 1.8158550305366516, 'time_step': 0.0072568562030792235, 'init_value': 34.432884216308594}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 16:33.27[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513163059: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002258202075958252, 'time_algorithm_update': 0.004629526138305664, 'loss': 1.75017338347435, 'time_step': 0.006943694353103638, 'init_value': 37.54693603515625}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 16:33.49[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513163059: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023630540370941163, 'time_algorithm_update': 0.005083833932876587, 'loss': 1.6309369283914565, 'time_step': 0.007509106159210205, 'init_value': 39.56816864013672}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-13 16:34.10[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513163059: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022853338718414307, 'time_algorithm_update': 0.004684842586517334, 'loss': 1.6845448125600815, 'time_step': 0.007026726961135864, 'init_value': 40.80158233642578}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-13 16:34.31[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513163059: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023210444450378416, 'time_algorithm_update': 0.004891751050949097, 'loss': 1.6625005378723146, 'time_step': 0.007271966934204102, 'init_value': 41.412567138671875}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.412567138671875
Starting 1000 evaluations
avg return on 3 trajectories of agent11: 1365.8836541823903
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 16:51.16[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 16:51.16[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 16:51.18[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 16:51.18[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 16:51.18[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513165118[0m
[2m2025-05-13 16:51.18[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 16:51.38[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513165118: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002159409046173096, 'time_algorithm_update': 0.004473517656326294, 'loss': 1.5761296803429723, 'time_step': 0.006687005519866943, 'init_value': 4.444950580596924}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 16:51.59[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513165118: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002307492971420288, 'time_algorithm_update': 0.004843963384628296, 'loss': 2.365001833021641, 'time_step': 0.007210986614227295, 'init_value': 11.720017433166504}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 16:52.21[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513165118: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002325988531112671, 'time_algorithm_update': 0.005165940046310425, 'loss': 2.2620185539722444, 'time_step': 0.007554700136184692, 'init_value': 18.74032974243164}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 16:52.41[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513165118: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022653894424438476, 'time_algorithm_update': 0.0047287287712097165, 'loss': 2.0888191846609114, 'time_step': 0.007051139831542969, 'init_value': 24.346982955932617}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 16:53.02[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513165118: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002171546459197998, 'time_algorithm_update': 0.004574407577514648, 'loss': 1.854281176507473, 'time_step': 0.006800869941711426, 'init_value': 28.982288360595703}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 16:53.23[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513165118: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002244997978210449, 'time_algorithm_update': 0.0048502709865570065, 'loss': 1.857435578584671, 'time_step': 0.007153479099273682, 'init_value': 31.4241943359375}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 16:53.44[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513165118: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023264579772949217, 'time_algorithm_update': 0.005116151809692383, 'loss': 1.8030384256839753, 'time_step': 0.007504901885986328, 'init_value': 36.30303192138672}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 16:54.05[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513165118: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002243414878845215, 'time_algorithm_update': 0.004730212450027466, 'loss': 1.7517997049689293, 'time_step': 0.007029938459396362, 'init_value': 38.00418472290039}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-13 16:54.26[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513165118: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022096872329711915, 'time_algorithm_update': 0.0045937981605529785, 'loss': 1.6792226129770278, 'time_step': 0.006858789682388305, 'init_value': 40.342430114746094}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-13 16:54.47[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513165118: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002282944917678833, 'time_algorithm_update': 0.004997788429260254, 'loss': 1.556164943933487, 'time_step': 0.007341428518295288, 'init_value': 41.726619720458984}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.726619720458984
Starting 1000 evaluations
avg return on 3 trajectories of agent12: 1382.8628024899824
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 17:11.26[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 17:11.26[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 17:11.27[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 17:11.27[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 17:11.27[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513171127[0m
[2m2025-05-13 17:11.27[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 17:11.48[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513171127: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021703667640686035, 'time_algorithm_update': 0.004504967451095581, 'loss': 1.5079293968528509, 'time_step': 0.0067296276092529295, 'init_value': 4.324728488922119}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 17:12.09[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513171127: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022767305374145506, 'time_algorithm_update': 0.00498054051399231, 'loss': 2.418019342362881, 'time_step': 0.007317404985427856, 'init_value': 11.219093322753906}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 17:12.30[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513171127: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022848315238952637, 'time_algorithm_update': 0.00496132493019104, 'loss': 2.3047262898683547, 'time_step': 0.00730610966682434, 'init_value': 18.95953941345215}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 17:12.50[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513171127: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022159523963928224, 'time_algorithm_update': 0.00459872579574585, 'loss': 2.035628567278385, 'time_step': 0.006869522094726563, 'init_value': 25.52437400817871}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 17:13.12[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513171127: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022113170623779296, 'time_algorithm_update': 0.004628315925598144, 'loss': 1.9102020688652992, 'time_step': 0.006895018577575684, 'init_value': 30.37156867980957}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 17:13.33[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513171127: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002321237325668335, 'time_algorithm_update': 0.004972260475158691, 'loss': 1.7596342543959618, 'time_step': 0.007353261947631836, 'init_value': 33.13694763183594}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 17:13.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513171127: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002282405138015747, 'time_algorithm_update': 0.004947836637496948, 'loss': 1.8078717646598816, 'time_step': 0.007289597988128662, 'init_value': 35.78351593017578}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 17:14.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513171127: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022362334728240965, 'time_algorithm_update': 0.00456314492225647, 'loss': 1.7497992619276046, 'time_step': 0.006853942632675171, 'init_value': 38.991615295410156}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-13 17:14.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513171127: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022821052074432375, 'time_algorithm_update': 0.004889185428619385, 'loss': 1.7045486602187156, 'time_step': 0.007230214834213257, 'init_value': 41.28672790527344}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-13 17:14.56[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513171127: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023256165981292726, 'time_algorithm_update': 0.005026638031005859, 'loss': 1.6731083083748817, 'time_step': 0.007412404298782349, 'init_value': 43.53321075439453}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 43.53321075439453
Starting 1000 evaluations
avg return on 3 trajectories of agent13: 1376.218087475575
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 17:31.37[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 17:31.37[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 17:31.39[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 17:31.39[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 17:31.39[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513173139[0m
[2m2025-05-13 17:31.39[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 17:32.00[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513173139: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002272045373916626, 'time_algorithm_update': 0.00501038384437561, 'loss': 1.7021146822422744, 'time_step': 0.007343029975891114, 'init_value': 4.612703323364258}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 17:32.21[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513173139: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022592456340789794, 'time_algorithm_update': 0.004644729137420654, 'loss': 2.382908394277096, 'time_step': 0.006960782766342163, 'init_value': 10.815021514892578}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 17:32.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513173139: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022880117893218995, 'time_algorithm_update': 0.0047773909568786625, 'loss': 2.2787875574827194, 'time_step': 0.007122481346130371, 'init_value': 18.34054946899414}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 17:33.03[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513173139: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023247644901275635, 'time_algorithm_update': 0.004700663566589355, 'loss': 2.0645417166948317, 'time_step': 0.007081785440444946, 'init_value': 24.554872512817383}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 17:33.24[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513173139: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022960789203643798, 'time_algorithm_update': 0.005009000062942505, 'loss': 1.9112309720516205, 'time_step': 0.00736642575263977, 'init_value': 29.213193893432617}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 17:33.45[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513173139: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022874557971954345, 'time_algorithm_update': 0.004777633428573609, 'loss': 1.8103616310358048, 'time_step': 0.007122399806976318, 'init_value': 32.37123107910156}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 17:34.05[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513173139: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023034210205078124, 'time_algorithm_update': 0.004796374320983887, 'loss': 1.7419735670089722, 'time_step': 0.0071570582389831544, 'init_value': 34.87056350708008}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 17:34.27[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513173139: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023070080280303954, 'time_algorithm_update': 0.004905463457107544, 'loss': 1.7617219654917717, 'time_step': 0.007271290063858032, 'init_value': 37.62156677246094}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-13 17:34.48[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513173139: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002280585050582886, 'time_algorithm_update': 0.004910111665725708, 'loss': 1.7088867790699005, 'time_step': 0.00724979567527771, 'init_value': 40.0600471496582}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-13 17:35.09[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513173139: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002285724639892578, 'time_algorithm_update': 0.00480215048789978, 'loss': 1.6255132012963296, 'time_step': 0.007145158290863037, 'init_value': 42.50724411010742}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.50724411010742
Starting 1000 evaluations
avg return on 3 trajectories of agent14: 1370.1045245724488
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 17:51.48[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 17:51.48[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 17:51.50[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 17:51.50[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 17:51.50[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513175150[0m
[2m2025-05-13 17:51.50[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 17:52.10[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513175150: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002288752794265747, 'time_algorithm_update': 0.0047903766632080074, 'loss': 1.6895629560649394, 'time_step': 0.007138406038284302, 'init_value': 4.009321212768555}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 17:52.31[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513175150: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002160369157791138, 'time_algorithm_update': 0.004510628223419189, 'loss': 2.320626941740513, 'time_step': 0.006725151538848877, 'init_value': 10.46779727935791}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 17:52.52[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513175150: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022358009815216066, 'time_algorithm_update': 0.0047301967144012455, 'loss': 2.3163444017767905, 'time_step': 0.0070244519710540776, 'init_value': 18.77528190612793}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 17:53.13[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513175150: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002355436563491821, 'time_algorithm_update': 0.005011032819747924, 'loss': 2.0980549175739287, 'time_step': 0.007427113771438599, 'init_value': 24.708595275878906}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 17:53.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513175150: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022598261833190916, 'time_algorithm_update': 0.0047511570453643796, 'loss': 2.0132375251054766, 'time_step': 0.007067823410034179, 'init_value': 31.429073333740234}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 17:53.54[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513175150: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002316530227661133, 'time_algorithm_update': 0.004705281496047974, 'loss': 1.859076667547226, 'time_step': 0.007078962326049805, 'init_value': 32.568641662597656}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 17:54.16[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513175150: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002310104608535767, 'time_algorithm_update': 0.004874905586242676, 'loss': 1.837870437681675, 'time_step': 0.007244209051132202, 'init_value': 35.913429260253906}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 17:54.37[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513175150: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023579607009887697, 'time_algorithm_update': 0.005030387639999389, 'loss': 1.8146687451004981, 'time_step': 0.00744975471496582, 'init_value': 37.59140396118164}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-13 17:54.57[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513175150: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022479379177093506, 'time_algorithm_update': 0.004760970115661621, 'loss': 1.764615568637848, 'time_step': 0.007065651416778565, 'init_value': 39.31859588623047}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-13 17:55.18[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513175150: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002323726654052734, 'time_algorithm_update': 0.004928951978683472, 'loss': 1.4104975033402443, 'time_step': 0.00731242036819458, 'init_value': 41.74346923828125}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.74346923828125
Starting 1000 evaluations
avg return on 3 trajectories of agent15: 1363.8227525567281
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 18:11.59[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 18:11.59[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 18:12.01[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 18:12.01[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 18:12.01[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513181201[0m
[2m2025-05-13 18:12.01[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 18:12.22[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513181201: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002249554872512817, 'time_algorithm_update': 0.004845596075057983, 'loss': 1.7379757288917899, 'time_step': 0.007154403686523437, 'init_value': 4.6224799156188965}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 18:12.43[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513181201: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022599515914916994, 'time_algorithm_update': 0.004908890008926392, 'loss': 2.201479872524738, 'time_step': 0.007228567361831665, 'init_value': 11.774755477905273}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 18:13.04[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513181201: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022402663230895997, 'time_algorithm_update': 0.0046398954391479496, 'loss': 2.347300273478031, 'time_step': 0.006936264991760254, 'init_value': 19.52424430847168}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 18:13.24[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513181201: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022087583541870117, 'time_algorithm_update': 0.004643311500549316, 'loss': 2.134797256410122, 'time_step': 0.006907740592956543, 'init_value': 26.493051528930664}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 18:13.45[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513181201: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022999203205108644, 'time_algorithm_update': 0.004909687519073487, 'loss': 1.9511746457815171, 'time_step': 0.007269170999526978, 'init_value': 31.145814895629883}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 18:14.06[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513181201: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002326815128326416, 'time_algorithm_update': 0.004950564622879028, 'loss': 1.8871304531693458, 'time_step': 0.007338003873825073, 'init_value': 33.61326217651367}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 18:14.27[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513181201: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022007100582122803, 'time_algorithm_update': 0.004694337129592895, 'loss': 1.8590737509727477, 'time_step': 0.006951287746429443, 'init_value': 36.320289611816406}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 18:14.47[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513181201: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002228950023651123, 'time_algorithm_update': 0.004759923219680786, 'loss': 1.7381287192106247, 'time_step': 0.007046343803405762, 'init_value': 39.326534271240234}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-13 18:15.09[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513181201: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022509989738464355, 'time_algorithm_update': 0.00488033938407898, 'loss': 1.6313623216748239, 'time_step': 0.007190649747848511, 'init_value': 41.043514251708984}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-13 18:15.29[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513181201: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002290426015853882, 'time_algorithm_update': 0.0048035264015197756, 'loss': 1.6312039224505424, 'time_step': 0.007152080059051514, 'init_value': 42.33981704711914}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.33981704711914
Starting 1000 evaluations
avg return on 3 trajectories of agent16: 1381.0816545185976
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 18:32.24[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 18:32.24[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 18:32.25[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 18:32.25[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 18:32.25[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513183225[0m
[2m2025-05-13 18:32.25[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 18:32.46[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513183225: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002299316644668579, 'time_algorithm_update': 0.004869569778442382, 'loss': 1.6185804505050183, 'time_step': 0.007227879524230957, 'init_value': 4.212250232696533}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 18:33.08[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513183225: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023503117561340333, 'time_algorithm_update': 0.0049295005798339845, 'loss': 2.199155515253544, 'time_step': 0.007339167356491089, 'init_value': 10.98882007598877}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 18:33.28[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513183225: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022855424880981446, 'time_algorithm_update': 0.00476924467086792, 'loss': 2.2631568943858147, 'time_step': 0.007112360477447509, 'init_value': 18.519716262817383}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 18:33.49[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513183225: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002291113615036011, 'time_algorithm_update': 0.004732820987701416, 'loss': 2.138933382630348, 'time_step': 0.007080895900726318, 'init_value': 26.083057403564453}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 18:34.11[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513183225: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023360280990600587, 'time_algorithm_update': 0.005027813911437988, 'loss': 1.9971461989879609, 'time_step': 0.007424540758132934, 'init_value': 31.116470336914062}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 18:34.32[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513183225: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023089678287506105, 'time_algorithm_update': 0.004804289102554322, 'loss': 1.869855288863182, 'time_step': 0.007171371936798096, 'init_value': 34.330604553222656}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 18:34.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513183225: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002261647939682007, 'time_algorithm_update': 0.0046894562244415286, 'loss': 1.7427015176415444, 'time_step': 0.00700727105140686, 'init_value': 35.99960708618164}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 18:35.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513183225: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002273150682449341, 'time_algorithm_update': 0.004760863065719605, 'loss': 1.6808650259971618, 'time_step': 0.007091085195541382, 'init_value': 38.64435577392578}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-13 18:35.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513183225: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023921418190002443, 'time_algorithm_update': 0.005083910465240479, 'loss': 1.7553578165769577, 'time_step': 0.007537502527236939, 'init_value': 41.80305862426758}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-13 18:35.57[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513183225: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023341224193573, 'time_algorithm_update': 0.0049630370140075685, 'loss': 1.7456658974289894, 'time_step': 0.007356430530548096, 'init_value': 42.77838134765625}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.77838134765625
Starting 1000 evaluations
avg return on 3 trajectories of agent17: 1377.1135084826635
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 18:52.41[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 18:52.41[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 18:52.43[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 18:52.43[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 18:52.43[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513185243[0m
[2m2025-05-13 18:52.43[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 18:53.04[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513185243: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022334163188934327, 'time_algorithm_update': 0.004680409669876099, 'loss': 1.652695288270712, 'time_step': 0.006971040964126587, 'init_value': 4.7030348777771}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 18:53.24[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513185243: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002246495246887207, 'time_algorithm_update': 0.004637444972991943, 'loss': 2.229125844657421, 'time_step': 0.006939990520477295, 'init_value': 11.296728134155273}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 18:53.45[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513185243: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022749669551849366, 'time_algorithm_update': 0.004631532669067383, 'loss': 2.3827425776124, 'time_step': 0.006963260412216186, 'init_value': 19.563457489013672}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 18:54.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513185243: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002319121599197388, 'time_algorithm_update': 0.0048921117782592775, 'loss': 2.1241541728377342, 'time_step': 0.007289454221725464, 'init_value': 25.761228561401367}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 18:54.27[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513185243: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002235270977020264, 'time_algorithm_update': 0.004715003490447998, 'loss': 1.9579583669900895, 'time_step': 0.007007194995880127, 'init_value': 30.73833656311035}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 18:54.48[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513185243: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002297065019607544, 'time_algorithm_update': 0.00475168490409851, 'loss': 1.963260591685772, 'time_step': 0.007105898380279541, 'init_value': 35.29136657714844}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 18:55.09[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513185243: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022671129703521727, 'time_algorithm_update': 0.004759393453598023, 'loss': 1.8185940588712692, 'time_step': 0.007084216594696045, 'init_value': 36.94422912597656}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 18:55.31[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513185243: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002354360818862915, 'time_algorithm_update': 0.004909734964370727, 'loss': 1.7670782818198203, 'time_step': 0.007323105096817017, 'init_value': 39.73659133911133}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-13 18:55.52[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513185243: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023335347175598145, 'time_algorithm_update': 0.00493702220916748, 'loss': 1.6591279144883155, 'time_step': 0.007329731225967407, 'init_value': 42.18754196166992}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-13 18:56.13[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513185243: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00233333420753479, 'time_algorithm_update': 0.004779037714004517, 'loss': 1.7063855121135711, 'time_step': 0.007169920444488526, 'init_value': 43.774478912353516}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 43.774478912353516
Starting 1000 evaluations
avg return on 3 trajectories of agent18: 1366.9645717669277
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 19:13.00[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 19:13.00[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 19:13.01[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 19:13.01[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 19:13.01[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513191301[0m
[2m2025-05-13 19:13.01[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 19:13.21[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513191301: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002220074415206909, 'time_algorithm_update': 0.004641322135925293, 'loss': 1.6009842859134078, 'time_step': 0.0069176280498504635, 'init_value': 4.639676570892334}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 19:13.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513191301: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002215147972106934, 'time_algorithm_update': 0.004569287061691284, 'loss': 2.2471645721793174, 'time_step': 0.006840270757675171, 'init_value': 11.64792251586914}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 19:14.03[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513191301: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022522363662719727, 'time_algorithm_update': 0.004690685033798218, 'loss': 2.276931312263012, 'time_step': 0.006999638795852661, 'init_value': 18.625226974487305}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 19:14.24[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513191301: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002329902410507202, 'time_algorithm_update': 0.00509590482711792, 'loss': 2.1704794752597807, 'time_step': 0.0074885041713714596, 'init_value': 26.7788028717041}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 19:14.45[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513191301: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022698183059692385, 'time_algorithm_update': 0.004739779710769654, 'loss': 1.967820011138916, 'time_step': 0.00706682562828064, 'init_value': 30.0484561920166}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 19:15.06[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513191301: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002262720823287964, 'time_algorithm_update': 0.004631265163421631, 'loss': 1.7732214689850807, 'time_step': 0.006950149774551392, 'init_value': 34.13448715209961}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 19:15.28[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513191301: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002339086055755615, 'time_algorithm_update': 0.0049942400455474855, 'loss': 1.8325146045088767, 'time_step': 0.00739393162727356, 'init_value': 36.64976119995117}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 19:15.48[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513191301: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022521791458129884, 'time_algorithm_update': 0.004747247457504273, 'loss': 1.7130989909768104, 'time_step': 0.007057175636291504, 'init_value': 39.96637725830078}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-13 19:16.09[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513191301: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002261110782623291, 'time_algorithm_update': 0.004721265316009521, 'loss': 1.682976623237133, 'time_step': 0.0070408787727355955, 'init_value': 40.479217529296875}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-13 19:16.30[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513191301: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022731986045837404, 'time_algorithm_update': 0.0047925422191619875, 'loss': 1.8200126377344132, 'time_step': 0.007123836040496826, 'init_value': 42.185691833496094}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.185691833496094
Starting 1000 evaluations
avg return on 3 trajectories of agent19: 1357.9392129794787
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 19:33.15[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 19:33.15[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 19:33.16[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 19:33.16[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 19:33.16[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513193316[0m
[2m2025-05-13 19:33.16[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 19:33.37[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513193316: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022398707866668702, 'time_algorithm_update': 0.004645607948303223, 'loss': 1.5140222073569893, 'time_step': 0.006942208766937256, 'init_value': 4.398681640625}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 19:33.58[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513193316: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023279931545257568, 'time_algorithm_update': 0.004777385234832764, 'loss': 2.303369615137577, 'time_step': 0.0071639084815979005, 'init_value': 10.905576705932617}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 19:34.19[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513193316: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022887115478515624, 'time_algorithm_update': 0.004747262477874756, 'loss': 2.3532556099295614, 'time_step': 0.0070935204029083255, 'init_value': 19.035085678100586}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 19:34.40[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513193316: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002326743125915527, 'time_algorithm_update': 0.00493669319152832, 'loss': 2.0287236912846565, 'time_step': 0.007323872566223144, 'init_value': 25.341476440429688}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 19:35.01[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513193316: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022050397396087646, 'time_algorithm_update': 0.0044877417087554935, 'loss': 1.9661784357428551, 'time_step': 0.006747624397277832, 'init_value': 29.858829498291016}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 19:35.21[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513193316: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022876057624816896, 'time_algorithm_update': 0.004800312042236328, 'loss': 1.9270929504036904, 'time_step': 0.007146003723144531, 'init_value': 33.64274215698242}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 19:35.43[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513193316: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002308837890625, 'time_algorithm_update': 0.004692401647567749, 'loss': 1.805162140071392, 'time_step': 0.007058676242828369, 'init_value': 35.44242858886719}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 19:36.03[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513193316: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002287414789199829, 'time_algorithm_update': 0.004862929344177246, 'loss': 1.8029890065193177, 'time_step': 0.007210035085678101, 'init_value': 38.22359085083008}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-13 19:36.25[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513193316: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023067090511322023, 'time_algorithm_update': 0.004727768659591675, 'loss': 1.855439746260643, 'time_step': 0.007092041492462158, 'init_value': 39.70304489135742}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-13 19:36.45[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513193316: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022514197826385496, 'time_algorithm_update': 0.00471245265007019, 'loss': 1.7436038928627968, 'time_step': 0.007021355628967285, 'init_value': 41.7429313659668}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.7429313659668
ave advantage rew: 42.43268814086914, std: 0.7993225358864234
avg cum rews: 1378.6954083137705, std: 9.001721104839977
Pearson correlation coefficient: 0.3552333051811629
Spearman correlation coefficient: 0.3082706766917293
Kendall Tau correlation coefficient: 0.22105263157894736
the best agent: 5, best agent cum rewards: 1389.7847228694964
1960
Starting to collect rollouts
Collecting rollouts: 10000/1000000
Collecting rollouts: 20000/1000000
Collecting rollouts: 30000/1000000
Collecting rollouts: 40000/1000000
Collecting rollouts: 50000/1000000
Collecting rollouts: 60000/1000000
Collecting rollouts: 70000/1000000
Collecting rollouts: 80000/1000000
Collecting rollouts: 90000/1000000
Collecting rollouts: 100000/1000000
Collecting rollouts: 110000/1000000
Collecting rollouts: 120000/1000000
Collecting rollouts: 130000/1000000
Collecting rollouts: 140000/1000000
Collecting rollouts: 150000/1000000
Collecting rollouts: 160000/1000000
Collecting rollouts: 170000/1000000
Collecting rollouts: 180000/1000000
Collecting rollouts: 190000/1000000
Collecting rollouts: 200000/1000000
Collecting rollouts: 210000/1000000
Collecting rollouts: 220000/1000000
Collecting rollouts: 230000/1000000
Collecting rollouts: 240000/1000000
Collecting rollouts: 250000/1000000
Collecting rollouts: 260000/1000000
Collecting rollouts: 270000/1000000
Collecting rollouts: 280000/1000000
Collecting rollouts: 290000/1000000
Collecting rollouts: 300000/1000000
Collecting rollouts: 310000/1000000
Collecting rollouts: 320000/1000000
Collecting rollouts: 330000/1000000
Collecting rollouts: 340000/1000000
Collecting rollouts: 350000/1000000
Collecting rollouts: 360000/1000000
Collecting rollouts: 370000/1000000
Collecting rollouts: 380000/1000000
Collecting rollouts: 390000/1000000
Collecting rollouts: 400000/1000000
Collecting rollouts: 410000/1000000
Collecting rollouts: 420000/1000000
Collecting rollouts: 430000/1000000
Collecting rollouts: 440000/1000000
Collecting rollouts: 450000/1000000
Collecting rollouts: 460000/1000000
Collecting rollouts: 470000/1000000
Collecting rollouts: 480000/1000000
Collecting rollouts: 490000/1000000
Collecting rollouts: 500000/1000000
Collecting rollouts: 510000/1000000
Collecting rollouts: 520000/1000000
Collecting rollouts: 530000/1000000
Collecting rollouts: 540000/1000000
Collecting rollouts: 550000/1000000
Collecting rollouts: 560000/1000000
Collecting rollouts: 570000/1000000
Collecting rollouts: 580000/1000000
Collecting rollouts: 590000/1000000
Collecting rollouts: 600000/1000000
Collecting rollouts: 610000/1000000
Collecting rollouts: 620000/1000000
Collecting rollouts: 630000/1000000
Collecting rollouts: 640000/1000000
Collecting rollouts: 650000/1000000
Collecting rollouts: 660000/1000000
Collecting rollouts: 670000/1000000
Collecting rollouts: 680000/1000000
Collecting rollouts: 690000/1000000
Collecting rollouts: 700000/1000000
Collecting rollouts: 710000/1000000
Collecting rollouts: 720000/1000000
Collecting rollouts: 730000/1000000
Collecting rollouts: 740000/1000000
Collecting rollouts: 750000/1000000
Collecting rollouts: 760000/1000000
Collecting rollouts: 770000/1000000
Collecting rollouts: 780000/1000000
Collecting rollouts: 790000/1000000
Collecting rollouts: 800000/1000000
Collecting rollouts: 810000/1000000
Collecting rollouts: 820000/1000000
Collecting rollouts: 830000/1000000
Collecting rollouts: 840000/1000000
Collecting rollouts: 850000/1000000
Collecting rollouts: 860000/1000000
Collecting rollouts: 870000/1000000
Collecting rollouts: 880000/1000000
Collecting rollouts: 890000/1000000
Collecting rollouts: 900000/1000000
Collecting rollouts: 910000/1000000
Collecting rollouts: 920000/1000000
Collecting rollouts: 930000/1000000
Collecting rollouts: 940000/1000000
Collecting rollouts: 950000/1000000
Collecting rollouts: 960000/1000000
Collecting rollouts: 970000/1000000
Collecting rollouts: 980000/1000000
Collecting rollouts: 990000/1000000
Collecting rollouts: 1000000/1000000
Replay buffer size:  (1000000, 105)
Replay buffer saved
---------------------------------
Searching empty space policies
(10, 11472)
(20, 11472)
(20, 11472)
Average distance of agents to nearest neighbors: 0.018699624276708807
Starting 1000 evaluations
avg return on 3 trajectories of agent0: 1382.7578838378527
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 20:13.09[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 20:13.09[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 20:13.10[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 20:13.10[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 20:13.10[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513201310[0m
[2m2025-05-13 20:13.10[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 20:13.31[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513201310: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002201503038406372, 'time_algorithm_update': 0.004472079038619995, 'loss': 1.4732490158751608, 'time_step': 0.006727952480316162, 'init_value': 4.448001384735107}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 20:13.52[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513201310: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023760287761688233, 'time_algorithm_update': 0.005067661046981812, 'loss': 2.2668015739917755, 'time_step': 0.007505020618438721, 'init_value': 11.85000991821289}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 20:14.13[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513201310: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022838597297668455, 'time_algorithm_update': 0.00485037112236023, 'loss': 2.2385431639552116, 'time_step': 0.007193390130996704, 'init_value': 19.834959030151367}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 20:14.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513201310: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022750358581542967, 'time_algorithm_update': 0.004672303199768067, 'loss': 2.2717560296058656, 'time_step': 0.0070037820339202885, 'init_value': 26.294607162475586}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 20:14.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513201310: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002202023983001709, 'time_algorithm_update': 0.004517381429672241, 'loss': 1.9338265653252602, 'time_step': 0.006773823976516723, 'init_value': 30.75779914855957}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 20:15.16[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513201310: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002319784879684448, 'time_algorithm_update': 0.005025899410247803, 'loss': 1.9756268630623817, 'time_step': 0.007406458854675293, 'init_value': 33.97568130493164}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 20:15.37[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513201310: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002268413305282593, 'time_algorithm_update': 0.00472914171218872, 'loss': 1.9432786580324173, 'time_step': 0.007054839372634888, 'init_value': 37.836753845214844}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 20:15.58[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513201310: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002300356149673462, 'time_algorithm_update': 0.004767977714538575, 'loss': 1.7672086794376374, 'time_step': 0.007125449180603027, 'init_value': 40.35879898071289}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-13 20:16.19[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513201310: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022775118350982664, 'time_algorithm_update': 0.00469645643234253, 'loss': 1.798263494670391, 'time_step': 0.007030460357666015, 'init_value': 42.261512756347656}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-13 20:16.41[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513201310: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023405425548553467, 'time_algorithm_update': 0.00510718560218811, 'loss': 1.7023244997262954, 'time_step': 0.007510514974594117, 'init_value': 42.90530014038086}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.90530014038086
Starting 1000 evaluations
avg return on 3 trajectories of agent1: 1374.470738989896
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 20:33.27[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 20:33.27[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 20:33.28[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 20:33.28[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 20:33.28[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513203328[0m
[2m2025-05-13 20:33.28[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 20:33.49[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513203328: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002230263948440552, 'time_algorithm_update': 0.004805612802505493, 'loss': 1.7624427065700292, 'time_step': 0.007095001220703125, 'init_value': 4.334980487823486}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 20:34.10[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513203328: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00229949951171875, 'time_algorithm_update': 0.004713390827178955, 'loss': 2.458276956021786, 'time_step': 0.007070585727691651, 'init_value': 11.709433555603027}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 20:34.30[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513203328: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002193731069564819, 'time_algorithm_update': 0.004510773897171021, 'loss': 2.316236487984657, 'time_step': 0.006759339332580566, 'init_value': 19.3721923828125}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 20:34.51[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513203328: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002368422508239746, 'time_algorithm_update': 0.005026734113693238, 'loss': 2.1695572022795675, 'time_step': 0.007456739425659179, 'init_value': 26.730709075927734}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 20:35.12[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513203328: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022885878086090087, 'time_algorithm_update': 0.004821385383605957, 'loss': 1.9872688193917274, 'time_step': 0.007168576717376709, 'init_value': 31.901018142700195}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 20:35.33[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513203328: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022882421016693117, 'time_algorithm_update': 0.0047179853916168215, 'loss': 1.777925602912903, 'time_step': 0.007063899993896484, 'init_value': 34.10161590576172}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 20:35.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513203328: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002205116033554077, 'time_algorithm_update': 0.00454861569404602, 'loss': 1.8782976591587066, 'time_step': 0.006809305429458618, 'init_value': 37.33719253540039}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 20:36.15[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513203328: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023286752700805665, 'time_algorithm_update': 0.005142775535583496, 'loss': 1.7053269836306573, 'time_step': 0.007533687829971314, 'init_value': 39.99304962158203}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-13 20:36.36[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513203328: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023428306579589843, 'time_algorithm_update': 0.004883790969848633, 'loss': 1.7290055267810822, 'time_step': 0.007286031723022461, 'init_value': 42.310794830322266}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-13 20:36.56[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513203328: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002227278232574463, 'time_algorithm_update': 0.004632811546325683, 'loss': 1.6206596346497535, 'time_step': 0.006916173458099365, 'init_value': 42.256046295166016}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.256046295166016
Starting 1000 evaluations
avg return on 3 trajectories of agent2: 1356.7974646945904
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 20:53.44[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 20:53.44[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 20:53.45[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 20:53.45[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 20:53.45[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513205345[0m
[2m2025-05-13 20:53.45[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 20:54.06[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513205345: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022456812858581542, 'time_algorithm_update': 0.004670750617980957, 'loss': 1.6828777401223778, 'time_step': 0.0069730873107910155, 'init_value': 4.802870273590088}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 20:54.27[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513205345: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023383586406707764, 'time_algorithm_update': 0.00474445104598999, 'loss': 2.247798008799553, 'time_step': 0.007140734910964966, 'init_value': 12.264978408813477}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 20:54.48[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513205345: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022668750286102294, 'time_algorithm_update': 0.004757189273834229, 'loss': 2.3126858543753626, 'time_step': 0.007082229375839234, 'init_value': 18.641515731811523}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 20:55.09[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513205345: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023088204860687257, 'time_algorithm_update': 0.00474016523361206, 'loss': 2.139426997959614, 'time_step': 0.007106408834457397, 'init_value': 25.924272537231445}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 20:55.30[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513205345: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022757577896118163, 'time_algorithm_update': 0.004788636207580566, 'loss': 1.954714812874794, 'time_step': 0.007121755123138428, 'init_value': 30.318931579589844}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 20:55.51[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513205345: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00228989577293396, 'time_algorithm_update': 0.004789940118789673, 'loss': 1.881943363249302, 'time_step': 0.007137974262237549, 'init_value': 33.70933532714844}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 20:56.12[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513205345: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023658649921417235, 'time_algorithm_update': 0.0048205192089080815, 'loss': 1.8486103892326355, 'time_step': 0.00724447226524353, 'init_value': 37.179649353027344}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 20:56.33[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513205345: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023199827671051025, 'time_algorithm_update': 0.004845108509063721, 'loss': 1.8118260762691498, 'time_step': 0.007223804473876953, 'init_value': 39.54340744018555}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-13 20:56.54[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513205345: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023591156005859375, 'time_algorithm_update': 0.004848660230636597, 'loss': 1.7018531983494758, 'time_step': 0.007266746997833252, 'init_value': 39.74290084838867}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-13 20:57.15[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513205345: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023178229331970216, 'time_algorithm_update': 0.004824409246444702, 'loss': 1.7530261532068252, 'time_step': 0.007200437307357788, 'init_value': 42.3669319152832}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.3669319152832
Starting 1000 evaluations
avg return on 3 trajectories of agent3: 1330.051996381892
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 21:13.57[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 21:13.57[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 21:13.58[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 21:13.58[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 21:13.58[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513211358[0m
[2m2025-05-13 21:13.58[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 21:14.19[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513211358: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002273403167724609, 'time_algorithm_update': 0.004732034206390381, 'loss': 1.700413312137127, 'time_step': 0.007062206506729126, 'init_value': 4.413727283477783}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 21:14.40[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513211358: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002325101375579834, 'time_algorithm_update': 0.004765072345733643, 'loss': 2.4727059746980666, 'time_step': 0.007148015975952149, 'init_value': 11.475266456604004}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 21:15.01[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513211358: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022849488258361817, 'time_algorithm_update': 0.004731905460357666, 'loss': 2.3192879030108453, 'time_step': 0.007073832988739014, 'init_value': 20.054933547973633}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 21:15.23[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513211358: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023725266456604004, 'time_algorithm_update': 0.0049477629661560055, 'loss': 2.1184252368211745, 'time_step': 0.007379920244216919, 'init_value': 26.30085563659668}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 21:15.44[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513211358: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023066227436065673, 'time_algorithm_update': 0.004855457305908203, 'loss': 2.0631396877765655, 'time_step': 0.007220843315124512, 'init_value': 30.550355911254883}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 21:16.05[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513211358: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002272568941116333, 'time_algorithm_update': 0.004701489448547363, 'loss': 1.8602399100065232, 'time_step': 0.007030542850494385, 'init_value': 34.180171966552734}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 21:16.25[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513211358: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002332449197769165, 'time_algorithm_update': 0.004904089212417603, 'loss': 1.7709850664138793, 'time_step': 0.00729515027999878, 'init_value': 37.3806037902832}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 21:16.47[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513211358: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002322046518325806, 'time_algorithm_update': 0.0049601573944091796, 'loss': 1.773494634449482, 'time_step': 0.007342188119888305, 'init_value': 40.40334701538086}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-13 21:17.08[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513211358: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002314211845397949, 'time_algorithm_update': 0.004774438381195068, 'loss': 1.8026633645892143, 'time_step': 0.007145926475524902, 'init_value': 41.3087043762207}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-13 21:17.29[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513211358: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022907657623291015, 'time_algorithm_update': 0.004758059740066528, 'loss': 1.6325671827197075, 'time_step': 0.007106448173522949, 'init_value': 44.352081298828125}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 44.352081298828125
Starting 1000 evaluations
avg return on 3 trajectories of agent4: 1383.1539704581278
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 21:34.16[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 21:34.16[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 21:34.17[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 21:34.17[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 21:34.17[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513213417[0m
[2m2025-05-13 21:34.17[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 21:34.38[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513213417: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002229909658432007, 'time_algorithm_update': 0.004753182649612427, 'loss': 1.4966142802760005, 'time_step': 0.007042163610458374, 'init_value': 4.742019176483154}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 21:34.59[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513213417: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002305278778076172, 'time_algorithm_update': 0.004891543626785278, 'loss': 2.329797807276249, 'time_step': 0.007256766080856323, 'init_value': 11.751017570495605}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 21:35.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513213417: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002200211524963379, 'time_algorithm_update': 0.0045036647319793705, 'loss': 2.1650702484846116, 'time_step': 0.006758756399154663, 'init_value': 19.19881820678711}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 21:35.40[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513213417: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022343847751617432, 'time_algorithm_update': 0.004713479995727539, 'loss': 2.053558322370052, 'time_step': 0.0070047276020050045, 'init_value': 25.11176872253418}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 21:36.02[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513213417: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002355297327041626, 'time_algorithm_update': 0.004960792303085327, 'loss': 2.051010079205036, 'time_step': 0.0073764450550079345, 'init_value': 30.35186195373535}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 21:36.23[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513213417: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002316974878311157, 'time_algorithm_update': 0.00484037709236145, 'loss': 1.910530715763569, 'time_step': 0.007216352224349976, 'init_value': 34.3341064453125}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 21:36.43[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513213417: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002187134265899658, 'time_algorithm_update': 0.004437341690063477, 'loss': 1.8161241105794907, 'time_step': 0.006679040431976318, 'init_value': 36.65635299682617}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 21:37.04[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513213417: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023067429065704347, 'time_algorithm_update': 0.0048978133201599125, 'loss': 1.7559301264882088, 'time_step': 0.007263935089111328, 'init_value': 39.62232971191406}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-13 21:37.25[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513213417: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002286227226257324, 'time_algorithm_update': 0.004807776927947998, 'loss': 1.789277891933918, 'time_step': 0.007152453184127807, 'init_value': 41.55303955078125}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-13 21:37.46[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513213417: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002299680233001709, 'time_algorithm_update': 0.00473984432220459, 'loss': 1.691341494202614, 'time_step': 0.007097090005874634, 'init_value': 42.96391677856445}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.96391677856445
Starting 1000 evaluations
avg return on 3 trajectories of agent5: 1374.3379782518296
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 21:54.33[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 21:54.33[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 21:54.34[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 21:54.34[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 21:54.34[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513215434[0m
[2m2025-05-13 21:54.34[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 21:54.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513215434: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022429420948028565, 'time_algorithm_update': 0.004750322580337524, 'loss': 1.8071742661520838, 'time_step': 0.007051101922988892, 'init_value': 4.298916816711426}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 21:55.15[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513215434: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002257093906402588, 'time_algorithm_update': 0.004530956745147705, 'loss': 2.228354771435261, 'time_step': 0.006844099283218384, 'init_value': 10.31069278717041}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 21:55.36[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513215434: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022950870990753173, 'time_algorithm_update': 0.004801260709762573, 'loss': 2.3068193633556366, 'time_step': 0.007155206918716431, 'init_value': 18.503623962402344}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 21:55.58[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513215434: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002299525737762451, 'time_algorithm_update': 0.004805730819702148, 'loss': 2.1336793836951258, 'time_step': 0.007163923263549804, 'init_value': 25.18023109436035}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 21:56.19[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513215434: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023200218677520753, 'time_algorithm_update': 0.004971746921539307, 'loss': 1.9233927968144418, 'time_step': 0.0073521828651428225, 'init_value': 29.34864616394043}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 21:56.39[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513215434: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022557892799377442, 'time_algorithm_update': 0.004682628154754639, 'loss': 1.899113674223423, 'time_step': 0.006995379447937012, 'init_value': 33.12706756591797}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 21:57.01[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513215434: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002304750204086304, 'time_algorithm_update': 0.004735233306884766, 'loss': 1.8365956657528877, 'time_step': 0.007097818374633789, 'init_value': 36.294776916503906}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 21:57.22[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513215434: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022988250255584716, 'time_algorithm_update': 0.004791250467300415, 'loss': 1.7525764833688735, 'time_step': 0.0071485905647277834, 'init_value': 39.31443786621094}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-13 21:57.43[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513215434: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022788126468658446, 'time_algorithm_update': 0.004825567483901978, 'loss': 1.7010605002641679, 'time_step': 0.007163528919219971, 'init_value': 41.257530212402344}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-13 21:58.04[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513215434: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022756388187408446, 'time_algorithm_update': 0.004716312170028687, 'loss': 1.796442087352276, 'time_step': 0.007049790620803833, 'init_value': 43.71734619140625}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 43.71734619140625
Starting 1000 evaluations
avg return on 3 trajectories of agent6: 1366.4274993812219
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 22:14.51[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 22:14.51[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 22:14.52[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 22:14.52[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 22:14.52[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513221452[0m
[2m2025-05-13 22:14.52[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 22:15.13[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513221452: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022235283851623536, 'time_algorithm_update': 0.004646602630615234, 'loss': 1.582958525776863, 'time_step': 0.006926485776901245, 'init_value': 4.705371856689453}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 22:15.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513221452: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022640173435211183, 'time_algorithm_update': 0.004806294918060303, 'loss': 2.248888837456703, 'time_step': 0.007128687143325806, 'init_value': 11.339789390563965}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 22:15.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513221452: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002301233768463135, 'time_algorithm_update': 0.005118381977081299, 'loss': 2.239280207335949, 'time_step': 0.007481335163116455, 'init_value': 18.923978805541992}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 22:16.16[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513221452: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022290074825286866, 'time_algorithm_update': 0.0046312367916107175, 'loss': 2.0914514963030815, 'time_step': 0.006916300058364868, 'init_value': 25.753246307373047}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 22:16.37[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513221452: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022323930263519285, 'time_algorithm_update': 0.004628523588180542, 'loss': 2.022198935747147, 'time_step': 0.0069164326190948484, 'init_value': 30.340415954589844}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 22:16.58[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513221452: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023146235942840578, 'time_algorithm_update': 0.0048850390911102295, 'loss': 1.8478456770181655, 'time_step': 0.0072591199874877926, 'init_value': 33.87472915649414}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 22:17.19[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513221452: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00230597710609436, 'time_algorithm_update': 0.005013733148574829, 'loss': 1.8634171966910362, 'time_step': 0.007380285263061523, 'init_value': 36.42230987548828}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 22:17.40[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513221452: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022853376865386963, 'time_algorithm_update': 0.0048156163692474364, 'loss': 1.747192152917385, 'time_step': 0.007159126996994019, 'init_value': 38.57102966308594}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-13 22:18.01[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513221452: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022148144245147704, 'time_algorithm_update': 0.004708245992660522, 'loss': 1.6721662372350692, 'time_step': 0.006979885101318359, 'init_value': 40.15008544921875}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-13 22:18.22[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513221452: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023079466819763183, 'time_algorithm_update': 0.004943848848342896, 'loss': 1.7019167432785034, 'time_step': 0.007311731815338135, 'init_value': 42.52494430541992}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.52494430541992
Starting 1000 evaluations
avg return on 3 trajectories of agent7: 1354.818839632512
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 22:35.11[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 22:35.11[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 22:35.12[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 22:35.12[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 22:35.12[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513223512[0m
[2m2025-05-13 22:35.12[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 22:35.33[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513223512: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002184208631515503, 'time_algorithm_update': 0.004578112363815307, 'loss': 1.6139749615043402, 'time_step': 0.006818819999694825, 'init_value': 4.333946704864502}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 22:35.54[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513223512: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00234613037109375, 'time_algorithm_update': 0.005053673028945923, 'loss': 2.384476300597191, 'time_step': 0.007461856126785279, 'init_value': 11.157499313354492}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 22:36.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513223512: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002221461534500122, 'time_algorithm_update': 0.004704480886459351, 'loss': 2.332738695383072, 'time_step': 0.006982881784439087, 'init_value': 19.07175636291504}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 22:36.36[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513223512: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022852423191070557, 'time_algorithm_update': 0.004759089946746826, 'loss': 2.2130885514616967, 'time_step': 0.007102086782455445, 'init_value': 25.2191162109375}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 22:36.56[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513223512: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002231522083282471, 'time_algorithm_update': 0.004690234184265137, 'loss': 1.9392820194959641, 'time_step': 0.006978469371795654, 'init_value': 29.817256927490234}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 22:37.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513223512: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023262529373168947, 'time_algorithm_update': 0.004888227701187134, 'loss': 1.8767493849396706, 'time_step': 0.0072749249935150145, 'init_value': 33.33761215209961}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 22:37.38[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513223512: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022053453922271727, 'time_algorithm_update': 0.00467619252204895, 'loss': 1.7787774131894112, 'time_step': 0.006938292503356934, 'init_value': 37.565513610839844}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 22:37.59[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513223512: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00228010630607605, 'time_algorithm_update': 0.004837160348892212, 'loss': 1.848461387515068, 'time_step': 0.007176389932632446, 'init_value': 38.788116455078125}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-13 22:38.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513223512: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023320703506469727, 'time_algorithm_update': 0.005019133806228638, 'loss': 1.7441846459507941, 'time_step': 0.00741139030456543, 'init_value': 40.985355377197266}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-13 22:38.41[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513223512: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021966044902801516, 'time_algorithm_update': 0.004673606872558593, 'loss': 1.737194766163826, 'time_step': 0.006927000045776367, 'init_value': 42.33243179321289}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.33243179321289
Starting 1000 evaluations
avg return on 3 trajectories of agent8: 1377.7435091941577
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 22:55.34[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 22:55.34[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 22:55.35[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 22:55.35[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 22:55.35[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513225535[0m
[2m2025-05-13 22:55.35[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 22:55.56[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513225535: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022109599113464356, 'time_algorithm_update': 0.004641000747680664, 'loss': 1.7438178341463209, 'time_step': 0.006908396720886231, 'init_value': 4.2370758056640625}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 22:56.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513225535: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002306710958480835, 'time_algorithm_update': 0.0048233230113983155, 'loss': 2.1420505719780922, 'time_step': 0.007189191579818725, 'init_value': 10.903796195983887}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 22:56.38[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513225535: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002236968994140625, 'time_algorithm_update': 0.004681178092956543, 'loss': 2.3246390723586083, 'time_step': 0.006975330591201782, 'init_value': 19.304311752319336}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 22:56.59[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513225535: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022787840366363527, 'time_algorithm_update': 0.004775725364685059, 'loss': 2.0860598121285436, 'time_step': 0.007112509489059448, 'init_value': 24.91160011291504}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 22:57.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513225535: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002314892530441284, 'time_algorithm_update': 0.004878539085388184, 'loss': 1.9144246900677682, 'time_step': 0.0072521109580993654, 'init_value': 29.390838623046875}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 22:57.41[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513225535: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00229468035697937, 'time_algorithm_update': 0.004905328512191772, 'loss': 1.8699918670654296, 'time_step': 0.007259072303771973, 'init_value': 31.719989776611328}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 22:58.02[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513225535: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002279020071029663, 'time_algorithm_update': 0.004693834781646728, 'loss': 1.6991788712739944, 'time_step': 0.0070302882194519046, 'init_value': 33.60729217529297}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 22:58.23[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513225535: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022830963134765625, 'time_algorithm_update': 0.0048305211067199705, 'loss': 1.7133125579953195, 'time_step': 0.00717201828956604, 'init_value': 35.86310577392578}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-13 22:58.45[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513225535: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022864723205566406, 'time_algorithm_update': 0.004827277183532715, 'loss': 1.6825950624346733, 'time_step': 0.007172717571258545, 'init_value': 38.359169006347656}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-13 22:59.06[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513225535: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022662203311920167, 'time_algorithm_update': 0.004951252698898316, 'loss': 1.7886395366191865, 'time_step': 0.007277658700942993, 'init_value': 40.96417999267578}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.96417999267578
Starting 1000 evaluations
avg return on 3 trajectories of agent9: 1377.7587410567678
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 23:15.57[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 23:15.57[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 23:15.58[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 23:15.58[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 23:15.58[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513231558[0m
[2m2025-05-13 23:15.58[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 23:16.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513231558: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002293788194656372, 'time_algorithm_update': 0.004993768215179444, 'loss': 1.7357923264577986, 'time_step': 0.007349058389663697, 'init_value': 4.407635688781738}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 23:16.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513231558: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002306121349334717, 'time_algorithm_update': 0.005050094604492188, 'loss': 2.3580856997966766, 'time_step': 0.0074193313121795655, 'init_value': 11.160266876220703}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 23:17.03[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513231558: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002309117317199707, 'time_algorithm_update': 0.004921883106231689, 'loss': 2.291758355140686, 'time_step': 0.007291193962097168, 'init_value': 18.923381805419922}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 23:17.25[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513231558: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023175132274627685, 'time_algorithm_update': 0.005074017524719239, 'loss': 2.2001413011550905, 'time_step': 0.007453734397888183, 'init_value': 25.701799392700195}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 23:17.46[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513231558: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002302701711654663, 'time_algorithm_update': 0.00493384313583374, 'loss': 1.8509755907058716, 'time_step': 0.007297189474105835, 'init_value': 28.389284133911133}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 23:18.08[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513231558: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023613471984863283, 'time_algorithm_update': 0.005011133909225464, 'loss': 1.8524813603758812, 'time_step': 0.007433920860290527, 'init_value': 31.667081832885742}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 23:18.29[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513231558: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023420965671539307, 'time_algorithm_update': 0.004844209909439087, 'loss': 1.747831578910351, 'time_step': 0.007245822668075562, 'init_value': 33.281463623046875}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 23:18.51[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513231558: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023688600063323973, 'time_algorithm_update': 0.005054845571517945, 'loss': 1.6694651256203652, 'time_step': 0.007486528873443603, 'init_value': 35.57551574707031}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-13 23:19.13[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513231558: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002391352891921997, 'time_algorithm_update': 0.0052437069416046145, 'loss': 1.6962823135256768, 'time_step': 0.007699650287628174, 'init_value': 39.09842300415039}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-13 23:19.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513231558: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023244283199310304, 'time_algorithm_update': 0.004937602519989014, 'loss': 1.6723688403964043, 'time_step': 0.007322717666625977, 'init_value': 41.31794357299805}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.31794357299805
Starting 1000 evaluations
avg return on 3 trajectories of agent10: 1373.355298063648
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 23:36.27[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 23:36.27[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 23:36.28[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 23:36.28[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 23:36.28[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513233628[0m
[2m2025-05-13 23:36.28[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 23:36.49[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513233628: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002235360860824585, 'time_algorithm_update': 0.004678778886795044, 'loss': 1.6590631051808595, 'time_step': 0.006971578359603882, 'init_value': 4.668741703033447}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 23:37.10[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513233628: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002296664237976074, 'time_algorithm_update': 0.004859137535095215, 'loss': 2.443029676616192, 'time_step': 0.007215981483459473, 'init_value': 11.44347858428955}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 23:37.32[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513233628: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002320631742477417, 'time_algorithm_update': 0.005066800355911255, 'loss': 2.3533911996483803, 'time_step': 0.007449156999588012, 'init_value': 18.971981048583984}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 23:37.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513233628: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023213746547698973, 'time_algorithm_update': 0.004930622100830078, 'loss': 2.1395092639923097, 'time_step': 0.007312399625778198, 'init_value': 25.972679138183594}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 23:38.15[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513233628: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023025672435760497, 'time_algorithm_update': 0.004846364498138428, 'loss': 2.1084329832792283, 'time_step': 0.007208001136779785, 'init_value': 31.394010543823242}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 23:38.37[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513233628: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023574368953704836, 'time_algorithm_update': 0.005039015531539917, 'loss': 1.8811517057418823, 'time_step': 0.007458794116973877, 'init_value': 34.342220306396484}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 23:38.58[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513233628: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002324428081512451, 'time_algorithm_update': 0.005111297607421875, 'loss': 1.8461328914761543, 'time_step': 0.007498602151870728, 'init_value': 38.14505386352539}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 23:39.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513233628: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023332180976867677, 'time_algorithm_update': 0.004862293481826783, 'loss': 1.7513080241680146, 'time_step': 0.0072549254894256595, 'init_value': 40.607688903808594}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-13 23:39.41[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513233628: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002309706211090088, 'time_algorithm_update': 0.004839329004287719, 'loss': 1.6840538012385369, 'time_step': 0.007208816051483154, 'init_value': 42.27969741821289}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-13 23:40.03[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513233628: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023164973258972166, 'time_algorithm_update': 0.005044177293777465, 'loss': 1.701184795320034, 'time_step': 0.0074228599071502685, 'init_value': 43.16972351074219}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 43.16972351074219
Starting 1000 evaluations
avg return on 3 trajectories of agent11: 1371.220402333079
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-13 23:56.53[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-13 23:56.53[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-13 23:56.54[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-13 23:56.54[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-13 23:56.54[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250513235654[0m
[2m2025-05-13 23:56.54[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-13 23:57.15[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513235654: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022575669288635255, 'time_algorithm_update': 0.004809455394744873, 'loss': 1.7480510911792517, 'time_step': 0.007125223159790039, 'init_value': 4.236250877380371}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-13 23:57.37[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513235654: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023043015003204347, 'time_algorithm_update': 0.004929609775543213, 'loss': 2.390739132642746, 'time_step': 0.007294385433197021, 'init_value': 10.809670448303223}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-13 23:57.58[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513235654: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022886741161346437, 'time_algorithm_update': 0.004979686737060547, 'loss': 2.393817608773708, 'time_step': 0.007328674554824829, 'init_value': 18.531940460205078}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-13 23:58.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513235654: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002312169790267944, 'time_algorithm_update': 0.005073005437850952, 'loss': 2.188652430295944, 'time_step': 0.007446687459945678, 'init_value': 24.580429077148438}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-13 23:58.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513235654: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023590397834777834, 'time_algorithm_update': 0.0050656917095184325, 'loss': 2.0225809554457665, 'time_step': 0.00748634672164917, 'init_value': 30.247846603393555}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-13 23:59.03[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513235654: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022655165195465087, 'time_algorithm_update': 0.004859326839447021, 'loss': 1.914852576971054, 'time_step': 0.0071836371421813965, 'init_value': 34.167694091796875}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-13 23:59.25[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513235654: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023368542194366457, 'time_algorithm_update': 0.005049625158309937, 'loss': 1.7461441180706023, 'time_step': 0.007448241233825683, 'init_value': 36.80589294433594}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-13 23:59.46[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513235654: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002302943229675293, 'time_algorithm_update': 0.005040939807891846, 'loss': 1.7961385209560394, 'time_step': 0.0074052586555480955, 'init_value': 38.73188018798828}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 00:00.08[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513235654: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002350236654281616, 'time_algorithm_update': 0.005049421787261963, 'loss': 1.7944673973321914, 'time_step': 0.0074614653587341305, 'init_value': 40.150001525878906}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 00:00.29[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250513235654: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023088841438293458, 'time_algorithm_update': 0.004776769161224366, 'loss': 1.7576020733118056, 'time_step': 0.007143884897232056, 'init_value': 42.93478775024414}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.93478775024414
Starting 1000 evaluations
avg return on 3 trajectories of agent12: 1374.1614489387396
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 00:17.31[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 00:17.31[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 00:17.32[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 00:17.32[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 00:17.32[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514001732[0m
[2m2025-05-14 00:17.32[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 00:17.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514001732: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002285125494003296, 'time_algorithm_update': 0.0048577537536621095, 'loss': 1.5553528295010328, 'time_step': 0.007201860427856446, 'init_value': 4.241894721984863}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 00:18.15[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514001732: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002318786382675171, 'time_algorithm_update': 0.005050588369369507, 'loss': 2.587821447789669, 'time_step': 0.007431840896606446, 'init_value': 10.90954303741455}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 00:18.36[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514001732: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023689863681793212, 'time_algorithm_update': 0.005005300521850586, 'loss': 2.4717957521677016, 'time_step': 0.007435824155807495, 'init_value': 17.749650955200195}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 00:18.57[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514001732: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023107166290283203, 'time_algorithm_update': 0.004840582847595215, 'loss': 2.200838289618492, 'time_step': 0.007209615468978882, 'init_value': 23.7689151763916}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 00:19.19[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514001732: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023249850273132323, 'time_algorithm_update': 0.0049870750904083255, 'loss': 2.0408130551576615, 'time_step': 0.007372894048690796, 'init_value': 29.01605987548828}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 00:19.41[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514001732: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023708522319793703, 'time_algorithm_update': 0.00511479640007019, 'loss': 1.8495540212988852, 'time_step': 0.007548563957214356, 'init_value': 32.53834533691406}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 00:20.02[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514001732: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022987115383148195, 'time_algorithm_update': 0.004840321779251098, 'loss': 1.9316864852905273, 'time_step': 0.007198126792907715, 'init_value': 37.44198226928711}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 00:20.23[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514001732: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023025455474853514, 'time_algorithm_update': 0.004887657403945923, 'loss': 1.8293747735023498, 'time_step': 0.007249627113342285, 'init_value': 38.8116340637207}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 00:20.45[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514001732: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023274683952331544, 'time_algorithm_update': 0.00511322283744812, 'loss': 1.8117982736825944, 'time_step': 0.007503642797470093, 'init_value': 40.92340087890625}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 00:21.06[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514001732: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023119113445281983, 'time_algorithm_update': 0.0050387120246887206, 'loss': 1.6949283311367034, 'time_step': 0.0074129319190979, 'init_value': 42.39805221557617}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.39805221557617
Starting 1000 evaluations
avg return on 3 trajectories of agent13: 1376.9556534602532
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 00:37.58[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 00:37.58[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 00:37.59[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 00:37.59[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 00:37.59[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514003759[0m
[2m2025-05-14 00:37.59[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 00:38.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514003759: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002297149658203125, 'time_algorithm_update': 0.00493812084197998, 'loss': 1.8387098265364765, 'time_step': 0.007295932054519653, 'init_value': 4.656164169311523}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 00:38.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514003759: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022823796272277833, 'time_algorithm_update': 0.0048850467205047605, 'loss': 2.319617887079716, 'time_step': 0.007227501153945923, 'init_value': 11.258163452148438}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 00:39.03[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514003759: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023305928707122803, 'time_algorithm_update': 0.004967601776123047, 'loss': 2.219024131059647, 'time_step': 0.0073585593700408935, 'init_value': 18.115562438964844}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 00:39.25[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514003759: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023191916942596437, 'time_algorithm_update': 0.005040099620819092, 'loss': 2.147589124083519, 'time_step': 0.007421181917190552, 'init_value': 24.75819969177246}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 00:39.46[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514003759: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00231900691986084, 'time_algorithm_update': 0.004989583253860474, 'loss': 1.9891940420269967, 'time_step': 0.007369125604629516, 'init_value': 30.68486785888672}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 00:40.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514003759: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002287201642990112, 'time_algorithm_update': 0.004735241413116455, 'loss': 1.9329505415558814, 'time_step': 0.007079650163650513, 'init_value': 33.10441207885742}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 00:40.29[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514003759: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023175158500671387, 'time_algorithm_update': 0.004987438917160034, 'loss': 1.8377244886755943, 'time_step': 0.007365748882293701, 'init_value': 35.38671112060547}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 00:40.51[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514003759: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023024353981018065, 'time_algorithm_update': 0.0049607007503509526, 'loss': 1.7614151806235314, 'time_step': 0.007323383092880249, 'init_value': 37.058509826660156}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 00:41.12[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514003759: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002342525482177734, 'time_algorithm_update': 0.004976899385452271, 'loss': 1.6841853379011154, 'time_step': 0.007380667686462402, 'init_value': 38.655670166015625}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 00:41.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514003759: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002302053213119507, 'time_algorithm_update': 0.004855969190597534, 'loss': 1.674583564400673, 'time_step': 0.007217001676559448, 'init_value': 42.08900833129883}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.08900833129883
Starting 1000 evaluations
avg return on 3 trajectories of agent14: 1378.2537314021695
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 00:58.30[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 00:58.30[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 00:58.31[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 00:58.31[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 00:58.31[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514005831[0m
[2m2025-05-14 00:58.31[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 00:58.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514005831: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002275524616241455, 'time_algorithm_update': 0.004906026363372803, 'loss': 1.8114869220778347, 'time_step': 0.0072411904335021975, 'init_value': 4.159747123718262}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 00:59.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514005831: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023101072311401366, 'time_algorithm_update': 0.005007641077041626, 'loss': 2.2883542434573174, 'time_step': 0.007379703998565674, 'init_value': 10.47159194946289}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 00:59.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514005831: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023141820430755615, 'time_algorithm_update': 0.004932998657226562, 'loss': 2.33985859310627, 'time_step': 0.007307743072509766, 'init_value': 18.032054901123047}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 00:59.57[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514005831: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023476536273956297, 'time_algorithm_update': 0.00490990138053894, 'loss': 2.217395750939846, 'time_step': 0.007317195892333985, 'init_value': 22.9957332611084}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 01:00.19[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514005831: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023665244579315187, 'time_algorithm_update': 0.005098018169403076, 'loss': 2.1083002779483797, 'time_step': 0.007527188539505005, 'init_value': 27.883731842041016}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 01:00.40[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514005831: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002305626630783081, 'time_algorithm_update': 0.004991934299468994, 'loss': 1.946133795440197, 'time_step': 0.007357953786849975, 'init_value': 32.16225051879883}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 01:01.01[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514005831: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002303523540496826, 'time_algorithm_update': 0.004759467363357544, 'loss': 1.9277789345383645, 'time_step': 0.007121824502944947, 'init_value': 35.13597869873047}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 01:01.23[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514005831: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023012077808380127, 'time_algorithm_update': 0.004940842151641846, 'loss': 1.7284986985325814, 'time_step': 0.0073022785186767575, 'init_value': 37.894500732421875}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 01:01.45[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514005831: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002358566999435425, 'time_algorithm_update': 0.0051185150146484375, 'loss': 1.7609090983271598, 'time_step': 0.007540459394454956, 'init_value': 39.85778045654297}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 01:02.06[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514005831: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022929251194000245, 'time_algorithm_update': 0.004901102781295776, 'loss': 1.6975704021453857, 'time_step': 0.007254228591918945, 'init_value': 41.8173828125}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.8173828125
Starting 1000 evaluations
avg return on 3 trajectories of agent15: 1378.7228162063846
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 01:18.56[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 01:18.56[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 01:18.58[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 01:18.58[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 01:18.58[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514011858[0m
[2m2025-05-14 01:18.58[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 01:19.19[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514011858: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002253387451171875, 'time_algorithm_update': 0.004810448169708252, 'loss': 1.663746066726744, 'time_step': 0.007122543811798096, 'init_value': 4.421063423156738}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 01:19.40[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514011858: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002281362056732178, 'time_algorithm_update': 0.004888084888458252, 'loss': 2.3405741233229636, 'time_step': 0.007229346513748169, 'init_value': 10.690683364868164}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 01:20.02[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514011858: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023443830013275147, 'time_algorithm_update': 0.004983158111572266, 'loss': 2.323533182680607, 'time_step': 0.007388655424118042, 'init_value': 18.957529067993164}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 01:20.22[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514011858: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002254694938659668, 'time_algorithm_update': 0.004779832124710083, 'loss': 2.144510070323944, 'time_step': 0.007092593908309936, 'init_value': 25.679067611694336}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 01:20.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514011858: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020950722694396975, 'time_algorithm_update': 0.004399953126907349, 'loss': 1.920534299314022, 'time_step': 0.006549790859222412, 'init_value': 30.09342384338379}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 01:21.02[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514011858: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00218349027633667, 'time_algorithm_update': 0.004508806943893433, 'loss': 1.8203150388002396, 'time_step': 0.006748234987258911, 'init_value': 32.42544174194336}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 01:21.24[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514011858: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002291790008544922, 'time_algorithm_update': 0.004946238994598388, 'loss': 1.774305515050888, 'time_step': 0.007298897027969361, 'init_value': 36.12472152709961}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 01:21.44[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514011858: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002223128080368042, 'time_algorithm_update': 0.004565812110900879, 'loss': 1.7105854460597039, 'time_step': 0.006845163106918335, 'init_value': 37.97223663330078}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 01:22.05[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514011858: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022791376113891603, 'time_algorithm_update': 0.004921639919281006, 'loss': 1.7273554526567458, 'time_step': 0.0072619783878326415, 'init_value': 39.4014778137207}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 01:22.26[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514011858: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002287982940673828, 'time_algorithm_update': 0.004753963470458984, 'loss': 1.6516163476109504, 'time_step': 0.007100172042846679, 'init_value': 41.112369537353516}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.112369537353516
Starting 1000 evaluations
avg return on 3 trajectories of agent16: 1374.5015492089713
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 01:39.29[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 01:39.29[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 01:39.30[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 01:39.30[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 01:39.30[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514013930[0m
[2m2025-05-14 01:39.30[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 01:39.51[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514013930: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00225890588760376, 'time_algorithm_update': 0.004734506845474243, 'loss': 1.637542628839612, 'time_step': 0.007050544023513794, 'init_value': 5.012472629547119}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 01:40.13[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514013930: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002350025177001953, 'time_algorithm_update': 0.004931302070617676, 'loss': 2.3872001503705977, 'time_step': 0.007341034650802612, 'init_value': 11.442689895629883}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 01:40.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514013930: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022824578285217285, 'time_algorithm_update': 0.004780755519866943, 'loss': 2.2653513957262037, 'time_step': 0.007121250391006469, 'init_value': 19.48478126525879}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 01:40.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514013930: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002334599018096924, 'time_algorithm_update': 0.004825490474700928, 'loss': 2.1649196991324424, 'time_step': 0.007218507766723633, 'init_value': 26.614898681640625}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 01:41.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514013930: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022714345455169677, 'time_algorithm_update': 0.004745816707611084, 'loss': 2.0133598513603213, 'time_step': 0.007075440168380737, 'init_value': 31.112720489501953}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 01:41.38[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514013930: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023375043869018554, 'time_algorithm_update': 0.004989396333694458, 'loss': 1.8255980192422867, 'time_step': 0.007387682437896729, 'init_value': 33.44913864135742}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 01:41.59[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514013930: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023244235515594482, 'time_algorithm_update': 0.004849635124206543, 'loss': 1.757499957203865, 'time_step': 0.007233212471008301, 'init_value': 35.58641052246094}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 01:42.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514013930: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022486119270324705, 'time_algorithm_update': 0.004720363855361938, 'loss': 1.7665092136859895, 'time_step': 0.007026201486587525, 'init_value': 37.88349914550781}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 01:42.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514013930: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002350780248641968, 'time_algorithm_update': 0.004887046337127686, 'loss': 1.7129829456210137, 'time_step': 0.007297004222869873, 'init_value': 39.50323486328125}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 01:43.03[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514013930: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023489768505096436, 'time_algorithm_update': 0.005048925161361694, 'loss': 1.7398096234202385, 'time_step': 0.007459128141403198, 'init_value': 42.301307678222656}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.301307678222656
Starting 1000 evaluations
avg return on 3 trajectories of agent17: 1377.1149019758934
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 02:00.08[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 02:00.08[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 02:00.10[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 02:00.10[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 02:00.10[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514020010[0m
[2m2025-05-14 02:00.10[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 02:00.31[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514020010: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023170042037963866, 'time_algorithm_update': 0.0049103772640228275, 'loss': 1.6880232900232077, 'time_step': 0.007287495851516724, 'init_value': 4.144729137420654}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 02:00.51[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514020010: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022010495662689207, 'time_algorithm_update': 0.00452001166343689, 'loss': 2.3909365100860596, 'time_step': 0.006776031255722046, 'init_value': 10.313109397888184}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 02:01.13[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514020010: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023199279308319092, 'time_algorithm_update': 0.004964725255966186, 'loss': 2.321308815062046, 'time_step': 0.007344826221466065, 'init_value': 18.08387565612793}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 02:01.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514020010: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023237273693084716, 'time_algorithm_update': 0.004874715328216553, 'loss': 2.188780779838562, 'time_step': 0.007256943702697754, 'init_value': 24.930593490600586}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 02:01.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514020010: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023152334690093993, 'time_algorithm_update': 0.00486863660812378, 'loss': 1.965331084370613, 'time_step': 0.007242734909057617, 'init_value': 28.82758903503418}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 02:02.16[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514020010: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002266498565673828, 'time_algorithm_update': 0.004639069557189942, 'loss': 1.8280772327780723, 'time_step': 0.006961586236953735, 'init_value': 32.9609375}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 02:02.37[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514020010: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023416588306427004, 'time_algorithm_update': 0.005112886905670166, 'loss': 1.8257551591396333, 'time_step': 0.007515475749969482, 'init_value': 36.038063049316406}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 02:02.59[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514020010: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002381242036819458, 'time_algorithm_update': 0.005060032844543457, 'loss': 1.6963331122398377, 'time_step': 0.0075033514499664306, 'init_value': 39.05328369140625}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 02:03.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514020010: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022695109844207764, 'time_algorithm_update': 0.004695319175720215, 'loss': 1.6805310314893722, 'time_step': 0.007021565675735473, 'init_value': 40.30546951293945}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 02:03.41[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514020010: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022548975944519044, 'time_algorithm_update': 0.004678893089294434, 'loss': 1.6468961296081543, 'time_step': 0.00699056077003479, 'init_value': 41.69184112548828}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.69184112548828
Starting 1000 evaluations
avg return on 3 trajectories of agent18: 1382.0321984460932
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 02:20.51[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 02:20.51[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 02:20.52[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 02:20.52[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 02:20.52[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514022052[0m
[2m2025-05-14 02:20.52[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 02:21.13[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514022052: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002308706521987915, 'time_algorithm_update': 0.004877321481704712, 'loss': 1.4820187075585127, 'time_step': 0.007245457172393799, 'init_value': 4.650229454040527}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 02:21.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514022052: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023382372856140137, 'time_algorithm_update': 0.004780098199844361, 'loss': 2.2634755897521974, 'time_step': 0.0071763134002685545, 'init_value': 11.639172554016113}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 02:21.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514022052: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022366433143615723, 'time_algorithm_update': 0.004536964893341064, 'loss': 2.3131929540634157, 'time_step': 0.006828358173370361, 'init_value': 18.883214950561523}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 02:22.16[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514022052: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023135960102081297, 'time_algorithm_update': 0.004832925081253052, 'loss': 1.942635847389698, 'time_step': 0.007204588890075684, 'init_value': 24.406997680664062}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 02:22.38[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514022052: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023277692794799803, 'time_algorithm_update': 0.004937111377716064, 'loss': 1.9376607758998872, 'time_step': 0.007324550628662109, 'init_value': 29.233076095581055}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 02:22.59[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514022052: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002312570571899414, 'time_algorithm_update': 0.004872790575027466, 'loss': 1.8380280497074126, 'time_step': 0.007244471788406372, 'init_value': 32.31014633178711}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 02:23.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514022052: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002294264793395996, 'time_algorithm_update': 0.004656466484069824, 'loss': 1.7107889974713326, 'time_step': 0.007007038831710816, 'init_value': 35.321136474609375}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 02:23.41[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514022052: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002319580316543579, 'time_algorithm_update': 0.004921047687530517, 'loss': 1.714313671171665, 'time_step': 0.007300272703170776, 'init_value': 37.33995056152344}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 02:24.03[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514022052: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023554441928863527, 'time_algorithm_update': 0.0049395418167114255, 'loss': 1.5846567108631133, 'time_step': 0.007355714321136474, 'init_value': 39.81853103637695}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 02:24.24[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514022052: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002328889846801758, 'time_algorithm_update': 0.004879063129425049, 'loss': 1.8106446723937988, 'time_step': 0.0072675831317901615, 'init_value': 40.89424514770508}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.89424514770508
Starting 1000 evaluations
avg return on 3 trajectories of agent19: 1387.1413034642762
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 02:41.27[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 02:41.27[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 02:41.28[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 02:41.28[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 02:41.28[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514024128[0m
[2m2025-05-14 02:41.28[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 02:41.49[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514024128: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022463951110839844, 'time_algorithm_update': 0.004723312854766845, 'loss': 1.8984062356874347, 'time_step': 0.007026586532592773, 'init_value': 4.032497882843018}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 02:42.11[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514024128: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023139834403991697, 'time_algorithm_update': 0.00484401535987854, 'loss': 2.3769357362985613, 'time_step': 0.007217476844787598, 'init_value': 11.841582298278809}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 02:42.32[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514024128: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002285740613937378, 'time_algorithm_update': 0.0048126945495605465, 'loss': 2.3159752828478815, 'time_step': 0.0071569674015045165, 'init_value': 19.892303466796875}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 02:42.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514024128: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002265817165374756, 'time_algorithm_update': 0.004753440856933594, 'loss': 2.1251047151684763, 'time_step': 0.007077436447143554, 'init_value': 26.404020309448242}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 02:43.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514024128: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022655086517333984, 'time_algorithm_update': 0.004684682607650757, 'loss': 2.1839559524059298, 'time_step': 0.00700733733177185, 'init_value': 31.357421875}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 02:43.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514024128: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002307516098022461, 'time_algorithm_update': 0.004876011848449707, 'loss': 1.8737456285953522, 'time_step': 0.0072430260181427005, 'init_value': 35.383113861083984}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 02:43.57[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514024128: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023428831100463865, 'time_algorithm_update': 0.004899220705032349, 'loss': 1.7286353040337563, 'time_step': 0.007302353858947754, 'init_value': 38.47525405883789}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 02:44.18[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514024128: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022928996086120606, 'time_algorithm_update': 0.004807070732116699, 'loss': 1.8288293311595916, 'time_step': 0.0071590662002563475, 'init_value': 40.64654541015625}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 02:44.39[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514024128: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023070292472839355, 'time_algorithm_update': 0.004729234457015992, 'loss': 1.6697195633649826, 'time_step': 0.007094599962234497, 'init_value': 42.15977096557617}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 02:45.00[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514024128: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022986798286437986, 'time_algorithm_update': 0.004813776016235351, 'loss': 1.6041277182102203, 'time_step': 0.0071714668273925785, 'init_value': 42.57707214355469}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.57707214355469
ave advantage rew: 42.33434562683105, std: 0.8686215788047948
avg cum rews: 1372.5888962689178, std: 12.462404235175823
Pearson correlation coefficient: -0.5066283153774773
Spearman correlation coefficient: -0.37142857142857144
Kendall Tau correlation coefficient: -0.3157894736842105
the best agent: 19, best agent cum rewards: 1387.1413034642762
1961
Starting to collect rollouts
Collecting rollouts: 10000/1000000
Collecting rollouts: 20000/1000000
Collecting rollouts: 30000/1000000
Collecting rollouts: 40000/1000000
Collecting rollouts: 50000/1000000
Collecting rollouts: 60000/1000000
Collecting rollouts: 70000/1000000
Collecting rollouts: 80000/1000000
Collecting rollouts: 90000/1000000
Collecting rollouts: 100000/1000000
Collecting rollouts: 110000/1000000
Collecting rollouts: 120000/1000000
Collecting rollouts: 130000/1000000
Collecting rollouts: 140000/1000000
Collecting rollouts: 150000/1000000
Collecting rollouts: 160000/1000000
Collecting rollouts: 170000/1000000
Collecting rollouts: 180000/1000000
Collecting rollouts: 190000/1000000
Collecting rollouts: 200000/1000000
Collecting rollouts: 210000/1000000
Collecting rollouts: 220000/1000000
Collecting rollouts: 230000/1000000
Collecting rollouts: 240000/1000000
Collecting rollouts: 250000/1000000
Collecting rollouts: 260000/1000000
Collecting rollouts: 270000/1000000
Collecting rollouts: 280000/1000000
Collecting rollouts: 290000/1000000
Collecting rollouts: 300000/1000000
Collecting rollouts: 310000/1000000
Collecting rollouts: 320000/1000000
Collecting rollouts: 330000/1000000
Collecting rollouts: 340000/1000000
Collecting rollouts: 350000/1000000
Collecting rollouts: 360000/1000000
Collecting rollouts: 370000/1000000
Collecting rollouts: 380000/1000000
Collecting rollouts: 390000/1000000
Collecting rollouts: 400000/1000000
Collecting rollouts: 410000/1000000
Collecting rollouts: 420000/1000000
Collecting rollouts: 430000/1000000
Collecting rollouts: 440000/1000000
Collecting rollouts: 450000/1000000
Collecting rollouts: 460000/1000000
Collecting rollouts: 470000/1000000
Collecting rollouts: 480000/1000000
Collecting rollouts: 490000/1000000
Collecting rollouts: 500000/1000000
Collecting rollouts: 510000/1000000
Collecting rollouts: 520000/1000000
Collecting rollouts: 530000/1000000
Collecting rollouts: 540000/1000000
Collecting rollouts: 550000/1000000
Collecting rollouts: 560000/1000000
Collecting rollouts: 570000/1000000
Collecting rollouts: 580000/1000000
Collecting rollouts: 590000/1000000
Collecting rollouts: 600000/1000000
Collecting rollouts: 610000/1000000
Collecting rollouts: 620000/1000000
Collecting rollouts: 630000/1000000
Collecting rollouts: 640000/1000000
Collecting rollouts: 650000/1000000
Collecting rollouts: 660000/1000000
Collecting rollouts: 670000/1000000
Collecting rollouts: 680000/1000000
Collecting rollouts: 690000/1000000
Collecting rollouts: 700000/1000000
Collecting rollouts: 710000/1000000
Collecting rollouts: 720000/1000000
Collecting rollouts: 730000/1000000
Collecting rollouts: 740000/1000000
Collecting rollouts: 750000/1000000
Collecting rollouts: 760000/1000000
Collecting rollouts: 770000/1000000
Collecting rollouts: 780000/1000000
Collecting rollouts: 790000/1000000
Collecting rollouts: 800000/1000000
Collecting rollouts: 810000/1000000
Collecting rollouts: 820000/1000000
Collecting rollouts: 830000/1000000
Collecting rollouts: 840000/1000000
Collecting rollouts: 850000/1000000
Collecting rollouts: 860000/1000000
Collecting rollouts: 870000/1000000
Collecting rollouts: 880000/1000000
Collecting rollouts: 890000/1000000
Collecting rollouts: 900000/1000000
Collecting rollouts: 910000/1000000
Collecting rollouts: 920000/1000000
Collecting rollouts: 930000/1000000
Collecting rollouts: 940000/1000000
Collecting rollouts: 950000/1000000
Collecting rollouts: 960000/1000000
Collecting rollouts: 970000/1000000
Collecting rollouts: 980000/1000000
Collecting rollouts: 990000/1000000
Collecting rollouts: 1000000/1000000
Replay buffer size:  (1000000, 105)
Replay buffer saved
---------------------------------
Searching empty space policies
(10, 11472)
(20, 11472)
(20, 11472)
Average distance of agents to nearest neighbors: 0.017796454542597
Starting 1000 evaluations
avg return on 3 trajectories of agent0: 1369.0472900892687
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 03:22.12[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 03:22.12[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 03:22.13[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 03:22.13[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 03:22.13[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514032213[0m
[2m2025-05-14 03:22.13[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 03:22.33[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514032213: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022756519317626953, 'time_algorithm_update': 0.004673511266708374, 'loss': 1.683914245530963, 'time_step': 0.007006113052368164, 'init_value': 4.546450138092041}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 03:22.54[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514032213: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022740063667297363, 'time_algorithm_update': 0.004654746770858764, 'loss': 2.279931013941765, 'time_step': 0.0069854180812835695, 'init_value': 11.216814994812012}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 03:23.16[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514032213: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023408241271972658, 'time_algorithm_update': 0.004710573434829712, 'loss': 2.328810784161091, 'time_step': 0.007108697891235352, 'init_value': 19.010181427001953}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 03:23.38[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514032213: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023919374942779543, 'time_algorithm_update': 0.005020925521850586, 'loss': 2.0914200577139854, 'time_step': 0.007473905086517334, 'init_value': 25.545591354370117}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 03:23.58[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514032213: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022169318199157717, 'time_algorithm_update': 0.004561999797821045, 'loss': 1.930304607450962, 'time_step': 0.006834125995635986, 'init_value': 30.074302673339844}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 03:24.19[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514032213: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023153331279754637, 'time_algorithm_update': 0.004708439826965332, 'loss': 1.8161927227377892, 'time_step': 0.00708084511756897, 'init_value': 32.846126556396484}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 03:24.41[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514032213: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023511202335357666, 'time_algorithm_update': 0.0049342594146728515, 'loss': 1.8070786120295526, 'time_step': 0.007345448970794677, 'init_value': 35.69082260131836}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 03:25.02[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514032213: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002364804267883301, 'time_algorithm_update': 0.004952337741851807, 'loss': 1.7353081974983215, 'time_step': 0.0073776631355285645, 'init_value': 37.65470504760742}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 03:25.23[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514032213: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002292941093444824, 'time_algorithm_update': 0.004704860925674438, 'loss': 1.680046351313591, 'time_step': 0.007055142641067505, 'init_value': 40.66141128540039}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 03:25.44[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514032213: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022975800037384033, 'time_algorithm_update': 0.004633459091186523, 'loss': 1.7447225050330162, 'time_step': 0.006987241268157959, 'init_value': 42.62403106689453}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.62403106689453
Starting 1000 evaluations
avg return on 3 trajectories of agent1: 1379.0845038065886
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 03:42.45[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 03:42.45[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 03:42.47[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 03:42.47[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 03:42.47[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514034247[0m
[2m2025-05-14 03:42.47[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 03:43.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514034247: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002242344379425049, 'time_algorithm_update': 0.004598685026168823, 'loss': 1.5137450665608048, 'time_step': 0.006897108316421509, 'init_value': 4.188415050506592}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 03:43.29[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514034247: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022946083545684814, 'time_algorithm_update': 0.004866047620773316, 'loss': 2.371845324277878, 'time_step': 0.007220399618148804, 'init_value': 11.02980899810791}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 03:43.50[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514034247: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022677047252655028, 'time_algorithm_update': 0.004686521530151367, 'loss': 2.308513965725899, 'time_step': 0.007011680841445923, 'init_value': 19.17408561706543}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 03:44.11[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514034247: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002352379083633423, 'time_algorithm_update': 0.00486865496635437, 'loss': 2.110757888734341, 'time_step': 0.00728032922744751, 'init_value': 25.44807243347168}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 03:44.32[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514034247: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002248966693878174, 'time_algorithm_update': 0.004673668384552002, 'loss': 1.9432454575300218, 'time_step': 0.00697944450378418, 'init_value': 30.270933151245117}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 03:44.54[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514034247: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023479282855987547, 'time_algorithm_update': 0.004939637899398804, 'loss': 1.8394362167716027, 'time_step': 0.007347689628601074, 'init_value': 33.84914016723633}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 03:45.15[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514034247: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00228613018989563, 'time_algorithm_update': 0.0048417608737945554, 'loss': 1.7530714306235313, 'time_step': 0.007186224937438965, 'init_value': 36.78688430786133}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 03:45.36[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514034247: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023605914115905763, 'time_algorithm_update': 0.0049714469909667965, 'loss': 1.5906404441595077, 'time_step': 0.007392545938491821, 'init_value': 39.55558776855469}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 03:45.58[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514034247: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00226947808265686, 'time_algorithm_update': 0.0047412896156311035, 'loss': 1.6467277217507363, 'time_step': 0.007068181276321411, 'init_value': 41.72640609741211}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 03:46.19[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514034247: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022942087650299073, 'time_algorithm_update': 0.004845936775207519, 'loss': 1.6122333906888962, 'time_step': 0.007199558734893799, 'init_value': 43.36967086791992}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 43.36967086791992
Starting 1000 evaluations
avg return on 3 trajectories of agent2: 1372.1741792827586
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 04:03.23[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 04:03.23[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 04:03.25[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 04:03.25[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 04:03.25[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514040325[0m
[2m2025-05-14 04:03.25[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 04:03.45[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514040325: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022452394962310792, 'time_algorithm_update': 0.004590622901916504, 'loss': 1.7907742853909732, 'time_step': 0.006891583204269409, 'init_value': 4.198367595672607}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 04:04.06[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514040325: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023448238372802735, 'time_algorithm_update': 0.004777156591415406, 'loss': 2.4736064507365225, 'time_step': 0.007180661201477051, 'init_value': 10.83335018157959}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 04:04.28[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514040325: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002255516290664673, 'time_algorithm_update': 0.0046307692527770995, 'loss': 2.2295022792220114, 'time_step': 0.006941846132278442, 'init_value': 18.345319747924805}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 04:04.49[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514040325: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002348501443862915, 'time_algorithm_update': 0.004938623905181885, 'loss': 2.099433245122433, 'time_step': 0.007347454309463501, 'init_value': 25.171072006225586}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 04:05.10[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514040325: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002317404508590698, 'time_algorithm_update': 0.004856168985366821, 'loss': 2.0435837951898574, 'time_step': 0.007232475519180298, 'init_value': 29.40484619140625}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 04:05.31[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514040325: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022876064777374266, 'time_algorithm_update': 0.004759289979934692, 'loss': 1.9321626977920532, 'time_step': 0.007104862928390503, 'init_value': 32.01786804199219}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 04:05.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514040325: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002364903450012207, 'time_algorithm_update': 0.004875746726989746, 'loss': 1.789523158490658, 'time_step': 0.007299478530883789, 'init_value': 34.464542388916016}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 04:06.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514040325: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002382514715194702, 'time_algorithm_update': 0.005134960174560547, 'loss': 1.8360442438721656, 'time_step': 0.0075802128314971925, 'init_value': 37.82264709472656}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 04:06.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514040325: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002334594488143921, 'time_algorithm_update': 0.004708537817001343, 'loss': 1.7163350740075112, 'time_step': 0.00710057544708252, 'init_value': 39.55314636230469}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 04:06.56[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514040325: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002271878242492676, 'time_algorithm_update': 0.0046596465110778805, 'loss': 1.6898951810598373, 'time_step': 0.006988215446472168, 'init_value': 41.77033615112305}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.77033615112305
Starting 1000 evaluations
avg return on 3 trajectories of agent3: 1356.5144587717898
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 04:23.59[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 04:23.59[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 04:24.00[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 04:24.00[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 04:24.00[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514042400[0m
[2m2025-05-14 04:24.00[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 04:24.21[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514042400: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023172500133514405, 'time_algorithm_update': 0.005068181991577148, 'loss': 1.901542752481997, 'time_step': 0.007447255849838257, 'init_value': 4.719432353973389}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 04:24.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514042400: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022190861701965334, 'time_algorithm_update': 0.004520467758178711, 'loss': 2.430843946456909, 'time_step': 0.006795074462890625, 'init_value': 11.056863784790039}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 04:25.03[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514042400: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022796971797943116, 'time_algorithm_update': 0.004761264562606811, 'loss': 2.338350288808346, 'time_step': 0.007098674297332764, 'init_value': 19.169235229492188}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 04:25.24[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514042400: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022797157764434814, 'time_algorithm_update': 0.004629549503326416, 'loss': 2.12208116877079, 'time_step': 0.006965032815933228, 'init_value': 25.764896392822266}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 04:25.46[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514042400: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023762969970703126, 'time_algorithm_update': 0.005154510974884033, 'loss': 1.972749232530594, 'time_step': 0.007592607498168946, 'init_value': 30.003087997436523}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 04:26.06[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514042400: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002207733154296875, 'time_algorithm_update': 0.004519830226898194, 'loss': 1.8361937091946603, 'time_step': 0.006781997442245483, 'init_value': 33.931671142578125}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 04:26.27[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514042400: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002343839168548584, 'time_algorithm_update': 0.004841590404510498, 'loss': 1.779793885886669, 'time_step': 0.0072432572841644284, 'init_value': 36.776580810546875}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 04:26.49[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514042400: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023019711971282958, 'time_algorithm_update': 0.004879440069198608, 'loss': 1.7850495352745057, 'time_step': 0.00724017596244812, 'init_value': 39.161773681640625}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 04:27.10[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514042400: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023228747844696047, 'time_algorithm_update': 0.00491545844078064, 'loss': 1.8065797984004022, 'time_step': 0.007297891616821289, 'init_value': 41.26434326171875}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 04:27.31[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514042400: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002236480951309204, 'time_algorithm_update': 0.0046255505084991455, 'loss': 1.6754129630327226, 'time_step': 0.006917514085769653, 'init_value': 42.39117431640625}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.39117431640625
Starting 1000 evaluations
avg return on 3 trajectories of agent4: 1374.8057131777396
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 04:44.41[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 04:44.41[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 04:44.42[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 04:44.42[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 04:44.42[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514044442[0m
[2m2025-05-14 04:44.42[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 04:45.03[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514044442: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002291207790374756, 'time_algorithm_update': 0.004868106603622436, 'loss': 1.6415562691316008, 'time_step': 0.007218077182769776, 'init_value': 4.523277759552002}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 04:45.24[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514044442: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023270504474639893, 'time_algorithm_update': 0.004690109491348266, 'loss': 2.5372129313349725, 'time_step': 0.007074152708053589, 'init_value': 11.808300971984863}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 04:45.45[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514044442: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022863893508911133, 'time_algorithm_update': 0.004737394332885742, 'loss': 2.1945165767669677, 'time_step': 0.007080972909927368, 'init_value': 19.431974411010742}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 04:46.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514044442: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002318859338760376, 'time_algorithm_update': 0.004756356000900268, 'loss': 2.1461409242749214, 'time_step': 0.0071333410739898686, 'init_value': 26.442989349365234}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 04:46.28[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514044442: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002309170961380005, 'time_algorithm_update': 0.0049152979850769045, 'loss': 1.9908215820789337, 'time_step': 0.007285079479217529, 'init_value': 31.286649703979492}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 04:46.49[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514044442: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002272181749343872, 'time_algorithm_update': 0.004736045598983765, 'loss': 1.8787112165093423, 'time_step': 0.007065341472625732, 'init_value': 35.40614700317383}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 04:47.10[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514044442: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002298954963684082, 'time_algorithm_update': 0.004817264556884766, 'loss': 1.7805912642478943, 'time_step': 0.007174575567245483, 'init_value': 37.58404541015625}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 04:47.31[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514044442: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022853846549987793, 'time_algorithm_update': 0.004744280099868775, 'loss': 1.8031527810692787, 'time_step': 0.007087176322937012, 'init_value': 39.6740837097168}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 04:47.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514044442: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0024053802490234377, 'time_algorithm_update': 0.005022357702255249, 'loss': 1.7283734728693962, 'time_step': 0.0074892003536224366, 'init_value': 41.64842987060547}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 04:48.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514044442: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023034906387329104, 'time_algorithm_update': 0.00479898190498352, 'loss': 1.5935168391466141, 'time_step': 0.0071608231067657475, 'init_value': 43.79155349731445}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 43.79155349731445
Starting 1000 evaluations
avg return on 3 trajectories of agent5: 1380.7898223786801
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 05:05.17[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 05:05.17[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 05:05.18[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 05:05.18[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 05:05.18[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514050518[0m
[2m2025-05-14 05:05.18[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 05:05.39[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514050518: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022182886600494384, 'time_algorithm_update': 0.00455692720413208, 'loss': 1.6564405855983495, 'time_step': 0.006830671548843384, 'init_value': 4.433683395385742}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 05:06.00[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514050518: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023478801250457764, 'time_algorithm_update': 0.004935264825820923, 'loss': 2.2866132906079293, 'time_step': 0.0073433942794799804, 'init_value': 11.471212387084961}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 05:06.21[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514050518: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002296408653259277, 'time_algorithm_update': 0.004889170646667481, 'loss': 2.3562952846884726, 'time_step': 0.007244534969329834, 'init_value': 19.409439086914062}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 05:06.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514050518: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00230418062210083, 'time_algorithm_update': 0.004706356287002563, 'loss': 2.2133898943066597, 'time_step': 0.007067683696746826, 'init_value': 25.8630313873291}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 05:07.03[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514050518: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022820911407470702, 'time_algorithm_update': 0.004789289236068726, 'loss': 2.0792014400959014, 'time_step': 0.00712966275215149, 'init_value': 29.68568992614746}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 05:07.25[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514050518: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023411431312561036, 'time_algorithm_update': 0.004886894464492798, 'loss': 1.8611452593207358, 'time_step': 0.007287323236465454, 'init_value': 34.74127960205078}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 05:07.46[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514050518: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002321260452270508, 'time_algorithm_update': 0.004825875282287597, 'loss': 1.8121251261234284, 'time_step': 0.007205795764923095, 'init_value': 36.60960388183594}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 05:08.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514050518: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023013761043548585, 'time_algorithm_update': 0.004892385244369507, 'loss': 1.7566744049787522, 'time_step': 0.0072531657218933105, 'init_value': 38.505218505859375}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 05:08.28[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514050518: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023368868827819823, 'time_algorithm_update': 0.004873423814773559, 'loss': 1.724151262164116, 'time_step': 0.007269477367401123, 'init_value': 39.36330032348633}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 05:08.50[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514050518: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002288137435913086, 'time_algorithm_update': 0.00479975962638855, 'loss': 1.661932566344738, 'time_step': 0.007146332502365112, 'init_value': 40.9067268371582}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.9067268371582
Starting 1000 evaluations
avg return on 3 trajectories of agent6: 1380.587910612207
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 05:25.58[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 05:25.58[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 05:25.59[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 05:25.59[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 05:25.59[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514052559[0m
[2m2025-05-14 05:25.59[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 05:26.21[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514052559: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002263930082321167, 'time_algorithm_update': 0.004718061685562134, 'loss': 1.608306692250073, 'time_step': 0.0070399963855743404, 'init_value': 4.461032390594482}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 05:26.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514052559: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00231235933303833, 'time_algorithm_update': 0.0049051871299743656, 'loss': 2.152003013968468, 'time_step': 0.0072773280143737795, 'init_value': 11.32387638092041}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 05:27.02[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514052559: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002212874889373779, 'time_algorithm_update': 0.004541856527328491, 'loss': 2.320786411583424, 'time_step': 0.006809947490692139, 'init_value': 19.53462028503418}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 05:27.24[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514052559: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023629615306854247, 'time_algorithm_update': 0.0049506454467773435, 'loss': 2.24576577436924, 'time_step': 0.007373725652694702, 'init_value': 25.46314811706543}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 05:27.45[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514052559: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002296550989151001, 'time_algorithm_update': 0.004847055196762085, 'loss': 1.9845956965088845, 'time_step': 0.007202208995819092, 'init_value': 30.408472061157227}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 05:28.06[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514052559: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023031566143035887, 'time_algorithm_update': 0.00474589991569519, 'loss': 1.8871898792386055, 'time_step': 0.007106127262115479, 'init_value': 33.89443588256836}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 05:28.27[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514052559: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002267956256866455, 'time_algorithm_update': 0.004715451002120972, 'loss': 1.7983204587697983, 'time_step': 0.007040417909622192, 'init_value': 37.19499206542969}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 05:28.49[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514052559: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023678719997406008, 'time_algorithm_update': 0.0050050787925720215, 'loss': 1.7193794194459915, 'time_step': 0.007433402538299561, 'init_value': 39.521236419677734}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 05:29.10[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514052559: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023208537101745605, 'time_algorithm_update': 0.005033284902572632, 'loss': 1.7445919978022575, 'time_step': 0.007414443016052246, 'init_value': 40.967010498046875}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 05:29.31[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514052559: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002235252857208252, 'time_algorithm_update': 0.004617301702499389, 'loss': 1.6306593725681304, 'time_step': 0.006908000230789185, 'init_value': 43.158348083496094}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 43.158348083496094
Starting 1000 evaluations
avg return on 3 trajectories of agent7: 1385.2073041803633
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 05:46.33[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 05:46.33[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 05:46.34[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 05:46.34[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 05:46.34[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514054634[0m
[2m2025-05-14 05:46.34[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 05:46.56[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514054634: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023264224529266357, 'time_algorithm_update': 0.004845704793930054, 'loss': 1.8608096274286507, 'time_step': 0.007230324983596802, 'init_value': 4.4542083740234375}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 05:47.16[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514054634: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023360085487365723, 'time_algorithm_update': 0.004678194522857666, 'loss': 2.330914315640926, 'time_step': 0.007070097208023071, 'init_value': 10.736967086791992}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 05:47.38[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514054634: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002298833131790161, 'time_algorithm_update': 0.004665520429611206, 'loss': 2.2401325532794, 'time_step': 0.007020864725112915, 'init_value': 18.47076416015625}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 05:47.59[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514054634: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002389721870422363, 'time_algorithm_update': 0.005128633975982666, 'loss': 2.126434132814407, 'time_step': 0.007580350399017334, 'init_value': 24.355300903320312}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 05:48.21[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514054634: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023677427768707274, 'time_algorithm_update': 0.00493607497215271, 'loss': 1.9579890568852425, 'time_step': 0.007363404035568237, 'init_value': 29.240610122680664}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 05:48.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514054634: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002311964511871338, 'time_algorithm_update': 0.004601112365722656, 'loss': 1.8827060992717743, 'time_step': 0.006967846632003784, 'init_value': 33.79330825805664}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 05:49.03[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514054634: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002315526008605957, 'time_algorithm_update': 0.004758788824081421, 'loss': 1.7770830417871475, 'time_step': 0.00713120436668396, 'init_value': 35.4179801940918}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 05:49.25[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514054634: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0024385807514190672, 'time_algorithm_update': 0.005169320821762085, 'loss': 1.725753637611866, 'time_step': 0.007670705795288086, 'init_value': 38.063316345214844}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 05:49.46[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514054634: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023809642791748045, 'time_algorithm_update': 0.004853505611419678, 'loss': 1.8250974565148355, 'time_step': 0.007311493635177612, 'init_value': 38.62556076049805}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 05:50.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514054634: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022871806621551512, 'time_algorithm_update': 0.004691711902618408, 'loss': 1.6708069026470185, 'time_step': 0.007035353899002075, 'init_value': 41.50529861450195}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.50529861450195
Starting 1000 evaluations
avg return on 3 trajectories of agent8: 1368.263694831014
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 06:07.15[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 06:07.15[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 06:07.16[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 06:07.16[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 06:07.16[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514060716[0m
[2m2025-05-14 06:07.16[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 06:07.37[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514060716: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002248241662979126, 'time_algorithm_update': 0.004648964405059814, 'loss': 1.5696112302094698, 'time_step': 0.006954503536224365, 'init_value': 4.692061901092529}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 06:07.59[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514060716: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022998030185699464, 'time_algorithm_update': 0.004816308975219726, 'loss': 2.389646990060806, 'time_step': 0.0071750302314758305, 'init_value': 11.445550918579102}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 06:08.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514060716: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023249998092651366, 'time_algorithm_update': 0.0048599674701690675, 'loss': 2.2440519263744356, 'time_step': 0.007244878292083741, 'init_value': 18.395204544067383}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 06:08.41[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514060716: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022599449157714845, 'time_algorithm_update': 0.004542451381683349, 'loss': 2.0810490008592604, 'time_step': 0.006857288837432861, 'init_value': 25.235898971557617}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 06:09.02[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514060716: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023380260467529296, 'time_algorithm_update': 0.00498011565208435, 'loss': 2.0179647587537763, 'time_step': 0.007378917932510376, 'init_value': 29.76288604736328}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 06:09.24[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514060716: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023566250801086426, 'time_algorithm_update': 0.004854732513427734, 'loss': 2.0126645203232765, 'time_step': 0.007270389795303344, 'init_value': 33.46498489379883}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 06:09.45[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514060716: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002340597152709961, 'time_algorithm_update': 0.004925446510314941, 'loss': 1.6671417210698127, 'time_step': 0.0073257720470428465, 'init_value': 35.665870666503906}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 06:10.06[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514060716: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022589454650878906, 'time_algorithm_update': 0.004621514558792114, 'loss': 1.6341651200652123, 'time_step': 0.006935970544815063, 'init_value': 37.572303771972656}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 06:10.28[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514060716: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002334758996963501, 'time_algorithm_update': 0.0049278967380523685, 'loss': 1.608060366332531, 'time_step': 0.007322177171707154, 'init_value': 39.96982955932617}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 06:10.49[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514060716: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002309093236923218, 'time_algorithm_update': 0.004791147708892822, 'loss': 1.7556579247713089, 'time_step': 0.007157850503921509, 'init_value': 42.30424499511719}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.30424499511719
Starting 1000 evaluations
avg return on 3 trajectories of agent9: 1376.792436867016
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 06:27.55[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 06:27.55[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 06:27.56[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 06:27.56[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 06:27.56[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514062756[0m
[2m2025-05-14 06:27.56[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 06:28.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514062756: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002249302625656128, 'time_algorithm_update': 0.004640066623687744, 'loss': 1.7517809102237225, 'time_step': 0.006946084976196289, 'init_value': 4.26016902923584}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 06:28.39[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514062756: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023674609661102296, 'time_algorithm_update': 0.00504027771949768, 'loss': 2.459691286742687, 'time_step': 0.007469347715377808, 'init_value': 10.96782112121582}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 06:29.00[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514062756: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002270435094833374, 'time_algorithm_update': 0.00477179741859436, 'loss': 2.370920961022377, 'time_step': 0.007100142955780029, 'init_value': 18.458402633666992}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 06:29.21[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514062756: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022755932807922365, 'time_algorithm_update': 0.004662640333175659, 'loss': 2.069840688943863, 'time_step': 0.00699505066871643, 'init_value': 24.73476791381836}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 06:29.43[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514062756: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022902512550354004, 'time_algorithm_update': 0.004782131910324097, 'loss': 1.9495792570114137, 'time_step': 0.007129988193511963, 'init_value': 29.432132720947266}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 06:30.04[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514062756: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002329012870788574, 'time_algorithm_update': 0.005003032445907593, 'loss': 1.8823256467580796, 'time_step': 0.00739303731918335, 'init_value': 33.31658935546875}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 06:30.25[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514062756: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023259246349334717, 'time_algorithm_update': 0.0048234472274780275, 'loss': 1.7761966609954833, 'time_step': 0.007207979917526245, 'init_value': 34.812904357910156}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 06:30.46[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514062756: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002258375406265259, 'time_algorithm_update': 0.004707793235778809, 'loss': 1.6640121248364448, 'time_step': 0.00702307677268982, 'init_value': 37.45811462402344}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 06:31.08[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514062756: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023280820846557615, 'time_algorithm_update': 0.00481391167640686, 'loss': 1.6168858960866928, 'time_step': 0.007200895309448242, 'init_value': 39.41569900512695}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 06:31.29[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514062756: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002287968873977661, 'time_algorithm_update': 0.004781276941299439, 'loss': 1.683172849714756, 'time_step': 0.007127163887023925, 'init_value': 41.04798889160156}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.04798889160156
Starting 1000 evaluations
avg return on 3 trajectories of agent10: 1379.7353556537591
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 06:48.38[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 06:48.38[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 06:48.39[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 06:48.39[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 06:48.39[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514064839[0m
[2m2025-05-14 06:48.39[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 06:49.01[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514064839: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002308252573013306, 'time_algorithm_update': 0.004836669921875, 'loss': 1.5123678575381636, 'time_step': 0.00720417857170105, 'init_value': 4.606541633605957}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 06:49.22[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514064839: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002303736925125122, 'time_algorithm_update': 0.004698249340057373, 'loss': 2.3891001685857773, 'time_step': 0.007058800220489502, 'init_value': 11.815916061401367}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 06:49.43[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514064839: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023096253871917726, 'time_algorithm_update': 0.004805374622344971, 'loss': 2.1894461675882337, 'time_step': 0.007173099040985107, 'init_value': 18.8154296875}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 06:50.04[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514064839: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023324127197265625, 'time_algorithm_update': 0.004729117155075073, 'loss': 2.1185889548659325, 'time_step': 0.007118396520614624, 'init_value': 25.739500045776367}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 06:50.26[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514064839: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023596904277801514, 'time_algorithm_update': 0.005015762090682984, 'loss': 2.024630747795105, 'time_step': 0.00743600082397461, 'init_value': 31.172279357910156}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 06:50.47[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514064839: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022968733310699463, 'time_algorithm_update': 0.004736746072769165, 'loss': 1.8874086025953294, 'time_step': 0.007090736865997314, 'init_value': 34.00972366333008}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 06:51.08[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514064839: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023188774585723875, 'time_algorithm_update': 0.004865649461746216, 'loss': 1.7503299298882484, 'time_step': 0.007243675947189331, 'init_value': 37.17983627319336}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 06:51.30[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514064839: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002308743953704834, 'time_algorithm_update': 0.004688637733459473, 'loss': 1.7667300199866296, 'time_step': 0.007054178476333618, 'init_value': 40.14777755737305}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 06:51.52[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514064839: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002401238203048706, 'time_algorithm_update': 0.005094050168991089, 'loss': 1.6423424957990647, 'time_step': 0.00755618691444397, 'init_value': 42.044952392578125}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 06:52.13[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514064839: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023491199016571047, 'time_algorithm_update': 0.00492335319519043, 'loss': 1.7247376563549042, 'time_step': 0.007332359552383423, 'init_value': 42.75225067138672}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.75225067138672
Starting 1000 evaluations
avg return on 3 trajectories of agent11: 1371.4739647996812
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 07:09.22[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 07:09.22[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 07:09.24[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 07:09.24[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 07:09.24[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514070924[0m
[2m2025-05-14 07:09.24[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 07:09.44[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514070924: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022416772842407226, 'time_algorithm_update': 0.004590408802032471, 'loss': 1.7792839119657875, 'time_step': 0.006888439178466797, 'init_value': 4.626567363739014}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 07:10.06[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514070924: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002318859338760376, 'time_algorithm_update': 0.004835922718048096, 'loss': 2.344553202152252, 'time_step': 0.007214228630065918, 'init_value': 11.376131057739258}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 07:10.27[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514070924: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022740135192871095, 'time_algorithm_update': 0.004688044548034668, 'loss': 2.3332667644023894, 'time_step': 0.007019498586654663, 'init_value': 18.303171157836914}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 07:10.48[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514070924: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023622076511383054, 'time_algorithm_update': 0.004937130689620972, 'loss': 2.184784488260746, 'time_step': 0.007359919548034668, 'init_value': 25.213171005249023}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 07:11.09[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514070924: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002256416082382202, 'time_algorithm_update': 0.004640613555908203, 'loss': 2.053815161705017, 'time_step': 0.006953993558883667, 'init_value': 30.516223907470703}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 07:11.31[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514070924: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002346055269241333, 'time_algorithm_update': 0.004907988786697388, 'loss': 1.8396458313465118, 'time_step': 0.007313581228256226, 'init_value': 35.0285530090332}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 07:11.52[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514070924: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023280155658721925, 'time_algorithm_update': 0.004850925445556641, 'loss': 1.9235935167074203, 'time_step': 0.007237985849380493, 'init_value': 37.482276916503906}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 07:12.13[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514070924: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022885701656341555, 'time_algorithm_update': 0.004684190511703492, 'loss': 1.7108611842393875, 'time_step': 0.007030022144317627, 'init_value': 37.71229553222656}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 07:12.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514070924: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023004474639892578, 'time_algorithm_update': 0.004738498210906983, 'loss': 1.5818337984085082, 'time_step': 0.00709660291671753, 'init_value': 38.821163177490234}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 07:12.56[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514070924: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00227409553527832, 'time_algorithm_update': 0.004668559789657593, 'loss': 1.640895879626274, 'time_step': 0.006999974966049195, 'init_value': 40.081947326660156}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.081947326660156
Starting 1000 evaluations
avg return on 3 trajectories of agent12: 1367.5597659595146
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 07:30.04[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 07:30.04[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 07:30.05[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 07:30.05[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 07:30.05[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514073005[0m
[2m2025-05-14 07:30.05[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 07:30.26[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514073005: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022280800342559816, 'time_algorithm_update': 0.0044868519306182865, 'loss': 1.5518656033352018, 'time_step': 0.0067696039676666256, 'init_value': 4.670766353607178}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 07:30.47[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514073005: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002306917190551758, 'time_algorithm_update': 0.004761667728424073, 'loss': 2.2957167803049088, 'time_step': 0.007126280069351196, 'init_value': 11.486967086791992}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 07:31.09[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514073005: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002328291654586792, 'time_algorithm_update': 0.0049442994594573976, 'loss': 2.3200170969963074, 'time_step': 0.007332422494888306, 'init_value': 18.84369468688965}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 07:31.30[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514073005: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002353296518325806, 'time_algorithm_update': 0.004916637182235718, 'loss': 2.070005448281765, 'time_step': 0.007329018592834473, 'init_value': 25.672801971435547}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 07:31.51[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514073005: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022505128383636473, 'time_algorithm_update': 0.004569581031799316, 'loss': 1.9544166719913483, 'time_step': 0.0068747026920318605, 'init_value': 30.896442413330078}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 07:32.12[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514073005: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002323843955993652, 'time_algorithm_update': 0.004743927717208862, 'loss': 1.9110976932048798, 'time_step': 0.007124701261520386, 'init_value': 34.38376235961914}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 07:32.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514073005: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002383872032165527, 'time_algorithm_update': 0.005223570823669433, 'loss': 1.750604777932167, 'time_step': 0.007670555591583252, 'init_value': 36.398681640625}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 07:32.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514073005: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023392200469970702, 'time_algorithm_update': 0.004745740413665772, 'loss': 1.7728171491026878, 'time_step': 0.007142541408538819, 'init_value': 39.23701095581055}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 07:33.16[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514073005: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022809863090515136, 'time_algorithm_update': 0.004677521467208862, 'loss': 1.6610426540374756, 'time_step': 0.007014960050582886, 'init_value': 41.880828857421875}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 07:33.38[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514073005: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002320716142654419, 'time_algorithm_update': 0.0047926676273345944, 'loss': 1.613685998916626, 'time_step': 0.007171403169631958, 'init_value': 43.833492279052734}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 43.833492279052734
Starting 1000 evaluations
avg return on 3 trajectories of agent13: 1366.6283634733988
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 07:50.44[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 07:50.44[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 07:50.45[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 07:50.45[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 07:50.45[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514075045[0m
[2m2025-05-14 07:50.45[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 07:51.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514075045: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023351702690124513, 'time_algorithm_update': 0.0049288878440856936, 'loss': 1.5180544461011887, 'time_step': 0.007325011253356934, 'init_value': 4.189807891845703}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 07:51.28[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514075045: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023329594135284423, 'time_algorithm_update': 0.004684285879135132, 'loss': 2.2641395000219346, 'time_step': 0.007074217796325683, 'init_value': 10.682965278625488}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 07:51.49[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514075045: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023244507312774657, 'time_algorithm_update': 0.004852220296859742, 'loss': 2.3828492472171785, 'time_step': 0.007235132217407227, 'init_value': 18.968608856201172}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 07:52.10[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514075045: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002260580539703369, 'time_algorithm_update': 0.004654499769210815, 'loss': 2.205405294299126, 'time_step': 0.006971156835556031, 'init_value': 25.37425994873047}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 07:52.32[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514075045: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023713245391845704, 'time_algorithm_update': 0.005055881261825561, 'loss': 1.9754680542349816, 'time_step': 0.007489378452301025, 'init_value': 29.839401245117188}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 07:52.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514075045: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023392148017883302, 'time_algorithm_update': 0.004786254167556763, 'loss': 1.95636300355196, 'time_step': 0.007183761358261109, 'init_value': 33.88884353637695}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 07:53.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514075045: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002326842784881592, 'time_algorithm_update': 0.004814999341964722, 'loss': 1.8452502142190934, 'time_step': 0.0072001745700836185, 'init_value': 37.10121154785156}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 07:53.36[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514075045: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023638794422149658, 'time_algorithm_update': 0.004832735061645508, 'loss': 1.7808096648454665, 'time_step': 0.007255154132843018, 'init_value': 38.260555267333984}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 07:53.57[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514075045: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002378184080123901, 'time_algorithm_update': 0.00490235185623169, 'loss': 1.6406087928414346, 'time_step': 0.007339895009994507, 'init_value': 39.74123764038086}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 07:54.18[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514075045: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022967362403869627, 'time_algorithm_update': 0.0047066667079925534, 'loss': 1.6607211596369744, 'time_step': 0.007061063766479492, 'init_value': 42.30453109741211}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.30453109741211
Starting 1000 evaluations
avg return on 3 trajectories of agent14: 1356.7995269118733
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 08:11.23[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 08:11.23[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 08:11.24[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 08:11.24[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 08:11.24[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514081124[0m
[2m2025-05-14 08:11.24[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 08:11.45[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514081124: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002239187955856323, 'time_algorithm_update': 0.004615921258926392, 'loss': 1.5517449757754802, 'time_step': 0.006911270141601563, 'init_value': 4.466450214385986}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 08:12.06[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514081124: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002289201021194458, 'time_algorithm_update': 0.004591086387634277, 'loss': 2.5413903088569643, 'time_step': 0.006936338186264038, 'init_value': 11.60878849029541}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 08:12.28[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514081124: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023208351135253907, 'time_algorithm_update': 0.004931434869766236, 'loss': 2.3254682478904725, 'time_step': 0.007312704563140869, 'init_value': 18.650615692138672}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 08:12.49[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514081124: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022965075969696045, 'time_algorithm_update': 0.004780768632888794, 'loss': 2.130159216046333, 'time_step': 0.007135647535324097, 'init_value': 25.469881057739258}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 08:13.10[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514081124: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002264750003814697, 'time_algorithm_update': 0.004712243556976318, 'loss': 2.0035571277141573, 'time_step': 0.007033918619155884, 'init_value': 30.097797393798828}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 08:13.32[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514081124: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023471479415893555, 'time_algorithm_update': 0.004840642690658569, 'loss': 1.7648668905496598, 'time_step': 0.007247025489807129, 'init_value': 32.537681579589844}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 08:13.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514081124: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002363781213760376, 'time_algorithm_update': 0.0049631125926971435, 'loss': 1.7206844151616096, 'time_step': 0.007387670755386352, 'init_value': 34.403724670410156}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 08:14.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514081124: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022965195178985594, 'time_algorithm_update': 0.0047923181056976315, 'loss': 1.6479753514528275, 'time_step': 0.007147346258163452, 'init_value': 37.30594253540039}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 08:14.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514081124: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022589714527130127, 'time_algorithm_update': 0.004548449754714965, 'loss': 1.6408710993528366, 'time_step': 0.006862709760665894, 'init_value': 39.34352493286133}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 08:14.57[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514081124: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002344845533370972, 'time_algorithm_update': 0.0049774317741394045, 'loss': 1.7340646559596062, 'time_step': 0.007382861375808716, 'init_value': 40.686222076416016}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.686222076416016
Starting 1000 evaluations
avg return on 3 trajectories of agent15: 1333.917395572383
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 08:32.00[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 08:32.00[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 08:32.01[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 08:32.01[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 08:32.01[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514083201[0m
[2m2025-05-14 08:32.01[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 08:32.23[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514083201: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023401894569396973, 'time_algorithm_update': 0.005017670154571533, 'loss': 1.7500006371214987, 'time_step': 0.007419392585754394, 'init_value': 4.611804008483887}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 08:32.43[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514083201: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002252120494842529, 'time_algorithm_update': 0.004509300947189331, 'loss': 2.2835681682825086, 'time_step': 0.00681678557395935, 'init_value': 10.876314163208008}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 08:33.04[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514083201: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022995071411132813, 'time_algorithm_update': 0.004803715467453003, 'loss': 2.2925845568180083, 'time_step': 0.007161489486694336, 'init_value': 18.484630584716797}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 08:33.26[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514083201: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023402414321899412, 'time_algorithm_update': 0.004836548089981079, 'loss': 2.063303577721119, 'time_step': 0.0072353057861328125, 'init_value': 24.96258544921875}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 08:33.48[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514083201: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023423047065734863, 'time_algorithm_update': 0.00488699197769165, 'loss': 1.9121466292738913, 'time_step': 0.0072883710861206055, 'init_value': 28.998437881469727}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 08:34.08[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514083201: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022953670024871827, 'time_algorithm_update': 0.0047651522159576415, 'loss': 1.8312906528115271, 'time_step': 0.00711822772026062, 'init_value': 32.4928092956543}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 08:34.30[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514083201: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002370721101760864, 'time_algorithm_update': 0.004944031715393067, 'loss': 1.7251577915549279, 'time_step': 0.00737486457824707, 'init_value': 35.42611312866211}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 08:34.52[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514083201: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002349944829940796, 'time_algorithm_update': 0.0050602321624755855, 'loss': 1.742908535182476, 'time_step': 0.007471720695495606, 'init_value': 37.46094512939453}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 08:35.13[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514083201: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023219141960144044, 'time_algorithm_update': 0.004708649635314942, 'loss': 1.8280672531723976, 'time_step': 0.0070883240699768065, 'init_value': 41.72575378417969}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 08:35.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514083201: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022837276458740233, 'time_algorithm_update': 0.00471098279953003, 'loss': 1.6133725846409797, 'time_step': 0.007052025079727173, 'init_value': 42.01022720336914}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.01022720336914
Starting 1000 evaluations
avg return on 3 trajectories of agent16: 1368.3164253727903
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 08:52.39[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 08:52.39[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 08:52.41[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 08:52.41[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 08:52.41[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514085241[0m
[2m2025-05-14 08:52.41[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 08:53.02[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514085241: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002245882034301758, 'time_algorithm_update': 0.004567873477935791, 'loss': 1.5250681825876236, 'time_step': 0.006869534492492676, 'init_value': 4.364707946777344}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 08:53.23[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514085241: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023149967193603514, 'time_algorithm_update': 0.004802761793136596, 'loss': 2.5038791268467904, 'time_step': 0.00717641544342041, 'init_value': 11.115262031555176}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 08:53.44[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514085241: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002324404001235962, 'time_algorithm_update': 0.004906264066696167, 'loss': 2.306260424077511, 'time_step': 0.007289863348007202, 'init_value': 18.039518356323242}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 08:54.06[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514085241: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002369625806808472, 'time_algorithm_update': 0.004837748289108277, 'loss': 2.142944559276104, 'time_step': 0.007265897035598755, 'init_value': 25.431190490722656}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 08:54.27[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514085241: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022862141132354735, 'time_algorithm_update': 0.004685262441635132, 'loss': 2.0266115261912345, 'time_step': 0.0070282862186431885, 'init_value': 30.480255126953125}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 08:54.49[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514085241: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023596489429473875, 'time_algorithm_update': 0.004849279642105102, 'loss': 1.962053553879261, 'time_step': 0.007267648696899414, 'init_value': 33.877689361572266}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 08:55.10[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514085241: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023267726898193357, 'time_algorithm_update': 0.004839377403259277, 'loss': 1.9309448137879373, 'time_step': 0.007225014209747314, 'init_value': 35.990333557128906}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 08:55.31[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514085241: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023682312965393067, 'time_algorithm_update': 0.0048581576347351075, 'loss': 1.6945196760892869, 'time_step': 0.007285398483276367, 'init_value': 37.3028678894043}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 08:55.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514085241: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002354806661605835, 'time_algorithm_update': 0.004872026205062866, 'loss': 1.635114622592926, 'time_step': 0.007285465002059937, 'init_value': 40.54255676269531}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 08:56.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514085241: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002338944673538208, 'time_algorithm_update': 0.004930790424346924, 'loss': 1.625028201043606, 'time_step': 0.007329782724380493, 'init_value': 41.61107635498047}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.61107635498047
Starting 1000 evaluations
avg return on 3 trajectories of agent17: 1367.4216525140423
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 09:13.18[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 09:13.18[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 09:13.19[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 09:13.19[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 09:13.19[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514091319[0m
[2m2025-05-14 09:13.19[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 09:13.40[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514091319: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022294883728027344, 'time_algorithm_update': 0.004580481767654419, 'loss': 1.8021811915710568, 'time_step': 0.00686641526222229, 'init_value': 4.417120456695557}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 09:14.02[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514091319: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002369075059890747, 'time_algorithm_update': 0.004855427026748657, 'loss': 2.3160743121504783, 'time_step': 0.007284080266952515, 'init_value': 11.145631790161133}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 09:14.23[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514091319: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023243138790130617, 'time_algorithm_update': 0.004940184354782104, 'loss': 2.1641596658229827, 'time_step': 0.0073249232769012455, 'init_value': 17.791656494140625}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 09:14.45[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514091319: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023376142978668215, 'time_algorithm_update': 0.004811722040176392, 'loss': 2.0885875583291056, 'time_step': 0.007208056211471557, 'init_value': 24.12329864501953}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 09:15.05[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514091319: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022499969005584717, 'time_algorithm_update': 0.004629280805587769, 'loss': 1.9680027608275414, 'time_step': 0.0069355516433715824, 'init_value': 28.80015754699707}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 09:15.27[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514091319: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022925589084625245, 'time_algorithm_update': 0.004762326717376709, 'loss': 1.8514170716404914, 'time_step': 0.007113296985626221, 'init_value': 32.589603424072266}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 09:15.48[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514091319: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023074779510498045, 'time_algorithm_update': 0.004843850374221801, 'loss': 1.7913204949498176, 'time_step': 0.007210141658782959, 'init_value': 35.84101104736328}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 09:16.09[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514091319: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022968645095825194, 'time_algorithm_update': 0.0047871432304382325, 'loss': 1.8636265995502472, 'time_step': 0.00714243483543396, 'init_value': 38.74143600463867}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 09:16.31[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514091319: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023676700592041014, 'time_algorithm_update': 0.0049757685661315915, 'loss': 1.7553503022193908, 'time_step': 0.007403861045837403, 'init_value': 40.09213638305664}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 09:16.52[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514091319: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002339474439620972, 'time_algorithm_update': 0.004984623432159424, 'loss': 1.8083017103672028, 'time_step': 0.007384848833084106, 'init_value': 41.631683349609375}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.631683349609375
Starting 1000 evaluations
avg return on 3 trajectories of agent18: 1359.3422815072531
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 09:33.56[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 09:33.56[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 09:33.57[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 09:33.57[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 09:33.57[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514093357[0m
[2m2025-05-14 09:33.57[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 09:34.18[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514093357: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022581071853637696, 'time_algorithm_update': 0.004723891973495483, 'loss': 1.5735354606509209, 'time_step': 0.0070390024185180665, 'init_value': 4.781692981719971}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 09:34.40[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514093357: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002279238224029541, 'time_algorithm_update': 0.004626806497573853, 'loss': 2.167520298361778, 'time_step': 0.006962268590927124, 'init_value': 11.761373519897461}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 09:35.01[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514093357: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023199193477630616, 'time_algorithm_update': 0.004898926734924316, 'loss': 2.2301730477809905, 'time_step': 0.0072780723571777345, 'init_value': 19.331195831298828}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 09:35.22[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514093357: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023243191242218017, 'time_algorithm_update': 0.004918215751647949, 'loss': 2.0406170298457145, 'time_step': 0.007302563428878784, 'init_value': 25.566242218017578}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 09:35.44[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514093357: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022982592582702637, 'time_algorithm_update': 0.004846680879592896, 'loss': 1.897363143146038, 'time_step': 0.0072035729885101315, 'init_value': 29.461572647094727}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 09:36.05[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514093357: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002291996479034424, 'time_algorithm_update': 0.004761427164077759, 'loss': 1.954727743923664, 'time_step': 0.007110836267471313, 'init_value': 33.631004333496094}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 09:36.27[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514093357: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002346283197402954, 'time_algorithm_update': 0.004901710748672485, 'loss': 1.7145555332899094, 'time_step': 0.007307336091995239, 'init_value': 35.22715759277344}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 09:36.48[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514093357: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002311861753463745, 'time_algorithm_update': 0.004847238302230835, 'loss': 1.8038890544176103, 'time_step': 0.00721777081489563, 'init_value': 37.8260498046875}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 09:37.09[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514093357: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023056156635284423, 'time_algorithm_update': 0.004703625917434693, 'loss': 1.6242444443106652, 'time_step': 0.00706653881072998, 'init_value': 39.91312789916992}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 09:37.31[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514093357: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023245251178741454, 'time_algorithm_update': 0.004951409101486206, 'loss': 1.6705641137957572, 'time_step': 0.0073351945877075195, 'init_value': 41.893070220947266}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.893070220947266
Starting 1000 evaluations
avg return on 3 trajectories of agent19: 1346.4746474556625
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 09:54.33[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 09:54.33[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 09:54.34[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 09:54.34[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 09:54.34[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514095434[0m
[2m2025-05-14 09:54.34[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 09:54.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514095434: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022802140712738037, 'time_algorithm_update': 0.004820605039596557, 'loss': 1.6985473756566645, 'time_step': 0.00716026759147644, 'init_value': 4.5928754806518555}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 09:55.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514095434: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002356740713119507, 'time_algorithm_update': 0.0049144854545593265, 'loss': 2.3807146396636965, 'time_step': 0.007331883907318116, 'init_value': 11.237611770629883}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 09:55.38[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514095434: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002300608396530151, 'time_algorithm_update': 0.004839766025543213, 'loss': 2.290424689948559, 'time_step': 0.007198653221130371, 'init_value': 18.333309173583984}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 09:55.59[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514095434: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022872393131256104, 'time_algorithm_update': 0.004825183629989624, 'loss': 2.073606920361519, 'time_step': 0.007171301126480102, 'init_value': 24.118833541870117}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 09:56.21[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514095434: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002258901357650757, 'time_algorithm_update': 0.0047164297103881835, 'loss': 2.072193327307701, 'time_step': 0.0070326743125915525, 'init_value': 30.003570556640625}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 09:56.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514095434: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023062355518341064, 'time_algorithm_update': 0.00492475938796997, 'loss': 1.914234712600708, 'time_step': 0.0072912869453430175, 'init_value': 33.23329162597656}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 09:57.03[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514095434: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002310312271118164, 'time_algorithm_update': 0.004781566619873047, 'loss': 1.8578254321813583, 'time_step': 0.007149696111679077, 'init_value': 37.07151794433594}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 09:57.24[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514095434: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022994346618652344, 'time_algorithm_update': 0.004862206697463989, 'loss': 1.8068070063591004, 'time_step': 0.007221443891525269, 'init_value': 39.933807373046875}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 09:57.46[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514095434: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023439202308654784, 'time_algorithm_update': 0.004907357931137085, 'loss': 1.7680897799730302, 'time_step': 0.00731129789352417, 'init_value': 41.91631317138672}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 09:58.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514095434: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022945055961608885, 'time_algorithm_update': 0.0048623356819152835, 'loss': 1.7326525371670722, 'time_step': 0.007216599702835083, 'init_value': 42.64299774169922}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.64299774169922
ave advantage rew: 42.11584358215332, std: 0.9831133542507232
avg cum rews: 1368.046834660889, std: 12.232639540433402
Pearson correlation coefficient: 0.03635954977212559
Spearman correlation coefficient: -0.021052631578947368
Kendall Tau correlation coefficient: -0.042105263157894736
the best agent: 7, best agent cum rewards: 1385.2073041803633
1962
Starting to collect rollouts
Collecting rollouts: 10000/1000000
Collecting rollouts: 20000/1000000
Collecting rollouts: 30000/1000000
Collecting rollouts: 40000/1000000
Collecting rollouts: 50000/1000000
Collecting rollouts: 60000/1000000
Collecting rollouts: 70000/1000000
Collecting rollouts: 80000/1000000
Collecting rollouts: 90000/1000000
Collecting rollouts: 100000/1000000
Collecting rollouts: 110000/1000000
Collecting rollouts: 120000/1000000
Collecting rollouts: 130000/1000000
Collecting rollouts: 140000/1000000
Collecting rollouts: 150000/1000000
Collecting rollouts: 160000/1000000
Collecting rollouts: 170000/1000000
Collecting rollouts: 180000/1000000
Collecting rollouts: 190000/1000000
Collecting rollouts: 200000/1000000
Collecting rollouts: 210000/1000000
Collecting rollouts: 220000/1000000
Collecting rollouts: 230000/1000000
Collecting rollouts: 240000/1000000
Collecting rollouts: 250000/1000000
Collecting rollouts: 260000/1000000
Collecting rollouts: 270000/1000000
Collecting rollouts: 280000/1000000
Collecting rollouts: 290000/1000000
Collecting rollouts: 300000/1000000
Collecting rollouts: 310000/1000000
Collecting rollouts: 320000/1000000
Collecting rollouts: 330000/1000000
Collecting rollouts: 340000/1000000
Collecting rollouts: 350000/1000000
Collecting rollouts: 360000/1000000
Collecting rollouts: 370000/1000000
Collecting rollouts: 380000/1000000
Collecting rollouts: 390000/1000000
Collecting rollouts: 400000/1000000
Collecting rollouts: 410000/1000000
Collecting rollouts: 420000/1000000
Collecting rollouts: 430000/1000000
Collecting rollouts: 440000/1000000
Collecting rollouts: 450000/1000000
Collecting rollouts: 460000/1000000
Collecting rollouts: 470000/1000000
Collecting rollouts: 480000/1000000
Collecting rollouts: 490000/1000000
Collecting rollouts: 500000/1000000
Collecting rollouts: 510000/1000000
Collecting rollouts: 520000/1000000
Collecting rollouts: 530000/1000000
Collecting rollouts: 540000/1000000
Collecting rollouts: 550000/1000000
Collecting rollouts: 560000/1000000
Collecting rollouts: 570000/1000000
Collecting rollouts: 580000/1000000
Collecting rollouts: 590000/1000000
Collecting rollouts: 600000/1000000
Collecting rollouts: 610000/1000000
Collecting rollouts: 620000/1000000
Collecting rollouts: 630000/1000000
Collecting rollouts: 640000/1000000
Collecting rollouts: 650000/1000000
Collecting rollouts: 660000/1000000
Collecting rollouts: 670000/1000000
Collecting rollouts: 680000/1000000
Collecting rollouts: 690000/1000000
Collecting rollouts: 700000/1000000
Collecting rollouts: 710000/1000000
Collecting rollouts: 720000/1000000
Collecting rollouts: 730000/1000000
Collecting rollouts: 740000/1000000
Collecting rollouts: 750000/1000000
Collecting rollouts: 760000/1000000
Collecting rollouts: 770000/1000000
Collecting rollouts: 780000/1000000
Collecting rollouts: 790000/1000000
Collecting rollouts: 800000/1000000
Collecting rollouts: 810000/1000000
Collecting rollouts: 820000/1000000
Collecting rollouts: 830000/1000000
Collecting rollouts: 840000/1000000
Collecting rollouts: 850000/1000000
Collecting rollouts: 860000/1000000
Collecting rollouts: 870000/1000000
Collecting rollouts: 880000/1000000
Collecting rollouts: 890000/1000000
Collecting rollouts: 900000/1000000
Collecting rollouts: 910000/1000000
Collecting rollouts: 920000/1000000
Collecting rollouts: 930000/1000000
Collecting rollouts: 940000/1000000
Collecting rollouts: 950000/1000000
Collecting rollouts: 960000/1000000
Collecting rollouts: 970000/1000000
Collecting rollouts: 980000/1000000
Collecting rollouts: 990000/1000000
Collecting rollouts: 1000000/1000000
Replay buffer size:  (1000000, 105)
Replay buffer saved
---------------------------------
Searching empty space policies
(10, 11472)
(20, 11472)
(20, 11472)
Average distance of agents to nearest neighbors: 0.018718206117544427
Starting 1000 evaluations
avg return on 3 trajectories of agent0: 1360.0525672786735
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 10:35.17[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 10:35.17[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 10:35.18[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 10:35.18[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 10:35.18[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514103518[0m
[2m2025-05-14 10:35.18[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 10:35.39[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514103518: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002322181463241577, 'time_algorithm_update': 0.004963032245635986, 'loss': 1.5574334625527262, 'time_step': 0.0073459258079528805, 'init_value': 4.205331325531006}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 10:36.01[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514103518: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002279740810394287, 'time_algorithm_update': 0.004728325843811035, 'loss': 2.5110184991955755, 'time_step': 0.007065540313720703, 'init_value': 10.666257858276367}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 10:36.22[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514103518: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022162113189697265, 'time_algorithm_update': 0.004514780282974243, 'loss': 2.2889422585368155, 'time_step': 0.006785969734191894, 'init_value': 17.94924545288086}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 10:36.43[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514103518: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002345942974090576, 'time_algorithm_update': 0.004907127380371094, 'loss': 2.086781840920448, 'time_step': 0.0073127148151397705, 'init_value': 25.21581268310547}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 10:37.05[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514103518: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023434059619903565, 'time_algorithm_update': 0.00498956823348999, 'loss': 1.9632004325985908, 'time_step': 0.007394226551055908, 'init_value': 30.416330337524414}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 10:37.26[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514103518: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002318507671356201, 'time_algorithm_update': 0.004726355075836182, 'loss': 1.9023418303132058, 'time_step': 0.007102473020553589, 'init_value': 33.08498001098633}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 10:37.47[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514103518: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002322293758392334, 'time_algorithm_update': 0.004945735931396484, 'loss': 1.744041887819767, 'time_step': 0.007328276634216309, 'init_value': 37.188575744628906}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 10:38.09[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514103518: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002327177286148071, 'time_algorithm_update': 0.004953190326690674, 'loss': 1.828266255557537, 'time_step': 0.0073410277366638185, 'init_value': 38.807186126708984}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 10:38.30[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514103518: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023638076782226563, 'time_algorithm_update': 0.005139636278152466, 'loss': 1.7391217955350875, 'time_step': 0.007565809726715088, 'init_value': 41.50035095214844}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 10:38.51[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514103518: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022287681102752684, 'time_algorithm_update': 0.004553488492965698, 'loss': 1.6420353780388832, 'time_step': 0.006837637901306153, 'init_value': 42.21080017089844}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.21080017089844
Starting 1000 evaluations
avg return on 3 trajectories of agent1: 1369.639713031404
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 10:55.59[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 10:55.59[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 10:56.00[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 10:56.00[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 10:56.00[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514105600[0m
[2m2025-05-14 10:56.00[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 10:56.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514105600: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002219956159591675, 'time_algorithm_update': 0.0044818038940429685, 'loss': 1.5438538045436143, 'time_step': 0.006756030797958374, 'init_value': 4.077274322509766}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 10:56.41[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514105600: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00234287166595459, 'time_algorithm_update': 0.004758469343185425, 'loss': 2.574222048163414, 'time_step': 0.007159826755523682, 'init_value': 10.327473640441895}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 10:57.03[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514105600: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022995476722717286, 'time_algorithm_update': 0.004784270524978638, 'loss': 2.467829348921776, 'time_step': 0.0071420068740844726, 'init_value': 18.168006896972656}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 10:57.25[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514105600: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0024072890281677246, 'time_algorithm_update': 0.005175278902053833, 'loss': 2.1768656752109528, 'time_step': 0.007645587205886841, 'init_value': 24.95174789428711}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 10:57.46[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514105600: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002253767251968384, 'time_algorithm_update': 0.00462985897064209, 'loss': 2.0317918094992637, 'time_step': 0.006938885450363159, 'init_value': 29.83727264404297}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 10:58.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514105600: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002307722330093384, 'time_algorithm_update': 0.004800406455993653, 'loss': 1.8799624010920524, 'time_step': 0.007166373729705811, 'init_value': 33.081092834472656}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 10:58.28[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514105600: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023359954357147217, 'time_algorithm_update': 0.004805967807769775, 'loss': 1.69226752024889, 'time_step': 0.007200137138366699, 'init_value': 36.43429183959961}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 10:58.49[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514105600: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023235857486724855, 'time_algorithm_update': 0.004887247800827026, 'loss': 1.6825550268292426, 'time_step': 0.00726992392539978, 'init_value': 38.3719482421875}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 10:59.10[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514105600: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023162240982055665, 'time_algorithm_update': 0.004684118509292602, 'loss': 1.6823441353440285, 'time_step': 0.007057104825973511, 'init_value': 41.03805160522461}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 10:59.31[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514105600: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022873685359954834, 'time_algorithm_update': 0.004746337175369262, 'loss': 1.7395909128189087, 'time_step': 0.00709138298034668, 'init_value': 43.30266189575195}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 43.30266189575195
Starting 1000 evaluations
avg return on 3 trajectories of agent2: 1374.2509627964666
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 11:16.22[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 11:16.22[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 11:16.23[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 11:16.23[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 11:16.23[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514111623[0m
[2m2025-05-14 11:16.23[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 11:16.45[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514111623: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022994885444641115, 'time_algorithm_update': 0.004972452640533447, 'loss': 1.7054620299264789, 'time_step': 0.00733289361000061, 'init_value': 4.309535026550293}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 11:17.06[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514111623: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022849583625793456, 'time_algorithm_update': 0.004826810121536255, 'loss': 2.5320145145654678, 'time_step': 0.007171106338500976, 'init_value': 11.301405906677246}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 11:17.28[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514111623: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023486294746398926, 'time_algorithm_update': 0.004867233037948608, 'loss': 2.4143413890004157, 'time_step': 0.007275380849838257, 'init_value': 19.2756290435791}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 11:17.49[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514111623: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002354921579360962, 'time_algorithm_update': 0.00494832444190979, 'loss': 2.268676305413246, 'time_step': 0.007364027500152588, 'init_value': 26.278644561767578}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 11:18.11[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514111623: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023170266151428223, 'time_algorithm_update': 0.004953437805175781, 'loss': 2.1150969403386117, 'time_step': 0.0073309106826782225, 'init_value': 30.805007934570312}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 11:18.33[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514111623: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023092358112335207, 'time_algorithm_update': 0.005032368421554565, 'loss': 1.8440655257105827, 'time_step': 0.0074034292697906495, 'init_value': 34.49802780151367}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 11:18.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514111623: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023355791568756105, 'time_algorithm_update': 0.005058925151824951, 'loss': 1.7759930178523065, 'time_step': 0.007456566095352173, 'init_value': 37.69301223754883}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 11:19.16[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514111623: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023335750102996826, 'time_algorithm_update': 0.005030417203903198, 'loss': 1.7887003190517425, 'time_step': 0.00742579984664917, 'init_value': 39.094295501708984}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 11:19.38[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514111623: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002362863063812256, 'time_algorithm_update': 0.0051162314414978025, 'loss': 1.7458439003825188, 'time_step': 0.007541485786437988, 'init_value': 41.43932342529297}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 11:20.00[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514111623: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023308355808258057, 'time_algorithm_update': 0.005072175979614258, 'loss': 1.7334668311476706, 'time_step': 0.007465125322341919, 'init_value': 41.98601531982422}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.98601531982422
Starting 1000 evaluations
avg return on 3 trajectories of agent3: 1378.4651122733135
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 11:37.04[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 11:37.04[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 11:37.05[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 11:37.05[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 11:37.05[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514113705[0m
[2m2025-05-14 11:37.05[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 11:37.26[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514113705: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002282209396362305, 'time_algorithm_update': 0.004901017189025879, 'loss': 1.432875228397548, 'time_step': 0.0072434253692626955, 'init_value': 4.363663673400879}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 11:37.49[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514113705: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002338616132736206, 'time_algorithm_update': 0.005092660427093506, 'loss': 2.3534749985933305, 'time_step': 0.007494969606399536, 'init_value': 11.079416275024414}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 11:38.10[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514113705: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002278543472290039, 'time_algorithm_update': 0.004903190612792969, 'loss': 2.4284898120164873, 'time_step': 0.007242202520370483, 'init_value': 18.767126083374023}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 11:38.32[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514113705: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002316251516342163, 'time_algorithm_update': 0.005112157106399536, 'loss': 2.252485050022602, 'time_step': 0.007491221666336059, 'init_value': 26.3428955078125}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 11:38.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514113705: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023154382705688477, 'time_algorithm_update': 0.004956193208694458, 'loss': 2.0847299330830573, 'time_step': 0.007332660436630249, 'init_value': 31.204275131225586}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 11:39.15[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514113705: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023412668704986574, 'time_algorithm_update': 0.005199584007263183, 'loss': 1.8893447992801666, 'time_step': 0.007604274988174438, 'init_value': 33.780235290527344}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 11:39.37[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514113705: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002275601863861084, 'time_algorithm_update': 0.004875279903411865, 'loss': 1.8080492671728134, 'time_step': 0.007210724115371704, 'init_value': 36.578269958496094}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 11:39.58[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514113705: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002289867401123047, 'time_algorithm_update': 0.004849875926971435, 'loss': 1.7035186246037484, 'time_step': 0.007198324918746948, 'init_value': 38.66007614135742}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 11:40.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514113705: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023534200191497805, 'time_algorithm_update': 0.005121623277664185, 'loss': 1.725436982691288, 'time_step': 0.007538209438323975, 'init_value': 41.28984069824219}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 11:40.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514113705: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023112707138061525, 'time_algorithm_update': 0.005041290283203125, 'loss': 1.5807265728116036, 'time_step': 0.0074145858287811275, 'init_value': 42.815086364746094}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.815086364746094
Starting 1000 evaluations
avg return on 3 trajectories of agent4: 1369.5957135365657
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 11:57.42[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 11:57.42[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 11:57.43[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 11:57.43[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 11:57.43[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514115743[0m
[2m2025-05-14 11:57.43[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 11:58.05[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514115743: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022519493103027345, 'time_algorithm_update': 0.004814863443374634, 'loss': 1.6877275734990835, 'time_step': 0.007125445365905762, 'init_value': 4.319650650024414}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 11:58.27[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514115743: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00236626672744751, 'time_algorithm_update': 0.00504207968711853, 'loss': 2.160656640589237, 'time_step': 0.007470145463943482, 'init_value': 11.57418155670166}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 11:58.48[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514115743: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002329962730407715, 'time_algorithm_update': 0.005136976003646851, 'loss': 2.2633052360415458, 'time_step': 0.007530222892761231, 'init_value': 19.487232208251953}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 11:59.10[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514115743: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023285353183746336, 'time_algorithm_update': 0.00491305661201477, 'loss': 2.2450415044426917, 'time_step': 0.007301247358322144, 'init_value': 25.338672637939453}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 11:59.32[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514115743: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023040010929107667, 'time_algorithm_update': 0.004994223117828369, 'loss': 1.926398313999176, 'time_step': 0.007359036922454834, 'init_value': 28.849464416503906}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 11:59.54[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514115743: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002309889554977417, 'time_algorithm_update': 0.005076734542846679, 'loss': 1.7393596158623696, 'time_step': 0.007448826313018799, 'init_value': 33.2275276184082}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 12:00.16[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514115743: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023458292484283445, 'time_algorithm_update': 0.005079585075378418, 'loss': 1.6841814077496529, 'time_step': 0.007488590002059936, 'init_value': 34.809207916259766}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 12:00.37[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514115743: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022990612983703612, 'time_algorithm_update': 0.004778029680252075, 'loss': 1.6850384228527546, 'time_step': 0.007135479688644409, 'init_value': 37.34537887573242}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 12:00.59[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514115743: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023284251689910888, 'time_algorithm_update': 0.005024472951889038, 'loss': 1.7726694219708443, 'time_step': 0.007414713859558105, 'init_value': 38.6862678527832}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 12:01.21[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514115743: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002371671438217163, 'time_algorithm_update': 0.00520457673072815, 'loss': 1.6625782276391983, 'time_step': 0.007640232801437378, 'init_value': 41.666404724121094}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.666404724121094
Starting 1000 evaluations
avg return on 3 trajectories of agent5: 1376.9986517223986
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 12:18.22[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 12:18.22[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 12:18.23[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 12:18.23[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 12:18.23[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514121823[0m
[2m2025-05-14 12:18.23[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 12:18.45[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514121823: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002302719593048096, 'time_algorithm_update': 0.004961219072341919, 'loss': 1.4767934828773142, 'time_step': 0.007324215888977051, 'init_value': 4.105137825012207}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 12:19.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514121823: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002345494270324707, 'time_algorithm_update': 0.00483669900894165, 'loss': 2.305943091452122, 'time_step': 0.0072416064739227294, 'init_value': 10.182840347290039}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 12:19.29[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514121823: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023113672733306883, 'time_algorithm_update': 0.005051813125610352, 'loss': 2.369275767326355, 'time_step': 0.007424552202224732, 'init_value': 17.438064575195312}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 12:19.50[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514121823: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023231475353240965, 'time_algorithm_update': 0.005064878225326538, 'loss': 2.2140739073753357, 'time_step': 0.00744905686378479, 'init_value': 24.256488800048828}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 12:20.12[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514121823: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002361100435256958, 'time_algorithm_update': 0.005092937231063843, 'loss': 2.037049308657646, 'time_step': 0.0075161678791046144, 'init_value': 29.804048538208008}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 12:20.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514121823: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002327982187271118, 'time_algorithm_update': 0.005024579524993897, 'loss': 1.8218539521694184, 'time_step': 0.0074136991500854494, 'init_value': 32.90087127685547}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 12:20.56[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514121823: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023277337551116943, 'time_algorithm_update': 0.004948940753936768, 'loss': 1.7436173132658004, 'time_step': 0.0073368937969207765, 'init_value': 35.90896987915039}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 12:21.18[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514121823: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023210370540618897, 'time_algorithm_update': 0.005037235736846924, 'loss': 1.7352088963985444, 'time_step': 0.007419677019119263, 'init_value': 39.10323715209961}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 12:21.40[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514121823: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023868703842163086, 'time_algorithm_update': 0.005180920362472534, 'loss': 1.752563407123089, 'time_step': 0.007630885362625122, 'init_value': 41.49274826049805}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 12:22.01[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514121823: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002356790542602539, 'time_algorithm_update': 0.005054554224014282, 'loss': 1.8094024290442468, 'time_step': 0.007472877979278565, 'init_value': 43.29017639160156}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 43.29017639160156
Starting 1000 evaluations
avg return on 3 trajectories of agent6: 1387.1248995648655
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 12:39.01[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 12:39.01[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 12:39.02[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 12:39.02[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 12:39.02[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514123902[0m
[2m2025-05-14 12:39.02[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 12:39.23[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514123902: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022907636165618896, 'time_algorithm_update': 0.004779642820358277, 'loss': 1.807405639566481, 'time_step': 0.0071289541721343995, 'init_value': 4.3719940185546875}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 12:39.45[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514123902: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002360746145248413, 'time_algorithm_update': 0.004918960809707641, 'loss': 2.346889818549156, 'time_step': 0.007339727163314819, 'init_value': 10.833820343017578}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 12:40.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514123902: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00233430814743042, 'time_algorithm_update': 0.005173488140106201, 'loss': 2.464784410774708, 'time_step': 0.007571130275726318, 'init_value': 18.585670471191406}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 12:40.28[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514123902: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002312150716781616, 'time_algorithm_update': 0.00490512228012085, 'loss': 2.1730491448640823, 'time_step': 0.0072776291370391846, 'init_value': 23.88524627685547}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 12:40.50[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514123902: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022596521377563476, 'time_algorithm_update': 0.00474252462387085, 'loss': 1.9747757852077483, 'time_step': 0.007059462308883667, 'init_value': 28.87765121459961}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 12:41.12[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514123902: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023842711448669434, 'time_algorithm_update': 0.005040095806121826, 'loss': 1.888147293627262, 'time_step': 0.007485973358154297, 'init_value': 31.961833953857422}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 12:41.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514123902: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00233827543258667, 'time_algorithm_update': 0.005242846965789795, 'loss': 1.744237664937973, 'time_step': 0.007645150661468506, 'init_value': 34.03755569458008}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 12:41.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514123902: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00225349497795105, 'time_algorithm_update': 0.004628838062286377, 'loss': 1.7390514721274375, 'time_step': 0.006938872337341309, 'init_value': 36.96220016479492}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 12:42.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514123902: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023686375617980957, 'time_algorithm_update': 0.004994505882263183, 'loss': 1.7480930514931678, 'time_step': 0.007424118518829345, 'init_value': 39.62156295776367}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 12:42.39[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514123902: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023493692874908445, 'time_algorithm_update': 0.005081464529037475, 'loss': 1.7264585319757462, 'time_step': 0.00749298095703125, 'init_value': 41.12408447265625}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.12408447265625
Starting 1000 evaluations
avg return on 3 trajectories of agent7: 1392.1250645721514
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 12:59.39[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 12:59.39[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 12:59.40[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 12:59.40[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 12:59.40[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514125940[0m
[2m2025-05-14 12:59.40[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 13:00.02[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514125940: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022724347114562986, 'time_algorithm_update': 0.004944081306457519, 'loss': 1.7563347971513867, 'time_step': 0.007276679515838623, 'init_value': 4.584986209869385}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 13:00.24[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514125940: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023735225200653075, 'time_algorithm_update': 0.005076195240020752, 'loss': 2.4421450133323668, 'time_step': 0.007512177467346191, 'init_value': 10.529687881469727}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 13:00.45[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514125940: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00230403995513916, 'time_algorithm_update': 0.004863914728164673, 'loss': 2.2951179921627043, 'time_step': 0.007227389335632324, 'init_value': 17.282928466796875}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 13:01.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514125940: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00231528377532959, 'time_algorithm_update': 0.005113317966461182, 'loss': 2.193961972117424, 'time_step': 0.007492284774780273, 'init_value': 23.781578063964844}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 13:01.29[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514125940: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002326952934265137, 'time_algorithm_update': 0.005004560708999634, 'loss': 2.1023623089790346, 'time_step': 0.00739269232749939, 'init_value': 28.426008224487305}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 13:01.51[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514125940: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023852648735046386, 'time_algorithm_update': 0.005093661785125733, 'loss': 1.9698088546395303, 'time_step': 0.007541731834411621, 'init_value': 31.442489624023438}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 13:02.12[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514125940: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002319011211395264, 'time_algorithm_update': 0.005056702375411988, 'loss': 1.848227281332016, 'time_step': 0.007437039375305176, 'init_value': 33.613765716552734}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 13:02.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514125940: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023785810470581055, 'time_algorithm_update': 0.005103229761123657, 'loss': 1.817365185379982, 'time_step': 0.007544793844223022, 'init_value': 36.43693161010742}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 13:02.56[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514125940: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002359032392501831, 'time_algorithm_update': 0.005011215209960938, 'loss': 1.8320797191858291, 'time_step': 0.007431158304214478, 'init_value': 37.88144302368164}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 13:03.18[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514125940: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002322869300842285, 'time_algorithm_update': 0.005074302196502686, 'loss': 1.7147795513868331, 'time_step': 0.007458770513534546, 'init_value': 39.61541748046875}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 39.61541748046875
Starting 1000 evaluations
avg return on 3 trajectories of agent8: 1357.6645786857946
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 13:20.18[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 13:20.18[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 13:20.19[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 13:20.19[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 13:20.19[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514132019[0m
[2m2025-05-14 13:20.19[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 13:20.41[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514132019: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002276613235473633, 'time_algorithm_update': 0.004947351932525635, 'loss': 1.5298824476748705, 'time_step': 0.0072856216430664065, 'init_value': 4.293088912963867}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 13:21.03[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514132019: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023291394710540773, 'time_algorithm_update': 0.0048950231075286866, 'loss': 2.3504100702404975, 'time_step': 0.0072841191291809085, 'init_value': 11.102083206176758}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 13:21.24[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514132019: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002276990175247192, 'time_algorithm_update': 0.004943623781204224, 'loss': 2.3827122911810874, 'time_step': 0.007279805421829224, 'init_value': 19.238445281982422}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 13:21.46[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514132019: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023238799571990965, 'time_algorithm_update': 0.005102507829666138, 'loss': 2.1639483409523965, 'time_step': 0.007489171743392945, 'init_value': 25.519813537597656}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 13:22.08[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514132019: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023122992515563967, 'time_algorithm_update': 0.0051516199111938474, 'loss': 1.906596426308155, 'time_step': 0.007528139591217041, 'init_value': 29.54132652282715}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 13:22.29[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514132019: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023340282440185546, 'time_algorithm_update': 0.004973770618438721, 'loss': 1.8423664203882217, 'time_step': 0.007368763208389282, 'init_value': 33.77143478393555}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 13:22.51[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514132019: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023415701389312743, 'time_algorithm_update': 0.005017458438873291, 'loss': 1.7916259590387345, 'time_step': 0.007420806169509887, 'init_value': 35.71437454223633}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 13:23.13[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514132019: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002343058109283447, 'time_algorithm_update': 0.005116712093353271, 'loss': 1.6464123051166535, 'time_step': 0.007522847652435303, 'init_value': 37.29987335205078}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 13:23.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514132019: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023578987121582033, 'time_algorithm_update': 0.005099706888198853, 'loss': 1.6534343649148942, 'time_step': 0.007520524263381958, 'init_value': 38.77461242675781}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 13:23.56[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514132019: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022330098152160646, 'time_algorithm_update': 0.0046988754272460935, 'loss': 1.5740055013895036, 'time_step': 0.006989721298217773, 'init_value': 40.84182357788086}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.84182357788086
Starting 1000 evaluations
avg return on 3 trajectories of agent9: 1371.4954946006844
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 13:40.55[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 13:40.55[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 13:40.56[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 13:40.56[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 13:40.56[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514134056[0m
[2m2025-05-14 13:40.56[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 13:41.18[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514134056: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002300339698791504, 'time_algorithm_update': 0.004953029632568359, 'loss': 1.88424426972121, 'time_step': 0.0073140525817871095, 'init_value': 4.516941547393799}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 13:41.39[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514134056: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023017239570617674, 'time_algorithm_update': 0.004755414485931396, 'loss': 2.497745139718056, 'time_step': 0.007115703582763672, 'init_value': 11.649123191833496}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 13:42.01[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514134056: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002322997808456421, 'time_algorithm_update': 0.0050668251514434815, 'loss': 2.2569991289973257, 'time_step': 0.007451860189437866, 'init_value': 18.595020294189453}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 13:42.22[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514134056: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022431774139404295, 'time_algorithm_update': 0.004800965785980224, 'loss': 2.1338834673762324, 'time_step': 0.007103319883346558, 'init_value': 24.960956573486328}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 13:42.44[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514134056: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023150250911712646, 'time_algorithm_update': 0.004827427387237549, 'loss': 1.958369732260704, 'time_step': 0.007201611280441284, 'init_value': 29.202436447143555}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 13:43.06[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514134056: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023246333599090574, 'time_algorithm_update': 0.0050352392196655275, 'loss': 1.915590278327465, 'time_step': 0.007420949935913086, 'init_value': 32.15233612060547}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 13:43.27[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514134056: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022964301109313964, 'time_algorithm_update': 0.0048783583641052244, 'loss': 1.7701496665477752, 'time_step': 0.0072340149879455565, 'init_value': 35.716590881347656}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 13:43.48[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514134056: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002314754247665405, 'time_algorithm_update': 0.004952197790145874, 'loss': 1.7676645171046257, 'time_step': 0.00732733416557312, 'init_value': 37.12299728393555}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 13:44.10[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514134056: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023756964206695557, 'time_algorithm_update': 0.005072623014450073, 'loss': 1.676980339705944, 'time_step': 0.0075107417106628415, 'init_value': 39.7183837890625}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 13:44.32[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514134056: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023116669654846193, 'time_algorithm_update': 0.004968132495880127, 'loss': 1.6067839701771736, 'time_step': 0.007340447902679443, 'init_value': 41.160560607910156}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.160560607910156
Starting 1000 evaluations
avg return on 3 trajectories of agent10: 1371.6696066027848
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 14:01.32[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 14:01.32[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 14:01.33[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 14:01.33[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 14:01.33[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514140133[0m
[2m2025-05-14 14:01.33[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 14:01.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514140133: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002242335557937622, 'time_algorithm_update': 0.004756295442581176, 'loss': 2.0174394149929284, 'time_step': 0.007057245492935181, 'init_value': 4.158892631530762}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 14:02.16[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514140133: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002317545175552368, 'time_algorithm_update': 0.0049172954559326175, 'loss': 2.309594367861748, 'time_step': 0.007295603275299072, 'init_value': 10.28337574005127}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 14:02.38[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514140133: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023663132190704346, 'time_algorithm_update': 0.0050445210933685305, 'loss': 2.2250382845401764, 'time_step': 0.007473061084747315, 'init_value': 17.356481552124023}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 14:03.00[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514140133: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023730928897857666, 'time_algorithm_update': 0.005155393362045288, 'loss': 2.165177223980427, 'time_step': 0.007591041803359985, 'init_value': 24.564817428588867}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 14:03.21[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514140133: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022961246967315675, 'time_algorithm_update': 0.0049469201564788816, 'loss': 1.988999334871769, 'time_step': 0.007303993463516236, 'init_value': 29.49392318725586}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 14:03.43[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514140133: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023784286975860594, 'time_algorithm_update': 0.005002613544464111, 'loss': 1.855497931420803, 'time_step': 0.0074425613880157475, 'init_value': 32.22502136230469}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 14:04.05[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514140133: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023291194438934326, 'time_algorithm_update': 0.005029483556747437, 'loss': 1.82135860568285, 'time_step': 0.007420371294021607, 'init_value': 34.06142807006836}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 14:04.27[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514140133: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022942767143249512, 'time_algorithm_update': 0.0048567397594451904, 'loss': 1.7383635102510453, 'time_step': 0.007210043907165528, 'init_value': 37.567237854003906}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 14:04.48[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514140133: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00235097336769104, 'time_algorithm_update': 0.005212686538696289, 'loss': 1.730964411199093, 'time_step': 0.007627277851104736, 'init_value': 39.713775634765625}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 14:05.11[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514140133: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023456761837005614, 'time_algorithm_update': 0.005112906217575073, 'loss': 1.7791955103874206, 'time_step': 0.007521763801574707, 'init_value': 42.07804870605469}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.07804870605469
Starting 1000 evaluations
avg return on 3 trajectories of agent11: 1368.231847523079
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 14:22.10[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 14:22.10[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 14:22.11[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 14:22.11[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 14:22.11[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514142211[0m
[2m2025-05-14 14:22.11[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 14:22.33[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514142211: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002297903299331665, 'time_algorithm_update': 0.004956431627273559, 'loss': 1.7584171102941035, 'time_step': 0.007315602779388428, 'init_value': 4.162163734436035}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 14:22.54[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514142211: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023239026069641114, 'time_algorithm_update': 0.004903640031814575, 'loss': 2.2660190074443816, 'time_step': 0.0072874314785003665, 'init_value': 11.034064292907715}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 14:23.16[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514142211: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022757222652435303, 'time_algorithm_update': 0.004799127817153931, 'loss': 2.320051548779011, 'time_step': 0.00713287878036499, 'init_value': 17.66503143310547}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 14:23.38[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514142211: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002367753267288208, 'time_algorithm_update': 0.005177055597305298, 'loss': 2.0962022855877875, 'time_step': 0.0076095228195190425, 'init_value': 24.6519775390625}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 14:23.59[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514142211: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002287318229675293, 'time_algorithm_update': 0.0048920905590057375, 'loss': 2.011246083676815, 'time_step': 0.007239447116851806, 'init_value': 29.275606155395508}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 14:24.21[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514142211: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002325172185897827, 'time_algorithm_update': 0.004892908573150635, 'loss': 1.976508902132511, 'time_step': 0.007278045415878296, 'init_value': 33.30299377441406}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 14:24.43[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514142211: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002351433038711548, 'time_algorithm_update': 0.005103519916534424, 'loss': 1.9308631020784377, 'time_step': 0.007517735242843628, 'init_value': 34.71309280395508}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 14:25.04[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514142211: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00234432315826416, 'time_algorithm_update': 0.005141883611679077, 'loss': 1.738958274960518, 'time_step': 0.007549793958663941, 'init_value': 36.29379653930664}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 14:25.26[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514142211: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002327441692352295, 'time_algorithm_update': 0.0048647370338439945, 'loss': 1.742404417157173, 'time_step': 0.007252261400222778, 'init_value': 38.448455810546875}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 14:25.48[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514142211: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023059189319610597, 'time_algorithm_update': 0.004981803894042969, 'loss': 1.6893278742432594, 'time_step': 0.007350031852722168, 'init_value': 39.91138458251953}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 39.91138458251953
Starting 1000 evaluations
avg return on 3 trajectories of agent12: 1357.3947571357844
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 14:42.29[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 14:42.29[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 14:42.30[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 14:42.30[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 14:42.30[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514144230[0m
[2m2025-05-14 14:42.30[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 14:42.51[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514144230: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002205638647079468, 'time_algorithm_update': 0.004742008209228515, 'loss': 1.5990172599554062, 'time_step': 0.007005667924880982, 'init_value': 4.300995826721191}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 14:43.12[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514144230: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022618582248687745, 'time_algorithm_update': 0.004840969324111938, 'loss': 2.4574572669267654, 'time_step': 0.007161962032318115, 'init_value': 11.113460540771484}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 14:43.33[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514144230: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002189969301223755, 'time_algorithm_update': 0.004730745315551758, 'loss': 2.257651350557804, 'time_step': 0.006978606700897217, 'init_value': 18.922433853149414}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 14:43.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514144230: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00229444146156311, 'time_algorithm_update': 0.004991302490234375, 'loss': 2.102377415239811, 'time_step': 0.007346735715866089, 'init_value': 25.36791229248047}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 14:44.16[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514144230: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002235414743423462, 'time_algorithm_update': 0.0048562860488891605, 'loss': 2.0148267579078674, 'time_step': 0.007151269674301147, 'init_value': 30.259870529174805}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 14:44.37[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514144230: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022754826545715334, 'time_algorithm_update': 0.004941821575164795, 'loss': 1.8551881186962127, 'time_step': 0.007278276920318604, 'init_value': 33.154483795166016}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 14:44.58[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514144230: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022765140533447265, 'time_algorithm_update': 0.004965186834335327, 'loss': 1.7890585306286813, 'time_step': 0.007302893400192261, 'init_value': 35.74971008300781}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 14:45.19[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514144230: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021764624118804934, 'time_algorithm_update': 0.004548458814620971, 'loss': 1.7651770396232604, 'time_step': 0.006779703140258789, 'init_value': 38.034366607666016}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 14:45.40[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514144230: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023048300743103026, 'time_algorithm_update': 0.004951932668685913, 'loss': 1.7459480422139169, 'time_step': 0.007316332578659057, 'init_value': 38.52510452270508}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 14:46.02[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514144230: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022819511890411377, 'time_algorithm_update': 0.004924862146377563, 'loss': 1.6536759869456292, 'time_step': 0.007267032146453857, 'init_value': 39.34061050415039}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 39.34061050415039
Starting 1000 evaluations
avg return on 3 trajectories of agent13: 1363.2261270105253
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 15:02.34[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 15:02.34[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 15:02.36[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 15:02.36[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 15:02.36[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514150236[0m
[2m2025-05-14 15:02.36[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 15:02.57[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514150236: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022738058567047118, 'time_algorithm_update': 0.0049410128593444826, 'loss': 1.782909969203174, 'time_step': 0.007276227235794067, 'init_value': 4.108475685119629}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 15:03.18[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514150236: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002285792589187622, 'time_algorithm_update': 0.004846283197402954, 'loss': 2.4964901608824728, 'time_step': 0.007191620349884033, 'init_value': 10.463330268859863}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 15:03.38[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514150236: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002185338020324707, 'time_algorithm_update': 0.00462844729423523, 'loss': 2.4539160151481627, 'time_step': 0.006870084762573242, 'init_value': 18.25215721130371}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 15:04.00[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514150236: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002323873043060303, 'time_algorithm_update': 0.005010717153549195, 'loss': 2.188758289337158, 'time_step': 0.0073965339660644535, 'init_value': 25.751625061035156}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 15:04.22[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514150236: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022920196056365966, 'time_algorithm_update': 0.004933584928512574, 'loss': 2.0276330373883247, 'time_step': 0.007287126779556274, 'init_value': 31.238548278808594}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 15:04.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514150236: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022334382534027098, 'time_algorithm_update': 0.00475478196144104, 'loss': 2.004974822461605, 'time_step': 0.007046528100967407, 'init_value': 34.98890686035156}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 15:05.04[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514150236: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022847583293914794, 'time_algorithm_update': 0.0048546864986419675, 'loss': 1.8333855572342872, 'time_step': 0.007198263168334961, 'init_value': 36.44923400878906}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 15:05.25[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514150236: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022938916683197023, 'time_algorithm_update': 0.005003923177719116, 'loss': 1.7788005725741387, 'time_step': 0.007359272003173828, 'init_value': 38.64543151855469}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 15:05.47[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514150236: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002326711654663086, 'time_algorithm_update': 0.00507669734954834, 'loss': 1.6695193687677383, 'time_step': 0.007466103553771973, 'init_value': 40.69243240356445}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 15:06.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514150236: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002217453479766846, 'time_algorithm_update': 0.0047434761524200435, 'loss': 1.798635985136032, 'time_step': 0.007019063949584961, 'init_value': 42.49196243286133}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.49196243286133
Starting 1000 evaluations
avg return on 3 trajectories of agent14: 1370.1283166741407
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 15:22.47[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 15:22.47[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 15:22.49[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 15:22.49[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 15:22.49[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514152249[0m
[2m2025-05-14 15:22.49[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 15:23.09[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514152249: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002189858436584473, 'time_algorithm_update': 0.004710187673568725, 'loss': 1.786040766246617, 'time_step': 0.006957476615905762, 'init_value': 4.175482749938965}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 15:23.30[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514152249: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002217692136764526, 'time_algorithm_update': 0.004711172103881836, 'loss': 2.191480434179306, 'time_step': 0.0069875259399414065, 'init_value': 10.28406810760498}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 15:23.51[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514152249: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00215088415145874, 'time_algorithm_update': 0.004497093439102173, 'loss': 2.3392689799666404, 'time_step': 0.006703314542770386, 'init_value': 17.88498878479004}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 15:24.11[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514152249: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022304792404174807, 'time_algorithm_update': 0.004851582765579223, 'loss': 2.311670167863369, 'time_step': 0.007142175197601319, 'init_value': 23.969772338867188}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 15:24.33[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514152249: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002235901355743408, 'time_algorithm_update': 0.004855078935623169, 'loss': 1.9931189113259316, 'time_step': 0.007149973154067993, 'init_value': 28.598846435546875}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 15:24.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514152249: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002198670148849487, 'time_algorithm_update': 0.0047603280544281, 'loss': 1.8704274856448173, 'time_step': 0.007017897605895996, 'init_value': 31.677143096923828}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 15:25.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514152249: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002280550241470337, 'time_algorithm_update': 0.004852660894393921, 'loss': 1.6932814638018607, 'time_step': 0.007193573236465454, 'init_value': 35.47364807128906}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 15:25.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514152249: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022676644325256346, 'time_algorithm_update': 0.004922521591186523, 'loss': 1.7678900810480118, 'time_step': 0.007251077890396118, 'init_value': 37.600990295410156}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 15:25.56[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514152249: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002258089542388916, 'time_algorithm_update': 0.004796849727630615, 'loss': 1.6098246585726739, 'time_step': 0.0071144216060638425, 'init_value': 40.272804260253906}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 15:26.16[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514152249: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002175736665725708, 'time_algorithm_update': 0.00463923454284668, 'loss': 1.7137533710598947, 'time_step': 0.006872206449508667, 'init_value': 42.32378005981445}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.32378005981445
Starting 1000 evaluations
avg return on 3 trajectories of agent15: 1376.75862145897
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 15:41.31[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 15:41.31[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 15:41.32[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 15:41.32[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 15:41.32[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514154132[0m
[2m2025-05-14 15:41.32[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 15:41.51[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514154132: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019349300861358644, 'time_algorithm_update': 0.003904135465621948, 'loss': 1.7238552193641663, 'time_step': 0.005888080358505249, 'init_value': 4.434979438781738}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 15:42.10[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514154132: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002079380750656128, 'time_algorithm_update': 0.00422393012046814, 'loss': 2.5217801396846773, 'time_step': 0.006356296300888062, 'init_value': 10.945256233215332}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 15:42.30[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514154132: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021182305812835695, 'time_algorithm_update': 0.004560420036315918, 'loss': 2.364909733891487, 'time_step': 0.006735508680343628, 'init_value': 18.85413360595703}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 15:42.48[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514154132: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019824833869934084, 'time_algorithm_update': 0.004071696519851685, 'loss': 2.2503322598934172, 'time_step': 0.0061051974296569824, 'init_value': 25.197677612304688}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 15:43.06[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514154132: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020013611316680906, 'time_algorithm_update': 0.00408040189743042, 'loss': 2.053228528857231, 'time_step': 0.006132797956466675, 'init_value': 30.1180477142334}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 15:43.26[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514154132: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00211686110496521, 'time_algorithm_update': 0.004419521808624267, 'loss': 1.8376826734542846, 'time_step': 0.00659157657623291, 'init_value': 32.502803802490234}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 15:43.45[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514154132: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002115010976791382, 'time_algorithm_update': 0.004503660917282105, 'loss': 1.8083320900201798, 'time_step': 0.006675557374954223, 'init_value': 35.68163299560547}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 15:44.04[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514154132: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002020935535430908, 'time_algorithm_update': 0.004035487174987793, 'loss': 1.6904495658874512, 'time_step': 0.006106777429580689, 'init_value': 38.52895736694336}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 15:44.22[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514154132: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001974698066711426, 'time_algorithm_update': 0.004045880317687988, 'loss': 1.6347036356925964, 'time_step': 0.006071205854415894, 'init_value': 40.57851028442383}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 15:44.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514154132: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020794739723205566, 'time_algorithm_update': 0.0043745489120483394, 'loss': 1.6639317920804024, 'time_step': 0.006509227275848389, 'init_value': 43.45445251464844}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 43.45445251464844
Starting 1000 evaluations
avg return on 3 trajectories of agent16: 1358.305408110552
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 15:59.36[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 15:59.36[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 15:59.37[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 15:59.37[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 15:59.37[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514155937[0m
[2m2025-05-14 15:59.37[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 15:59.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514155937: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018235743045806885, 'time_algorithm_update': 0.003524521589279175, 'loss': 1.893236937969923, 'time_step': 0.005394722938537598, 'init_value': 4.127769947052002}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 16:00.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514155937: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001993524789810181, 'time_algorithm_update': 0.004008868455886841, 'loss': 2.273795926094055, 'time_step': 0.0060535001754760745, 'init_value': 10.714181900024414}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 16:00.32[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514155937: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019507925510406493, 'time_algorithm_update': 0.0039287712574005125, 'loss': 2.4549163407087327, 'time_step': 0.005930111646652221, 'init_value': 18.954130172729492}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 16:00.50[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514155937: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001839353322982788, 'time_algorithm_update': 0.003649522304534912, 'loss': 2.2692074307203294, 'time_step': 0.005535617113113404, 'init_value': 25.29292106628418}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 16:01.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514155937: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018517558574676514, 'time_algorithm_update': 0.003665093183517456, 'loss': 2.017437080800533, 'time_step': 0.005564177274703979, 'init_value': 30.44627571105957}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 16:01.26[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514155937: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001957728862762451, 'time_algorithm_update': 0.0038668510913848876, 'loss': 1.910188489973545, 'time_step': 0.005874511480331421, 'init_value': 34.073387145996094}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 16:01.44[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514155937: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019170658588409423, 'time_algorithm_update': 0.003835061311721802, 'loss': 1.7226201785802842, 'time_step': 0.005801725149154663, 'init_value': 36.88230514526367}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 16:02.02[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514155937: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018411731719970702, 'time_algorithm_update': 0.0036612000465393066, 'loss': 1.739950039625168, 'time_step': 0.005549884557723999, 'init_value': 37.79479217529297}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 16:02.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514155937: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018455507755279542, 'time_algorithm_update': 0.003647769212722778, 'loss': 1.5993965592384338, 'time_step': 0.005540458440780639, 'init_value': 40.035194396972656}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 16:02.39[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514155937: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019998340606689454, 'time_algorithm_update': 0.0040182828903198246, 'loss': 1.7178868920207024, 'time_step': 0.006069321870803833, 'init_value': 40.645912170410156}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.645912170410156
Starting 1000 evaluations
avg return on 3 trajectories of agent17: 1362.1487371877543
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 16:16.46[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 16:16.46[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 16:16.47[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 16:16.47[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 16:16.47[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514161647[0m
[2m2025-05-14 16:16.47[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 16:17.05[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514161647: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018315405845642089, 'time_algorithm_update': 0.003553596019744873, 'loss': 1.6884480327740312, 'time_step': 0.005432048559188843, 'init_value': 4.327000617980957}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 16:17.23[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514161647: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001977600574493408, 'time_algorithm_update': 0.003910973787307739, 'loss': 2.4143468251228333, 'time_step': 0.005939913511276245, 'init_value': 11.048346519470215}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 16:17.41[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514161647: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019354467391967773, 'time_algorithm_update': 0.0039043872356414795, 'loss': 2.273876800596714, 'time_step': 0.00589049220085144, 'init_value': 18.08911895751953}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 16:17.59[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514161647: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019076917171478272, 'time_algorithm_update': 0.003748317003250122, 'loss': 2.2060176909565925, 'time_step': 0.005705279350280762, 'init_value': 25.726734161376953}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 16:18.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514161647: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018699936866760254, 'time_algorithm_update': 0.003707453966140747, 'loss': 2.0424688783288003, 'time_step': 0.005625479459762574, 'init_value': 31.166929244995117}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 16:18.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514161647: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001999804496765137, 'time_algorithm_update': 0.004013724565505981, 'loss': 1.8751809688210488, 'time_step': 0.006064717769622803, 'init_value': 33.68556594848633}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 16:18.54[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514161647: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019644906520843507, 'time_algorithm_update': 0.004010189771652222, 'loss': 1.7453632603883744, 'time_step': 0.006026718378067016, 'init_value': 36.177886962890625}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 16:19.11[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514161647: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019013166427612304, 'time_algorithm_update': 0.0037073068618774414, 'loss': 1.7436741939783096, 'time_step': 0.0056571483612060545, 'init_value': 38.73701095581055}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 16:19.30[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514161647: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018940563201904296, 'time_algorithm_update': 0.003767171621322632, 'loss': 1.6773011066317558, 'time_step': 0.005710209608078003, 'init_value': 41.63418960571289}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 16:19.48[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514161647: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001922393798828125, 'time_algorithm_update': 0.0037898924350738524, 'loss': 1.8274677682518958, 'time_step': 0.005761817693710327, 'init_value': 42.91834259033203}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.91834259033203
Starting 1000 evaluations
avg return on 3 trajectories of agent18: 1364.7212450384707
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 16:33.52[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 16:33.52[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 16:33.54[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 16:33.54[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 16:33.54[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514163354[0m
[2m2025-05-14 16:33.54[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 16:34.11[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514163354: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018364150524139405, 'time_algorithm_update': 0.0035510237216949464, 'loss': 1.578076472312212, 'time_step': 0.005434272766113281, 'init_value': 4.625508785247803}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 16:34.30[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514163354: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00198374342918396, 'time_algorithm_update': 0.003942003011703491, 'loss': 2.280902755379677, 'time_step': 0.005976632356643676, 'init_value': 11.425048828125}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 16:34.48[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514163354: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001906541347503662, 'time_algorithm_update': 0.0037714769840240477, 'loss': 2.3570856427550315, 'time_step': 0.005727632999420166, 'init_value': 19.322994232177734}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 16:35.06[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514163354: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001963624954223633, 'time_algorithm_update': 0.0038753955364227294, 'loss': 2.151703759610653, 'time_step': 0.005889806032180786, 'init_value': 25.28390884399414}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 16:35.24[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514163354: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018962087631225586, 'time_algorithm_update': 0.0037465968132019043, 'loss': 1.9960193846821785, 'time_step': 0.005692516565322876, 'init_value': 29.82227897644043}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 16:35.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514163354: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019261035919189453, 'time_algorithm_update': 0.0037880303859710693, 'loss': 1.983031080663204, 'time_step': 0.005763782501220703, 'init_value': 33.329254150390625}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 16:36.00[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514163354: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019104807376861572, 'time_algorithm_update': 0.0037596166133880616, 'loss': 1.8007447726130485, 'time_step': 0.005719500780105591, 'init_value': 36.2930793762207}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 16:36.18[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514163354: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019273288249969482, 'time_algorithm_update': 0.00375449538230896, 'loss': 1.8794128442406655, 'time_step': 0.00573236083984375, 'init_value': 38.81122589111328}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 16:36.36[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514163354: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018935394287109375, 'time_algorithm_update': 0.0037317068576812745, 'loss': 1.8154475815296174, 'time_step': 0.005675058126449585, 'init_value': 39.836299896240234}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 16:36.54[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514163354: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001877152442932129, 'time_algorithm_update': 0.0036451082229614256, 'loss': 1.7909160873293877, 'time_step': 0.00557041335105896, 'init_value': 41.169925689697266}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.169925689697266
Starting 1000 evaluations
avg return on 3 trajectories of agent19: 1369.9444879193184
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 16:50.53[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 16:50.53[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 16:50.54[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 16:50.54[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 16:50.54[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514165054[0m
[2m2025-05-14 16:50.54[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 16:51.12[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514165054: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018071029186248779, 'time_algorithm_update': 0.003494743585586548, 'loss': 1.6703189584463836, 'time_step': 0.0053475768566131595, 'init_value': 4.600108623504639}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 16:51.30[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514165054: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018643426895141601, 'time_algorithm_update': 0.003646205186843872, 'loss': 2.3503030174970627, 'time_step': 0.0055597925186157224, 'init_value': 11.338332176208496}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 16:51.47[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514165054: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001857593536376953, 'time_algorithm_update': 0.00364580774307251, 'loss': 2.4501918045282363, 'time_step': 0.005552378654479981, 'init_value': 19.226287841796875}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 16:52.04[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514165054: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018037993907928467, 'time_algorithm_update': 0.0035179343223571777, 'loss': 2.25532789516449, 'time_step': 0.005368335247039795, 'init_value': 26.282939910888672}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 16:52.22[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514165054: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018530523777008057, 'time_algorithm_update': 0.003560800552368164, 'loss': 2.0869520831108095, 'time_step': 0.0054613490104675295, 'init_value': 30.937559127807617}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 16:52.40[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514165054: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018689529895782472, 'time_algorithm_update': 0.003659264087677002, 'loss': 1.9043695549964905, 'time_step': 0.005577385187149048, 'init_value': 33.386112213134766}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 16:52.58[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514165054: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018696694374084474, 'time_algorithm_update': 0.0036789002418518065, 'loss': 1.7822989074587823, 'time_step': 0.005597860336303711, 'init_value': 36.306785583496094}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 16:53.15[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514165054: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018121395111083984, 'time_algorithm_update': 0.0035313193798065185, 'loss': 1.8663610222935676, 'time_step': 0.005390530109405518, 'init_value': 39.823455810546875}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 16:53.33[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514165054: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00185052490234375, 'time_algorithm_update': 0.0035487396717071534, 'loss': 1.8623427100777625, 'time_step': 0.005446112871170044, 'init_value': 41.08158874511719}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 16:53.50[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514165054: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018845670223236084, 'time_algorithm_update': 0.0037278597354888916, 'loss': 1.6820137451887132, 'time_step': 0.005661955118179321, 'init_value': 42.73540115356445}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.73540115356445
ave advantage rew: 41.7541425704956, std: 1.2100028663557167
avg cum rews: 1369.997095636185, std: 9.104381512518232
Pearson correlation coefficient: 0.07056516554589168
Spearman correlation coefficient: 0.2556390977443609
Kendall Tau correlation coefficient: 0.16842105263157894
the best agent: 7, best agent cum rewards: 1392.1250645721514
1963
Starting to collect rollouts
Collecting rollouts: 10000/1000000
Collecting rollouts: 20000/1000000
Collecting rollouts: 30000/1000000
Collecting rollouts: 40000/1000000
Collecting rollouts: 50000/1000000
Collecting rollouts: 60000/1000000
Collecting rollouts: 70000/1000000
Collecting rollouts: 80000/1000000
Collecting rollouts: 90000/1000000
Collecting rollouts: 100000/1000000
Collecting rollouts: 110000/1000000
Collecting rollouts: 120000/1000000
Collecting rollouts: 130000/1000000
Collecting rollouts: 140000/1000000
Collecting rollouts: 150000/1000000
Collecting rollouts: 160000/1000000
Collecting rollouts: 170000/1000000
Collecting rollouts: 180000/1000000
Collecting rollouts: 190000/1000000
Collecting rollouts: 200000/1000000
Collecting rollouts: 210000/1000000
Collecting rollouts: 220000/1000000
Collecting rollouts: 230000/1000000
Collecting rollouts: 240000/1000000
Collecting rollouts: 250000/1000000
Collecting rollouts: 260000/1000000
Collecting rollouts: 270000/1000000
Collecting rollouts: 280000/1000000
Collecting rollouts: 290000/1000000
Collecting rollouts: 300000/1000000
Collecting rollouts: 310000/1000000
Collecting rollouts: 320000/1000000
Collecting rollouts: 330000/1000000
Collecting rollouts: 340000/1000000
Collecting rollouts: 350000/1000000
Collecting rollouts: 360000/1000000
Collecting rollouts: 370000/1000000
Collecting rollouts: 380000/1000000
Collecting rollouts: 390000/1000000
Collecting rollouts: 400000/1000000
Collecting rollouts: 410000/1000000
Collecting rollouts: 420000/1000000
Collecting rollouts: 430000/1000000
Collecting rollouts: 440000/1000000
Collecting rollouts: 450000/1000000
Collecting rollouts: 460000/1000000
Collecting rollouts: 470000/1000000
Collecting rollouts: 480000/1000000
Collecting rollouts: 490000/1000000
Collecting rollouts: 500000/1000000
Collecting rollouts: 510000/1000000
Collecting rollouts: 520000/1000000
Collecting rollouts: 530000/1000000
Collecting rollouts: 540000/1000000
Collecting rollouts: 550000/1000000
Collecting rollouts: 560000/1000000
Collecting rollouts: 570000/1000000
Collecting rollouts: 580000/1000000
Collecting rollouts: 590000/1000000
Collecting rollouts: 600000/1000000
Collecting rollouts: 610000/1000000
Collecting rollouts: 620000/1000000
Collecting rollouts: 630000/1000000
Collecting rollouts: 640000/1000000
Collecting rollouts: 650000/1000000
Collecting rollouts: 660000/1000000
Collecting rollouts: 670000/1000000
Collecting rollouts: 680000/1000000
Collecting rollouts: 690000/1000000
Collecting rollouts: 700000/1000000
Collecting rollouts: 710000/1000000
Collecting rollouts: 720000/1000000
Collecting rollouts: 730000/1000000
Collecting rollouts: 740000/1000000
Collecting rollouts: 750000/1000000
Collecting rollouts: 760000/1000000
Collecting rollouts: 770000/1000000
Collecting rollouts: 780000/1000000
Collecting rollouts: 790000/1000000
Collecting rollouts: 800000/1000000
Collecting rollouts: 810000/1000000
Collecting rollouts: 820000/1000000
Collecting rollouts: 830000/1000000
Collecting rollouts: 840000/1000000
Collecting rollouts: 850000/1000000
Collecting rollouts: 860000/1000000
Collecting rollouts: 870000/1000000
Collecting rollouts: 880000/1000000
Collecting rollouts: 890000/1000000
Collecting rollouts: 900000/1000000
Collecting rollouts: 910000/1000000
Collecting rollouts: 920000/1000000
Collecting rollouts: 930000/1000000
Collecting rollouts: 940000/1000000
Collecting rollouts: 950000/1000000
Collecting rollouts: 960000/1000000
Collecting rollouts: 970000/1000000
Collecting rollouts: 980000/1000000
Collecting rollouts: 990000/1000000
Collecting rollouts: 1000000/1000000
Replay buffer size:  (1000000, 105)
Replay buffer saved
---------------------------------
Searching empty space policies
(10, 11472)
(20, 11472)
(20, 11472)
Average distance of agents to nearest neighbors: 0.018779402906716616
Starting 1000 evaluations
avg return on 3 trajectories of agent0: 1401.5063999372687
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 17:24.05[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 17:24.05[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 17:24.07[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 17:24.07[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 17:24.07[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514172407[0m
[2m2025-05-14 17:24.07[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 17:24.24[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514172407: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019091107845306396, 'time_algorithm_update': 0.003772822380065918, 'loss': 1.8673855042159557, 'time_step': 0.005731288194656372, 'init_value': 4.377140998840332}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 17:24.41[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514172407: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018317432403564453, 'time_algorithm_update': 0.003500990629196167, 'loss': 2.42010063457489, 'time_step': 0.005379859685897827, 'init_value': 10.06706428527832}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 17:24.59[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514172407: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018860135078430176, 'time_algorithm_update': 0.003566000461578369, 'loss': 2.395273114025593, 'time_step': 0.00550021743774414, 'init_value': 17.73638343811035}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 17:25.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514172407: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018814373016357421, 'time_algorithm_update': 0.0036699626445770264, 'loss': 2.111343366801739, 'time_step': 0.00560113787651062, 'init_value': 23.498565673828125}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 17:25.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514172407: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019306106567382813, 'time_algorithm_update': 0.003686350584030151, 'loss': 2.0320473936796186, 'time_step': 0.005666773080825806, 'init_value': 27.19074058532715}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 17:25.52[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514172407: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018940219879150391, 'time_algorithm_update': 0.003771907091140747, 'loss': 1.8288140698075295, 'time_step': 0.005714414596557617, 'init_value': 30.422142028808594}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 17:26.10[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514172407: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019114816188812256, 'time_algorithm_update': 0.0036884801387786865, 'loss': 1.7557852885127068, 'time_step': 0.005648850440979004, 'init_value': 34.461673736572266}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 17:26.28[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514172407: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019009876251220702, 'time_algorithm_update': 0.003712440252304077, 'loss': 1.7401750226616859, 'time_step': 0.005663279056549072, 'init_value': 37.45922088623047}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 17:26.46[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514172407: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018911232948303222, 'time_algorithm_update': 0.00359342622756958, 'loss': 1.7037964110970498, 'time_step': 0.0055326161384582516, 'init_value': 39.13605499267578}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 17:27.03[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514172407: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00185077166557312, 'time_algorithm_update': 0.0036159274578094485, 'loss': 1.8620583516955376, 'time_step': 0.00551469349861145, 'init_value': 41.18741989135742}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.18741989135742
Starting 1000 evaluations
avg return on 3 trajectories of agent1: 1394.405613416178
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 17:40.57[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 17:40.57[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 17:40.58[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 17:40.58[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 17:40.58[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514174058[0m
[2m2025-05-14 17:40.58[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 17:41.15[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514174058: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018493843078613282, 'time_algorithm_update': 0.0036098108291625977, 'loss': 1.7351274449974299, 'time_step': 0.00550706958770752, 'init_value': 4.092550277709961}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 17:41.32[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514174058: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018167240619659424, 'time_algorithm_update': 0.003527930736541748, 'loss': 2.2754821043014526, 'time_step': 0.005391305685043335, 'init_value': 10.93967056274414}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 17:41.49[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514174058: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018405044078826905, 'time_algorithm_update': 0.0035424702167510987, 'loss': 2.4379594700336455, 'time_step': 0.00542943549156189, 'init_value': 19.4686336517334}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 17:42.08[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514174058: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019252865314483643, 'time_algorithm_update': 0.0038591272830963133, 'loss': 2.257870225548744, 'time_step': 0.005835239887237549, 'init_value': 25.97931671142578}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 17:42.25[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514174058: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018337841033935548, 'time_algorithm_update': 0.0036286897659301757, 'loss': 2.0055413862466813, 'time_step': 0.0055100290775299075, 'init_value': 29.757461547851562}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 17:42.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514174058: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001821321487426758, 'time_algorithm_update': 0.0035682599544525147, 'loss': 1.8325498924851418, 'time_step': 0.005436068773269654, 'init_value': 33.08313751220703}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 17:43.00[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514174058: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018473172187805176, 'time_algorithm_update': 0.0035259175300598146, 'loss': 1.9228438567519188, 'time_step': 0.00542019772529602, 'init_value': 36.556114196777344}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 17:43.18[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514174058: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019128103256225587, 'time_algorithm_update': 0.0038345403671264646, 'loss': 1.7671992762088775, 'time_step': 0.00579725193977356, 'init_value': 38.7384147644043}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 17:43.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514174058: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001866971731185913, 'time_algorithm_update': 0.0036630713939666748, 'loss': 1.6815527439713478, 'time_step': 0.005578035116195678, 'init_value': 40.45863723754883}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 17:43.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514174058: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001805732250213623, 'time_algorithm_update': 0.0035240862369537353, 'loss': 1.6481322567462922, 'time_step': 0.005375525236129761, 'init_value': 41.33196258544922}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.33196258544922
Starting 1000 evaluations
avg return on 3 trajectories of agent2: 1375.090353722381
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 17:57.51[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 17:57.51[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 17:57.52[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 17:57.52[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 17:57.52[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514175752[0m
[2m2025-05-14 17:57.52[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 17:58.09[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514175752: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001897449254989624, 'time_algorithm_update': 0.003727194786071777, 'loss': 1.835532501772046, 'time_step': 0.005674199104309082, 'init_value': 4.066592693328857}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 17:58.26[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514175752: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018137979507446289, 'time_algorithm_update': 0.003468623638153076, 'loss': 2.336594322025776, 'time_step': 0.0053288893699646, 'init_value': 10.708536148071289}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 17:58.44[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514175752: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018282463550567626, 'time_algorithm_update': 0.0034417946338653567, 'loss': 2.325223253309727, 'time_step': 0.005315548181533814, 'init_value': 19.454883575439453}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 17:59.02[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514175752: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018506760597229003, 'time_algorithm_update': 0.003615962266921997, 'loss': 2.1202882202267648, 'time_step': 0.0055145277976989746, 'init_value': 26.380338668823242}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 17:59.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514175752: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019140217304229735, 'time_algorithm_update': 0.0037360994815826415, 'loss': 1.976942618906498, 'time_step': 0.0057003734111785885, 'init_value': 30.03205680847168}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 17:59.37[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514175752: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018066551685333252, 'time_algorithm_update': 0.0034793877601623537, 'loss': 1.8553678855895996, 'time_step': 0.005331595420837402, 'init_value': 34.27164077758789}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 17:59.54[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514175752: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018456614017486573, 'time_algorithm_update': 0.0035088508129119873, 'loss': 1.7720349375605584, 'time_step': 0.005400633811950684, 'init_value': 36.414493560791016}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 18:00.12[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514175752: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018611629009246827, 'time_algorithm_update': 0.003586024284362793, 'loss': 1.6750423702001571, 'time_step': 0.00549516248703003, 'init_value': 38.46744918823242}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 18:00.30[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514175752: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019129664897918701, 'time_algorithm_update': 0.0037286179065704347, 'loss': 1.6810010775327682, 'time_step': 0.0056910240650177, 'init_value': 40.621192932128906}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 18:00.47[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514175752: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018239078521728516, 'time_algorithm_update': 0.0035312256813049316, 'loss': 1.7362766786813737, 'time_step': 0.005401054382324219, 'init_value': 43.020835876464844}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 43.020835876464844
Starting 1000 evaluations
avg return on 3 trajectories of agent3: 1350.445617887854
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 18:14.44[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 18:14.44[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 18:14.46[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 18:14.46[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 18:14.46[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514181446[0m
[2m2025-05-14 18:14.46[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 18:15.04[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514181446: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018710381984710694, 'time_algorithm_update': 0.003631943941116333, 'loss': 1.712450229205191, 'time_step': 0.005552276611328125, 'init_value': 4.614425182342529}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 18:15.21[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514181446: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019140241146087646, 'time_algorithm_update': 0.0036204006671905517, 'loss': 2.3056079832315444, 'time_step': 0.005583415746688843, 'init_value': 11.410479545593262}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 18:15.39[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514181446: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018496370315551757, 'time_algorithm_update': 0.0036337628364562988, 'loss': 2.3734202589392663, 'time_step': 0.005530948877334595, 'init_value': 19.75954246520996}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 18:15.56[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514181446: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018225347995758057, 'time_algorithm_update': 0.003524568319320679, 'loss': 2.160727939248085, 'time_step': 0.005393459796905518, 'init_value': 25.60757827758789}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 18:16.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514181446: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019114530086517334, 'time_algorithm_update': 0.003772254228591919, 'loss': 2.003653617322445, 'time_step': 0.005734137535095215, 'init_value': 29.95654296875}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 18:16.32[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514181446: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018513097763061524, 'time_algorithm_update': 0.0036170825958251954, 'loss': 1.858339246928692, 'time_step': 0.005517246484756469, 'init_value': 32.39610290527344}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 18:16.49[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514181446: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018140618801116943, 'time_algorithm_update': 0.0034983723163604734, 'loss': 1.7178438240885734, 'time_step': 0.005359944343566895, 'init_value': 35.49248123168945}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 18:17.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514181446: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018434460163116455, 'time_algorithm_update': 0.003624382495880127, 'loss': 1.7777264432311057, 'time_step': 0.005514932155609131, 'init_value': 38.12709045410156}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 18:17.25[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514181446: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019435973167419433, 'time_algorithm_update': 0.0038791589736938475, 'loss': 1.69135828769207, 'time_step': 0.005874052524566651, 'init_value': 39.33980941772461}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 18:17.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514181446: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018077194690704346, 'time_algorithm_update': 0.0034989655017852784, 'loss': 1.716923097372055, 'time_step': 0.005353208780288696, 'init_value': 40.8994140625}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.8994140625
Starting 1000 evaluations
avg return on 3 trajectories of agent4: 1403.0486447968403
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 18:31.38[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 18:31.38[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 18:31.39[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 18:31.39[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 18:31.39[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514183139[0m
[2m2025-05-14 18:31.39[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 18:31.56[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514183139: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001818504810333252, 'time_algorithm_update': 0.0034518659114837645, 'loss': 1.52937717282027, 'time_step': 0.005316735029220581, 'init_value': 4.3826904296875}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 18:32.13[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514183139: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018263702392578125, 'time_algorithm_update': 0.0034499495029449464, 'loss': 2.4517678319215777, 'time_step': 0.005322266817092896, 'init_value': 11.027933120727539}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 18:32.30[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514183139: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017991392612457275, 'time_algorithm_update': 0.0034672455787658693, 'loss': 2.3314088218212126, 'time_step': 0.005312517404556274, 'init_value': 18.01420021057129}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 18:32.48[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514183139: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018282663822174073, 'time_algorithm_update': 0.003497331619262695, 'loss': 2.1480860725045203, 'time_step': 0.005371002435684204, 'init_value': 23.63005256652832}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 18:33.05[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514183139: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018522415161132811, 'time_algorithm_update': 0.003592965602874756, 'loss': 2.0455426704287527, 'time_step': 0.005493580102920532, 'init_value': 28.83461570739746}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 18:33.23[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514183139: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018751654624938965, 'time_algorithm_update': 0.003678984880447388, 'loss': 1.946649886250496, 'time_step': 0.005601148366928101, 'init_value': 32.32151412963867}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 18:33.39[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514183139: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018072128295898438, 'time_algorithm_update': 0.0035140233039855956, 'loss': 1.7868482246398927, 'time_step': 0.005367501020431519, 'init_value': 35.59149169921875}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 18:33.57[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514183139: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001857398509979248, 'time_algorithm_update': 0.003572460412979126, 'loss': 1.7470316556096077, 'time_step': 0.005477349758148193, 'init_value': 38.54136657714844}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 18:34.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514183139: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018420424461364747, 'time_algorithm_update': 0.0035813069343566895, 'loss': 1.654748085141182, 'time_step': 0.005470860242843628, 'init_value': 39.8216438293457}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 18:34.32[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514183139: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018561811447143554, 'time_algorithm_update': 0.00366125750541687, 'loss': 1.7709695588350296, 'time_step': 0.005565411329269409, 'init_value': 41.83952331542969}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.83952331542969
Starting 1000 evaluations
avg return on 3 trajectories of agent5: 1387.9493328217945
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 18:48.29[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 18:48.29[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 18:48.30[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 18:48.30[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 18:48.30[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514184830[0m
[2m2025-05-14 18:48.30[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 18:48.47[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514184830: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018160383701324462, 'time_algorithm_update': 0.003436410188674927, 'loss': 1.5590167991816997, 'time_step': 0.005299097299575806, 'init_value': 4.822366237640381}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 18:49.04[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514184830: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001807384490966797, 'time_algorithm_update': 0.003377213716506958, 'loss': 2.356716559946537, 'time_step': 0.005229689836502075, 'init_value': 11.82398796081543}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 18:49.21[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514184830: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017788350582122804, 'time_algorithm_update': 0.003396254777908325, 'loss': 2.343331632435322, 'time_step': 0.0052192013263702396, 'init_value': 18.818790435791016}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 18:49.39[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514184830: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019297595024108886, 'time_algorithm_update': 0.0038032870292663574, 'loss': 2.320321396648884, 'time_step': 0.005782623529434204, 'init_value': 25.713973999023438}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 18:49.56[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514184830: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017819166183471679, 'time_algorithm_update': 0.0034201717376708984, 'loss': 2.045871949136257, 'time_step': 0.005247359275817871, 'init_value': 29.209558486938477}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 18:50.13[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514184830: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018144817352294923, 'time_algorithm_update': 0.003454752445220947, 'loss': 1.7893496798872948, 'time_step': 0.0053147985935211185, 'init_value': 32.478912353515625}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 18:50.30[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514184830: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017825140953063965, 'time_algorithm_update': 0.0034154171943664552, 'loss': 1.751065895318985, 'time_step': 0.00524370527267456, 'init_value': 36.826175689697266}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 18:50.48[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514184830: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018633882999420166, 'time_algorithm_update': 0.003629497528076172, 'loss': 1.6705454698204993, 'time_step': 0.0055416967868804935, 'init_value': 38.451507568359375}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 18:51.05[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514184830: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018018054962158202, 'time_algorithm_update': 0.0034747061729431153, 'loss': 1.6635707411766052, 'time_step': 0.005322877883911133, 'init_value': 39.75661087036133}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 18:51.22[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514184830: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017951476573944093, 'time_algorithm_update': 0.0034466960430145264, 'loss': 1.6785369071364402, 'time_step': 0.0052878005504608154, 'init_value': 42.257102966308594}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.257102966308594
Starting 1000 evaluations
avg return on 3 trajectories of agent6: 1337.364958939224
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 19:05.22[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 19:05.22[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 19:05.24[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 19:05.24[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 19:05.24[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514190524[0m
[2m2025-05-14 19:05.24[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 19:05.40[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514190524: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017953782081604004, 'time_algorithm_update': 0.00343935751914978, 'loss': 1.682447033137083, 'time_step': 0.00528000807762146, 'init_value': 4.30570125579834}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 19:05.58[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514190524: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001808114528656006, 'time_algorithm_update': 0.003479720592498779, 'loss': 2.4649271916151045, 'time_step': 0.0053335695266723635, 'init_value': 10.991469383239746}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 19:06.16[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514190524: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018915021419525146, 'time_algorithm_update': 0.0036274316310882567, 'loss': 2.370749164581299, 'time_step': 0.005566957712173462, 'init_value': 17.979034423828125}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 19:06.33[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514190524: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018027396202087403, 'time_algorithm_update': 0.003511737823486328, 'loss': 2.1567352499961854, 'time_step': 0.0053598909378051755, 'init_value': 24.324623107910156}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 19:06.50[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514190524: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018264284133911132, 'time_algorithm_update': 0.003551470756530762, 'loss': 1.9072007129192352, 'time_step': 0.005423936605453491, 'init_value': 29.506675720214844}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 19:07.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514190524: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018358101844787597, 'time_algorithm_update': 0.0035929789543151856, 'loss': 1.8633030586838721, 'time_step': 0.005476644277572632, 'init_value': 32.97401809692383}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 19:07.25[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514190524: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019150066375732422, 'time_algorithm_update': 0.0037023630142211912, 'loss': 1.7998050408363342, 'time_step': 0.005666327953338623, 'init_value': 35.107425689697266}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 19:07.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514190524: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018166778087615966, 'time_algorithm_update': 0.003558518886566162, 'loss': 1.7189801222682, 'time_step': 0.005421840906143188, 'init_value': 38.016204833984375}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 19:08.00[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514190524: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018605854511260986, 'time_algorithm_update': 0.003574080944061279, 'loss': 1.6758089590668679, 'time_step': 0.005481640100479126, 'init_value': 39.755455017089844}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 19:08.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514190524: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018236639499664307, 'time_algorithm_update': 0.0035791471004486086, 'loss': 1.6991143271923066, 'time_step': 0.005449677467346191, 'init_value': 41.88505554199219}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.88505554199219
Starting 1000 evaluations
avg return on 3 trajectories of agent7: 1267.6251152214613
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 19:22.19[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 19:22.19[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 19:22.20[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 19:22.20[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 19:22.20[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514192220[0m
[2m2025-05-14 19:22.20[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 19:22.37[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514192220: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017761449813842773, 'time_algorithm_update': 0.0033749268054962156, 'loss': 1.5825685690566897, 'time_step': 0.005195273876190186, 'init_value': 4.6233906745910645}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 19:22.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514192220: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018496758937835694, 'time_algorithm_update': 0.003451347589492798, 'loss': 2.3197463502287863, 'time_step': 0.005346719026565552, 'init_value': 11.055730819702148}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 19:23.12[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514192220: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001824944019317627, 'time_algorithm_update': 0.003521020174026489, 'loss': 2.3124682047367098, 'time_step': 0.005393229961395264, 'init_value': 18.573427200317383}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 19:23.29[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514192220: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018575587272644043, 'time_algorithm_update': 0.0036339638233184816, 'loss': 2.2189864119887353, 'time_step': 0.005539058446884155, 'init_value': 25.05839729309082}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 19:23.46[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514192220: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001786722183227539, 'time_algorithm_update': 0.0034516446590423583, 'loss': 2.094031544148922, 'time_step': 0.005283428907394409, 'init_value': 29.823177337646484}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 19:24.04[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514192220: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018336894512176515, 'time_algorithm_update': 0.0035465028285980226, 'loss': 1.852935871899128, 'time_step': 0.005427325963973999, 'init_value': 32.65940475463867}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 19:24.21[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514192220: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001805757761001587, 'time_algorithm_update': 0.003523622751235962, 'loss': 1.6772582240104674, 'time_step': 0.005375197172164917, 'init_value': 35.96311569213867}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 19:24.39[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514192220: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018244681358337402, 'time_algorithm_update': 0.0035634140968322753, 'loss': 1.5884813013076782, 'time_step': 0.005434863805770874, 'init_value': 38.38267135620117}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 19:24.56[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514192220: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017803399562835694, 'time_algorithm_update': 0.0034584107398986817, 'loss': 1.69959112906456, 'time_step': 0.005283846139907837, 'init_value': 40.67601013183594}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 19:25.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514192220: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018296475410461426, 'time_algorithm_update': 0.0035694878101348877, 'loss': 1.6495921816825867, 'time_step': 0.005446984767913819, 'init_value': 42.69380187988281}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.69380187988281
Starting 1000 evaluations
avg return on 3 trajectories of agent8: 1401.3499958061384
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 19:39.08[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 19:39.08[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 19:39.09[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 19:39.09[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 19:39.09[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514193909[0m
[2m2025-05-14 19:39.09[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 19:39.26[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514193909: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017995827198028565, 'time_algorithm_update': 0.003442652702331543, 'loss': 1.5204175842106342, 'time_step': 0.005287910938262939, 'init_value': 4.624599933624268}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 19:39.44[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514193909: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001900604486465454, 'time_algorithm_update': 0.0037416691780090333, 'loss': 2.4352312082648275, 'time_step': 0.005691046714782715, 'init_value': 11.274169921875}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 19:40.01[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514193909: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018465585708618165, 'time_algorithm_update': 0.0035077290534973144, 'loss': 2.266251459360123, 'time_step': 0.005400678634643555, 'init_value': 19.1865177154541}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 19:40.18[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514193909: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018052012920379639, 'time_algorithm_update': 0.0034786381721496583, 'loss': 2.073527042090893, 'time_step': 0.00533003044128418, 'init_value': 25.49898910522461}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 19:40.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514193909: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018277201652526856, 'time_algorithm_update': 0.003493346929550171, 'loss': 1.8527699921131133, 'time_step': 0.0053664731979370115, 'init_value': 29.718608856201172}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 19:40.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514193909: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018629751205444336, 'time_algorithm_update': 0.003610722541809082, 'loss': 1.7953497915863992, 'time_step': 0.005522531747817993, 'init_value': 32.8923225402832}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 19:41.10[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514193909: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018516051769256591, 'time_algorithm_update': 0.003498626708984375, 'loss': 1.796939543068409, 'time_step': 0.005396084070205688, 'init_value': 35.649417877197266}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 19:41.27[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514193909: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018121888637542725, 'time_algorithm_update': 0.003484217405319214, 'loss': 1.6921633412241937, 'time_step': 0.00534239649772644, 'init_value': 38.062843322753906}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 19:41.45[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514193909: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017961320877075196, 'time_algorithm_update': 0.003465880870819092, 'loss': 1.8008884540200234, 'time_step': 0.0053073554039001465, 'init_value': 39.911293029785156}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 19:42.02[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514193909: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001856379508972168, 'time_algorithm_update': 0.0035788073539733886, 'loss': 1.670533978819847, 'time_step': 0.0054834034442901615, 'init_value': 42.30067825317383}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.30067825317383
Starting 1000 evaluations
avg return on 3 trajectories of agent9: 1409.651212221546
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 19:55.58[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 19:55.58[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 19:55.59[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 19:55.59[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 19:55.59[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514195559[0m
[2m2025-05-14 19:55.59[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 19:56.16[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514195559: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017959072589874268, 'time_algorithm_update': 0.0034282169342041017, 'loss': 1.4243855080902577, 'time_step': 0.005269354343414307, 'init_value': 4.511509418487549}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 19:56.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514195559: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018432137966156005, 'time_algorithm_update': 0.0035490152835845946, 'loss': 2.3073852571845053, 'time_step': 0.005439935445785522, 'init_value': 10.566091537475586}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 19:56.51[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514195559: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018165867328643799, 'time_algorithm_update': 0.0035174012184143065, 'loss': 2.242849260389805, 'time_step': 0.005380328416824341, 'init_value': 18.139339447021484}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 19:57.08[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514195559: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001782029390335083, 'time_algorithm_update': 0.0034621927738189696, 'loss': 2.063365228533745, 'time_step': 0.0052892906665802, 'init_value': 24.425037384033203}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 19:57.25[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514195559: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018888964653015136, 'time_algorithm_update': 0.0037173175811767577, 'loss': 1.9146732795238495, 'time_step': 0.005653730392456055, 'init_value': 29.18634605407715}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 19:57.43[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514195559: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018466930389404296, 'time_algorithm_update': 0.0035984766483306884, 'loss': 1.7668640893697738, 'time_step': 0.005493477821350097, 'init_value': 31.900699615478516}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 19:58.00[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514195559: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017917239665985107, 'time_algorithm_update': 0.003497074842453003, 'loss': 1.766845496237278, 'time_step': 0.005334386348724365, 'init_value': 34.69186019897461}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 19:58.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514195559: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001798008680343628, 'time_algorithm_update': 0.0034977662563323974, 'loss': 1.7376095194220542, 'time_step': 0.0053407948017120364, 'init_value': 37.79412841796875}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 19:58.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514195559: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018501253128051758, 'time_algorithm_update': 0.003547415018081665, 'loss': 1.7005010939836502, 'time_step': 0.005443909168243408, 'init_value': 41.12087631225586}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 19:58.52[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514195559: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018208284378051758, 'time_algorithm_update': 0.0035203919410705564, 'loss': 1.6439608626961708, 'time_step': 0.005388686180114746, 'init_value': 42.6916618347168}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.6916618347168
Starting 1000 evaluations
avg return on 3 trajectories of agent10: 1405.3832537032924
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 20:12.42[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 20:12.42[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 20:12.43[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 20:12.43[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 20:12.43[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514201243[0m
[2m2025-05-14 20:12.43[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 20:13.00[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514201243: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017871050834655762, 'time_algorithm_update': 0.003407728910446167, 'loss': 1.7188778510913252, 'time_step': 0.005239565372467041, 'init_value': 4.475240707397461}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 20:13.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514201243: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017915821075439452, 'time_algorithm_update': 0.003412968158721924, 'loss': 2.474723324239254, 'time_step': 0.005249631404876709, 'init_value': 10.574384689331055}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 20:13.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514201243: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018838636875152589, 'time_algorithm_update': 0.0036604793071746827, 'loss': 2.473707780480385, 'time_step': 0.005592791318893432, 'init_value': 17.49934959411621}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 20:13.52[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514201243: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001783238649368286, 'time_algorithm_update': 0.003437207221984863, 'loss': 2.279521909713745, 'time_step': 0.005265790462493897, 'init_value': 23.60634994506836}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 20:14.09[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514201243: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018149077892303466, 'time_algorithm_update': 0.003463655710220337, 'loss': 1.9833451682329177, 'time_step': 0.005324104070663452, 'init_value': 28.047388076782227}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 20:14.27[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514201243: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001784679412841797, 'time_algorithm_update': 0.0034357972145080567, 'loss': 1.9312813718914985, 'time_step': 0.005265703201293945, 'init_value': 32.935550689697266}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 20:14.44[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514201243: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018858306407928468, 'time_algorithm_update': 0.0035939273834228514, 'loss': 1.706449319779873, 'time_step': 0.005528118133544922, 'init_value': 35.350460052490234}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 20:15.01[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514201243: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017784008979797364, 'time_algorithm_update': 0.0034382872581481933, 'loss': 1.7871272447705269, 'time_step': 0.005261916875839234, 'init_value': 38.67007827758789}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 20:15.18[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514201243: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017789793014526367, 'time_algorithm_update': 0.0034619603157043455, 'loss': 1.7811187410354614, 'time_step': 0.005286669254302979, 'init_value': 40.0712776184082}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 20:15.36[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514201243: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017914862632751464, 'time_algorithm_update': 0.0034725961685180664, 'loss': 1.7278353013396264, 'time_step': 0.005309795141220093, 'init_value': 42.64948272705078}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.64948272705078
Starting 1000 evaluations
avg return on 3 trajectories of agent11: 1398.4431751438935
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 20:29.29[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 20:29.29[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 20:29.30[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 20:29.30[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 20:29.30[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514202930[0m
[2m2025-05-14 20:29.30[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 20:29.47[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514202930: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017857515811920165, 'time_algorithm_update': 0.003408018350601196, 'loss': 1.6581898556351662, 'time_step': 0.005239284992218017, 'init_value': 4.16996955871582}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 20:30.05[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514202930: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018177897930145264, 'time_algorithm_update': 0.003519068717956543, 'loss': 2.334350997745991, 'time_step': 0.005383292436599732, 'init_value': 10.72952938079834}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 20:30.22[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514202930: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018408541679382324, 'time_algorithm_update': 0.0035626764297485352, 'loss': 2.2953730595111845, 'time_step': 0.005451890707015991, 'init_value': 17.71184539794922}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 20:30.39[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514202930: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017906396389007569, 'time_algorithm_update': 0.0034669411182403566, 'loss': 2.19927519595623, 'time_step': 0.005303354024887085, 'init_value': 24.387310028076172}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 20:30.56[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514202930: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018139891624450683, 'time_algorithm_update': 0.003446758031845093, 'loss': 2.089030673503876, 'time_step': 0.005306702136993408, 'init_value': 27.85076332092285}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 20:31.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514202930: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018310251235961915, 'time_algorithm_update': 0.003589280843734741, 'loss': 1.8909995311498642, 'time_step': 0.0054677374362945555, 'init_value': 31.358274459838867}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 20:31.32[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514202930: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018733155727386475, 'time_algorithm_update': 0.003574179410934448, 'loss': 1.865776063978672, 'time_step': 0.005495534896850586, 'init_value': 33.56752395629883}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 20:31.49[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514202930: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017958440780639648, 'time_algorithm_update': 0.0034645798206329346, 'loss': 1.715794687271118, 'time_step': 0.005306110620498657, 'init_value': 35.83247756958008}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 20:32.06[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514202930: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018305888175964356, 'time_algorithm_update': 0.0034886834621429444, 'loss': 1.7520976373553276, 'time_step': 0.005365388870239258, 'init_value': 38.46539306640625}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 20:32.24[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514202930: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018357207775115967, 'time_algorithm_update': 0.003563157558441162, 'loss': 1.7661231293082238, 'time_step': 0.0054469616413116454, 'init_value': 40.197208404541016}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.197208404541016
Starting 1000 evaluations
avg return on 3 trajectories of agent12: 1403.3037802107892
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 20:46.14[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 20:46.14[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 20:46.15[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 20:46.15[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 20:46.15[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514204615[0m
[2m2025-05-14 20:46.15[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 20:46.32[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514204615: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017891190052032472, 'time_algorithm_update': 0.0034239542484283446, 'loss': 1.7226580533459783, 'time_step': 0.005258037090301514, 'init_value': 4.541520595550537}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 20:46.49[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514204615: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018136210441589355, 'time_algorithm_update': 0.0034830453395843504, 'loss': 2.3759340181946755, 'time_step': 0.0053431599140167235, 'init_value': 10.92209529876709}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 20:47.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514204615: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018787167072296142, 'time_algorithm_update': 0.003626306772232056, 'loss': 2.338832201719284, 'time_step': 0.005553335428237915, 'init_value': 16.916738510131836}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 20:47.24[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514204615: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001804049015045166, 'time_algorithm_update': 0.003498251676559448, 'loss': 2.1162389224767684, 'time_step': 0.005348618268966675, 'init_value': 23.463937759399414}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 20:47.41[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514204615: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019283301830291747, 'time_algorithm_update': 0.0037710659503936766, 'loss': 2.0589880853295326, 'time_step': 0.0057474708557128905, 'init_value': 29.276933670043945}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 20:47.59[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514204615: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018385181427001953, 'time_algorithm_update': 0.003603513240814209, 'loss': 1.9129441862106322, 'time_step': 0.005489742279052735, 'init_value': 32.83612060546875}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 20:48.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514204615: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018793511390686034, 'time_algorithm_update': 0.003585283041000366, 'loss': 1.7436194643974303, 'time_step': 0.005512076854705811, 'init_value': 35.44261169433594}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 20:48.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514204615: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018082070350646973, 'time_algorithm_update': 0.0035340580940246584, 'loss': 1.7233520022034645, 'time_step': 0.005388715744018555, 'init_value': 39.548057556152344}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 20:48.51[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514204615: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018506674766540527, 'time_algorithm_update': 0.0035876126289367677, 'loss': 1.6216650435328483, 'time_step': 0.005485616207122803, 'init_value': 40.979068756103516}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 20:49.09[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514204615: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018599367141723634, 'time_algorithm_update': 0.003643463611602783, 'loss': 1.744565534234047, 'time_step': 0.0055517745018005375, 'init_value': 42.7396354675293}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.7396354675293
Starting 1000 evaluations
avg return on 3 trajectories of agent13: 1396.4229199023857
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 21:02.58[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 21:02.58[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 21:02.59[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 21:02.59[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 21:02.59[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514210259[0m
[2m2025-05-14 21:02.59[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 21:03.16[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514210259: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017846171855926513, 'time_algorithm_update': 0.003406439781188965, 'loss': 1.561862233646214, 'time_step': 0.005236099481582642, 'init_value': 4.271117687225342}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 21:03.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514210259: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018034851551055908, 'time_algorithm_update': 0.0034624338150024414, 'loss': 2.3718737300038337, 'time_step': 0.005311866760253906, 'init_value': 10.99349308013916}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 21:03.51[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514210259: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018889822959899903, 'time_algorithm_update': 0.0036670253276824953, 'loss': 2.3059991108775137, 'time_step': 0.005604398488998413, 'init_value': 19.18549919128418}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 21:04.08[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514210259: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001797304630279541, 'time_algorithm_update': 0.0034729833602905272, 'loss': 2.0895318982005118, 'time_step': 0.005315871000289917, 'init_value': 24.74153709411621}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 21:04.25[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514210259: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018296680450439454, 'time_algorithm_update': 0.003504825830459595, 'loss': 1.940476143836975, 'time_step': 0.005381108283996582, 'init_value': 28.811731338500977}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 21:04.43[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514210259: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018301587104797364, 'time_algorithm_update': 0.0035606637001037596, 'loss': 1.8205950316786765, 'time_step': 0.005437965631484985, 'init_value': 33.75758361816406}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 21:05.01[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514210259: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018362810611724854, 'time_algorithm_update': 0.003506763935089111, 'loss': 1.711615648627281, 'time_step': 0.005389355897903443, 'init_value': 36.03550720214844}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 21:05.18[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514210259: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017969605922698974, 'time_algorithm_update': 0.0034730954170227053, 'loss': 1.7858756586313247, 'time_step': 0.00531637167930603, 'init_value': 38.11724090576172}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 21:05.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514210259: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018218798637390137, 'time_algorithm_update': 0.0034898393154144287, 'loss': 1.7226943670511246, 'time_step': 0.005357020378112793, 'init_value': 40.25351333618164}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 21:05.52[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514210259: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018443140983581542, 'time_algorithm_update': 0.003570420265197754, 'loss': 1.6838037924170495, 'time_step': 0.005463077783584595, 'init_value': 42.41025161743164}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.41025161743164
Starting 1000 evaluations
avg return on 3 trajectories of agent14: 1394.2848094953547
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 21:19.44[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 21:19.44[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 21:19.45[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 21:19.45[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 21:19.45[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514211945[0m
[2m2025-05-14 21:19.45[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 21:20.02[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514211945: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017845189571380614, 'time_algorithm_update': 0.003416398286819458, 'loss': 1.8477430828213692, 'time_step': 0.005246511697769165, 'init_value': 4.059483051300049}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 21:20.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514211945: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018110544681549073, 'time_algorithm_update': 0.0035242910385131837, 'loss': 2.4432296088337897, 'time_step': 0.00538237452507019, 'init_value': 10.603470802307129}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 21:20.37[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514211945: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001868483781814575, 'time_algorithm_update': 0.0035661845207214356, 'loss': 2.2318552520871164, 'time_step': 0.0054832761287689205, 'init_value': 17.25242805480957}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 21:20.54[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514211945: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001785456418991089, 'time_algorithm_update': 0.003468005657196045, 'loss': 2.1755176267027854, 'time_step': 0.005298856735229492, 'init_value': 24.12838363647461}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 21:21.11[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514211945: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017878692150115967, 'time_algorithm_update': 0.0034583895206451417, 'loss': 1.925733633518219, 'time_step': 0.005292227745056152, 'init_value': 28.763656616210938}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 21:21.29[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514211945: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018417651653289794, 'time_algorithm_update': 0.00363114333152771, 'loss': 1.8019368742704391, 'time_step': 0.0055206773281097415, 'init_value': 32.45135498046875}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 21:21.46[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514211945: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018365371227264404, 'time_algorithm_update': 0.003485509157180786, 'loss': 1.8319240166544914, 'time_step': 0.005368767023086548, 'init_value': 35.41417694091797}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 21:22.03[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514211945: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017768008708953858, 'time_algorithm_update': 0.003451134204864502, 'loss': 1.780059817671776, 'time_step': 0.005273565292358399, 'init_value': 38.125587463378906}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 21:22.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514211945: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018320064544677735, 'time_algorithm_update': 0.0034616148471832277, 'loss': 1.6633536174297332, 'time_step': 0.00533990740776062, 'init_value': 40.006649017333984}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 21:22.38[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514211945: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018354907035827636, 'time_algorithm_update': 0.003569498062133789, 'loss': 1.714820765376091, 'time_step': 0.005453454971313477, 'init_value': 41.86534881591797}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.86534881591797
Starting 1000 evaluations
avg return on 3 trajectories of agent15: 1385.1808846805839
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 21:36.28[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 21:36.28[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 21:36.29[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 21:36.29[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 21:36.29[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514213629[0m
[2m2025-05-14 21:36.29[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 21:36.46[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514213629: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017831268310546874, 'time_algorithm_update': 0.003383463382720947, 'loss': 1.618894803211093, 'time_step': 0.005211760282516479, 'init_value': 4.26186466217041}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 21:37.04[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514213629: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017813563346862793, 'time_algorithm_update': 0.0034047515392303467, 'loss': 2.4003215937018396, 'time_step': 0.005231136322021484, 'init_value': 10.760293006896973}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 21:37.21[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514213629: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00185528302192688, 'time_algorithm_update': 0.003540303707122803, 'loss': 2.2633375750184057, 'time_step': 0.005442816495895386, 'init_value': 17.796249389648438}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 21:37.38[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514213629: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017968120574951172, 'time_algorithm_update': 0.0034452898502349855, 'loss': 2.1750154044628145, 'time_step': 0.005287710666656494, 'init_value': 23.823701858520508}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 21:37.56[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514213629: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018760688304901123, 'time_algorithm_update': 0.003615482568740845, 'loss': 2.047182297885418, 'time_step': 0.005538658380508423, 'init_value': 27.612768173217773}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 21:38.13[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514213629: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018445093631744385, 'time_algorithm_update': 0.0035654828548431394, 'loss': 1.887724322140217, 'time_step': 0.005458329439163208, 'init_value': 31.216785430908203}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 21:38.31[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514213629: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018525049686431885, 'time_algorithm_update': 0.0034839322566986085, 'loss': 1.6942237030863763, 'time_step': 0.005383380651473999, 'init_value': 34.15022659301758}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 21:38.48[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514213629: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017872421741485596, 'time_algorithm_update': 0.003439337968826294, 'loss': 1.7655714753866196, 'time_step': 0.005271883249282837, 'init_value': 36.42856216430664}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 21:39.05[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514213629: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018819539546966553, 'time_algorithm_update': 0.003589027404785156, 'loss': 1.6247663808465005, 'time_step': 0.005518232822418213, 'init_value': 38.211524963378906}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 21:39.23[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514213629: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018492605686187744, 'time_algorithm_update': 0.0035696842670440675, 'loss': 1.5786900453567505, 'time_step': 0.005467264652252197, 'init_value': 40.27211380004883}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.27211380004883
Starting 1000 evaluations
avg return on 3 trajectories of agent16: 1401.644872175918
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 21:53.17[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 21:53.17[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 21:53.19[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 21:53.19[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 21:53.19[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514215319[0m
[2m2025-05-14 21:53.19[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 21:53.36[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514215319: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001774949312210083, 'time_algorithm_update': 0.003386069059371948, 'loss': 1.5583370183035732, 'time_step': 0.005206157207489013, 'init_value': 4.58209228515625}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 21:53.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514215319: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017953345775604248, 'time_algorithm_update': 0.0034448630809783935, 'loss': 2.3697432540655137, 'time_step': 0.005286052703857422, 'init_value': 10.967123031616211}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 21:54.10[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514215319: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018485047817230224, 'time_algorithm_update': 0.0036167354583740235, 'loss': 2.2600738530158995, 'time_step': 0.005513838529586792, 'init_value': 18.055055618286133}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 21:54.27[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514215319: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018006129264831543, 'time_algorithm_update': 0.003500586986541748, 'loss': 2.130001353919506, 'time_step': 0.00534747838973999, 'init_value': 24.404035568237305}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 21:54.45[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514215319: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018357484340667724, 'time_algorithm_update': 0.0035394949913024904, 'loss': 1.9729016342163086, 'time_step': 0.005421745300292969, 'init_value': 28.4527645111084}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 21:55.02[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514215319: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018218462467193604, 'time_algorithm_update': 0.00355841326713562, 'loss': 1.7765317018032074, 'time_step': 0.005427513360977173, 'init_value': 31.75002670288086}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 21:55.19[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514215319: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018953735828399659, 'time_algorithm_update': 0.003705894947052002, 'loss': 1.6682859441637994, 'time_step': 0.0056493299007415775, 'init_value': 35.34436798095703}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 21:55.37[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514215319: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017842352390289307, 'time_algorithm_update': 0.0034087183475494383, 'loss': 1.6921020130515099, 'time_step': 0.005239354848861694, 'init_value': 38.566741943359375}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 21:55.54[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514215319: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001813309907913208, 'time_algorithm_update': 0.0035487310886383057, 'loss': 1.5826840065717698, 'time_step': 0.005408598899841309, 'init_value': 39.99692153930664}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 21:56.11[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514215319: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018573055267333985, 'time_algorithm_update': 0.0036496126651763914, 'loss': 1.5989919545054436, 'time_step': 0.005555344581604004, 'init_value': 42.66936111450195}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.66936111450195
Starting 1000 evaluations
avg return on 3 trajectories of agent17: 1396.8417816264632
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 22:10.02[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 22:10.02[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 22:10.03[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 22:10.03[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 22:10.03[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514221003[0m
[2m2025-05-14 22:10.03[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 22:10.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514221003: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001856384515762329, 'time_algorithm_update': 0.003597343921661377, 'loss': 1.8429419051781297, 'time_step': 0.0055011982917785645, 'init_value': 4.476129055023193}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 22:10.38[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514221003: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018742437362670899, 'time_algorithm_update': 0.0036164908409118653, 'loss': 2.2249451510310174, 'time_step': 0.005539365291595459, 'init_value': 11.65710735321045}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 22:10.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514221003: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018327128887176513, 'time_algorithm_update': 0.0035277087688446044, 'loss': 2.390086825489998, 'time_step': 0.005407908916473389, 'init_value': 20.172603607177734}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 22:11.12[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514221003: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018215501308441163, 'time_algorithm_update': 0.003521267890930176, 'loss': 2.1166624076366425, 'time_step': 0.005389617919921875, 'init_value': 25.690818786621094}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 22:11.30[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514221003: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001850076198577881, 'time_algorithm_update': 0.0035375380516052247, 'loss': 1.9242987531423568, 'time_step': 0.005434245586395264, 'init_value': 29.976253509521484}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 22:11.47[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514221003: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001867830753326416, 'time_algorithm_update': 0.003633977174758911, 'loss': 1.7876290576457978, 'time_step': 0.005550838470458984, 'init_value': 32.95418930053711}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 22:12.04[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514221003: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018514106273651123, 'time_algorithm_update': 0.0035255577564239503, 'loss': 1.7746236138343812, 'time_step': 0.005423826217651367, 'init_value': 35.26923370361328}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 22:12.21[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514221003: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018051624298095702, 'time_algorithm_update': 0.0034968318939208984, 'loss': 1.554975481569767, 'time_step': 0.0053480064868927, 'init_value': 37.25123596191406}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 22:12.39[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514221003: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018458297252655028, 'time_algorithm_update': 0.0035228278636932372, 'loss': 1.6513441640138626, 'time_step': 0.005415231704711914, 'init_value': 39.14570617675781}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 22:12.57[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514221003: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019048094749450684, 'time_algorithm_update': 0.0037858400344848633, 'loss': 1.6259685535430908, 'time_step': 0.005739713907241821, 'init_value': 41.02933120727539}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.02933120727539
Starting 1000 evaluations
avg return on 3 trajectories of agent18: 1388.49302045276
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 22:26.51[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 22:26.51[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 22:26.52[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 22:26.52[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 22:26.52[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514222652[0m
[2m2025-05-14 22:26.52[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 22:27.09[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514222652: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018167054653167724, 'time_algorithm_update': 0.0035052449703216553, 'loss': 1.8184885192066431, 'time_step': 0.005368796586990357, 'init_value': 4.497683048248291}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 22:27.26[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514222652: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018420310020446776, 'time_algorithm_update': 0.00355861234664917, 'loss': 2.3538851401805876, 'time_step': 0.005448693037033081, 'init_value': 10.511116027832031}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 22:27.44[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514222652: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00183445405960083, 'time_algorithm_update': 0.00348923659324646, 'loss': 2.278022519946098, 'time_step': 0.005369677543640137, 'init_value': 17.49778938293457}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 22:28.01[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514222652: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018376502990722656, 'time_algorithm_update': 0.0036376488208770754, 'loss': 2.11757074201107, 'time_step': 0.005522770643234253, 'init_value': 24.066408157348633}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 22:28.19[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514222652: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018332061767578126, 'time_algorithm_update': 0.003628138542175293, 'loss': 2.091928482890129, 'time_step': 0.00550996470451355, 'init_value': 29.470489501953125}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 22:28.36[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514222652: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001811253786087036, 'time_algorithm_update': 0.0035578765869140627, 'loss': 1.9563469308018684, 'time_step': 0.005416109561920166, 'init_value': 34.07991409301758}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 22:28.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514222652: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018367390632629394, 'time_algorithm_update': 0.0035203964710235594, 'loss': 1.813032976925373, 'time_step': 0.005403494358062744, 'init_value': 36.16624069213867}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 22:29.11[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514222652: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018091263771057129, 'time_algorithm_update': 0.0035509467124938965, 'loss': 1.6545163161158563, 'time_step': 0.005407057762145996, 'init_value': 39.003482818603516}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 22:29.29[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514222652: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018704259395599366, 'time_algorithm_update': 0.00364739727973938, 'loss': 1.7959055098295211, 'time_step': 0.005566099166870117, 'init_value': 40.94945526123047}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 22:29.46[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514222652: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018016600608825684, 'time_algorithm_update': 0.0035303137302398683, 'loss': 1.6513245064616204, 'time_step': 0.005377700090408325, 'init_value': 41.854732513427734}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.854732513427734
Starting 1000 evaluations
avg return on 3 trajectories of agent19: 1378.8640554827498
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 22:43.38[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 22:43.38[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 22:43.39[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 22:43.39[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 22:43.39[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514224339[0m
[2m2025-05-14 22:43.39[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 22:43.57[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514224339: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018538000583648681, 'time_algorithm_update': 0.0035997114181518554, 'loss': 1.9353225940167904, 'time_step': 0.005501326084136963, 'init_value': 4.64150857925415}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 22:44.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514224339: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018733272552490235, 'time_algorithm_update': 0.0037086856365203856, 'loss': 2.3611471276283265, 'time_step': 0.005630160093307495, 'init_value': 11.12197208404541}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 22:44.32[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514224339: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018129181861877442, 'time_algorithm_update': 0.003524514675140381, 'loss': 2.339788397550583, 'time_step': 0.005383891105651855, 'init_value': 19.208389282226562}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 22:44.49[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514224339: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018223865032196045, 'time_algorithm_update': 0.003562312126159668, 'loss': 2.1537520989179613, 'time_step': 0.005431549072265625, 'init_value': 25.57879638671875}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 22:45.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514224339: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018892464637756347, 'time_algorithm_update': 0.003659632921218872, 'loss': 1.9860007908940316, 'time_step': 0.005597589254379273, 'init_value': 29.279268264770508}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 22:45.24[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514224339: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018254895210266114, 'time_algorithm_update': 0.00356610107421875, 'loss': 1.8248879914283753, 'time_step': 0.005438539505004883, 'init_value': 31.68686294555664}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 22:45.41[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514224339: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001854830503463745, 'time_algorithm_update': 0.0035427422523498535, 'loss': 1.7696142519712448, 'time_step': 0.005443539619445801, 'init_value': 33.3701171875}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 22:45.59[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514224339: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018174097537994385, 'time_algorithm_update': 0.0035530292987823488, 'loss': 1.743805613219738, 'time_step': 0.005416751146316528, 'init_value': 34.728248596191406}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 22:46.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514224339: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019005022048950194, 'time_algorithm_update': 0.0036865475177764893, 'loss': 1.6758433653712272, 'time_step': 0.005636030673980713, 'init_value': 37.18056869506836}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 22:46.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514224339: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018107779026031495, 'time_algorithm_update': 0.003530910015106201, 'loss': 1.640599718809128, 'time_step': 0.0053875594139099125, 'init_value': 39.33901596069336}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 39.33901596069336
ave advantage rew: 41.75669689178467, std: 0.9801636108192266
avg cum rews: 1383.864989882244, std: 32.013953343363156
Pearson correlation coefficient: -0.051474423682280286
Spearman correlation coefficient: 0.20601503759398496
Kendall Tau correlation coefficient: 0.16842105263157894
the best agent: 9, best agent cum rewards: 1409.651212221546
1964
Starting to collect rollouts
Collecting rollouts: 10000/1000000
Collecting rollouts: 20000/1000000
Collecting rollouts: 30000/1000000
Collecting rollouts: 40000/1000000
Collecting rollouts: 50000/1000000
Collecting rollouts: 60000/1000000
Collecting rollouts: 70000/1000000
Collecting rollouts: 80000/1000000
Collecting rollouts: 90000/1000000
Collecting rollouts: 100000/1000000
Collecting rollouts: 110000/1000000
Collecting rollouts: 120000/1000000
Collecting rollouts: 130000/1000000
Collecting rollouts: 140000/1000000
Collecting rollouts: 150000/1000000
Collecting rollouts: 160000/1000000
Collecting rollouts: 170000/1000000
Collecting rollouts: 180000/1000000
Collecting rollouts: 190000/1000000
Collecting rollouts: 200000/1000000
Collecting rollouts: 210000/1000000
Collecting rollouts: 220000/1000000
Collecting rollouts: 230000/1000000
Collecting rollouts: 240000/1000000
Collecting rollouts: 250000/1000000
Collecting rollouts: 260000/1000000
Collecting rollouts: 270000/1000000
Collecting rollouts: 280000/1000000
Collecting rollouts: 290000/1000000
Collecting rollouts: 300000/1000000
Collecting rollouts: 310000/1000000
Collecting rollouts: 320000/1000000
Collecting rollouts: 330000/1000000
Collecting rollouts: 340000/1000000
Collecting rollouts: 350000/1000000
Collecting rollouts: 360000/1000000
Collecting rollouts: 370000/1000000
Collecting rollouts: 380000/1000000
Collecting rollouts: 390000/1000000
Collecting rollouts: 400000/1000000
Collecting rollouts: 410000/1000000
Collecting rollouts: 420000/1000000
Collecting rollouts: 430000/1000000
Collecting rollouts: 440000/1000000
Collecting rollouts: 450000/1000000
Collecting rollouts: 460000/1000000
Collecting rollouts: 470000/1000000
Collecting rollouts: 480000/1000000
Collecting rollouts: 490000/1000000
Collecting rollouts: 500000/1000000
Collecting rollouts: 510000/1000000
Collecting rollouts: 520000/1000000
Collecting rollouts: 530000/1000000
Collecting rollouts: 540000/1000000
Collecting rollouts: 550000/1000000
Collecting rollouts: 560000/1000000
Collecting rollouts: 570000/1000000
Collecting rollouts: 580000/1000000
Collecting rollouts: 590000/1000000
Collecting rollouts: 600000/1000000
Collecting rollouts: 610000/1000000
Collecting rollouts: 620000/1000000
Collecting rollouts: 630000/1000000
Collecting rollouts: 640000/1000000
Collecting rollouts: 650000/1000000
Collecting rollouts: 660000/1000000
Collecting rollouts: 670000/1000000
Collecting rollouts: 680000/1000000
Collecting rollouts: 690000/1000000
Collecting rollouts: 700000/1000000
Collecting rollouts: 710000/1000000
Collecting rollouts: 720000/1000000
Collecting rollouts: 730000/1000000
Collecting rollouts: 740000/1000000
Collecting rollouts: 750000/1000000
Collecting rollouts: 760000/1000000
Collecting rollouts: 770000/1000000
Collecting rollouts: 780000/1000000
Collecting rollouts: 790000/1000000
Collecting rollouts: 800000/1000000
Collecting rollouts: 810000/1000000
Collecting rollouts: 820000/1000000
Collecting rollouts: 830000/1000000
Collecting rollouts: 840000/1000000
Collecting rollouts: 850000/1000000
Collecting rollouts: 860000/1000000
Collecting rollouts: 870000/1000000
Collecting rollouts: 880000/1000000
Collecting rollouts: 890000/1000000
Collecting rollouts: 900000/1000000
Collecting rollouts: 910000/1000000
Collecting rollouts: 920000/1000000
Collecting rollouts: 930000/1000000
Collecting rollouts: 940000/1000000
Collecting rollouts: 950000/1000000
Collecting rollouts: 960000/1000000
Collecting rollouts: 970000/1000000
Collecting rollouts: 980000/1000000
Collecting rollouts: 990000/1000000
Collecting rollouts: 1000000/1000000
Replay buffer size:  (1000000, 105)
Replay buffer saved
---------------------------------
Searching empty space policies
(10, 11472)
(20, 11472)
(20, 11472)
Average distance of agents to nearest neighbors: 0.018504879093138336
Starting 1000 evaluations
avg return on 3 trajectories of agent0: 1386.7705196166246
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 23:16.35[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 23:16.35[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 23:16.36[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 23:16.36[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 23:16.36[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514231636[0m
[2m2025-05-14 23:16.36[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 23:16.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514231636: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001807513475418091, 'time_algorithm_update': 0.0034636526107788084, 'loss': 1.8212859500199556, 'time_step': 0.005317065954208374, 'init_value': 4.6209869384765625}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 23:17.10[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514231636: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017964508533477783, 'time_algorithm_update': 0.0034103033542633057, 'loss': 2.3517145439982414, 'time_step': 0.005252087831497192, 'init_value': 11.292245864868164}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 23:17.28[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514231636: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018518192768096923, 'time_algorithm_update': 0.003503141403198242, 'loss': 2.1877788563370704, 'time_step': 0.005401854991912842, 'init_value': 18.23476219177246}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 23:17.45[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514231636: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001836874008178711, 'time_algorithm_update': 0.00353096866607666, 'loss': 2.138612860739231, 'time_step': 0.00541487717628479, 'init_value': 24.40237045288086}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 23:18.02[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514231636: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001821969509124756, 'time_algorithm_update': 0.003434725046157837, 'loss': 2.082315077483654, 'time_step': 0.005302219867706299, 'init_value': 28.93789291381836}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 23:18.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514231636: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018415830135345458, 'time_algorithm_update': 0.0035922195911407473, 'loss': 1.9821064721941948, 'time_step': 0.005480352401733398, 'init_value': 32.41147994995117}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 23:18.37[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514231636: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018822057247161864, 'time_algorithm_update': 0.003591398477554321, 'loss': 1.9175522601008415, 'time_step': 0.005521827697753906, 'init_value': 35.509056091308594}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 23:18.54[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514231636: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018282434940338134, 'time_algorithm_update': 0.003520794630050659, 'loss': 1.7648147180080413, 'time_step': 0.005395525693893432, 'init_value': 37.163326263427734}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 23:19.12[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514231636: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001835416555404663, 'time_algorithm_update': 0.0034926257133483887, 'loss': 1.7005052726864816, 'time_step': 0.005373971223831177, 'init_value': 39.432273864746094}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 23:19.29[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514231636: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018462183475494384, 'time_algorithm_update': 0.00355476188659668, 'loss': 1.7640748832225799, 'time_step': 0.00544820499420166, 'init_value': 42.030548095703125}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.030548095703125
Starting 1000 evaluations
avg return on 3 trajectories of agent1: 1401.0442833925813
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 23:33.25[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 23:33.25[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 23:33.26[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 23:33.26[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 23:33.26[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514233326[0m
[2m2025-05-14 23:33.26[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 23:33.43[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514233326: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017748444080352783, 'time_algorithm_update': 0.0033622748851776124, 'loss': 1.5113273742720486, 'time_step': 0.0051822690963745114, 'init_value': 4.1355462074279785}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 23:34.00[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514233326: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017964630126953126, 'time_algorithm_update': 0.0034172022342681884, 'loss': 2.568921246290207, 'time_step': 0.005259587287902832, 'init_value': 11.140192031860352}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 23:34.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514233326: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018607473373413086, 'time_algorithm_update': 0.0035381641387939454, 'loss': 2.6347758575677873, 'time_step': 0.00544630241394043, 'init_value': 18.74359893798828}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 23:34.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514233326: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001832054376602173, 'time_algorithm_update': 0.0035631632804870605, 'loss': 2.144065339684486, 'time_step': 0.005442961931228638, 'init_value': 25.00940704345703}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 23:34.51[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514233326: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018043878078460693, 'time_algorithm_update': 0.003502492666244507, 'loss': 2.0862107028365133, 'time_step': 0.005353695631027221, 'init_value': 28.940187454223633}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 23:35.09[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514233326: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018080132007598877, 'time_algorithm_update': 0.0034995315074920655, 'loss': 1.9522532970309256, 'time_step': 0.005354032039642334, 'init_value': 31.9652099609375}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 23:35.26[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514233326: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018722424507141113, 'time_algorithm_update': 0.003589085102081299, 'loss': 1.8800744454264642, 'time_step': 0.005509777069091797, 'init_value': 34.930389404296875}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 23:35.43[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514233326: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001860673427581787, 'time_algorithm_update': 0.0036536881923675537, 'loss': 1.9750729250311851, 'time_step': 0.0055627250671386715, 'init_value': 36.980709075927734}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 23:36.01[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514233326: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018509864807128907, 'time_algorithm_update': 0.0035115671157836914, 'loss': 1.8709984622597695, 'time_step': 0.005408950328826904, 'init_value': 38.31666564941406}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 23:36.18[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514233326: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018195290565490724, 'time_algorithm_update': 0.0035285990238189697, 'loss': 1.735830301463604, 'time_step': 0.005394736051559448, 'init_value': 40.07630157470703}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.07630157470703
Starting 1000 evaluations
avg return on 3 trajectories of agent2: 1380.8961484009756
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-14 23:50.14[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-14 23:50.14[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-14 23:50.16[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-14 23:50.16[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-14 23:50.16[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250514235016[0m
[2m2025-05-14 23:50.16[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-14 23:50.33[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514235016: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018112103939056396, 'time_algorithm_update': 0.0034479677677154543, 'loss': 1.7012544601783157, 'time_step': 0.005305477619171143, 'init_value': 4.4763264656066895}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-14 23:50.50[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514235016: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018705601692199708, 'time_algorithm_update': 0.0036395885944366453, 'loss': 2.398471407234669, 'time_step': 0.005558515310287475, 'init_value': 11.179058074951172}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-14 23:51.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514235016: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001910118818283081, 'time_algorithm_update': 0.003609067678451538, 'loss': 2.3702294533252717, 'time_step': 0.005567683219909668, 'init_value': 18.833271026611328}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-14 23:51.24[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514235016: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001820772647857666, 'time_algorithm_update': 0.0035022890567779543, 'loss': 2.2687213252782823, 'time_step': 0.00536967921257019, 'init_value': 25.752599716186523}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-14 23:51.41[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514235016: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001813368797302246, 'time_algorithm_update': 0.0033679230213165285, 'loss': 2.1086411081552505, 'time_step': 0.005227178812026978, 'init_value': 30.182693481445312}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-14 23:51.59[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514235016: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017973005771636963, 'time_algorithm_update': 0.003375838041305542, 'loss': 1.8900964159369469, 'time_step': 0.0052198684215545655, 'init_value': 33.15384292602539}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-14 23:52.16[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514235016: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018767094612121582, 'time_algorithm_update': 0.003504114627838135, 'loss': 1.9082375806570053, 'time_step': 0.005428739547729492, 'init_value': 35.39448928833008}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-14 23:52.33[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514235016: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018244609832763672, 'time_algorithm_update': 0.003503039598464966, 'loss': 1.8990951061844825, 'time_step': 0.005373994588851929, 'init_value': 38.659114837646484}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-14 23:52.50[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514235016: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018493614196777343, 'time_algorithm_update': 0.003510092258453369, 'loss': 1.80621194845438, 'time_step': 0.005405907869338989, 'init_value': 40.53910446166992}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-14 23:53.08[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250514235016: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018208866119384765, 'time_algorithm_update': 0.003478349685668945, 'loss': 1.7177118596434593, 'time_step': 0.005345415830612182, 'init_value': 42.99396896362305}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.99396896362305
Starting 1000 evaluations
avg return on 3 trajectories of agent3: 1346.0512902489338
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 00:07.02[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 00:07.02[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 00:07.04[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 00:07.04[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 00:07.04[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515000704[0m
[2m2025-05-15 00:07.04[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 00:07.21[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515000704: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017697193622589111, 'time_algorithm_update': 0.0033701789379119874, 'loss': 1.6195945887118577, 'time_step': 0.00518497371673584, 'init_value': 4.268340587615967}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 00:07.38[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515000704: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018452646732330321, 'time_algorithm_update': 0.0034851083755493163, 'loss': 2.485819972336292, 'time_step': 0.005377775430679322, 'init_value': 11.813061714172363}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 00:07.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515000704: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001804241418838501, 'time_algorithm_update': 0.003478235721588135, 'loss': 2.30030946624279, 'time_step': 0.00532916808128357, 'init_value': 20.700448989868164}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 00:08.12[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515000704: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018491318225860595, 'time_algorithm_update': 0.003500248670578003, 'loss': 2.178634083390236, 'time_step': 0.00539611005783081, 'init_value': 26.122608184814453}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 00:08.30[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515000704: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018330795764923097, 'time_algorithm_update': 0.0036050088405609132, 'loss': 2.0119960328936575, 'time_step': 0.00548559045791626, 'init_value': 30.12181282043457}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 00:08.47[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515000704: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018693091869354248, 'time_algorithm_update': 0.0036170132160186766, 'loss': 1.7907593791484833, 'time_step': 0.0055352520942687986, 'init_value': 34.07279586791992}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 00:09.04[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515000704: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018177471160888672, 'time_algorithm_update': 0.0035211634635925293, 'loss': 1.7990423527359962, 'time_step': 0.005385698318481446, 'init_value': 35.47916793823242}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 00:09.22[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515000704: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018231234550476075, 'time_algorithm_update': 0.0034874160289764403, 'loss': 1.8117534529566766, 'time_step': 0.005357215404510498, 'init_value': 36.9857292175293}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 00:09.39[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515000704: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018134396076202393, 'time_algorithm_update': 0.0035264177322387696, 'loss': 1.8761860808730126, 'time_step': 0.005386669397354126, 'init_value': 39.91034698486328}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 00:09.56[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515000704: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001874880075454712, 'time_algorithm_update': 0.0037017154693603518, 'loss': 1.7579546205997467, 'time_step': 0.005626429080963135, 'init_value': 41.74357223510742}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.74357223510742
Starting 1000 evaluations
avg return on 3 trajectories of agent4: 1391.9043320933147
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 00:23.48[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 00:23.48[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 00:23.50[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 00:23.50[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 00:23.50[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515002350[0m
[2m2025-05-15 00:23.50[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 00:24.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515002350: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001772972583770752, 'time_algorithm_update': 0.00335637903213501, 'loss': 1.945180445589125, 'time_step': 0.0051737198829650876, 'init_value': 4.309134006500244}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 00:24.24[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515002350: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001875971555709839, 'time_algorithm_update': 0.003605582237243652, 'loss': 2.3374781478643416, 'time_step': 0.00553010892868042, 'init_value': 10.63967514038086}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 00:24.41[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515002350: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018356268405914306, 'time_algorithm_update': 0.003534632444381714, 'loss': 2.452216270625591, 'time_step': 0.0054171872138977055, 'init_value': 19.04441261291504}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 00:24.58[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515002350: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017937521934509278, 'time_algorithm_update': 0.003448195934295654, 'loss': 2.2390472809076307, 'time_step': 0.005288018703460694, 'init_value': 23.807804107666016}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 00:25.16[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515002350: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018077013492584228, 'time_algorithm_update': 0.003455230474472046, 'loss': 2.0791055139899255, 'time_step': 0.005308797121047973, 'init_value': 28.147794723510742}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 00:25.33[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515002350: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018621435165405273, 'time_algorithm_update': 0.003595923185348511, 'loss': 1.947670850753784, 'time_step': 0.005506588459014893, 'init_value': 32.25189208984375}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 00:25.50[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515002350: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018408904075622558, 'time_algorithm_update': 0.0034753754138946535, 'loss': 1.8699325335621835, 'time_step': 0.005362318277359009, 'init_value': 35.2841911315918}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 00:26.08[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515002350: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001834679126739502, 'time_algorithm_update': 0.0035740914344787596, 'loss': 1.7476008757948875, 'time_step': 0.0054557411670684815, 'init_value': 37.5719108581543}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 00:26.25[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515002350: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018222863674163818, 'time_algorithm_update': 0.0034962430000305177, 'loss': 1.7457437283992767, 'time_step': 0.005365305662155152, 'init_value': 40.10688018798828}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 00:26.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515002350: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001864733934402466, 'time_algorithm_update': 0.003587552785873413, 'loss': 1.7329113830924034, 'time_step': 0.005500603437423706, 'init_value': 41.45967102050781}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.45967102050781
Starting 1000 evaluations
avg return on 3 trajectories of agent5: 1407.8939510970902
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 00:40.34[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 00:40.34[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 00:40.36[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 00:40.36[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 00:40.36[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515004036[0m
[2m2025-05-15 00:40.36[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 00:40.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515004036: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018558638095855712, 'time_algorithm_update': 0.0035635762214660644, 'loss': 1.862676944464445, 'time_step': 0.005467175960540771, 'init_value': 4.445830821990967}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 00:41.10[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515004036: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018604590892791748, 'time_algorithm_update': 0.003618471145629883, 'loss': 2.364339069187641, 'time_step': 0.005526439666748047, 'init_value': 10.757349014282227}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 00:41.27[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515004036: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018343989849090576, 'time_algorithm_update': 0.0034489800930023193, 'loss': 2.4686065287590027, 'time_step': 0.005328786611557007, 'init_value': 18.872955322265625}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 00:41.45[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515004036: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001800044298171997, 'time_algorithm_update': 0.003465810775756836, 'loss': 2.1387279859781265, 'time_step': 0.005311668634414673, 'init_value': 25.116336822509766}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 00:42.02[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515004036: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018530519008636474, 'time_algorithm_update': 0.0035932414531707766, 'loss': 1.9344274173378944, 'time_step': 0.005494385480880737, 'init_value': 29.395183563232422}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 00:42.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515004036: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018070588111877442, 'time_algorithm_update': 0.0034783883094787597, 'loss': 1.8557316974401474, 'time_step': 0.005333125829696655, 'init_value': 32.85547637939453}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 00:42.37[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515004036: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001838592529296875, 'time_algorithm_update': 0.003503671407699585, 'loss': 1.8340103564858437, 'time_step': 0.0053881614208221434, 'init_value': 36.185791015625}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 00:42.54[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515004036: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001817087173461914, 'time_algorithm_update': 0.003495969772338867, 'loss': 1.8801790049672127, 'time_step': 0.005358936548233032, 'init_value': 38.28862762451172}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 00:43.12[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515004036: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001894498586654663, 'time_algorithm_update': 0.003617257833480835, 'loss': 1.7176865046024323, 'time_step': 0.005560404539108276, 'init_value': 39.806026458740234}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 00:43.29[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515004036: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018133680820465088, 'time_algorithm_update': 0.0034846718311309813, 'loss': 1.6293179446458816, 'time_step': 0.005344106197357178, 'init_value': 41.14023971557617}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.14023971557617
Starting 1000 evaluations
avg return on 3 trajectories of agent6: 1410.4561487051562
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 00:57.20[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 00:57.20[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 00:57.21[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 00:57.21[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 00:57.21[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515005721[0m
[2m2025-05-15 00:57.21[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 00:57.38[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515005721: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018086376190185546, 'time_algorithm_update': 0.003436060905456543, 'loss': 1.5872803165391087, 'time_step': 0.005291652917861938, 'init_value': 4.395974636077881}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 00:57.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515005721: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017806103229522706, 'time_algorithm_update': 0.0033819022178649904, 'loss': 2.341509321987629, 'time_step': 0.005207681894302368, 'init_value': 11.077125549316406}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 00:58.12[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515005721: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017868802547454834, 'time_algorithm_update': 0.003426213264465332, 'loss': 2.269570891857147, 'time_step': 0.005258144855499268, 'init_value': 18.917461395263672}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 00:58.29[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515005721: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017847130298614502, 'time_algorithm_update': 0.003423232316970825, 'loss': 2.2160960087180137, 'time_step': 0.005253666639328003, 'init_value': 26.316436767578125}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 00:58.47[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515005721: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001877434253692627, 'time_algorithm_update': 0.0035378491878509523, 'loss': 2.1003045883178713, 'time_step': 0.005463701725006103, 'init_value': 30.411182403564453}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 00:59.04[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515005721: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017838740348815917, 'time_algorithm_update': 0.0034268131256103515, 'loss': 1.9181949033141137, 'time_step': 0.0052565929889678955, 'init_value': 34.22931671142578}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 00:59.21[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515005721: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018187541961669923, 'time_algorithm_update': 0.0034401686191558836, 'loss': 1.8943379136323928, 'time_step': 0.005304992437362671, 'init_value': 36.24103927612305}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 00:59.39[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515005721: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018005237579345704, 'time_algorithm_update': 0.0034534151554107668, 'loss': 1.7922973163723945, 'time_step': 0.005301257848739624, 'init_value': 37.26449966430664}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 00:59.56[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515005721: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001879056453704834, 'time_algorithm_update': 0.003588767051696777, 'loss': 1.6160621590018271, 'time_step': 0.005517105102539063, 'init_value': 39.58763885498047}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 01:00.13[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515005721: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001849494218826294, 'time_algorithm_update': 0.003630143404006958, 'loss': 1.6531275210380554, 'time_step': 0.005527697324752808, 'init_value': 40.85618591308594}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.85618591308594
Starting 1000 evaluations
avg return on 3 trajectories of agent7: 1419.7630636595445
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 01:14.05[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 01:14.05[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 01:14.07[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 01:14.07[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 01:14.07[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515011407[0m
[2m2025-05-15 01:14.07[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 01:14.24[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515011407: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018080718517303467, 'time_algorithm_update': 0.0034513356685638426, 'loss': 1.8567989751547576, 'time_step': 0.005306351661682129, 'init_value': 4.096223831176758}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 01:14.41[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515011407: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017695720195770263, 'time_algorithm_update': 0.0033877739906311034, 'loss': 2.331305551826954, 'time_step': 0.005203099489212036, 'init_value': 11.382346153259277}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 01:14.58[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515011407: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018116400241851808, 'time_algorithm_update': 0.003425960063934326, 'loss': 2.385058465242386, 'time_step': 0.005283492565155029, 'init_value': 19.188825607299805}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 01:15.16[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515011407: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018301377296447755, 'time_algorithm_update': 0.0035611701011657713, 'loss': 2.083436871290207, 'time_step': 0.005439059019088745, 'init_value': 25.921131134033203}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 01:15.33[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515011407: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018130450248718263, 'time_algorithm_update': 0.0035005202293395994, 'loss': 1.94837792378664, 'time_step': 0.005359755277633667, 'init_value': 30.187801361083984}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 01:15.50[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515011407: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017907299995422363, 'time_algorithm_update': 0.0034602930545806886, 'loss': 1.9948372251987456, 'time_step': 0.005296836376190186, 'init_value': 33.16690444946289}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 01:16.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515011407: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018064842224121095, 'time_algorithm_update': 0.003484243392944336, 'loss': 1.840839178621769, 'time_step': 0.005336915493011475, 'init_value': 35.94464874267578}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 01:16.25[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515011407: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018542709350585938, 'time_algorithm_update': 0.0036255569458007813, 'loss': 1.7607567964196205, 'time_step': 0.0055286941528320315, 'init_value': 38.70474624633789}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 01:16.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515011407: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001832749843597412, 'time_algorithm_update': 0.00361001181602478, 'loss': 1.7519838541150092, 'time_step': 0.005490947008132935, 'init_value': 40.07566833496094}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 01:16.59[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515011407: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017882721424102783, 'time_algorithm_update': 0.003457014322280884, 'loss': 1.6562851631641389, 'time_step': 0.005291200399398803, 'init_value': 42.013240814208984}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.013240814208984
Starting 1000 evaluations
avg return on 3 trajectories of agent8: 1386.3307506448798
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 01:30.46[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 01:30.46[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 01:30.47[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 01:30.47[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 01:30.47[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515013047[0m
[2m2025-05-15 01:30.47[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 01:31.04[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515013047: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018352773189544678, 'time_algorithm_update': 0.0035024209022521974, 'loss': 1.7000180391669273, 'time_step': 0.005385332584381104, 'init_value': 4.2706522941589355}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 01:31.21[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515013047: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001786637544631958, 'time_algorithm_update': 0.0033932037353515626, 'loss': 2.2668505762815476, 'time_step': 0.0052252197265625, 'init_value': 10.845878601074219}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 01:31.39[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515013047: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018416423797607423, 'time_algorithm_update': 0.0034605872631072996, 'loss': 2.2623821315765382, 'time_step': 0.005348135709762573, 'init_value': 18.817886352539062}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 01:31.56[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515013047: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017989833354949952, 'time_algorithm_update': 0.0034615886211395263, 'loss': 2.220050272345543, 'time_step': 0.005306329011917114, 'init_value': 25.161203384399414}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 01:32.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515013047: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018789973258972169, 'time_algorithm_update': 0.0035455489158630372, 'loss': 2.1034057136774065, 'time_step': 0.005471903562545777, 'init_value': 29.799320220947266}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 01:32.31[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515013047: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017807090282440186, 'time_algorithm_update': 0.003421739101409912, 'loss': 1.8734167816638947, 'time_step': 0.00524714994430542, 'init_value': 34.194618225097656}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 01:32.48[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515013047: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018206706047058105, 'time_algorithm_update': 0.003464282274246216, 'loss': 1.784462646305561, 'time_step': 0.005330518245697021, 'init_value': 37.55402755737305}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 01:33.06[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515013047: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019154374599456786, 'time_algorithm_update': 0.003788806200027466, 'loss': 1.8045790703892708, 'time_step': 0.005753422975540161, 'init_value': 39.74641418457031}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 01:33.23[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515013047: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018304061889648437, 'time_algorithm_update': 0.0035008394718170164, 'loss': 1.691528166115284, 'time_step': 0.005377820730209351, 'init_value': 43.112972259521484}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 01:33.40[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515013047: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017971878051757813, 'time_algorithm_update': 0.003449335813522339, 'loss': 1.7529220581650733, 'time_step': 0.005291933298110962, 'init_value': 44.48630142211914}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 44.48630142211914
Starting 1000 evaluations
avg return on 3 trajectories of agent9: 1393.4998395509497
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 01:47.32[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 01:47.32[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 01:47.33[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 01:47.33[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 01:47.33[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515014733[0m
[2m2025-05-15 01:47.33[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 01:47.50[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515014733: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001851640224456787, 'time_algorithm_update': 0.003570047616958618, 'loss': 1.7735037292316556, 'time_step': 0.005469836711883545, 'init_value': 4.2389726638793945}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 01:48.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515014733: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017650463581085204, 'time_algorithm_update': 0.003312072515487671, 'loss': 2.2269559994339945, 'time_step': 0.005121071100234986, 'init_value': 10.888164520263672}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 01:48.24[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515014733: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018184289932250976, 'time_algorithm_update': 0.003380403995513916, 'loss': 2.275885097503662, 'time_step': 0.005245725393295288, 'init_value': 18.236373901367188}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 01:48.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515014733: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017997817993164063, 'time_algorithm_update': 0.003369028568267822, 'loss': 2.1379593113064765, 'time_step': 0.005215256929397583, 'init_value': 24.463459014892578}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 01:48.59[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515014733: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018874716758728028, 'time_algorithm_update': 0.003542588949203491, 'loss': 2.0102527039051057, 'time_step': 0.005478211879730225, 'init_value': 29.70360565185547}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 01:49.16[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515014733: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018232240676879883, 'time_algorithm_update': 0.003514068365097046, 'loss': 1.7936294789910316, 'time_step': 0.005385050773620606, 'init_value': 33.620948791503906}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 01:49.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515014733: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018368852138519287, 'time_algorithm_update': 0.00343847131729126, 'loss': 1.8011349611282348, 'time_step': 0.005321344137191772, 'init_value': 35.8569221496582}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 01:49.51[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515014733: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018063864707946777, 'time_algorithm_update': 0.0034534938335418703, 'loss': 1.668819883286953, 'time_step': 0.005306185007095337, 'init_value': 37.746883392333984}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 01:50.08[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515014733: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018577282428741456, 'time_algorithm_update': 0.0035644314289093016, 'loss': 1.6840036458969116, 'time_step': 0.0054708864688873295, 'init_value': 39.1429443359375}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 01:50.25[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515014733: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017985529899597168, 'time_algorithm_update': 0.0034354407787322997, 'loss': 1.726525781273842, 'time_step': 0.005279804468154907, 'init_value': 41.28645706176758}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.28645706176758
Starting 1000 evaluations
avg return on 3 trajectories of agent10: 1395.9930466735
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 02:04.15[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 02:04.15[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 02:04.16[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 02:04.16[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 02:04.16[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515020416[0m
[2m2025-05-15 02:04.16[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 02:04.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515020416: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017852673530578613, 'time_algorithm_update': 0.003419691562652588, 'loss': 1.5727653865292668, 'time_step': 0.005250373363494873, 'init_value': 4.652436256408691}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 02:04.51[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515020416: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018442037105560302, 'time_algorithm_update': 0.0035383036136627196, 'loss': 2.6398171527981757, 'time_step': 0.005430606842041016, 'init_value': 11.389145851135254}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 02:05.08[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515020416: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017926595211029052, 'time_algorithm_update': 0.0034553606510162355, 'loss': 2.3299229691028596, 'time_step': 0.005294316291809082, 'init_value': 18.954668045043945}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 02:05.25[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515020416: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017929277420043945, 'time_algorithm_update': 0.0034472668170928956, 'loss': 2.187985623598099, 'time_step': 0.005286123514175415, 'init_value': 25.495277404785156}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 02:05.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515020416: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018429801464080811, 'time_algorithm_update': 0.003493849515914917, 'loss': 2.0621510775089265, 'time_step': 0.005383875370025635, 'init_value': 29.856609344482422}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 02:05.59[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515020416: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018329458236694335, 'time_algorithm_update': 0.003538024187088013, 'loss': 1.7961354630589486, 'time_step': 0.005419276475906372, 'init_value': 33.035911560058594}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 02:06.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515020416: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018336246013641358, 'time_algorithm_update': 0.0034800460338592527, 'loss': 1.80254327750206, 'time_step': 0.005359461545944214, 'init_value': 35.74209213256836}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 02:06.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515020416: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017809970378875732, 'time_algorithm_update': 0.003419675350189209, 'loss': 1.7792954710125923, 'time_step': 0.005246253252029419, 'init_value': 38.20735168457031}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 02:06.51[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515020416: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018867230415344238, 'time_algorithm_update': 0.0036008985042572023, 'loss': 1.7109628253579139, 'time_step': 0.0055357439517974855, 'init_value': 40.22750473022461}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 02:07.08[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515020416: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018020110130310058, 'time_algorithm_update': 0.0034695889949798585, 'loss': 1.7375036412477494, 'time_step': 0.005318221807479859, 'init_value': 42.05540466308594}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.05540466308594
Starting 1000 evaluations
avg return on 3 trajectories of agent11: 1401.3916148918115
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 02:21.02[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 02:21.02[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 02:21.03[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 02:21.03[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 02:21.03[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515022103[0m
[2m2025-05-15 02:21.03[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 02:21.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515022103: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001830420732498169, 'time_algorithm_update': 0.0035157315731048585, 'loss': 1.573426318757236, 'time_step': 0.005393851518630982, 'init_value': 4.449192047119141}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 02:21.37[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515022103: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018327763080596923, 'time_algorithm_update': 0.003447224855422974, 'loss': 2.427048019230366, 'time_step': 0.0053256328105926514, 'init_value': 10.7913179397583}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 02:21.54[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515022103: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001852532148361206, 'time_algorithm_update': 0.0035872204303741455, 'loss': 2.2910719506144526, 'time_step': 0.005487718343734741, 'init_value': 18.73569679260254}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 02:22.12[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515022103: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018388092517852782, 'time_algorithm_update': 0.003522902250289917, 'loss': 2.0900746828913688, 'time_step': 0.005407989501953125, 'init_value': 25.510385513305664}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 02:22.29[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515022103: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018523037433624268, 'time_algorithm_update': 0.003601242780685425, 'loss': 2.193805543065071, 'time_step': 0.0055019426345825195, 'init_value': 30.570146560668945}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 02:22.46[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515022103: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018255841732025147, 'time_algorithm_update': 0.0035080246925354003, 'loss': 1.9899746896028518, 'time_step': 0.005380098342895508, 'init_value': 34.4664192199707}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 02:23.03[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515022103: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001810774564743042, 'time_algorithm_update': 0.003507126569747925, 'loss': 1.8260475872159003, 'time_step': 0.005364422798156738, 'init_value': 36.80852508544922}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 02:23.21[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515022103: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018130631446838378, 'time_algorithm_update': 0.0035430305004119874, 'loss': 1.7407890270352364, 'time_step': 0.0054029769897460935, 'init_value': 38.60124588012695}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 02:23.38[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515022103: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018552334308624267, 'time_algorithm_update': 0.0036076138019561768, 'loss': 1.6622973546385764, 'time_step': 0.005511516809463501, 'init_value': 40.13852310180664}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 02:23.56[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515022103: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001818777084350586, 'time_algorithm_update': 0.0035277299880981444, 'loss': 1.792710998415947, 'time_step': 0.005392988681793213, 'init_value': 42.54964065551758}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.54964065551758
Starting 1000 evaluations
avg return on 3 trajectories of agent12: 1385.1493213334497
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 02:38.26[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 02:38.26[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 02:38.27[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 02:38.27[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 02:38.27[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515023827[0m
[2m2025-05-15 02:38.27[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 02:38.47[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515023827: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021084442138671875, 'time_algorithm_update': 0.004507858514785767, 'loss': 1.7052137619256973, 'time_step': 0.006671672344207764, 'init_value': 4.191091537475586}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 02:39.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515023827: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021507742404937745, 'time_algorithm_update': 0.0045267436504364015, 'loss': 2.360404074847698, 'time_step': 0.0067338342666625976, 'init_value': 11.033453941345215}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 02:39.27[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515023827: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021474711894989016, 'time_algorithm_update': 0.004550214052200317, 'loss': 2.393623006284237, 'time_step': 0.006753313779830933, 'init_value': 17.9290771484375}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 02:39.47[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515023827: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002147998332977295, 'time_algorithm_update': 0.004604023694992065, 'loss': 2.1639874200224876, 'time_step': 0.006809089183807373, 'init_value': 25.600351333618164}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 02:40.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515023827: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021516740322113036, 'time_algorithm_update': 0.004582356452941894, 'loss': 2.097533111810684, 'time_step': 0.00678934907913208, 'init_value': 30.257732391357422}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 02:40.27[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515023827: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021843328475952147, 'time_algorithm_update': 0.004563766002655029, 'loss': 1.9253657724261284, 'time_step': 0.0068041694164276125, 'init_value': 33.91170883178711}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 02:40.47[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515023827: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021302001476287843, 'time_algorithm_update': 0.004514107704162598, 'loss': 1.8657725845575333, 'time_step': 0.00669961142539978, 'init_value': 36.913516998291016}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 02:41.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515023827: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022217748165130617, 'time_algorithm_update': 0.004690365314483642, 'loss': 1.7843295155763625, 'time_step': 0.00697009801864624, 'init_value': 38.466522216796875}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 02:41.27[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515023827: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021538743972778322, 'time_algorithm_update': 0.004533705234527588, 'loss': 1.635767430126667, 'time_step': 0.0067436697483062745, 'init_value': 40.088844299316406}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 02:41.48[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515023827: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002194424390792847, 'time_algorithm_update': 0.004698756217956543, 'loss': 1.6634852189421654, 'time_step': 0.006950340747833252, 'init_value': 41.865447998046875}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.865447998046875
Starting 1000 evaluations
avg return on 3 trajectories of agent13: 1384.840893947427
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 02:57.21[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 02:57.21[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 02:57.22[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 02:57.22[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 02:57.22[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515025722[0m
[2m2025-05-15 02:57.23[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 02:57.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515025722: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021014487743377685, 'time_algorithm_update': 0.004413957595825195, 'loss': 1.8581292764917017, 'time_step': 0.006568526983261109, 'init_value': 4.175896167755127}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 02:58.02[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515025722: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021838338375091554, 'time_algorithm_update': 0.004573507785797119, 'loss': 2.2990088881254196, 'time_step': 0.006812427997589111, 'init_value': 10.675549507141113}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 02:58.22[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515025722: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021645519733428957, 'time_algorithm_update': 0.004588642120361328, 'loss': 2.4057837226986885, 'time_step': 0.00680823802947998, 'init_value': 18.59844398498535}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 02:58.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515025722: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021746110916137694, 'time_algorithm_update': 0.004503282070159912, 'loss': 2.356906904876232, 'time_step': 0.006733088016510009, 'init_value': 24.900739669799805}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 02:59.02[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515025722: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021226603984832765, 'time_algorithm_update': 0.004537869930267334, 'loss': 2.0159563470482826, 'time_step': 0.006715230226516724, 'init_value': 29.86863136291504}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 02:59.23[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515025722: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002235448360443115, 'time_algorithm_update': 0.004706352949142456, 'loss': 1.885822637617588, 'time_step': 0.006998875617980957, 'init_value': 33.35481643676758}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 02:59.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515025722: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002111044645309448, 'time_algorithm_update': 0.00448224401473999, 'loss': 1.887103032708168, 'time_step': 0.006648322105407715, 'init_value': 36.53226852416992}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 03:00.02[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515025722: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021001114845275877, 'time_algorithm_update': 0.004458146572113037, 'loss': 1.7570437072515488, 'time_step': 0.0066130485534667965, 'init_value': 38.030784606933594}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 03:00.22[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515025722: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021683270931243896, 'time_algorithm_update': 0.004646836757659912, 'loss': 1.8254086825847626, 'time_step': 0.0068710665702819826, 'init_value': 39.23308563232422}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 03:00.43[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515025722: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002265998601913452, 'time_algorithm_update': 0.0048144059181213375, 'loss': 1.6880674271583558, 'time_step': 0.007138144493103027, 'init_value': 41.329715728759766}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.329715728759766
Starting 1000 evaluations
avg return on 3 trajectories of agent14: 1387.091876217256
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 03:17.00[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 03:17.00[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 03:17.01[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 03:17.01[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 03:17.01[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515031701[0m
[2m2025-05-15 03:17.01[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 03:17.22[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515031701: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002259479522705078, 'time_algorithm_update': 0.004960445642471313, 'loss': 1.4515722177252173, 'time_step': 0.007279276132583618, 'init_value': 4.325114727020264}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 03:17.43[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515031701: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022279365062713623, 'time_algorithm_update': 0.004761271476745606, 'loss': 2.4668715794086458, 'time_step': 0.007045707941055298, 'init_value': 11.277677536010742}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 03:18.04[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515031701: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002252460956573486, 'time_algorithm_update': 0.0046846895217895505, 'loss': 2.454364810883999, 'time_step': 0.006992850303649902, 'init_value': 18.888961791992188}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 03:18.25[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515031701: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002245957851409912, 'time_algorithm_update': 0.004698556900024414, 'loss': 2.1142313583493233, 'time_step': 0.007000823974609375, 'init_value': 25.077299118041992}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 03:18.47[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515031701: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022967443466186525, 'time_algorithm_update': 0.005025466680526733, 'loss': 2.0151812174916266, 'time_step': 0.007382791519165039, 'init_value': 29.678020477294922}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 03:19.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515031701: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00226139235496521, 'time_algorithm_update': 0.004687366962432861, 'loss': 1.9474931647777558, 'time_step': 0.00700411581993103, 'init_value': 32.94239044189453}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 03:19.28[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515031701: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022480759620666503, 'time_algorithm_update': 0.004818004608154297, 'loss': 1.8631738872528076, 'time_step': 0.007123531341552735, 'init_value': 35.5323600769043}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 03:19.50[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515031701: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002351186513900757, 'time_algorithm_update': 0.005094600677490234, 'loss': 1.7690764071345328, 'time_step': 0.007506969451904297, 'init_value': 39.28107833862305}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 03:20.11[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515031701: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023061699867248536, 'time_algorithm_update': 0.004963781118392944, 'loss': 1.741578465104103, 'time_step': 0.007329015731811523, 'init_value': 40.48027038574219}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 03:20.32[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515031701: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022400152683258057, 'time_algorithm_update': 0.004637841463088989, 'loss': 1.7665550147294997, 'time_step': 0.006932543039321899, 'init_value': 42.43061447143555}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.43061447143555
Starting 1000 evaluations
avg return on 3 trajectories of agent15: 1368.250306672504
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 03:36.54[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 03:36.54[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 03:36.55[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 03:36.55[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 03:36.55[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515033655[0m
[2m2025-05-15 03:36.55[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 03:37.16[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515033655: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022180137634277342, 'time_algorithm_update': 0.004682490587234497, 'loss': 1.578933327063918, 'time_step': 0.006956838130950928, 'init_value': 4.7836198806762695}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 03:37.37[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515033655: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002231607675552368, 'time_algorithm_update': 0.004753492832183838, 'loss': 2.4001687318086624, 'time_step': 0.0070431756973266604, 'init_value': 11.813308715820312}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 03:37.58[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515033655: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00223186993598938, 'time_algorithm_update': 0.00471902322769165, 'loss': 2.5670013031959535, 'time_step': 0.007007397890090942, 'init_value': 20.107160568237305}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 03:38.19[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515033655: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00226165246963501, 'time_algorithm_update': 0.004704677820205688, 'loss': 2.1345565994381905, 'time_step': 0.007024614095687866, 'init_value': 26.192142486572266}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 03:38.40[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515033655: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022397656440734863, 'time_algorithm_update': 0.004789837598800659, 'loss': 1.9220462979078292, 'time_step': 0.007117501735687256, 'init_value': 30.025259017944336}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 03:39.01[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515033655: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022983765602111817, 'time_algorithm_update': 0.004827967166900635, 'loss': 1.8364907781481743, 'time_step': 0.007184269905090332, 'init_value': 32.95359802246094}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 03:39.23[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515033655: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002320175647735596, 'time_algorithm_update': 0.00502385663986206, 'loss': 1.6933609114289283, 'time_step': 0.007404365062713623, 'init_value': 35.56747817993164}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 03:39.45[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515033655: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002330098867416382, 'time_algorithm_update': 0.0051203773021698, 'loss': 1.7559731160998344, 'time_step': 0.007511894464492798, 'init_value': 39.2431755065918}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 03:40.05[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515033655: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002258312225341797, 'time_algorithm_update': 0.004818438768386841, 'loss': 1.8101088919043542, 'time_step': 0.007134538173675537, 'init_value': 41.27326583862305}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 03:40.26[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515033655: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002183819770812988, 'time_algorithm_update': 0.004504633665084839, 'loss': 1.7674290404319764, 'time_step': 0.006753772735595703, 'init_value': 41.99547576904297}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.99547576904297
Starting 1000 evaluations
avg return on 3 trajectories of agent16: 1387.1900738385755
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 03:56.37[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 03:56.37[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 03:56.38[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 03:56.38[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 03:56.38[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515035638[0m
[2m2025-05-15 03:56.38[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 03:56.59[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515035638: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022699246406555178, 'time_algorithm_update': 0.004794354677200317, 'loss': 1.6547639612928033, 'time_step': 0.007121614217758179, 'init_value': 4.280491828918457}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 03:57.21[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515035638: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002262336492538452, 'time_algorithm_update': 0.004816080093383789, 'loss': 2.353302745342255, 'time_step': 0.007136664628982544, 'init_value': 11.673178672790527}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 03:57.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515035638: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023301613330841066, 'time_algorithm_update': 0.004951970815658569, 'loss': 2.5040801463723183, 'time_step': 0.007341542482376099, 'init_value': 19.63193130493164}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 03:58.03[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515035638: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023163056373596193, 'time_algorithm_update': 0.004967849493026733, 'loss': 2.2444471502900125, 'time_step': 0.007343375921249389, 'init_value': 27.025238037109375}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 03:58.24[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515035638: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023147282600402834, 'time_algorithm_update': 0.005070957660675049, 'loss': 2.0245596542358397, 'time_step': 0.007446224451065063, 'init_value': 31.30609893798828}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 03:58.46[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515035638: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002311056613922119, 'time_algorithm_update': 0.004880756616592407, 'loss': 1.903336189031601, 'time_step': 0.007249977827072144, 'init_value': 33.9114990234375}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 03:59.06[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515035638: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021635367870330813, 'time_algorithm_update': 0.004452428579330444, 'loss': 1.7920668580532073, 'time_step': 0.006669202089309692, 'init_value': 35.78707504272461}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 03:59.27[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515035638: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00226493501663208, 'time_algorithm_update': 0.004856122970581055, 'loss': 1.7405101934075355, 'time_step': 0.007179569244384765, 'init_value': 38.45120620727539}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 03:59.48[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515035638: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002275991678237915, 'time_algorithm_update': 0.00487158203125, 'loss': 1.7698602361083031, 'time_step': 0.007205717086791992, 'init_value': 41.08632278442383}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 04:00.09[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515035638: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002305549383163452, 'time_algorithm_update': 0.004815574884414673, 'loss': 1.59516336363554, 'time_step': 0.007178281307220459, 'init_value': 42.5839729309082}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.5839729309082
Starting 1000 evaluations
avg return on 3 trajectories of agent17: 1385.932441939159
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 04:16.29[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 04:16.29[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 04:16.31[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 04:16.31[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 04:16.31[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515041631[0m
[2m2025-05-15 04:16.31[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 04:16.52[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515041631: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022546844482421876, 'time_algorithm_update': 0.004945527553558349, 'loss': 1.7382790425717831, 'time_step': 0.0072595224380493165, 'init_value': 4.239140033721924}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 04:17.13[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515041631: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002216280221939087, 'time_algorithm_update': 0.004654671192169189, 'loss': 2.337890450835228, 'time_step': 0.006927098035812378, 'init_value': 11.082000732421875}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 04:17.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515041631: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022648842334747313, 'time_algorithm_update': 0.004809911966323853, 'loss': 2.4063043258190153, 'time_step': 0.007132136583328247, 'init_value': 18.638195037841797}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 04:17.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515041631: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002296225547790527, 'time_algorithm_update': 0.00491303300857544, 'loss': 2.245755486309528, 'time_step': 0.0072681245803833, 'init_value': 26.92860984802246}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 04:18.16[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515041631: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021783225536346437, 'time_algorithm_update': 0.00449271035194397, 'loss': 2.1871776644587517, 'time_step': 0.006731872081756592, 'init_value': 30.378028869628906}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 04:18.37[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515041631: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022608747482299805, 'time_algorithm_update': 0.004733578681945801, 'loss': 1.9030577235221864, 'time_step': 0.007058686017990113, 'init_value': 33.60602951049805}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 04:18.58[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515041631: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022689480781555174, 'time_algorithm_update': 0.004874686717987061, 'loss': 1.8969794558882713, 'time_step': 0.007202425241470337, 'init_value': 34.86711883544922}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 04:19.19[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515041631: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0023213381767272947, 'time_algorithm_update': 0.0049505548477172855, 'loss': 1.8147167721390725, 'time_step': 0.007331216812133789, 'init_value': 37.569129943847656}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 04:19.40[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515041631: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022337038516998292, 'time_algorithm_update': 0.0047232391834259035, 'loss': 1.7845619419813157, 'time_step': 0.007013802289962769, 'init_value': 38.139015197753906}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 04:20.00[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515041631: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002201546907424927, 'time_algorithm_update': 0.004613665342330933, 'loss': 1.6370591678023338, 'time_step': 0.006870932817459106, 'init_value': 40.8665657043457}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.8665657043457
Starting 1000 evaluations
avg return on 3 trajectories of agent18: 1381.047629446825
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 04:36.22[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 04:36.22[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 04:36.23[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 04:36.23[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 04:36.23[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515043623[0m
[2m2025-05-15 04:36.23[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 04:36.44[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515043623: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002201709747314453, 'time_algorithm_update': 0.004701356410980225, 'loss': 1.7180871843025087, 'time_step': 0.006961442470550537, 'init_value': 4.588759899139404}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 04:37.05[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515043623: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002285125494003296, 'time_algorithm_update': 0.0049970090389251706, 'loss': 2.3846383192539213, 'time_step': 0.007341741561889648, 'init_value': 11.710885047912598}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 04:37.26[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515043623: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021835365295410154, 'time_algorithm_update': 0.004617877244949341, 'loss': 2.233442454576492, 'time_step': 0.006856297016143799, 'init_value': 19.12369728088379}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 04:37.46[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515043623: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002234489440917969, 'time_algorithm_update': 0.004583352327346802, 'loss': 2.1652822350859644, 'time_step': 0.006871927738189698, 'init_value': 25.239744186401367}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 04:38.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515043623: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002264497756958008, 'time_algorithm_update': 0.004925435543060303, 'loss': 1.987187139570713, 'time_step': 0.007248133182525635, 'init_value': 29.205183029174805}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 04:38.29[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515043623: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002341059446334839, 'time_algorithm_update': 0.005054474115371704, 'loss': 1.844668566584587, 'time_step': 0.0074556834697723385, 'init_value': 32.66135787963867}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 04:38.50[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515043623: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022468528747558595, 'time_algorithm_update': 0.004865164041519165, 'loss': 1.7327909219264983, 'time_step': 0.00717934775352478, 'init_value': 34.87214660644531}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 04:39.11[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515043623: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022575478553771974, 'time_algorithm_update': 0.004860790729522705, 'loss': 1.7403639020323753, 'time_step': 0.0071872293949127196, 'init_value': 38.3045768737793}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 04:39.33[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515043623: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002271561861038208, 'time_algorithm_update': 0.004928630590438843, 'loss': 1.856542230963707, 'time_step': 0.007258844137191772, 'init_value': 40.19297409057617}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 04:39.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515043623: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022181704044342042, 'time_algorithm_update': 0.004711815357208252, 'loss': 1.8230203461050987, 'time_step': 0.006985684871673584, 'init_value': 42.205692291259766}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.205692291259766
Starting 1000 evaluations
avg return on 3 trajectories of agent19: 1363.57103049063
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 04:56.14[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 04:56.14[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 04:56.15[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 04:56.15[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 04:56.15[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515045615[0m
[2m2025-05-15 04:56.15[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 04:56.36[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515045615: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002166511297225952, 'time_algorithm_update': 0.004507609367370605, 'loss': 1.7668178755193948, 'time_step': 0.006730756044387817, 'init_value': 4.223224639892578}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 04:56.56[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515045615: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002271996736526489, 'time_algorithm_update': 0.004777386665344239, 'loss': 2.366028914809227, 'time_step': 0.007107342481613159, 'init_value': 10.672402381896973}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 04:57.18[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515045615: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002328991413116455, 'time_algorithm_update': 0.0050846834182739255, 'loss': 2.4525751133561133, 'time_step': 0.007474971294403076, 'init_value': 17.34109115600586}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 04:57.39[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515045615: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00227634596824646, 'time_algorithm_update': 0.004768120288848877, 'loss': 2.103390668272972, 'time_step': 0.007101523160934448, 'init_value': 24.574174880981445}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 04:58.00[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515045615: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022365410327911377, 'time_algorithm_update': 0.004783589839935303, 'loss': 2.112147939860821, 'time_step': 0.007076542854309082, 'init_value': 29.329742431640625}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 04:58.21[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515045615: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022875545024871827, 'time_algorithm_update': 0.005047057628631592, 'loss': 1.9930209961533547, 'time_step': 0.00739467740058899, 'init_value': 33.31775665283203}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 04:58.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515045615: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022510058879852296, 'time_algorithm_update': 0.0048381974697113035, 'loss': 1.818491670012474, 'time_step': 0.007147615194320679, 'init_value': 36.657432556152344}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 04:59.04[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515045615: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022687339782714844, 'time_algorithm_update': 0.004808389186859131, 'loss': 1.7145170097351075, 'time_step': 0.007134358882904052, 'init_value': 38.60578918457031}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 04:59.25[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515045615: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022830564975738527, 'time_algorithm_update': 0.004865795612335205, 'loss': 1.725608995258808, 'time_step': 0.007206373929977417, 'init_value': 40.77233123779297}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 04:59.46[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515045615: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002295262336730957, 'time_algorithm_update': 0.005081388473510742, 'loss': 1.7197575805783272, 'time_step': 0.00743747878074646, 'init_value': 43.12190628051758}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 43.12190628051758
ave advantage rew: 41.95454616546631, std: 0.9388587351323309
avg cum rews: 1388.2534281430594, std: 16.18642065396124
Pearson correlation coefficient: -0.2984905868204564
Spearman correlation coefficient: -0.3323308270676692
Kendall Tau correlation coefficient: -0.24210526315789474
the best agent: 7, best agent cum rewards: 1419.7630636595445
1965
Starting to collect rollouts
Collecting rollouts: 10000/1000000
Collecting rollouts: 20000/1000000
Collecting rollouts: 30000/1000000
Collecting rollouts: 40000/1000000
Collecting rollouts: 50000/1000000
Collecting rollouts: 60000/1000000
Collecting rollouts: 70000/1000000
Collecting rollouts: 80000/1000000
Collecting rollouts: 90000/1000000
Collecting rollouts: 100000/1000000
Collecting rollouts: 110000/1000000
Collecting rollouts: 120000/1000000
Collecting rollouts: 130000/1000000
Collecting rollouts: 140000/1000000
Collecting rollouts: 150000/1000000
Collecting rollouts: 160000/1000000
Collecting rollouts: 170000/1000000
Collecting rollouts: 180000/1000000
Collecting rollouts: 190000/1000000
Collecting rollouts: 200000/1000000
Collecting rollouts: 210000/1000000
Collecting rollouts: 220000/1000000
Collecting rollouts: 230000/1000000
Collecting rollouts: 240000/1000000
Collecting rollouts: 250000/1000000
Collecting rollouts: 260000/1000000
Collecting rollouts: 270000/1000000
Collecting rollouts: 280000/1000000
Collecting rollouts: 290000/1000000
Collecting rollouts: 300000/1000000
Collecting rollouts: 310000/1000000
Collecting rollouts: 320000/1000000
Collecting rollouts: 330000/1000000
Collecting rollouts: 340000/1000000
Collecting rollouts: 350000/1000000
Collecting rollouts: 360000/1000000
Collecting rollouts: 370000/1000000
Collecting rollouts: 380000/1000000
Collecting rollouts: 390000/1000000
Collecting rollouts: 400000/1000000
Collecting rollouts: 410000/1000000
Collecting rollouts: 420000/1000000
Collecting rollouts: 430000/1000000
Collecting rollouts: 440000/1000000
Collecting rollouts: 450000/1000000
Collecting rollouts: 460000/1000000
Collecting rollouts: 470000/1000000
Collecting rollouts: 480000/1000000
Collecting rollouts: 490000/1000000
Collecting rollouts: 500000/1000000
Collecting rollouts: 510000/1000000
Collecting rollouts: 520000/1000000
Collecting rollouts: 530000/1000000
Collecting rollouts: 540000/1000000
Collecting rollouts: 550000/1000000
Collecting rollouts: 560000/1000000
Collecting rollouts: 570000/1000000
Collecting rollouts: 580000/1000000
Collecting rollouts: 590000/1000000
Collecting rollouts: 600000/1000000
Collecting rollouts: 610000/1000000
Collecting rollouts: 620000/1000000
Collecting rollouts: 630000/1000000
Collecting rollouts: 640000/1000000
Collecting rollouts: 650000/1000000
Collecting rollouts: 660000/1000000
Collecting rollouts: 670000/1000000
Collecting rollouts: 680000/1000000
Collecting rollouts: 690000/1000000
Collecting rollouts: 700000/1000000
Collecting rollouts: 710000/1000000
Collecting rollouts: 720000/1000000
Collecting rollouts: 730000/1000000
Collecting rollouts: 740000/1000000
Collecting rollouts: 750000/1000000
Collecting rollouts: 760000/1000000
Collecting rollouts: 770000/1000000
Collecting rollouts: 780000/1000000
Collecting rollouts: 790000/1000000
Collecting rollouts: 800000/1000000
Collecting rollouts: 810000/1000000
Collecting rollouts: 820000/1000000
Collecting rollouts: 830000/1000000
Collecting rollouts: 840000/1000000
Collecting rollouts: 850000/1000000
Collecting rollouts: 860000/1000000
Collecting rollouts: 870000/1000000
Collecting rollouts: 880000/1000000
Collecting rollouts: 890000/1000000
Collecting rollouts: 900000/1000000
Collecting rollouts: 910000/1000000
Collecting rollouts: 920000/1000000
Collecting rollouts: 930000/1000000
Collecting rollouts: 940000/1000000
Collecting rollouts: 950000/1000000
Collecting rollouts: 960000/1000000
Collecting rollouts: 970000/1000000
Collecting rollouts: 980000/1000000
Collecting rollouts: 990000/1000000
Collecting rollouts: 1000000/1000000
Replay buffer size:  (1000000, 105)
Replay buffer saved
---------------------------------
Searching empty space policies
(10, 11472)
(20, 11472)
(20, 11472)
Average distance of agents to nearest neighbors: 0.018843058344455713
Starting 1000 evaluations
avg return on 3 trajectories of agent0: 1400.0790077226552
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 05:35.28[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 05:35.28[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 05:35.29[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 05:35.29[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 05:35.29[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515053529[0m
[2m2025-05-15 05:35.30[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 05:35.51[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515053529: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022540528774261477, 'time_algorithm_update': 0.004747588634490967, 'loss': 1.63360908126086, 'time_step': 0.007058624982833862, 'init_value': 4.3856120109558105}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 05:36.12[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515053529: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022546720504760744, 'time_algorithm_update': 0.004794739246368408, 'loss': 2.398840097606182, 'time_step': 0.007107189655303955, 'init_value': 11.158246994018555}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 05:36.32[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515053529: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002298779010772705, 'time_algorithm_update': 0.004981178998947144, 'loss': 2.3754478943943975, 'time_step': 0.007340013742446899, 'init_value': 18.455442428588867}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 05:36.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515053529: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022449080944061278, 'time_algorithm_update': 0.004709214448928833, 'loss': 2.2286437460184096, 'time_step': 0.007042039155960083, 'init_value': 24.009296417236328}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 05:37.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515053529: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022318139076232912, 'time_algorithm_update': 0.004680229187011719, 'loss': 2.085428053855896, 'time_step': 0.006967765808105469, 'init_value': 29.299964904785156}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 05:37.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515053529: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002372800350189209, 'time_algorithm_update': 0.0050985260009765625, 'loss': 1.8179984107017517, 'time_step': 0.007532686471939087, 'init_value': 32.9230842590332}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 05:37.57[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515053529: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022972700595855714, 'time_algorithm_update': 0.004951220989227295, 'loss': 1.8014878715872764, 'time_step': 0.007308026313781738, 'init_value': 34.62472152709961}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 05:38.18[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515053529: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022865662574768067, 'time_algorithm_update': 0.004704262971878052, 'loss': 1.6775654172897339, 'time_step': 0.007047743797302246, 'init_value': 37.40166091918945}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 05:38.39[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515053529: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002276561737060547, 'time_algorithm_update': 0.004853396654129028, 'loss': 1.7117866285443306, 'time_step': 0.007201319456100464, 'init_value': 38.71432876586914}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 05:39.00[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515053529: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002263751983642578, 'time_algorithm_update': 0.0048383033275604245, 'loss': 1.6169582759141923, 'time_step': 0.00715986704826355, 'init_value': 40.80153274536133}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.80153274536133
Starting 1000 evaluations
avg return on 3 trajectories of agent1: 1399.263284688169
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 05:55.16[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 05:55.16[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 05:55.17[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 05:55.17[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 05:55.17[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515055517[0m
[2m2025-05-15 05:55.17[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 05:55.38[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515055517: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002179784297943115, 'time_algorithm_update': 0.004609280347824097, 'loss': 1.752609386600554, 'time_step': 0.00684504771232605, 'init_value': 4.042059898376465}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 05:55.59[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515055517: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002278578996658325, 'time_algorithm_update': 0.00497344970703125, 'loss': 2.4211249309182166, 'time_step': 0.007312078714370727, 'init_value': 10.716736793518066}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 05:56.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515055517: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002225165605545044, 'time_algorithm_update': 0.004795075654983521, 'loss': 2.3346699595451357, 'time_step': 0.0070781991481781, 'init_value': 18.18012046813965}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 05:56.41[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515055517: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00223958683013916, 'time_algorithm_update': 0.0047839701175689696, 'loss': 2.2618962063789367, 'time_step': 0.007081245422363281, 'init_value': 24.913169860839844}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 05:57.02[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515055517: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022380602359771727, 'time_algorithm_update': 0.0047454826831817625, 'loss': 2.0350343616604807, 'time_step': 0.007040186643600464, 'init_value': 29.074962615966797}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 05:57.23[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515055517: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002202341079711914, 'time_algorithm_update': 0.004619219541549683, 'loss': 1.8362570605278015, 'time_step': 0.006879134178161621, 'init_value': 32.68696212768555}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 05:57.43[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515055517: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021890459060668944, 'time_algorithm_update': 0.004632740497589111, 'loss': 1.882846476793289, 'time_step': 0.0068773188591003415, 'init_value': 34.58846664428711}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 05:58.04[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515055517: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022702219486236573, 'time_algorithm_update': 0.004829058647155762, 'loss': 1.7366401852965354, 'time_step': 0.007179995775222778, 'init_value': 35.390533447265625}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 05:58.25[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515055517: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022762229442596436, 'time_algorithm_update': 0.00505058479309082, 'loss': 1.7288203772902488, 'time_step': 0.007387425899505615, 'init_value': 38.73078536987305}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 05:58.47[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515055517: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002276242733001709, 'time_algorithm_update': 0.00488377046585083, 'loss': 1.6322136411070824, 'time_step': 0.007218912601470947, 'init_value': 41.39579772949219}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.39579772949219
Starting 1000 evaluations
avg return on 3 trajectories of agent2: 1386.1987764207568
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 06:14.41[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 06:14.41[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 06:14.42[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 06:14.42[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 06:14.42[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515061442[0m
[2m2025-05-15 06:14.42[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 06:15.01[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515061442: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020796947479248045, 'time_algorithm_update': 0.004363836526870728, 'loss': 1.6061532209143043, 'time_step': 0.006497545957565308, 'init_value': 4.552375316619873}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 06:15.21[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515061442: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021263535022735596, 'time_algorithm_update': 0.00448698616027832, 'loss': 2.2433764721155165, 'time_step': 0.006669007778167725, 'init_value': 10.98299789428711}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 06:15.41[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515061442: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00215448260307312, 'time_algorithm_update': 0.004531267404556274, 'loss': 2.286537561416626, 'time_step': 0.006742182493209839, 'init_value': 19.058687210083008}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 06:16.00[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515061442: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021120972633361817, 'time_algorithm_update': 0.004487776517868042, 'loss': 2.22351222550869, 'time_step': 0.00665511155128479, 'init_value': 25.108783721923828}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 06:16.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515061442: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021572036743164064, 'time_algorithm_update': 0.004454190731048584, 'loss': 1.916415887773037, 'time_step': 0.006666080713272095, 'init_value': 28.604541778564453}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 06:16.39[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515061442: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002108851432800293, 'time_algorithm_update': 0.004427287817001343, 'loss': 1.900035386145115, 'time_step': 0.0065908043384552, 'init_value': 31.27859878540039}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 06:16.59[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515061442: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020714457035064695, 'time_algorithm_update': 0.00432483720779419, 'loss': 1.8127860574126244, 'time_step': 0.006449620008468628, 'init_value': 34.12688446044922}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 06:17.18[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515061442: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021573507785797117, 'time_algorithm_update': 0.004523592233657837, 'loss': 1.7181389075517655, 'time_step': 0.006740385770797729, 'init_value': 37.4615478515625}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 06:17.38[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515061442: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002111679792404175, 'time_algorithm_update': 0.0044008100032806394, 'loss': 1.6472066615223884, 'time_step': 0.006566218137741089, 'init_value': 38.670318603515625}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 06:17.58[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515061442: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021652143001556394, 'time_algorithm_update': 0.004556508302688599, 'loss': 1.6294038220643998, 'time_step': 0.006777597665786743, 'init_value': 39.66973876953125}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 39.66973876953125
Starting 1000 evaluations
avg return on 3 trajectories of agent3: 1380.4458722297768
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 06:33.16[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 06:33.16[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 06:33.17[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 06:33.17[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 06:33.17[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515063317[0m
[2m2025-05-15 06:33.17[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 06:33.37[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515063317: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002088726997375488, 'time_algorithm_update': 0.004448582887649536, 'loss': 1.6727291704714298, 'time_step': 0.006591862916946411, 'init_value': 4.598365306854248}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 06:33.57[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515063317: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021492390632629394, 'time_algorithm_update': 0.004494114398956299, 'loss': 2.3329821450710297, 'time_step': 0.006698082208633423, 'init_value': 12.07568073272705}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 06:34.16[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515063317: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020919785499572754, 'time_algorithm_update': 0.0043905434608459476, 'loss': 2.2642784004807472, 'time_step': 0.006536269187927246, 'init_value': 19.476093292236328}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 06:34.36[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515063317: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002187408447265625, 'time_algorithm_update': 0.004591272115707397, 'loss': 2.100344425857067, 'time_step': 0.006834487915039062, 'init_value': 25.588882446289062}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 06:34.56[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515063317: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021208653450012207, 'time_algorithm_update': 0.004498654127120972, 'loss': 1.9567956553697585, 'time_step': 0.0066741971969604495, 'init_value': 29.46010398864746}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 06:35.16[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515063317: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002101423978805542, 'time_algorithm_update': 0.004432746887207031, 'loss': 1.8334411926269532, 'time_step': 0.006588691234588623, 'init_value': 32.26787567138672}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 06:35.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515063317: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002123268127441406, 'time_algorithm_update': 0.004528089761734009, 'loss': 1.905531862437725, 'time_step': 0.0067070436477661135, 'init_value': 34.269588470458984}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 06:35.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515063317: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002173919916152954, 'time_algorithm_update': 0.0045889801979064945, 'loss': 1.84434797924757, 'time_step': 0.006819806098937988, 'init_value': 36.033111572265625}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 06:36.15[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515063317: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002130575180053711, 'time_algorithm_update': 0.004562240839004516, 'loss': 1.7352740576863288, 'time_step': 0.006749367475509644, 'init_value': 37.04887771606445}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 06:36.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515063317: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002144085168838501, 'time_algorithm_update': 0.0044727506637573244, 'loss': 1.6867862077951432, 'time_step': 0.006672461032867432, 'init_value': 39.56874084472656}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 39.56874084472656
Starting 1000 evaluations
avg return on 3 trajectories of agent4: 1405.542642218563
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 06:51.48[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 06:51.48[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 06:51.50[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 06:51.50[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 06:51.50[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515065150[0m
[2m2025-05-15 06:51.50[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 06:52.09[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515065150: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020708811283111574, 'time_algorithm_update': 0.004398814916610718, 'loss': 1.667265664562583, 'time_step': 0.006523680686950683, 'init_value': 4.508910179138184}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 06:52.29[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515065150: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002191911458969116, 'time_algorithm_update': 0.0046453759670257565, 'loss': 2.3294378645420073, 'time_step': 0.0068949472904205325, 'init_value': 11.801569938659668}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 06:52.49[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515065150: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021087212562561036, 'time_algorithm_update': 0.004518090009689331, 'loss': 2.286454052567482, 'time_step': 0.00668241810798645, 'init_value': 19.889339447021484}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 06:53.09[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515065150: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021835300922393797, 'time_algorithm_update': 0.004563192367553711, 'loss': 2.1884770714640616, 'time_step': 0.006802241325378418, 'init_value': 25.8164005279541}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 06:53.29[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515065150: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021227166652679442, 'time_algorithm_update': 0.004479320049285889, 'loss': 2.0319354673027994, 'time_step': 0.00665617823600769, 'init_value': 30.214500427246094}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 06:53.49[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515065150: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021122915744781496, 'time_algorithm_update': 0.004481528759002686, 'loss': 1.7537978250384332, 'time_step': 0.006648524045944214, 'init_value': 33.771209716796875}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 06:54.08[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515065150: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002089446067810059, 'time_algorithm_update': 0.004398646831512451, 'loss': 1.8025876165628434, 'time_step': 0.006541875123977661, 'init_value': 36.05358123779297}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 06:54.28[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515065150: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002076213836669922, 'time_algorithm_update': 0.00421069860458374, 'loss': 1.7730593193769455, 'time_step': 0.006338500499725342, 'init_value': 37.74140167236328}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 06:54.48[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515065150: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002096487283706665, 'time_algorithm_update': 0.004453086853027343, 'loss': 1.7944212222099305, 'time_step': 0.00660395622253418, 'init_value': 39.99049758911133}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 06:55.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515065150: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002125458240509033, 'time_algorithm_update': 0.004537868022918701, 'loss': 1.6692864698171617, 'time_step': 0.006719450950622558, 'init_value': 41.474544525146484}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.474544525146484
Starting 1000 evaluations
avg return on 3 trajectories of agent5: 1408.031487466894
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 07:10.20[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 07:10.20[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 07:10.21[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 07:10.21[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 07:10.21[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515071021[0m
[2m2025-05-15 07:10.21[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 07:10.41[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515071021: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002082266569137573, 'time_algorithm_update': 0.004443340063095093, 'loss': 1.5888663488849997, 'time_step': 0.006580211877822876, 'init_value': 4.44288969039917}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 07:11.01[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515071021: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021308543682098387, 'time_algorithm_update': 0.004414767026901245, 'loss': 2.2354348025918007, 'time_step': 0.006599572896957398, 'init_value': 11.030508041381836}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 07:11.21[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515071021: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020850400924682616, 'time_algorithm_update': 0.0044487154483795165, 'loss': 2.382921274781227, 'time_step': 0.006588125944137573, 'init_value': 18.625104904174805}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 07:11.40[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515071021: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021638309955596922, 'time_algorithm_update': 0.004595494031906128, 'loss': 2.162727680563927, 'time_step': 0.006814771175384522, 'init_value': 24.466947555541992}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 07:12.00[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515071021: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021376609802246094, 'time_algorithm_update': 0.004600414037704468, 'loss': 1.9180136387348174, 'time_step': 0.0068004605770111085, 'init_value': 29.181859970092773}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 07:12.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515071021: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021368224620819092, 'time_algorithm_update': 0.004459597587585449, 'loss': 1.8812778455018997, 'time_step': 0.00665107798576355, 'init_value': 32.75431442260742}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 07:12.40[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515071021: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002099464416503906, 'time_algorithm_update': 0.0044194402694702145, 'loss': 1.7378240232467652, 'time_step': 0.006572455883026123, 'init_value': 35.26545333862305}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 07:13.00[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515071021: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002125439167022705, 'time_algorithm_update': 0.004525660991668701, 'loss': 1.789517139315605, 'time_step': 0.0067064080238342285, 'init_value': 38.69319152832031}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 07:13.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515071021: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002091074705123901, 'time_algorithm_update': 0.004433831214904785, 'loss': 1.733515170097351, 'time_step': 0.006579785585403442, 'init_value': 40.28797149658203}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 07:13.39[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515071021: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021226704120635986, 'time_algorithm_update': 0.004429895877838135, 'loss': 1.750908423423767, 'time_step': 0.006606750726699829, 'init_value': 42.08774948120117}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.08774948120117
Starting 1000 evaluations
avg return on 3 trajectories of agent6: 1409.4774824528415
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 07:28.56[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 07:28.56[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 07:28.57[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 07:28.57[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 07:28.57[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515072857[0m
[2m2025-05-15 07:28.57[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 07:29.16[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515072857: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002086808919906616, 'time_algorithm_update': 0.004385264158248902, 'loss': 1.689813494846225, 'time_step': 0.006525961875915527, 'init_value': 4.5716400146484375}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 07:29.36[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515072857: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020849251747131346, 'time_algorithm_update': 0.0043811070919036865, 'loss': 2.38356102758646, 'time_step': 0.0065197114944458, 'init_value': 11.549080848693848}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 07:29.56[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515072857: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021517903804779055, 'time_algorithm_update': 0.004544297218322754, 'loss': 2.267191344499588, 'time_step': 0.006751960754394532, 'init_value': 19.23566246032715}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 07:30.16[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515072857: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002144650220870972, 'time_algorithm_update': 0.004560421228408814, 'loss': 2.119589876651764, 'time_step': 0.006761139154434204, 'init_value': 25.57101821899414}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 07:30.36[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515072857: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021313636302947997, 'time_algorithm_update': 0.004481910467147827, 'loss': 2.0579033055901528, 'time_step': 0.006668715238571167, 'init_value': 29.72609519958496}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 07:30.56[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515072857: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021372056007385254, 'time_algorithm_update': 0.004526867151260376, 'loss': 1.892898801267147, 'time_step': 0.0067205047607421875, 'init_value': 33.85828399658203}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 07:31.15[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515072857: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002125948667526245, 'time_algorithm_update': 0.004500203847885132, 'loss': 1.7997681064605713, 'time_step': 0.00668153429031372, 'init_value': 35.77456283569336}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 07:31.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515072857: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021555826663970947, 'time_algorithm_update': 0.004519760131835937, 'loss': 1.802627713918686, 'time_step': 0.006730118036270142, 'init_value': 37.96554183959961}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 07:31.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515072857: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002115960121154785, 'time_algorithm_update': 0.004490447044372558, 'loss': 1.786663811326027, 'time_step': 0.006661900520324707, 'init_value': 39.484466552734375}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 07:32.15[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515072857: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022511241436004637, 'time_algorithm_update': 0.004752653121948242, 'loss': 1.8633127185106277, 'time_step': 0.007061829090118408, 'init_value': 41.98860549926758}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.98860549926758
Starting 1000 evaluations
avg return on 3 trajectories of agent7: 1404.6790545404322
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 07:47.35[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 07:47.35[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 07:47.36[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 07:47.36[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 07:47.36[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515074736[0m
[2m2025-05-15 07:47.36[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 07:47.56[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515074736: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021090869903564453, 'time_algorithm_update': 0.004476534605026245, 'loss': 1.7602725240141153, 'time_step': 0.00664104700088501, 'init_value': 4.130651950836182}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 07:48.15[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515074736: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020828897953033445, 'time_algorithm_update': 0.004369010210037231, 'loss': 2.440312764585018, 'time_step': 0.006505820035934448, 'init_value': 10.693209648132324}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 07:48.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515074736: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002148410081863403, 'time_algorithm_update': 0.004431340217590332, 'loss': 2.3473481709361077, 'time_step': 0.006634134769439698, 'init_value': 18.289976119995117}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 07:48.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515074736: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021172826290130615, 'time_algorithm_update': 0.004483297824859619, 'loss': 2.25091954433918, 'time_step': 0.006655947923660278, 'init_value': 24.302940368652344}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 07:49.15[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515074736: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021399123668670653, 'time_algorithm_update': 0.004463237047195434, 'loss': 2.1200007405281065, 'time_step': 0.006658245086669922, 'init_value': 29.212732315063477}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 07:49.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515074736: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002119025945663452, 'time_algorithm_update': 0.0044723799228668214, 'loss': 1.9349429805874825, 'time_step': 0.006646557569503784, 'init_value': 32.791141510009766}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 07:49.54[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515074736: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002106576681137085, 'time_algorithm_update': 0.00445914363861084, 'loss': 1.8291337561607361, 'time_step': 0.006621081590652466, 'init_value': 35.514713287353516}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 07:50.13[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515074736: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021629743576049806, 'time_algorithm_update': 0.004532621383666992, 'loss': 1.7651644963026047, 'time_step': 0.006751482486724854, 'init_value': 37.70306396484375}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 07:50.33[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515074736: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021000192165374757, 'time_algorithm_update': 0.004373286962509155, 'loss': 1.6889245495200158, 'time_step': 0.006526910543441773, 'init_value': 40.401878356933594}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 07:50.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515074736: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021191487312316893, 'time_algorithm_update': 0.0044109392166137695, 'loss': 1.8810256648659707, 'time_step': 0.006584633827209472, 'init_value': 41.159610748291016}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.159610748291016
Starting 1000 evaluations
avg return on 3 trajectories of agent8: 1396.9478925329838
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 08:06.07[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 08:06.07[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 08:06.09[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 08:06.09[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 08:06.09[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515080609[0m
[2m2025-05-15 08:06.09[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 08:06.28[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515080609: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020596837997436525, 'time_algorithm_update': 0.004345743417739868, 'loss': 1.6119171369746328, 'time_step': 0.0064593045711517335, 'init_value': 4.206588268280029}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 08:06.47[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515080609: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020415265560150145, 'time_algorithm_update': 0.004217083215713501, 'loss': 2.3329368255734444, 'time_step': 0.006310851335525513, 'init_value': 11.458651542663574}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 08:07.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515080609: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021660304069519042, 'time_algorithm_update': 0.004578796148300171, 'loss': 2.319003620505333, 'time_step': 0.006801164388656617, 'init_value': 19.275903701782227}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 08:07.27[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515080609: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021371386051177977, 'time_algorithm_update': 0.004503867864608765, 'loss': 2.0547089561223983, 'time_step': 0.006696098327636719, 'init_value': 25.50248908996582}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 08:07.46[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515080609: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002117175579071045, 'time_algorithm_update': 0.004483275175094605, 'loss': 1.9912873924970627, 'time_step': 0.006655502319335938, 'init_value': 30.422086715698242}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 08:08.06[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515080609: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022111093997955323, 'time_algorithm_update': 0.004597557544708252, 'loss': 1.8557902326583862, 'time_step': 0.006864635229110717, 'init_value': 32.86083221435547}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 08:08.26[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515080609: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002127177953720093, 'time_algorithm_update': 0.004590034008026123, 'loss': 1.8353790546059607, 'time_step': 0.0067745308876037596, 'init_value': 34.67619323730469}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 08:08.46[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515080609: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021525950431823732, 'time_algorithm_update': 0.004507085561752319, 'loss': 1.6868553369045258, 'time_step': 0.006715093374252319, 'init_value': 36.37553024291992}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 08:09.06[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515080609: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002130513668060303, 'time_algorithm_update': 0.00454346776008606, 'loss': 1.6631473041176796, 'time_step': 0.006729848861694336, 'init_value': 39.70307922363281}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 08:09.26[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515080609: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022536089420318603, 'time_algorithm_update': 0.004835167169570923, 'loss': 1.6385942249894143, 'time_step': 0.007147880554199218, 'init_value': 41.52382278442383}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.52382278442383
Starting 1000 evaluations
avg return on 3 trajectories of agent9: 1401.51432474727
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 08:24.26[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 08:24.26[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 08:24.28[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 08:24.28[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 08:24.28[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515082428[0m
[2m2025-05-15 08:24.28[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 08:24.47[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515082428: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020436112880706787, 'time_algorithm_update': 0.004296265840530396, 'loss': 1.7868660555183888, 'time_step': 0.006393297672271729, 'init_value': 4.134339332580566}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 08:25.06[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515082428: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002059107065200806, 'time_algorithm_update': 0.004295339584350586, 'loss': 2.487484189271927, 'time_step': 0.006409880161285401, 'init_value': 11.120945930480957}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 08:25.25[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515082428: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002071209669113159, 'time_algorithm_update': 0.004284905195236206, 'loss': 2.3057819018959997, 'time_step': 0.0064098012447357175, 'init_value': 17.716814041137695}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 08:25.44[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515082428: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002024698734283447, 'time_algorithm_update': 0.004196131467819214, 'loss': 2.1071609550714494, 'time_step': 0.0062727053165435795, 'init_value': 23.82420539855957}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 08:26.03[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515082428: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002067440986633301, 'time_algorithm_update': 0.004203784465789795, 'loss': 1.9060103231668473, 'time_step': 0.006324074983596802, 'init_value': 27.993391036987305}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 08:26.23[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515082428: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020621991157531738, 'time_algorithm_update': 0.00433801794052124, 'loss': 1.885550553560257, 'time_step': 0.006454420804977417, 'init_value': 31.192293167114258}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 08:26.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515082428: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020589306354522707, 'time_algorithm_update': 0.004325371503829956, 'loss': 1.7697282883524894, 'time_step': 0.006438216209411621, 'init_value': 34.54074478149414}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 08:27.01[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515082428: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00204455041885376, 'time_algorithm_update': 0.004265657901763916, 'loss': 1.705410447716713, 'time_step': 0.006363169431686401, 'init_value': 36.765296936035156}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 08:27.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515082428: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021094598770141602, 'time_algorithm_update': 0.004375015497207642, 'loss': 1.7440441938042641, 'time_step': 0.006538958072662354, 'init_value': 38.454586029052734}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 08:27.39[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515082428: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002031959772109985, 'time_algorithm_update': 0.004233815670013428, 'loss': 1.6973610882163048, 'time_step': 0.006318130970001221, 'init_value': 40.26067352294922}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.26067352294922
Starting 1000 evaluations
avg return on 3 trajectories of agent10: 1390.8533478040952
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 08:42.25[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 08:42.25[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 08:42.26[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 08:42.26[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 08:42.26[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515084226[0m
[2m2025-05-15 08:42.26[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 08:42.44[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515084226: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001815027952194214, 'time_algorithm_update': 0.003493244171142578, 'loss': 1.8961792778521775, 'time_step': 0.005354635953903199, 'init_value': 4.344814300537109}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 08:43.01[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515084226: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018548011779785157, 'time_algorithm_update': 0.0035545995235443115, 'loss': 2.376435762107372, 'time_step': 0.005456528902053833, 'init_value': 11.686690330505371}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 08:43.19[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515084226: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018401522636413575, 'time_algorithm_update': 0.0035719234943389893, 'loss': 2.264433032333851, 'time_step': 0.005459224939346314, 'init_value': 20.00681495666504}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 08:43.36[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515084226: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018455038070678712, 'time_algorithm_update': 0.003554147720336914, 'loss': 2.1496746624708174, 'time_step': 0.005446685791015625, 'init_value': 25.419082641601562}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 08:43.54[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515084226: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001835667610168457, 'time_algorithm_update': 0.003552064895629883, 'loss': 2.037020089030266, 'time_step': 0.005435141086578369, 'init_value': 30.464399337768555}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 08:44.11[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515084226: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018464856147766113, 'time_algorithm_update': 0.003621648073196411, 'loss': 1.8992849462032317, 'time_step': 0.005515692234039307, 'init_value': 33.713165283203125}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 08:44.29[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515084226: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018778414726257325, 'time_algorithm_update': 0.0035935893058776855, 'loss': 1.809179006934166, 'time_step': 0.005519617557525635, 'init_value': 35.446224212646484}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 08:44.47[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515084226: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018419678211212159, 'time_algorithm_update': 0.003579850435256958, 'loss': 1.5951507582068443, 'time_step': 0.005469149112701416, 'init_value': 37.92588806152344}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 08:45.04[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515084226: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018462684154510497, 'time_algorithm_update': 0.003594554662704468, 'loss': 1.727463883638382, 'time_step': 0.005488517522811889, 'init_value': 39.69718933105469}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 08:45.22[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515084226: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001830195188522339, 'time_algorithm_update': 0.0035454225540161133, 'loss': 1.652443138718605, 'time_step': 0.005423093318939209, 'init_value': 41.75009536743164}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.75009536743164
Starting 1000 evaluations
avg return on 3 trajectories of agent11: 1389.260381682504
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 08:59.05[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 08:59.05[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 08:59.06[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 08:59.06[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 08:59.06[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515085906[0m
[2m2025-05-15 08:59.06[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 08:59.22[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515085906: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001755946397781372, 'time_algorithm_update': 0.0032038910388946535, 'loss': 1.6672758980616926, 'time_step': 0.005003938436508179, 'init_value': 4.404669761657715}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 08:59.39[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515085906: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017556025981903076, 'time_algorithm_update': 0.003195164680480957, 'loss': 2.3880762450098993, 'time_step': 0.004994549036026001, 'init_value': 10.203540802001953}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 08:59.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515085906: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017537894248962403, 'time_algorithm_update': 0.0032618956565856933, 'loss': 2.34771257764101, 'time_step': 0.005059486150741577, 'init_value': 17.75747299194336}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 09:00.12[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515085906: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017950375080108643, 'time_algorithm_update': 0.003372616767883301, 'loss': 2.1395937945246697, 'time_step': 0.0052135343551635745, 'init_value': 23.675582885742188}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 09:00.29[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515085906: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001793522357940674, 'time_algorithm_update': 0.0033082160949707033, 'loss': 2.020350490570068, 'time_step': 0.00514569091796875, 'init_value': 28.391895294189453}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 09:00.45[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515085906: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001759746551513672, 'time_algorithm_update': 0.003250964879989624, 'loss': 1.854809631705284, 'time_step': 0.005054705619812012, 'init_value': 31.94470977783203}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 09:01.02[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515085906: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017561423778533936, 'time_algorithm_update': 0.0032031052112579347, 'loss': 1.8234402092695237, 'time_step': 0.005003267049789429, 'init_value': 33.88032150268555}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 09:01.19[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515085906: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017940082550048828, 'time_algorithm_update': 0.0032744653224945066, 'loss': 1.6875030090212821, 'time_step': 0.005112558841705322, 'init_value': 36.41819763183594}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 09:01.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515085906: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001770148992538452, 'time_algorithm_update': 0.0032399327754974367, 'loss': 1.6611328691244125, 'time_step': 0.005054639339447021, 'init_value': 38.56525802612305}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 09:01.52[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515085906: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017699906826019287, 'time_algorithm_update': 0.003285041093826294, 'loss': 1.5922261940836906, 'time_step': 0.005099519491195679, 'init_value': 39.73055648803711}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 39.73055648803711
Starting 1000 evaluations
avg return on 3 trajectories of agent12: 1396.956413879864
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 09:15.26[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 09:15.26[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 09:15.27[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 09:15.27[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 09:15.27[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515091527[0m
[2m2025-05-15 09:15.27[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 09:15.44[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515091527: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017500965595245361, 'time_algorithm_update': 0.003221268653869629, 'loss': 1.5412401927411556, 'time_step': 0.005015422821044922, 'init_value': 4.025533199310303}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 09:16.00[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515091527: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017997868061065674, 'time_algorithm_update': 0.0034329199790954588, 'loss': 2.461997053384781, 'time_step': 0.005279002904891967, 'init_value': 10.386201858520508}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 09:16.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515091527: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017697532176971435, 'time_algorithm_update': 0.003301459074020386, 'loss': 2.3465714269280435, 'time_step': 0.005116087436676025, 'init_value': 18.15843963623047}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 09:16.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515091527: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001777446985244751, 'time_algorithm_update': 0.003366349220275879, 'loss': 2.0649646743535994, 'time_step': 0.0051882417201995846, 'init_value': 24.267549514770508}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 09:16.50[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515091527: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018150525093078612, 'time_algorithm_update': 0.0033283677101135253, 'loss': 2.0138973215818403, 'time_step': 0.005188225746154785, 'init_value': 29.092796325683594}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 09:17.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515091527: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018090577125549317, 'time_algorithm_update': 0.0035076472759246824, 'loss': 1.8978592559099197, 'time_step': 0.005363183259963989, 'init_value': 33.36050033569336}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 09:17.24[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515091527: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018077054023742675, 'time_algorithm_update': 0.003345062971115112, 'loss': 1.744760296702385, 'time_step': 0.0051973025798797605, 'init_value': 35.48354721069336}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 09:17.40[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515091527: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001779165506362915, 'time_algorithm_update': 0.0033227736949920654, 'loss': 1.8049279866218566, 'time_step': 0.005147320747375488, 'init_value': 38.81840515136719}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 09:17.57[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515091527: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018302416801452637, 'time_algorithm_update': 0.00337955904006958, 'loss': 1.7267148774862289, 'time_step': 0.005254972696304322, 'init_value': 39.86111068725586}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 09:18.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515091527: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017802295684814452, 'time_algorithm_update': 0.003329392671585083, 'loss': 1.7190426527261733, 'time_step': 0.005154692173004151, 'init_value': 41.948917388916016}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.948917388916016
Starting 1000 evaluations
avg return on 3 trajectories of agent13: 1402.7804312108979
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 09:31.51[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 09:31.51[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 09:31.52[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 09:31.52[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 09:31.52[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515093152[0m
[2m2025-05-15 09:31.52[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 09:32.08[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515093152: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001717888116836548, 'time_algorithm_update': 0.0031076045036315916, 'loss': 1.7270523376762867, 'time_step': 0.004867744445800781, 'init_value': 4.456742763519287}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 09:32.25[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515093152: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017479326725006103, 'time_algorithm_update': 0.0032204079627990725, 'loss': 2.3204450020194054, 'time_step': 0.00501184606552124, 'init_value': 11.194354057312012}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 09:32.41[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515093152: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018176219463348388, 'time_algorithm_update': 0.0033959007263183595, 'loss': 2.2830042597055433, 'time_step': 0.005260190486907959, 'init_value': 19.60379409790039}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 09:32.58[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515093152: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001738982915878296, 'time_algorithm_update': 0.0032523341178894044, 'loss': 2.213056993961334, 'time_step': 0.005034445762634277, 'init_value': 25.931123733520508}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 09:33.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515093152: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001765183448791504, 'time_algorithm_update': 0.003220827341079712, 'loss': 1.9815924258828164, 'time_step': 0.005029078483581543, 'init_value': 31.580142974853516}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 09:33.31[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515093152: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017422044277191162, 'time_algorithm_update': 0.003197646141052246, 'loss': 1.79330234926939, 'time_step': 0.004983163833618164, 'init_value': 33.783260345458984}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 09:33.48[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515093152: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017927649021148681, 'time_algorithm_update': 0.0033387281894683837, 'loss': 1.7797664844989776, 'time_step': 0.005176526546478271, 'init_value': 34.98710250854492}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 09:34.04[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515093152: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001728489875793457, 'time_algorithm_update': 0.003172171354293823, 'loss': 1.6425862852334976, 'time_step': 0.0049433262348175045, 'init_value': 36.23606491088867}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 09:34.21[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515093152: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017315499782562256, 'time_algorithm_update': 0.003227476119995117, 'loss': 1.633689220249653, 'time_step': 0.0050017075538635256, 'init_value': 37.9555549621582}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 09:34.37[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515093152: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017720396518707275, 'time_algorithm_update': 0.0032160849571228026, 'loss': 1.6857226699590684, 'time_step': 0.005031445026397705, 'init_value': 40.7052116394043}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.7052116394043
Starting 1000 evaluations
avg return on 3 trajectories of agent14: 1409.4241939595213
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 09:48.13[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 09:48.13[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 09:48.14[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 09:48.14[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 09:48.14[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515094814[0m
[2m2025-05-15 09:48.14[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 09:48.30[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515094814: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017584993839263915, 'time_algorithm_update': 0.0032386617660522463, 'loss': 1.635500133894384, 'time_step': 0.005040987014770508, 'init_value': 4.465143203735352}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 09:48.47[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515094814: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017596893310546874, 'time_algorithm_update': 0.003248054027557373, 'loss': 2.377191187620163, 'time_step': 0.0050520384311676025, 'init_value': 10.609705924987793}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 09:49.03[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515094814: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001807624101638794, 'time_algorithm_update': 0.0033306608200073242, 'loss': 2.244465822815895, 'time_step': 0.005183952331542969, 'init_value': 17.47140121459961}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 09:49.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515094814: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017674670219421386, 'time_algorithm_update': 0.003285191297531128, 'loss': 2.2381906079053877, 'time_step': 0.005097593069076538, 'init_value': 24.684173583984375}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 09:49.37[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515094814: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018513283729553222, 'time_algorithm_update': 0.0035588507652282715, 'loss': 2.092601688802242, 'time_step': 0.005457643270492554, 'init_value': 28.36723518371582}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 09:49.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515094814: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017702383995056152, 'time_algorithm_update': 0.0032831153869628906, 'loss': 1.946540804386139, 'time_step': 0.005098286151885986, 'init_value': 31.995685577392578}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 09:50.10[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515094814: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017970407009124756, 'time_algorithm_update': 0.003366492509841919, 'loss': 1.792284725189209, 'time_step': 0.005208795547485352, 'init_value': 35.3398551940918}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 09:50.26[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515094814: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001767695665359497, 'time_algorithm_update': 0.0032871565818786623, 'loss': 1.7909086372852325, 'time_step': 0.005100203990936279, 'init_value': 37.858604431152344}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 09:50.43[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515094814: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001767364263534546, 'time_algorithm_update': 0.0032569572925567627, 'loss': 1.735403987288475, 'time_step': 0.005070549249649048, 'init_value': 40.37397766113281}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 09:51.00[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515094814: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017613730430603028, 'time_algorithm_update': 0.0032329721450805662, 'loss': 1.7364471951127052, 'time_step': 0.005039877414703369, 'init_value': 40.54330062866211}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.54330062866211
Starting 1000 evaluations
avg return on 3 trajectories of agent15: 1418.675932754966
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 10:04.36[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 10:04.36[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 10:04.37[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 10:04.37[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 10:04.37[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515100437[0m
[2m2025-05-15 10:04.37[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 10:04.54[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515100437: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017276802062988282, 'time_algorithm_update': 0.003170785665512085, 'loss': 1.4812128556743265, 'time_step': 0.004940629482269287, 'init_value': 4.495677471160889}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 10:05.10[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515100437: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001734243392944336, 'time_algorithm_update': 0.0031476423740386963, 'loss': 2.320957390606403, 'time_step': 0.004925355195999146, 'init_value': 10.721187591552734}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 10:05.26[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515100437: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017871980667114257, 'time_algorithm_update': 0.003274171352386475, 'loss': 2.2627180851101873, 'time_step': 0.005104908227920532, 'init_value': 17.30515480041504}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 10:05.43[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515100437: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017428414821624755, 'time_algorithm_update': 0.0031818354129791258, 'loss': 2.207788453519344, 'time_step': 0.004967899799346924, 'init_value': 25.282047271728516}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 10:05.59[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515100437: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017360918521881104, 'time_algorithm_update': 0.003142239809036255, 'loss': 1.9902552198171615, 'time_step': 0.004921007633209229, 'init_value': 28.940752029418945}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 10:06.16[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515100437: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017546169757843017, 'time_algorithm_update': 0.00326359224319458, 'loss': 1.8479179030060768, 'time_step': 0.005062348842620849, 'init_value': 32.54258346557617}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 10:06.32[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515100437: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018269181251525878, 'time_algorithm_update': 0.0034277174472808836, 'loss': 1.7606575101614, 'time_step': 0.005301445960998535, 'init_value': 36.37147903442383}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 10:06.49[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515100437: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017421343326568604, 'time_algorithm_update': 0.0032289745807647704, 'loss': 1.7545519006252288, 'time_step': 0.0050143756866455075, 'init_value': 38.95443344116211}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 10:07.05[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515100437: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017674047946929932, 'time_algorithm_update': 0.0032065181732177732, 'loss': 1.7214837710857391, 'time_step': 0.00501729965209961, 'init_value': 41.46418380737305}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 10:07.22[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515100437: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017558236122131347, 'time_algorithm_update': 0.0032665274143218992, 'loss': 1.6635762550234794, 'time_step': 0.005065947294235229, 'init_value': 41.45645523071289}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.45645523071289
Starting 1000 evaluations
avg return on 3 trajectories of agent16: 1395.7784047825924
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 10:20.56[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 10:20.56[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 10:20.57[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 10:20.57[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 10:20.57[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515102057[0m
[2m2025-05-15 10:20.57[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 10:21.13[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515102057: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017238521575927734, 'time_algorithm_update': 0.003117168188095093, 'loss': 1.623316295593977, 'time_step': 0.004884267091751098, 'init_value': 4.4832844734191895}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 10:21.30[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515102057: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017434391975402832, 'time_algorithm_update': 0.0032453665733337403, 'loss': 2.4024811180233954, 'time_step': 0.005032482624053955, 'init_value': 11.572474479675293}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 10:21.47[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515102057: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017809996604919434, 'time_algorithm_update': 0.0032313241958618166, 'loss': 2.3022342410087586, 'time_step': 0.00505664324760437, 'init_value': 18.829809188842773}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 10:22.03[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515102057: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018006744384765625, 'time_algorithm_update': 0.0034823415279388427, 'loss': 2.182452867567539, 'time_step': 0.0053297865390777585, 'init_value': 25.615554809570312}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 10:22.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515102057: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017919561862945557, 'time_algorithm_update': 0.003251702070236206, 'loss': 2.036694076359272, 'time_step': 0.005087845802307129, 'init_value': 29.779678344726562}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 10:22.36[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515102057: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017394895553588868, 'time_algorithm_update': 0.0032134528160095216, 'loss': 1.907760070502758, 'time_step': 0.0049967305660247804, 'init_value': 32.57229995727539}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 10:22.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515102057: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017520699501037598, 'time_algorithm_update': 0.003286167860031128, 'loss': 1.7583118905425072, 'time_step': 0.0050821959972381595, 'init_value': 35.305973052978516}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 10:23.09[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515102057: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017606031894683838, 'time_algorithm_update': 0.003241978645324707, 'loss': 1.731610812306404, 'time_step': 0.0050477986335754396, 'init_value': 37.573638916015625}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 10:23.26[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515102057: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017440743446350097, 'time_algorithm_update': 0.003231217861175537, 'loss': 1.6172593132257462, 'time_step': 0.005019170522689819, 'init_value': 39.537052154541016}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 10:23.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515102057: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017907874584197998, 'time_algorithm_update': 0.003339528799057007, 'loss': 1.6939958541989326, 'time_step': 0.005176065444946289, 'init_value': 42.19662094116211}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.19662094116211
Starting 1000 evaluations
avg return on 3 trajectories of agent17: 1393.1231283372097
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 10:37.22[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 10:37.22[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 10:37.23[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 10:37.23[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 10:37.23[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515103723[0m
[2m2025-05-15 10:37.23[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 10:37.40[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515103723: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017684037685394287, 'time_algorithm_update': 0.0033329086303710937, 'loss': 1.4870887479335069, 'time_step': 0.0051459562778472905, 'init_value': 4.4586710929870605}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 10:37.56[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515103723: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017509994506835938, 'time_algorithm_update': 0.0032039079666137697, 'loss': 2.4799031190276146, 'time_step': 0.004998806953430176, 'init_value': 11.63547420501709}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 10:38.12[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515103723: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017877302169799804, 'time_algorithm_update': 0.0032571337223052978, 'loss': 2.2958047001957893, 'time_step': 0.005089311838150024, 'init_value': 19.247692108154297}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 10:38.29[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515103723: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017613937854766845, 'time_algorithm_update': 0.0032768235206604005, 'loss': 2.337587696611881, 'time_step': 0.005082476139068604, 'init_value': 24.423961639404297}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 10:38.45[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515103723: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017874155044555664, 'time_algorithm_update': 0.003248830556869507, 'loss': 2.054559234201908, 'time_step': 0.005080619812011719, 'init_value': 29.198474884033203}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 10:39.02[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515103723: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018374357223510742, 'time_algorithm_update': 0.003584785223007202, 'loss': 1.9084883394241332, 'time_step': 0.005469861268997192, 'init_value': 33.02882385253906}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 10:39.18[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515103723: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017903761863708495, 'time_algorithm_update': 0.0032611210346221923, 'loss': 1.7921961904764176, 'time_step': 0.005095844984054566, 'init_value': 34.24489212036133}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 10:39.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515103723: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017693920135498048, 'time_algorithm_update': 0.0033454935550689697, 'loss': 1.7699957624673843, 'time_step': 0.005159351110458374, 'init_value': 36.331729888916016}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 10:39.51[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515103723: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017583322525024413, 'time_algorithm_update': 0.003266345500946045, 'loss': 1.8150105649232864, 'time_step': 0.005068946123123169, 'init_value': 37.74180603027344}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 10:40.08[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515103723: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018003909587860107, 'time_algorithm_update': 0.0033043835163116455, 'loss': 1.5945048966407775, 'time_step': 0.005150058269500732, 'init_value': 39.985782623291016}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 39.985782623291016
Starting 1000 evaluations
avg return on 3 trajectories of agent18: 1379.5694490789604
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 10:53.50[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 10:53.50[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 10:53.51[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 10:53.51[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 10:53.51[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515105351[0m
[2m2025-05-15 10:53.51[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 10:54.08[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515105351: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017527096271514892, 'time_algorithm_update': 0.0032744407653808594, 'loss': 1.5785222014710307, 'time_step': 0.005070385217666626, 'init_value': 4.187066555023193}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 10:54.24[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515105351: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017818901538848876, 'time_algorithm_update': 0.0032288548946380617, 'loss': 2.3909123059511184, 'time_step': 0.005054720878601074, 'init_value': 10.975014686584473}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 10:54.41[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515105351: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017733263969421386, 'time_algorithm_update': 0.003353954076766968, 'loss': 2.314092655837536, 'time_step': 0.005172997951507568, 'init_value': 18.686237335205078}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 10:54.57[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515105351: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017880375385284425, 'time_algorithm_update': 0.003332709074020386, 'loss': 2.1830206996798514, 'time_step': 0.0051656198501586915, 'init_value': 24.971281051635742}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 10:55.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515105351: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017585957050323486, 'time_algorithm_update': 0.0032670035362243654, 'loss': 2.015648094713688, 'time_step': 0.005069516181945801, 'init_value': 30.01555824279785}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 10:55.30[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515105351: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017606921195983886, 'time_algorithm_update': 0.0033346264362335205, 'loss': 1.8845757547020912, 'time_step': 0.005139917612075806, 'init_value': 34.39476013183594}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 10:55.47[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515105351: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017952401638031007, 'time_algorithm_update': 0.003280283212661743, 'loss': 1.829474421441555, 'time_step': 0.005120108127593994, 'init_value': 35.45124816894531}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 10:56.04[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515105351: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018059508800506593, 'time_algorithm_update': 0.0034763963222503662, 'loss': 1.844326965689659, 'time_step': 0.005328697919845581, 'init_value': 38.56950378417969}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 10:56.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515105351: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017728986740112305, 'time_algorithm_update': 0.00333064866065979, 'loss': 1.7839709362387657, 'time_step': 0.0051484408378601075, 'init_value': 38.849327087402344}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 10:56.37[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515105351: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017741825580596924, 'time_algorithm_update': 0.0033365604877471926, 'loss': 1.6660720065832137, 'time_step': 0.005155957221984863, 'init_value': 41.0360107421875}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.0360107421875
Starting 1000 evaluations
avg return on 3 trajectories of agent19: 1369.8268493772553
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 11:10.20[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 11:10.20[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 11:10.22[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 11:10.22[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 11:10.22[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515111022[0m
[2m2025-05-15 11:10.22[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 11:10.38[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515111022: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017418029308319091, 'time_algorithm_update': 0.0032121889591217043, 'loss': 1.669672034919262, 'time_step': 0.004996743440628052, 'init_value': 4.468820095062256}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 11:10.54[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515111022: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017485804557800294, 'time_algorithm_update': 0.0031987109184265137, 'loss': 2.3624516050815583, 'time_step': 0.00499055552482605, 'init_value': 11.370732307434082}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 11:11.11[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515111022: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017819595336914062, 'time_algorithm_update': 0.0032843811511993407, 'loss': 2.4563962742090224, 'time_step': 0.005110588312149048, 'init_value': 19.809749603271484}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 11:11.27[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515111022: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001747379779815674, 'time_algorithm_update': 0.0032255187034606935, 'loss': 2.040674981057644, 'time_step': 0.005016335010528564, 'init_value': 26.824928283691406}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 11:11.44[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515111022: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017841670513153076, 'time_algorithm_update': 0.00327745795249939, 'loss': 1.9866022548079492, 'time_step': 0.005104970932006836, 'init_value': 31.694684982299805}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 11:12.00[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515111022: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001758826494216919, 'time_algorithm_update': 0.003277146577835083, 'loss': 1.8497306364178658, 'time_step': 0.005079278945922852, 'init_value': 34.58638000488281}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 11:12.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515111022: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017520344257354735, 'time_algorithm_update': 0.003203035116195679, 'loss': 1.74421692943573, 'time_step': 0.00499798059463501, 'init_value': 37.39188003540039}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 11:12.33[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515111022: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001771437883377075, 'time_algorithm_update': 0.0033385920524597167, 'loss': 1.770118802011013, 'time_step': 0.0051543967723846435, 'init_value': 39.12552261352539}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 11:12.50[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515111022: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018078172206878662, 'time_algorithm_update': 0.003468404769897461, 'loss': 1.664561265707016, 'time_step': 0.005322993516921997, 'init_value': 41.41720199584961}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 11:13.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515111022: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017956552505493165, 'time_algorithm_update': 0.0033524374961853027, 'loss': 1.7289082056879996, 'time_step': 0.005193257331848144, 'init_value': 43.0108642578125}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 43.0108642578125
ave advantage rew: 41.11473159790039, std: 0.9237664261124945
avg cum rews: 1396.9214178944105, std: 11.508527657961357
Pearson correlation coefficient: 0.09249313971068632
Spearman correlation coefficient: 0.19548872180451127
Kendall Tau correlation coefficient: 0.1473684210526316
the best agent: 15, best agent cum rewards: 1418.675932754966
1966
Starting to collect rollouts
Collecting rollouts: 10000/1000000
Collecting rollouts: 20000/1000000
Collecting rollouts: 30000/1000000
Collecting rollouts: 40000/1000000
Collecting rollouts: 50000/1000000
Collecting rollouts: 60000/1000000
Collecting rollouts: 70000/1000000
Collecting rollouts: 80000/1000000
Collecting rollouts: 90000/1000000
Collecting rollouts: 100000/1000000
Collecting rollouts: 110000/1000000
Collecting rollouts: 120000/1000000
Collecting rollouts: 130000/1000000
Collecting rollouts: 140000/1000000
Collecting rollouts: 150000/1000000
Collecting rollouts: 160000/1000000
Collecting rollouts: 170000/1000000
Collecting rollouts: 180000/1000000
Collecting rollouts: 190000/1000000
Collecting rollouts: 200000/1000000
Collecting rollouts: 210000/1000000
Collecting rollouts: 220000/1000000
Collecting rollouts: 230000/1000000
Collecting rollouts: 240000/1000000
Collecting rollouts: 250000/1000000
Collecting rollouts: 260000/1000000
Collecting rollouts: 270000/1000000
Collecting rollouts: 280000/1000000
Collecting rollouts: 290000/1000000
Collecting rollouts: 300000/1000000
Collecting rollouts: 310000/1000000
Collecting rollouts: 320000/1000000
Collecting rollouts: 330000/1000000
Collecting rollouts: 340000/1000000
Collecting rollouts: 350000/1000000
Collecting rollouts: 360000/1000000
Collecting rollouts: 370000/1000000
Collecting rollouts: 380000/1000000
Collecting rollouts: 390000/1000000
Collecting rollouts: 400000/1000000
Collecting rollouts: 410000/1000000
Collecting rollouts: 420000/1000000
Collecting rollouts: 430000/1000000
Collecting rollouts: 440000/1000000
Collecting rollouts: 450000/1000000
Collecting rollouts: 460000/1000000
Collecting rollouts: 470000/1000000
Collecting rollouts: 480000/1000000
Collecting rollouts: 490000/1000000
Collecting rollouts: 500000/1000000
Collecting rollouts: 510000/1000000
Collecting rollouts: 520000/1000000
Collecting rollouts: 530000/1000000
Collecting rollouts: 540000/1000000
Collecting rollouts: 550000/1000000
Collecting rollouts: 560000/1000000
Collecting rollouts: 570000/1000000
Collecting rollouts: 580000/1000000
Collecting rollouts: 590000/1000000
Collecting rollouts: 600000/1000000
Collecting rollouts: 610000/1000000
Collecting rollouts: 620000/1000000
Collecting rollouts: 630000/1000000
Collecting rollouts: 640000/1000000
Collecting rollouts: 650000/1000000
Collecting rollouts: 660000/1000000
Collecting rollouts: 670000/1000000
Collecting rollouts: 680000/1000000
Collecting rollouts: 690000/1000000
Collecting rollouts: 700000/1000000
Collecting rollouts: 710000/1000000
Collecting rollouts: 720000/1000000
Collecting rollouts: 730000/1000000
Collecting rollouts: 740000/1000000
Collecting rollouts: 750000/1000000
Collecting rollouts: 760000/1000000
Collecting rollouts: 770000/1000000
Collecting rollouts: 780000/1000000
Collecting rollouts: 790000/1000000
Collecting rollouts: 800000/1000000
Collecting rollouts: 810000/1000000
Collecting rollouts: 820000/1000000
Collecting rollouts: 830000/1000000
Collecting rollouts: 840000/1000000
Collecting rollouts: 850000/1000000
Collecting rollouts: 860000/1000000
Collecting rollouts: 870000/1000000
Collecting rollouts: 880000/1000000
Collecting rollouts: 890000/1000000
Collecting rollouts: 900000/1000000
Collecting rollouts: 910000/1000000
Collecting rollouts: 920000/1000000
Collecting rollouts: 930000/1000000
Collecting rollouts: 940000/1000000
Collecting rollouts: 950000/1000000
Collecting rollouts: 960000/1000000
Collecting rollouts: 970000/1000000
Collecting rollouts: 980000/1000000
Collecting rollouts: 990000/1000000
Collecting rollouts: 1000000/1000000
Replay buffer size:  (1000000, 105)
Replay buffer saved
---------------------------------
Searching empty space policies
(10, 11472)
(20, 11472)
(20, 11472)
Average distance of agents to nearest neighbors: 0.01759746346685657
Starting 1000 evaluations
avg return on 3 trajectories of agent0: 1402.4863445784176
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 11:42.40[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 11:42.40[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 11:42.42[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 11:42.42[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 11:42.42[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515114242[0m
[2m2025-05-15 11:42.42[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 11:42.58[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515114242: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001775378704071045, 'time_algorithm_update': 0.0032677805423736573, 'loss': 1.554608559653163, 'time_step': 0.005087448596954346, 'init_value': 4.3784332275390625}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 11:43.15[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515114242: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017924418449401856, 'time_algorithm_update': 0.0032439472675323488, 'loss': 2.4143606517910956, 'time_step': 0.00508028793334961, 'init_value': 11.182633399963379}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 11:43.31[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515114242: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017744076251983642, 'time_algorithm_update': 0.0032903852462768555, 'loss': 2.339175270974636, 'time_step': 0.0051095025539398195, 'init_value': 19.739051818847656}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 11:43.48[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515114242: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017685024738311767, 'time_algorithm_update': 0.003250344276428223, 'loss': 2.2096441067457198, 'time_step': 0.005063225984573364, 'init_value': 26.450531005859375}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 11:44.04[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515114242: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001786851167678833, 'time_algorithm_update': 0.003356854200363159, 'loss': 1.9936616666913032, 'time_step': 0.005188989639282227, 'init_value': 29.84846305847168}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 11:44.21[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515114242: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018100979328155517, 'time_algorithm_update': 0.0034369776248931883, 'loss': 1.8501135134100914, 'time_step': 0.005293887138366699, 'init_value': 33.7425537109375}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 11:44.38[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515114242: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018194737434387208, 'time_algorithm_update': 0.0033326256275177, 'loss': 1.8537539133429528, 'time_step': 0.005197339534759522, 'init_value': 36.45582962036133}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 11:44.54[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515114242: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001769754409790039, 'time_algorithm_update': 0.0032629144191741945, 'loss': 1.740667541384697, 'time_step': 0.005077573776245117, 'init_value': 39.36735916137695}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 11:45.11[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515114242: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001809541940689087, 'time_algorithm_update': 0.0032550525665283204, 'loss': 1.7557485644817352, 'time_step': 0.0051084644794464115, 'init_value': 41.222965240478516}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 11:45.27[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515114242: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017892181873321532, 'time_algorithm_update': 0.0033803465366363523, 'loss': 1.7876714999079704, 'time_step': 0.005215854167938233, 'init_value': 42.800968170166016}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.800968170166016
Starting 1000 evaluations
avg return on 3 trajectories of agent1: 1419.6184464661355
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 11:59.06[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 11:59.06[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 11:59.07[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 11:59.07[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 11:59.07[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515115907[0m
[2m2025-05-15 11:59.07[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 11:59.24[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515115907: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001736656904220581, 'time_algorithm_update': 0.0031647446155548095, 'loss': 1.6885208771973848, 'time_step': 0.004944091558456421, 'init_value': 4.728419303894043}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 11:59.41[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515115907: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017639613151550293, 'time_algorithm_update': 0.0032184131145477296, 'loss': 2.3300398809313774, 'time_step': 0.005025238990783692, 'init_value': 11.971853256225586}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 11:59.57[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515115907: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017537777423858644, 'time_algorithm_update': 0.0032713148593902586, 'loss': 2.4280487276315688, 'time_step': 0.005069164752960205, 'init_value': 19.309072494506836}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 12:00.13[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515115907: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017550508975982665, 'time_algorithm_update': 0.003253009080886841, 'loss': 2.2023355907797812, 'time_step': 0.00505133318901062, 'init_value': 25.050382614135742}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 12:00.30[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515115907: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017834286689758301, 'time_algorithm_update': 0.0032267477512359618, 'loss': 2.057296746909618, 'time_step': 0.005054069995880127, 'init_value': 30.101896286010742}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 12:00.47[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515115907: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017488219738006593, 'time_algorithm_update': 0.0032051994800567627, 'loss': 1.9413701668977736, 'time_step': 0.004997687101364136, 'init_value': 33.467262268066406}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 12:01.03[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515115907: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001796410322189331, 'time_algorithm_update': 0.0034355521202087402, 'loss': 1.7742550249695779, 'time_step': 0.005279646396636963, 'init_value': 35.33172607421875}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 12:01.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515115907: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017556333541870117, 'time_algorithm_update': 0.0032490708827972413, 'loss': 1.6847226698994637, 'time_step': 0.0050483508110046385, 'init_value': 36.99724578857422}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 12:01.36[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515115907: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017805047035217285, 'time_algorithm_update': 0.0032574026584625245, 'loss': 1.6356219829320908, 'time_step': 0.0050823593139648435, 'init_value': 39.16353988647461}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 12:01.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515115907: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017514636516571046, 'time_algorithm_update': 0.0032396552562713623, 'loss': 1.7002984103560448, 'time_step': 0.005035228967666626, 'init_value': 41.461669921875}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.461669921875
Starting 1000 evaluations
avg return on 3 trajectories of agent2: 1409.163254572718
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 12:15.29[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 12:15.29[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 12:15.31[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 12:15.31[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 12:15.31[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515121531[0m
[2m2025-05-15 12:15.31[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 12:15.47[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515121531: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001756291151046753, 'time_algorithm_update': 0.003255115509033203, 'loss': 1.5912588474601508, 'time_step': 0.0050557518005371095, 'init_value': 4.6928582191467285}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 12:16.04[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515121531: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017566802501678468, 'time_algorithm_update': 0.003227816343307495, 'loss': 2.4071811547875406, 'time_step': 0.00502762770652771, 'init_value': 10.93639087677002}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 12:16.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515121531: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001777362585067749, 'time_algorithm_update': 0.0031979830265045166, 'loss': 2.2981728400588035, 'time_step': 0.005018859386444092, 'init_value': 18.09813117980957}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 12:16.37[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515121531: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017655024528503418, 'time_algorithm_update': 0.0032895009517669676, 'loss': 2.1447662974596025, 'time_step': 0.00509928822517395, 'init_value': 24.800430297851562}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 12:16.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515121531: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017533957958221435, 'time_algorithm_update': 0.0032333242893218994, 'loss': 2.1277560475468635, 'time_step': 0.005031185626983643, 'init_value': 30.4503116607666}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 12:17.10[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515121531: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017533559799194336, 'time_algorithm_update': 0.0032608020305633545, 'loss': 2.1011970821022987, 'time_step': 0.00505823016166687, 'init_value': 33.70492935180664}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 12:17.26[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515121531: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001773726463317871, 'time_algorithm_update': 0.003213114023208618, 'loss': 1.8098593111634254, 'time_step': 0.005030531406402588, 'init_value': 36.31035232543945}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 12:17.43[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515121531: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017614812850952149, 'time_algorithm_update': 0.0033115127086639404, 'loss': 1.8259766063690186, 'time_step': 0.005117479801177978, 'init_value': 38.579280853271484}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 12:17.59[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515121531: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018152852058410645, 'time_algorithm_update': 0.0033440206050872803, 'loss': 1.7020861232876778, 'time_step': 0.005205460786819458, 'init_value': 40.23106384277344}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 12:18.16[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515121531: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017611205577850342, 'time_algorithm_update': 0.003244950532913208, 'loss': 1.680535770535469, 'time_step': 0.005050358295440674, 'init_value': 42.00031280517578}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.00031280517578
Starting 1000 evaluations
avg return on 3 trajectories of agent3: 1382.1115950775813
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 12:31.51[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 12:31.51[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 12:31.53[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 12:31.53[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 12:31.53[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515123153[0m
[2m2025-05-15 12:31.53[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 12:32.09[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515123153: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017452843189239501, 'time_algorithm_update': 0.0031842613220214844, 'loss': 1.5336924410760402, 'time_step': 0.004973193645477295, 'init_value': 4.316666603088379}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 12:32.26[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515123153: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017909810543060302, 'time_algorithm_update': 0.0034076583385467527, 'loss': 2.419328316628933, 'time_step': 0.00524470329284668, 'init_value': 10.913273811340332}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 12:32.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515123153: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017963731288909912, 'time_algorithm_update': 0.003303807973861694, 'loss': 2.3417136863470076, 'time_step': 0.005144740104675293, 'init_value': 18.412769317626953}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 12:32.58[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515123153: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001764375686645508, 'time_algorithm_update': 0.0032810432910919188, 'loss': 2.1563124747276308, 'time_step': 0.005089440584182739, 'init_value': 24.0660400390625}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 12:33.15[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515123153: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001797778606414795, 'time_algorithm_update': 0.003363608360290527, 'loss': 1.99453641808033, 'time_step': 0.005206329822540283, 'init_value': 29.08660125732422}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 12:33.32[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515123153: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017712531089782715, 'time_algorithm_update': 0.003284929037094116, 'loss': 1.8860672909617424, 'time_step': 0.005100738763809204, 'init_value': 32.460975646972656}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 12:33.48[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515123153: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017770240306854248, 'time_algorithm_update': 0.0033649463653564454, 'loss': 1.895456319451332, 'time_step': 0.00518659782409668, 'init_value': 35.354949951171875}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 12:34.05[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515123153: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001768467664718628, 'time_algorithm_update': 0.0032832698822021483, 'loss': 1.7417191113233566, 'time_step': 0.0050964422225952145, 'init_value': 37.33094787597656}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 12:34.21[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515123153: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0017781379222869874, 'time_algorithm_update': 0.003385573148727417, 'loss': 1.6443427594304085, 'time_step': 0.005208647012710572, 'init_value': 40.2835807800293}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 12:34.38[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515123153: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018027033805847169, 'time_algorithm_update': 0.0033295190334320067, 'loss': 1.6670533385276793, 'time_step': 0.005177001953125, 'init_value': 40.808284759521484}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.808284759521484
Starting 1000 evaluations
avg return on 3 trajectories of agent4: 1412.1594836564352
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 12:48.31[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 12:48.31[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 12:48.33[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 12:48.33[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 12:48.33[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515124833[0m
[2m2025-05-15 12:48.33[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 12:48.51[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515124833: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019879047870635987, 'time_algorithm_update': 0.004009337902069092, 'loss': 1.7558271940201522, 'time_step': 0.006049149513244629, 'init_value': 4.168816089630127}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 12:49.10[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515124833: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020328836441040037, 'time_algorithm_update': 0.004084608554840088, 'loss': 2.3894845428466795, 'time_step': 0.006169604539871216, 'init_value': 11.0311279296875}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 12:49.28[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515124833: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019673922061920167, 'time_algorithm_update': 0.0038898587226867676, 'loss': 2.432369608283043, 'time_step': 0.005907768011093139, 'init_value': 19.16969871520996}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 12:49.48[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515124833: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021434762477874755, 'time_algorithm_update': 0.004444494247436524, 'loss': 2.0992039901018145, 'time_step': 0.006642267942428589, 'init_value': 24.70467185974121}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 12:50.06[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515124833: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002008141040802002, 'time_algorithm_update': 0.004078962802886963, 'loss': 1.950017147064209, 'time_step': 0.0061391282081604, 'init_value': 29.467805862426758}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 12:50.25[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515124833: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002058576822280884, 'time_algorithm_update': 0.004137073516845703, 'loss': 1.8765566208362578, 'time_step': 0.006248587846755981, 'init_value': 32.062007904052734}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 12:50.44[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515124833: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020207464694976807, 'time_algorithm_update': 0.004094200611114502, 'loss': 1.8403640147447586, 'time_step': 0.00616710352897644, 'init_value': 35.13783264160156}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 12:51.03[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515124833: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020594348907470705, 'time_algorithm_update': 0.004078839540481567, 'loss': 1.7525758615732192, 'time_step': 0.006190735101699829, 'init_value': 38.21897506713867}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 12:51.22[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515124833: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002021125078201294, 'time_algorithm_update': 0.004090110778808594, 'loss': 1.822710867524147, 'time_step': 0.006163215160369873, 'init_value': 40.73799133300781}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 12:51.40[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515124833: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001956174850463867, 'time_algorithm_update': 0.003826672554016113, 'loss': 1.7457390140295028, 'time_step': 0.005832373380661011, 'init_value': 41.18800735473633}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.18800735473633
Starting 1000 evaluations
avg return on 3 trajectories of agent5: 1429.70751552165
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 13:06.46[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 13:06.46[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 13:06.47[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 13:06.47[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 13:06.47[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515130647[0m
[2m2025-05-15 13:06.47[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 13:07.06[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515130647: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002051039695739746, 'time_algorithm_update': 0.004174002408981323, 'loss': 1.5895467345938086, 'time_step': 0.006277247190475464, 'init_value': 4.309807300567627}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 13:07.25[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515130647: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002019279956817627, 'time_algorithm_update': 0.004073687791824341, 'loss': 2.344506688773632, 'time_step': 0.006145111322402954, 'init_value': 10.4068021774292}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 13:07.43[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515130647: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00203233003616333, 'time_algorithm_update': 0.004025120496749878, 'loss': 2.3354917093515395, 'time_step': 0.00610909366607666, 'init_value': 17.438369750976562}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 13:08.02[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515130647: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019186487197875976, 'time_algorithm_update': 0.003796371936798096, 'loss': 2.200683264315128, 'time_step': 0.005764139175415039, 'init_value': 23.81418800354004}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 13:08.21[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515130647: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002025481462478638, 'time_algorithm_update': 0.00410708737373352, 'loss': 2.0617520329356194, 'time_step': 0.006184726238250732, 'init_value': 30.350337982177734}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 13:08.40[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515130647: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002059481143951416, 'time_algorithm_update': 0.004159111738204956, 'loss': 1.906033901810646, 'time_step': 0.006270583152770996, 'init_value': 34.06538772583008}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 13:08.58[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515130647: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002074826717376709, 'time_algorithm_update': 0.0041285955905914305, 'loss': 1.914900447487831, 'time_step': 0.006255719661712646, 'init_value': 36.707305908203125}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 13:09.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515130647: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002082419395446777, 'time_algorithm_update': 0.004292629957199097, 'loss': 1.7201863137483597, 'time_step': 0.006428521156311035, 'init_value': 38.52366638183594}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 13:09.36[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515130647: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021178417205810545, 'time_algorithm_update': 0.004291565179824829, 'loss': 1.7126457844972611, 'time_step': 0.006462555646896362, 'init_value': 40.123741149902344}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 13:09.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515130647: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020145413875579834, 'time_algorithm_update': 0.004093600034713745, 'loss': 1.752440968811512, 'time_step': 0.006160472869873047, 'init_value': 41.702579498291016}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.702579498291016
Starting 1000 evaluations
avg return on 3 trajectories of agent6: 1423.915371558811
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 13:25.04[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 13:25.04[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 13:25.05[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 13:25.05[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 13:25.05[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515132505[0m
[2m2025-05-15 13:25.05[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 13:25.24[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515132505: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020019261837005615, 'time_algorithm_update': 0.00401780366897583, 'loss': 1.7478882038444281, 'time_step': 0.0060710089206695555, 'init_value': 4.443101406097412}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 13:25.43[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515132505: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00208038854598999, 'time_algorithm_update': 0.004153908967971802, 'loss': 2.381656538903713, 'time_step': 0.006305801391601563, 'init_value': 11.838493347167969}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 13:26.02[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515132505: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020318968296051025, 'time_algorithm_update': 0.004095642566680908, 'loss': 2.31001521897316, 'time_step': 0.006180062532424927, 'init_value': 18.987112045288086}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 13:26.21[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515132505: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020559895038604736, 'time_algorithm_update': 0.004103332042694092, 'loss': 2.129056443452835, 'time_step': 0.006212290287017822, 'init_value': 25.010055541992188}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 13:26.39[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515132505: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019526331424713135, 'time_algorithm_update': 0.0038776328563690184, 'loss': 2.0196564155220984, 'time_step': 0.0058807461261749265, 'init_value': 30.02028465270996}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 13:26.58[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515132505: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020571482181549073, 'time_algorithm_update': 0.004109411001205444, 'loss': 1.8652320346832276, 'time_step': 0.006219739437103271, 'init_value': 33.948272705078125}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 13:27.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515132505: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020313873291015624, 'time_algorithm_update': 0.004123451471328735, 'loss': 1.872274432182312, 'time_step': 0.006207680225372315, 'init_value': 36.476661682128906}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 13:27.36[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515132505: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020606751441955566, 'time_algorithm_update': 0.004132497549057007, 'loss': 1.7599573543071747, 'time_step': 0.00624647855758667, 'init_value': 38.942832946777344}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 13:27.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515132505: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002059185266494751, 'time_algorithm_update': 0.004223313093185425, 'loss': 1.7415382780432702, 'time_step': 0.006335678100585937, 'init_value': 40.97133255004883}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 13:28.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515132505: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020462517738342287, 'time_algorithm_update': 0.004157577753067017, 'loss': 1.6734942644834518, 'time_step': 0.006257352352142334, 'init_value': 42.27743911743164}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.27743911743164
Starting 1000 evaluations
avg return on 3 trajectories of agent7: 1417.3006529074266
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 13:43.22[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 13:43.22[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 13:43.23[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 13:43.23[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 13:43.23[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515134323[0m
[2m2025-05-15 13:43.23[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 13:43.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515134323: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020068979263305666, 'time_algorithm_update': 0.004023788213729859, 'loss': 1.798098698720336, 'time_step': 0.006081928968429565, 'init_value': 4.498601913452148}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 13:44.00[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515134323: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001988740921020508, 'time_algorithm_update': 0.003995844125747681, 'loss': 2.314749127089977, 'time_step': 0.0060354373455047605, 'init_value': 10.775752067565918}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 13:44.19[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515134323: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019220225811004638, 'time_algorithm_update': 0.0037975034713745117, 'loss': 2.3885208134651186, 'time_step': 0.0057689988613128665, 'init_value': 18.409265518188477}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 13:44.38[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515134323: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002042379140853882, 'time_algorithm_update': 0.004141324758529663, 'loss': 2.2004024555683137, 'time_step': 0.006236205577850342, 'init_value': 24.76878547668457}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 13:44.56[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515134323: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020290017127990723, 'time_algorithm_update': 0.004027083873748779, 'loss': 1.9817693364620208, 'time_step': 0.006107877731323242, 'init_value': 28.91719627380371}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 13:45.15[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515134323: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020341789722442627, 'time_algorithm_update': 0.004125687837600708, 'loss': 1.8815771990418435, 'time_step': 0.006212647914886475, 'init_value': 33.037479400634766}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 13:45.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515134323: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00200089168548584, 'time_algorithm_update': 0.004041682481765747, 'loss': 1.855333825469017, 'time_step': 0.006094653606414795, 'init_value': 35.2613525390625}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 13:45.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515134323: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002035043478012085, 'time_algorithm_update': 0.004157507419586181, 'loss': 1.7339360944628714, 'time_step': 0.006245381116867065, 'init_value': 36.78065872192383}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 13:46.12[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515134323: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020811307430267335, 'time_algorithm_update': 0.004285452127456665, 'loss': 1.815580017209053, 'time_step': 0.006420106649398804, 'init_value': 39.8132209777832}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 13:46.30[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515134323: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019512922763824463, 'time_algorithm_update': 0.003880894899368286, 'loss': 1.8316152278184892, 'time_step': 0.0058828125, 'init_value': 41.801292419433594}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.801292419433594
Starting 1000 evaluations
avg return on 3 trajectories of agent8: 1408.1281343317323
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 14:01.34[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 14:01.34[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 14:01.35[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 14:01.35[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 14:01.35[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515140135[0m
[2m2025-05-15 14:01.35[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 14:01.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515140135: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001888237237930298, 'time_algorithm_update': 0.003682856321334839, 'loss': 1.6866622013524175, 'time_step': 0.005619656085968017, 'init_value': 4.203032493591309}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 14:02.12[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515140135: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002069756507873535, 'time_algorithm_update': 0.004149671316146851, 'loss': 2.366990894138813, 'time_step': 0.006271942138671875, 'init_value': 10.029271125793457}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 14:02.30[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515140135: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019827768802642824, 'time_algorithm_update': 0.003985252618789673, 'loss': 2.2176033047437667, 'time_step': 0.006019904375076294, 'init_value': 17.315263748168945}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 14:02.49[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515140135: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002039784669876099, 'time_algorithm_update': 0.004114199876785279, 'loss': 2.162902920305729, 'time_step': 0.006206099033355713, 'init_value': 24.10038948059082}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 14:03.08[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515140135: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002060608148574829, 'time_algorithm_update': 0.004259373664855957, 'loss': 2.0049527996182444, 'time_step': 0.006373343467712403, 'init_value': 28.546058654785156}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 14:03.27[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515140135: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002046553134918213, 'time_algorithm_update': 0.004098464727401733, 'loss': 1.888698429107666, 'time_step': 0.00619712233543396, 'init_value': 32.810726165771484}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 14:03.46[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515140135: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019984469413757322, 'time_algorithm_update': 0.00407055926322937, 'loss': 1.9537379163503648, 'time_step': 0.006121176481246948, 'init_value': 36.87165069580078}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 14:04.04[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515140135: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001982433319091797, 'time_algorithm_update': 0.0038640124797821047, 'loss': 1.8059374837875366, 'time_step': 0.005896533250808716, 'init_value': 38.77300262451172}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 14:04.23[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515140135: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002033698081970215, 'time_algorithm_update': 0.004162745475769043, 'loss': 1.728384363591671, 'time_step': 0.006249598503112793, 'init_value': 39.881778717041016}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 14:04.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515140135: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020725219249725342, 'time_algorithm_update': 0.004181240797042847, 'loss': 1.8522361468672752, 'time_step': 0.00630703067779541, 'init_value': 42.6284065246582}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.6284065246582
Starting 1000 evaluations
avg return on 3 trajectories of agent9: 1420.6915634297318
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 14:19.52[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 14:19.52[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 14:19.53[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 14:19.53[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 14:19.53[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515141953[0m
[2m2025-05-15 14:19.53[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 14:20.12[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515141953: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020293478965759276, 'time_algorithm_update': 0.0040904896259307865, 'loss': 1.8696689616888762, 'time_step': 0.006171500444412232, 'init_value': 4.102611064910889}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 14:20.30[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515141953: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019989774227142333, 'time_algorithm_update': 0.004019758462905884, 'loss': 2.412113423585892, 'time_step': 0.006070988416671753, 'init_value': 10.827667236328125}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 14:20.49[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515141953: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020576958656311037, 'time_algorithm_update': 0.0041021924018859865, 'loss': 2.375699039697647, 'time_step': 0.0062123208045959475, 'init_value': 18.408123016357422}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 14:21.09[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515141953: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020312631130218507, 'time_algorithm_update': 0.004127713680267334, 'loss': 2.1312280529737473, 'time_step': 0.006212400197982788, 'init_value': 24.47504997253418}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 14:21.27[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515141953: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020433251857757567, 'time_algorithm_update': 0.004179189443588257, 'loss': 2.1131140993237496, 'time_step': 0.006275391578674317, 'init_value': 28.94292640686035}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 14:21.46[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515141953: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001968619108200073, 'time_algorithm_update': 0.00387009334564209, 'loss': 1.8223922165036202, 'time_step': 0.005889140605926514, 'init_value': 31.94158935546875}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 14:22.05[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515141953: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020240652561187744, 'time_algorithm_update': 0.004088802099227905, 'loss': 1.8268451765179634, 'time_step': 0.006165528297424316, 'init_value': 35.866573333740234}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 14:22.24[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515141953: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002022977352142334, 'time_algorithm_update': 0.00403496789932251, 'loss': 1.8023369436264038, 'time_step': 0.0061101560592651365, 'init_value': 38.44769287109375}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 14:22.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515141953: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002007642984390259, 'time_algorithm_update': 0.004029562711715698, 'loss': 1.7657064292430877, 'time_step': 0.006089605093002319, 'init_value': 40.777652740478516}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 14:23.01[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515141953: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002101182460784912, 'time_algorithm_update': 0.004227798223495483, 'loss': 1.6803870657086373, 'time_step': 0.006382318258285523, 'init_value': 41.68987274169922}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.68987274169922
Starting 1000 evaluations
avg return on 3 trajectories of agent10: 1421.589882913222
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 14:38.09[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 14:38.09[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 14:38.10[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 14:38.10[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 14:38.10[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515143810[0m
[2m2025-05-15 14:38.10[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 14:38.29[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515143810: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002089070796966553, 'time_algorithm_update': 0.004264550447463989, 'loss': 1.655731735624373, 'time_step': 0.006407073974609375, 'init_value': 4.401595592498779}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 14:38.48[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515143810: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001997293472290039, 'time_algorithm_update': 0.003990928888320923, 'loss': 2.3940577421188354, 'time_step': 0.006039653301239014, 'init_value': 11.701519966125488}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 14:39.06[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515143810: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020387609004974367, 'time_algorithm_update': 0.004050499439239502, 'loss': 2.348459502220154, 'time_step': 0.006141870260238647, 'init_value': 19.45429039001465}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 14:39.25[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515143810: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019734761714935304, 'time_algorithm_update': 0.003943920373916626, 'loss': 2.1265862365961077, 'time_step': 0.005968520879745484, 'init_value': 25.714706420898438}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 14:39.44[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515143810: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002083676815032959, 'time_algorithm_update': 0.004170235872268677, 'loss': 2.0177993720173837, 'time_step': 0.006306748867034912, 'init_value': 30.571531295776367}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 14:40.03[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515143810: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020385115146636964, 'time_algorithm_update': 0.0041318731307983395, 'loss': 1.872824368238449, 'time_step': 0.006222902774810791, 'init_value': 33.87328338623047}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 14:40.21[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515143810: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001945072889328003, 'time_algorithm_update': 0.003870492458343506, 'loss': 1.7571794250011443, 'time_step': 0.00586611557006836, 'init_value': 36.06769943237305}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 14:40.40[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515143810: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002042880296707153, 'time_algorithm_update': 0.004170310497283935, 'loss': 1.7314925360679627, 'time_step': 0.0062669339179992675, 'init_value': 37.290897369384766}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 14:40.59[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515143810: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002092495918273926, 'time_algorithm_update': 0.004174057006835937, 'loss': 1.6540908757448196, 'time_step': 0.006319516658782959, 'init_value': 39.45455551147461}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 14:41.18[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515143810: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002075909614562988, 'time_algorithm_update': 0.004246797561645508, 'loss': 1.6097737365365028, 'time_step': 0.00637595534324646, 'init_value': 41.13911056518555}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.13911056518555
Starting 1000 evaluations
avg return on 3 trajectories of agent11: 1407.8245526192638
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 14:56.31[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 14:56.31[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 14:56.32[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 14:56.32[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 14:56.32[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515145632[0m
[2m2025-05-15 14:56.32[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 14:56.50[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515145632: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020157067775726316, 'time_algorithm_update': 0.004133973836898804, 'loss': 1.6385919941365719, 'time_step': 0.006202096462249756, 'init_value': 4.152820110321045}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 14:57.09[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515145632: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019910941123962404, 'time_algorithm_update': 0.003926552772521972, 'loss': 2.289519081413746, 'time_step': 0.005967853546142578, 'init_value': 10.437357902526855}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 14:57.28[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515145632: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002020693302154541, 'time_algorithm_update': 0.0041092393398284915, 'loss': 2.351656376004219, 'time_step': 0.006182073354721069, 'init_value': 18.322839736938477}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 14:57.47[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515145632: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002044567346572876, 'time_algorithm_update': 0.00408778715133667, 'loss': 2.1519849941134455, 'time_step': 0.006184616565704346, 'init_value': 24.390779495239258}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 14:58.05[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515145632: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00193288254737854, 'time_algorithm_update': 0.0038581297397613525, 'loss': 1.9279331302642821, 'time_step': 0.005840883493423462, 'init_value': 29.371078491210938}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 14:58.24[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515145632: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002112969160079956, 'time_algorithm_update': 0.0043025617599487306, 'loss': 1.871013228058815, 'time_step': 0.0064692022800445555, 'init_value': 32.5465202331543}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 14:58.43[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515145632: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019887921810150147, 'time_algorithm_update': 0.004055750608444214, 'loss': 1.8143843326568603, 'time_step': 0.006096481800079346, 'init_value': 35.429779052734375}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 14:59.02[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515145632: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001992790460586548, 'time_algorithm_update': 0.004085278511047364, 'loss': 1.8418660924434662, 'time_step': 0.006130821228027343, 'init_value': 37.84891891479492}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 14:59.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515145632: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001926828145980835, 'time_algorithm_update': 0.003850240707397461, 'loss': 1.744743455529213, 'time_step': 0.005827181816101075, 'init_value': 38.480690002441406}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 14:59.40[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515145632: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002113642454147339, 'time_algorithm_update': 0.004359888792037964, 'loss': 1.7831820939183236, 'time_step': 0.0065277543067932126, 'init_value': 40.53739547729492}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.53739547729492
Starting 1000 evaluations
avg return on 3 trajectories of agent12: 1407.395263905351
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 15:14.47[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 15:14.47[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 15:14.48[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 15:14.48[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 15:14.48[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515151448[0m
[2m2025-05-15 15:14.48[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 15:15.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515151448: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002024127721786499, 'time_algorithm_update': 0.0041219983100891115, 'loss': 1.5699096801131964, 'time_step': 0.006198673009872436, 'init_value': 3.9171152114868164}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 15:15.26[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515151448: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021194119453430177, 'time_algorithm_update': 0.0042508399486541745, 'loss': 2.262455882847309, 'time_step': 0.006423155784606934, 'init_value': 10.734435081481934}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 15:15.45[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515151448: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002024384021759033, 'time_algorithm_update': 0.0041160333156585694, 'loss': 2.187460465848446, 'time_step': 0.006192752838134766, 'init_value': 18.007373809814453}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 15:16.04[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515151448: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019819695949554444, 'time_algorithm_update': 0.003938273191452026, 'loss': 2.0881010763645174, 'time_step': 0.005969966411590576, 'init_value': 24.44452667236328}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 15:16.23[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515151448: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002082820177078247, 'time_algorithm_update': 0.004253735065460205, 'loss': 2.018901488125324, 'time_step': 0.006389594316482544, 'init_value': 30.047420501708984}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 15:16.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515151448: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020741162300109864, 'time_algorithm_update': 0.0041914088726043705, 'loss': 1.8504955163002015, 'time_step': 0.006317792892456054, 'init_value': 33.29090881347656}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 15:17.00[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515151448: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019620916843414308, 'time_algorithm_update': 0.0038889729976654052, 'loss': 1.9074556844234467, 'time_step': 0.00590168809890747, 'init_value': 36.70241165161133}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 15:17.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515151448: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002107123851776123, 'time_algorithm_update': 0.004261342525482178, 'loss': 1.8164774852991104, 'time_step': 0.006422018051147461, 'init_value': 39.63111877441406}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 15:17.39[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515151448: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020381765365600586, 'time_algorithm_update': 0.004134168863296509, 'loss': 1.8483093050122261, 'time_step': 0.006225058078765869, 'init_value': 40.60179138183594}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 15:17.57[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515151448: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002129936456680298, 'time_algorithm_update': 0.004236842632293701, 'loss': 1.7489477078318596, 'time_step': 0.006420744180679321, 'init_value': 42.806114196777344}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.806114196777344
Starting 1000 evaluations
avg return on 3 trajectories of agent13: 1404.0760736642364
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 15:33.06[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 15:33.06[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 15:33.08[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 15:33.08[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 15:33.08[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515153308[0m
[2m2025-05-15 15:33.08[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 15:33.27[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515153308: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020173614025115966, 'time_algorithm_update': 0.0040726721286773685, 'loss': 1.6922463520690798, 'time_step': 0.006141676425933838, 'init_value': 4.784064292907715}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 15:33.46[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515153308: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002024744987487793, 'time_algorithm_update': 0.004118863344192505, 'loss': 2.4613128007650373, 'time_step': 0.006196210861206055, 'init_value': 11.282939910888672}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 15:34.05[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515153308: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020338263511657717, 'time_algorithm_update': 0.004179805278778076, 'loss': 2.3323928381800654, 'time_step': 0.006266188383102417, 'init_value': 18.912540435791016}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 15:34.23[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515153308: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001933863401412964, 'time_algorithm_update': 0.0038743340969085694, 'loss': 2.1780709788799286, 'time_step': 0.005858530521392822, 'init_value': 26.225793838500977}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 15:34.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515153308: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020733087062835692, 'time_algorithm_update': 0.004168720006942749, 'loss': 1.9755446307063103, 'time_step': 0.006295130491256714, 'init_value': 29.874969482421875}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 15:35.01[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515153308: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002035611867904663, 'time_algorithm_update': 0.004187823295593262, 'loss': 1.8332722862958908, 'time_step': 0.006276003837585449, 'init_value': 33.21311569213867}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 15:35.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515153308: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019913594722747803, 'time_algorithm_update': 0.004050848484039307, 'loss': 1.8376907618045808, 'time_step': 0.006094473123550415, 'init_value': 37.094207763671875}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 15:35.38[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515153308: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001961510181427002, 'time_algorithm_update': 0.00393798565864563, 'loss': 1.825043716430664, 'time_step': 0.005950091361999511, 'init_value': 38.678035736083984}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 15:35.58[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515153308: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020371055603027343, 'time_algorithm_update': 0.004174247264862061, 'loss': 1.7133604689836501, 'time_step': 0.006264183759689331, 'init_value': 40.424076080322266}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 15:36.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515153308: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002051534414291382, 'time_algorithm_update': 0.004164160490036011, 'loss': 1.689513338804245, 'time_step': 0.00626813793182373, 'init_value': 43.159812927246094}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 43.159812927246094
Starting 1000 evaluations
avg return on 3 trajectories of agent14: 1402.7229145220733
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 15:51.28[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 15:51.28[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 15:51.29[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 15:51.29[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 15:51.29[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515155129[0m
[2m2025-05-15 15:51.29[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 15:51.48[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515155129: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00200376296043396, 'time_algorithm_update': 0.004011114120483398, 'loss': 1.8015088570043445, 'time_step': 0.006066652774810791, 'init_value': 4.480283737182617}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 15:52.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515155129: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001958845376968384, 'time_algorithm_update': 0.0039047479629516603, 'loss': 2.1882705944776535, 'time_step': 0.005914138078689575, 'init_value': 11.222277641296387}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 15:52.26[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515155129: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020732288360595704, 'time_algorithm_update': 0.00413048243522644, 'loss': 2.353331442952156, 'time_step': 0.00625660252571106, 'init_value': 18.885391235351562}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 15:52.44[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515155129: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002026524066925049, 'time_algorithm_update': 0.004133856296539307, 'loss': 2.1142029978036883, 'time_step': 0.0062130591869354245, 'init_value': 25.140613555908203}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 15:53.03[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515155129: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020365240573883055, 'time_algorithm_update': 0.004009942054748535, 'loss': 2.0527829639315605, 'time_step': 0.006098251342773437, 'init_value': 30.83926773071289}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 15:53.22[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515155129: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020448408126831053, 'time_algorithm_update': 0.004186723709106445, 'loss': 1.9708147213459015, 'time_step': 0.0062841160297393795, 'init_value': 34.20598602294922}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 15:53.41[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515155129: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002038444995880127, 'time_algorithm_update': 0.0041467583179473876, 'loss': 1.7660325551629066, 'time_step': 0.00623878264427185, 'init_value': 35.3056755065918}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 15:54.00[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515155129: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002014122009277344, 'time_algorithm_update': 0.004097737312316894, 'loss': 1.7023418244123458, 'time_step': 0.006164303064346313, 'init_value': 37.94338607788086}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 15:54.18[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515155129: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019476535320281983, 'time_algorithm_update': 0.0037976129055023195, 'loss': 1.7904366763234139, 'time_step': 0.005795152187347412, 'init_value': 39.8345832824707}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 15:54.37[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515155129: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002045933485031128, 'time_algorithm_update': 0.004169327974319458, 'loss': 1.7599160056710244, 'time_step': 0.006268455743789673, 'init_value': 40.79936218261719}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.79936218261719
Starting 1000 evaluations
avg return on 3 trajectories of agent15: 1388.181336656406
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 16:09.50[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 16:09.50[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 16:09.51[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 16:09.51[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 16:09.51[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515160951[0m
[2m2025-05-15 16:09.51[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 16:10.10[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515160951: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020115602016448973, 'time_algorithm_update': 0.00409232759475708, 'loss': 1.8126692520901562, 'time_step': 0.006156126022338867, 'init_value': 4.4555792808532715}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 16:10.29[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515160951: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002086174249649048, 'time_algorithm_update': 0.004177234888076782, 'loss': 2.4939203909635546, 'time_step': 0.006316409111022949, 'init_value': 11.616165161132812}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 16:10.48[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515160951: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001927168607711792, 'time_algorithm_update': 0.0038271877765655516, 'loss': 2.3218364448547364, 'time_step': 0.0058045580387115474, 'init_value': 19.716745376586914}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 16:11.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515160951: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020839924812316893, 'time_algorithm_update': 0.0042308931350708, 'loss': 2.2228848188519477, 'time_step': 0.006368515729904175, 'init_value': 26.269105911254883}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 16:11.25[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515160951: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002005279302597046, 'time_algorithm_update': 0.004082741737365722, 'loss': 2.0447471881508825, 'time_step': 0.006139595746994018, 'init_value': 29.37250518798828}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 16:11.44[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515160951: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020184314250946047, 'time_algorithm_update': 0.0040245063304901125, 'loss': 1.927468332886696, 'time_step': 0.006094287633895874, 'init_value': 32.480751037597656}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 16:12.03[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515160951: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020341618061065674, 'time_algorithm_update': 0.004170210599899292, 'loss': 1.9015069587230682, 'time_step': 0.006257120609283447, 'init_value': 36.52247619628906}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 16:12.22[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515160951: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020617601871490477, 'time_algorithm_update': 0.004142363071441651, 'loss': 1.8636822575330734, 'time_step': 0.0062573163509368895, 'init_value': 38.93649673461914}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 16:12.41[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515160951: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002030257225036621, 'time_algorithm_update': 0.004153866052627564, 'loss': 1.7755608048439027, 'time_step': 0.006236860990524292, 'init_value': 40.28091812133789}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 16:13.00[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515160951: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001999690771102905, 'time_algorithm_update': 0.004000092506408691, 'loss': 1.7864562366008758, 'time_step': 0.006052072763442993, 'init_value': 43.66294479370117}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 43.66294479370117
Starting 1000 evaluations
avg return on 3 trajectories of agent16: 1408.2239886721786
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 16:28.11[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 16:28.11[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 16:28.12[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 16:28.12[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 16:28.12[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515162812[0m
[2m2025-05-15 16:28.12[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 16:28.31[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515162812: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001985609769821167, 'time_algorithm_update': 0.004003079414367676, 'loss': 1.6086429021060467, 'time_step': 0.006039412021636963, 'init_value': 4.093593597412109}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 16:28.50[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515162812: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020605621337890625, 'time_algorithm_update': 0.004162755012512207, 'loss': 2.580554513275623, 'time_step': 0.006276484966278076, 'init_value': 10.35149097442627}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 16:29.09[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515162812: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002041146993637085, 'time_algorithm_update': 0.004202952623367309, 'loss': 2.338846317708492, 'time_step': 0.006297114849090576, 'init_value': 18.21245002746582}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 16:29.27[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515162812: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020016624927520752, 'time_algorithm_update': 0.0039800496101379396, 'loss': 2.2033265435099603, 'time_step': 0.006032895565032959, 'init_value': 24.87696647644043}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 16:29.47[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515162812: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00204327654838562, 'time_algorithm_update': 0.004190984964370727, 'loss': 1.9577463517785072, 'time_step': 0.00628687572479248, 'init_value': 29.167781829833984}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 16:30.06[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515162812: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002115206480026245, 'time_algorithm_update': 0.004316200256347656, 'loss': 1.8392263879776, 'time_step': 0.006485211372375488, 'init_value': 32.955650329589844}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 16:30.25[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515162812: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020019795894622803, 'time_algorithm_update': 0.004045128107070923, 'loss': 1.7565656690597533, 'time_step': 0.006098843336105346, 'init_value': 34.70726776123047}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 16:30.44[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515162812: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00210860538482666, 'time_algorithm_update': 0.004272951602935791, 'loss': 1.6790705012083054, 'time_step': 0.0064359033107757565, 'init_value': 36.367855072021484}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 16:31.03[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515162812: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002056610584259033, 'time_algorithm_update': 0.0042122390270233154, 'loss': 1.6632861768603324, 'time_step': 0.006322365045547485, 'init_value': 38.661651611328125}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 16:31.22[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515162812: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002077291011810303, 'time_algorithm_update': 0.00420809531211853, 'loss': 1.778497318804264, 'time_step': 0.006338438034057617, 'init_value': 40.37504577636719}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.37504577636719
Starting 1000 evaluations
avg return on 3 trajectories of agent17: 1400.2087785267336
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 16:46.25[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 16:46.25[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 16:46.26[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 16:46.26[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 16:46.26[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515164626[0m
[2m2025-05-15 16:46.26[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 16:46.45[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515164626: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001993025541305542, 'time_algorithm_update': 0.0040291731357574466, 'loss': 1.833356444567442, 'time_step': 0.0060737781524658205, 'init_value': 4.594107627868652}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 16:47.04[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515164626: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020703790187835695, 'time_algorithm_update': 0.004253875255584716, 'loss': 2.5112316987514496, 'time_step': 0.006377237319946289, 'init_value': 11.695802688598633}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 16:47.23[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515164626: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002080862283706665, 'time_algorithm_update': 0.004177819967269897, 'loss': 2.516570360124111, 'time_step': 0.006311721801757812, 'init_value': 18.469650268554688}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 16:47.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515164626: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002016831398010254, 'time_algorithm_update': 0.004135233402252197, 'loss': 2.31189884865284, 'time_step': 0.006204252243041992, 'init_value': 24.760141372680664}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 16:48.00[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515164626: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019813332557678223, 'time_algorithm_update': 0.0039945683479309085, 'loss': 1.9674798204898833, 'time_step': 0.006027165174484253, 'init_value': 29.13725471496582}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 16:48.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515164626: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020407118797302246, 'time_algorithm_update': 0.004196615934371949, 'loss': 1.913963449060917, 'time_step': 0.006290375471115112, 'init_value': 32.33277130126953}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 16:48.39[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515164626: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002103269338607788, 'time_algorithm_update': 0.004265279769897461, 'loss': 1.7700022488832474, 'time_step': 0.006421807050704956, 'init_value': 34.790855407714844}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 16:48.58[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515164626: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019505698680877686, 'time_algorithm_update': 0.003926476001739502, 'loss': 1.7586716350913048, 'time_step': 0.005927530288696289, 'init_value': 37.90336227416992}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 16:49.16[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515164626: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020325703620910646, 'time_algorithm_update': 0.0041549990177154545, 'loss': 1.6279638885259629, 'time_step': 0.006240579605102539, 'init_value': 39.40229415893555}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 16:49.36[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515164626: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002024038076400757, 'time_algorithm_update': 0.00412955379486084, 'loss': 1.6561874256134033, 'time_step': 0.0062061607837677005, 'init_value': 40.41574478149414}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.41574478149414
Starting 1000 evaluations
avg return on 3 trajectories of agent18: 1412.8138277356088
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 17:04.50[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 17:04.50[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 17:04.52[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 17:04.52[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 17:04.52[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515170452[0m
[2m2025-05-15 17:04.52[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 17:05.10[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515170452: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001982740879058838, 'time_algorithm_update': 0.003988498210906982, 'loss': 1.7075605532452465, 'time_step': 0.00602254581451416, 'init_value': 4.456455230712891}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 17:05.29[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515170452: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020302321910858154, 'time_algorithm_update': 0.0041309077739715575, 'loss': 2.218890877008438, 'time_step': 0.006213420629501342, 'init_value': 11.018460273742676}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 17:05.48[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515170452: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002033200263977051, 'time_algorithm_update': 0.004169427394866944, 'loss': 2.1939095677733422, 'time_step': 0.0062556638717651365, 'init_value': 17.955663681030273}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 17:06.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515170452: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002025113105773926, 'time_algorithm_update': 0.00416592526435852, 'loss': 2.0919032109379767, 'time_step': 0.0062439172267913816, 'init_value': 24.54120445251465}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 17:06.25[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515170452: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020217087268829346, 'time_algorithm_update': 0.00405743408203125, 'loss': 2.020605371296406, 'time_step': 0.006131537437438965, 'init_value': 28.30512809753418}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 17:06.45[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515170452: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020322842597961426, 'time_algorithm_update': 0.0041754024028778074, 'loss': 1.9625756011009217, 'time_step': 0.00626078200340271, 'init_value': 32.990753173828125}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 17:07.04[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515170452: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00206615948677063, 'time_algorithm_update': 0.004285278558731079, 'loss': 1.8439559448957443, 'time_step': 0.0064049108028411865, 'init_value': 34.87902069091797}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 17:07.22[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515170452: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019373166561126708, 'time_algorithm_update': 0.003885854482650757, 'loss': 1.7123199162483216, 'time_step': 0.005873197793960571, 'init_value': 36.65520477294922}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 17:07.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515170452: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020957279205322268, 'time_algorithm_update': 0.00426894474029541, 'loss': 1.627320979297161, 'time_step': 0.006418748378753662, 'init_value': 38.60478973388672}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 17:08.01[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515170452: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002060811996459961, 'time_algorithm_update': 0.004170043468475342, 'loss': 1.753175495326519, 'time_step': 0.006284157514572144, 'init_value': 40.50496292114258}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.50496292114258
Starting 1000 evaluations
avg return on 3 trajectories of agent19: 1404.4642737153986
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 17:23.11[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 17:23.11[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 17:23.12[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 17:23.12[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 17:23.12[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515172312[0m
[2m2025-05-15 17:23.12[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 17:23.31[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515172312: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019556286334991456, 'time_algorithm_update': 0.0038371169567108154, 'loss': 2.023567823305726, 'time_step': 0.005842920780181885, 'init_value': 4.600612163543701}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 17:23.50[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515172312: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020819196701049804, 'time_algorithm_update': 0.004270208358764648, 'loss': 2.2887930926084517, 'time_step': 0.006405230283737183, 'init_value': 11.550371170043945}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 17:24.09[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515172312: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020399446487426756, 'time_algorithm_update': 0.004086977005004883, 'loss': 2.4534025900363923, 'time_step': 0.0061793382167816165, 'init_value': 19.351783752441406}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 17:24.27[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515172312: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00200924015045166, 'time_algorithm_update': 0.004037205696105957, 'loss': 2.1605973441004753, 'time_step': 0.006098469018936157, 'init_value': 24.60519027709961}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 17:24.46[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515172312: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020176160335540773, 'time_algorithm_update': 0.004063333988189697, 'loss': 1.9608932682871818, 'time_step': 0.006133276700973511, 'init_value': 28.959583282470703}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 17:25.05[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515172312: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002034777879714966, 'time_algorithm_update': 0.004114984035491943, 'loss': 1.9056773782372474, 'time_step': 0.006202396154403687, 'init_value': 32.6815299987793}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 17:25.24[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515172312: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002052052736282349, 'time_algorithm_update': 0.004070588111877441, 'loss': 1.7379608384370804, 'time_step': 0.0061752347946167, 'init_value': 34.98845672607422}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 17:25.43[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515172312: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019520530700683594, 'time_algorithm_update': 0.0038886654376983644, 'loss': 1.7673044609427453, 'time_step': 0.005891274452209472, 'init_value': 37.01410675048828}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 17:26.01[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515172312: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020144948959350587, 'time_algorithm_update': 0.004080946922302246, 'loss': 1.7538828917741776, 'time_step': 0.006148039102554321, 'init_value': 38.489418029785156}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 17:26.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515172312: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020191776752471924, 'time_algorithm_update': 0.004060016870498657, 'loss': 1.6590396549701691, 'time_step': 0.006131486654281616, 'init_value': 40.54640197753906}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.54640197753906
ave advantage rew: 41.61528644561768, std: 0.9830420963317831
avg cum rews: 1409.1391627515557, std: 11.22038705365746
Pearson correlation coefficient: -0.06961111738413839
Spearman correlation coefficient: -0.02406015037593985
Kendall Tau correlation coefficient: -0.052631578947368425
the best agent: 5, best agent cum rewards: 1429.70751552165
1967
Starting to collect rollouts
Collecting rollouts: 10000/1000000
Collecting rollouts: 20000/1000000
Collecting rollouts: 30000/1000000
Collecting rollouts: 40000/1000000
Collecting rollouts: 50000/1000000
Collecting rollouts: 60000/1000000
Collecting rollouts: 70000/1000000
Collecting rollouts: 80000/1000000
Collecting rollouts: 90000/1000000
Collecting rollouts: 100000/1000000
Collecting rollouts: 110000/1000000
Collecting rollouts: 120000/1000000
Collecting rollouts: 130000/1000000
Collecting rollouts: 140000/1000000
Collecting rollouts: 150000/1000000
Collecting rollouts: 160000/1000000
Collecting rollouts: 170000/1000000
Collecting rollouts: 180000/1000000
Collecting rollouts: 190000/1000000
Collecting rollouts: 200000/1000000
Collecting rollouts: 210000/1000000
Collecting rollouts: 220000/1000000
Collecting rollouts: 230000/1000000
Collecting rollouts: 240000/1000000
Collecting rollouts: 250000/1000000
Collecting rollouts: 260000/1000000
Collecting rollouts: 270000/1000000
Collecting rollouts: 280000/1000000
Collecting rollouts: 290000/1000000
Collecting rollouts: 300000/1000000
Collecting rollouts: 310000/1000000
Collecting rollouts: 320000/1000000
Collecting rollouts: 330000/1000000
Collecting rollouts: 340000/1000000
Collecting rollouts: 350000/1000000
Collecting rollouts: 360000/1000000
Collecting rollouts: 370000/1000000
Collecting rollouts: 380000/1000000
Collecting rollouts: 390000/1000000
Collecting rollouts: 400000/1000000
Collecting rollouts: 410000/1000000
Collecting rollouts: 420000/1000000
Collecting rollouts: 430000/1000000
Collecting rollouts: 440000/1000000
Collecting rollouts: 450000/1000000
Collecting rollouts: 460000/1000000
Collecting rollouts: 470000/1000000
Collecting rollouts: 480000/1000000
Collecting rollouts: 490000/1000000
Collecting rollouts: 500000/1000000
Collecting rollouts: 510000/1000000
Collecting rollouts: 520000/1000000
Collecting rollouts: 530000/1000000
Collecting rollouts: 540000/1000000
Collecting rollouts: 550000/1000000
Collecting rollouts: 560000/1000000
Collecting rollouts: 570000/1000000
Collecting rollouts: 580000/1000000
Collecting rollouts: 590000/1000000
Collecting rollouts: 600000/1000000
Collecting rollouts: 610000/1000000
Collecting rollouts: 620000/1000000
Collecting rollouts: 630000/1000000
Collecting rollouts: 640000/1000000
Collecting rollouts: 650000/1000000
Collecting rollouts: 660000/1000000
Collecting rollouts: 670000/1000000
Collecting rollouts: 680000/1000000
Collecting rollouts: 690000/1000000
Collecting rollouts: 700000/1000000
Collecting rollouts: 710000/1000000
Collecting rollouts: 720000/1000000
Collecting rollouts: 730000/1000000
Collecting rollouts: 740000/1000000
Collecting rollouts: 750000/1000000
Collecting rollouts: 760000/1000000
Collecting rollouts: 770000/1000000
Collecting rollouts: 780000/1000000
Collecting rollouts: 790000/1000000
Collecting rollouts: 800000/1000000
Collecting rollouts: 810000/1000000
Collecting rollouts: 820000/1000000
Collecting rollouts: 830000/1000000
Collecting rollouts: 840000/1000000
Collecting rollouts: 850000/1000000
Collecting rollouts: 860000/1000000
Collecting rollouts: 870000/1000000
Collecting rollouts: 880000/1000000
Collecting rollouts: 890000/1000000
Collecting rollouts: 900000/1000000
Collecting rollouts: 910000/1000000
Collecting rollouts: 920000/1000000
Collecting rollouts: 930000/1000000
Collecting rollouts: 940000/1000000
Collecting rollouts: 950000/1000000
Collecting rollouts: 960000/1000000
Collecting rollouts: 970000/1000000
Collecting rollouts: 980000/1000000
Collecting rollouts: 990000/1000000
Collecting rollouts: 1000000/1000000
Replay buffer size:  (1000000, 105)
Replay buffer saved
---------------------------------
Searching empty space policies
(10, 11472)
(20, 11472)
(20, 11472)
Average distance of agents to nearest neighbors: 0.019049548596056214
Starting 1000 evaluations
avg return on 3 trajectories of agent0: 1437.1957777341831
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 17:59.45[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 17:59.45[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 17:59.46[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 17:59.46[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 17:59.46[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515175946[0m
[2m2025-05-15 17:59.46[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 18:00.05[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515175946: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020199437141418457, 'time_algorithm_update': 0.0040419516563415525, 'loss': 1.7531486995890737, 'time_step': 0.006113885641098022, 'init_value': 3.8951449394226074}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 18:00.24[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515175946: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020453264713287352, 'time_algorithm_update': 0.004116329193115234, 'loss': 2.1218596435189245, 'time_step': 0.006214345216751098, 'init_value': 10.852410316467285}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 18:00.43[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515175946: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019955787658691407, 'time_algorithm_update': 0.0038939335346221925, 'loss': 2.2711773664951322, 'time_step': 0.0059405572414398195, 'init_value': 17.918283462524414}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 18:01.02[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515175946: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002064230442047119, 'time_algorithm_update': 0.004168946981430053, 'loss': 2.220381139576435, 'time_step': 0.006285541772842408, 'init_value': 24.62359619140625}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 18:01.21[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515175946: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020981175899505615, 'time_algorithm_update': 0.004165747404098511, 'loss': 1.9370665317177773, 'time_step': 0.006317273616790771, 'init_value': 29.15030288696289}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 18:01.40[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515175946: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019952526092529297, 'time_algorithm_update': 0.003972609758377075, 'loss': 1.7712894633412362, 'time_step': 0.006019103050231934, 'init_value': 32.01506423950195}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 18:01.59[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515175946: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002059783935546875, 'time_algorithm_update': 0.004169990539550781, 'loss': 1.7496377872228623, 'time_step': 0.0062829766273498535, 'init_value': 34.730712890625}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 18:02.18[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515175946: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020692167282104494, 'time_algorithm_update': 0.004215962648391723, 'loss': 1.6933642805218696, 'time_step': 0.006338543891906738, 'init_value': 38.05836486816406}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 18:02.37[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515175946: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020877466201782227, 'time_algorithm_update': 0.00413415002822876, 'loss': 1.722390706717968, 'time_step': 0.006274874448776245, 'init_value': 40.543373107910156}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 18:02.56[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515175946: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00208315372467041, 'time_algorithm_update': 0.004226189374923706, 'loss': 1.5654221294522286, 'time_step': 0.0063628249168395995, 'init_value': 40.795631408691406}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.795631408691406
Starting 1000 evaluations
avg return on 3 trajectories of agent1: 1444.4104475783292
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 18:18.02[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 18:18.02[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 18:18.04[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 18:18.04[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 18:18.04[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515181804[0m
[2m2025-05-15 18:18.04[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 18:18.22[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515181804: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020061051845550537, 'time_algorithm_update': 0.004043831586837769, 'loss': 1.5498428621739149, 'time_step': 0.006102056503295899, 'init_value': 4.319897651672363}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 18:18.41[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515181804: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020312986373901367, 'time_algorithm_update': 0.004059662342071533, 'loss': 2.2954563575387, 'time_step': 0.006143240451812744, 'init_value': 11.465514183044434}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 18:19.00[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515181804: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019885463714599608, 'time_algorithm_update': 0.004012871265411377, 'loss': 2.3632291883826255, 'time_step': 0.006053710699081421, 'init_value': 19.383453369140625}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 18:19.19[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515181804: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020408146381378175, 'time_algorithm_update': 0.00410263204574585, 'loss': 2.107502624690533, 'time_step': 0.006196279525756836, 'init_value': 25.861955642700195}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 18:19.37[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515181804: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002005906581878662, 'time_algorithm_update': 0.004029038906097412, 'loss': 2.023559204161167, 'time_step': 0.006087000846862793, 'init_value': 29.538148880004883}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 18:19.56[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515181804: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020667672157287597, 'time_algorithm_update': 0.004076863288879394, 'loss': 1.8606336328983306, 'time_step': 0.006196575403213501, 'init_value': 32.103302001953125}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 18:20.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515181804: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019262242317199707, 'time_algorithm_update': 0.00378472113609314, 'loss': 1.8068643884658813, 'time_step': 0.005761410713195801, 'init_value': 33.507171630859375}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 18:20.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515181804: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020870606899261474, 'time_algorithm_update': 0.004200910806655884, 'loss': 1.8827127265930175, 'time_step': 0.006340787649154663, 'init_value': 37.222835540771484}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 18:20.52[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515181804: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00200079345703125, 'time_algorithm_update': 0.0040119941234588626, 'loss': 1.7382857005596162, 'time_step': 0.006065669298171997, 'init_value': 40.13467025756836}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 18:21.10[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515181804: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001977216720581055, 'time_algorithm_update': 0.003855187654495239, 'loss': 1.623137609064579, 'time_step': 0.00588310718536377, 'init_value': 40.55936813354492}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.55936813354492
Starting 1000 evaluations
avg return on 3 trajectories of agent2: 1447.044180601063
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 18:36.36[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 18:36.36[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 18:36.37[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 18:36.37[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 18:36.37[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515183637[0m
[2m2025-05-15 18:36.37[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 18:36.56[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515183637: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001977365255355835, 'time_algorithm_update': 0.003909050226211548, 'loss': 1.6173684444203973, 'time_step': 0.005936881065368652, 'init_value': 4.059124946594238}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 18:37.15[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515183637: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002070547103881836, 'time_algorithm_update': 0.004174216985702515, 'loss': 2.2561823307275772, 'time_step': 0.0062976241111755375, 'init_value': 11.103798866271973}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 18:37.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515183637: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020825629234313965, 'time_algorithm_update': 0.004246825933456421, 'loss': 2.324316537082195, 'time_step': 0.0063831484317779545, 'init_value': 18.534015655517578}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 18:37.54[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515183637: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020628194808959962, 'time_algorithm_update': 0.004217927694320679, 'loss': 2.1551249482631682, 'time_step': 0.006332957029342652, 'init_value': 26.5657901763916}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 18:38.13[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515183637: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021294322013854982, 'time_algorithm_update': 0.004283362150192261, 'loss': 2.0418969928622244, 'time_step': 0.006466889858245849, 'init_value': 31.325193405151367}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 18:38.33[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515183637: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002104072093963623, 'time_algorithm_update': 0.004295521497726441, 'loss': 1.9193838879466056, 'time_step': 0.006452767372131347, 'init_value': 33.68924331665039}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 18:38.52[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515183637: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020506038665771484, 'time_algorithm_update': 0.004124929428100586, 'loss': 1.815640206217766, 'time_step': 0.006228096008300781, 'init_value': 36.094512939453125}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 18:39.11[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515183637: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002120495080947876, 'time_algorithm_update': 0.0042062711715698245, 'loss': 1.7648473633527755, 'time_step': 0.006379579305648804, 'init_value': 37.63725662231445}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 18:39.30[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515183637: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00207958984375, 'time_algorithm_update': 0.0041442873477935795, 'loss': 1.7325706087350845, 'time_step': 0.006276726484298706, 'init_value': 39.27707290649414}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 18:39.49[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515183637: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020852580070495606, 'time_algorithm_update': 0.004151872396469116, 'loss': 1.7447018548846245, 'time_step': 0.006290527820587158, 'init_value': 40.32588195800781}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.32588195800781
Starting 1000 evaluations
avg return on 3 trajectories of agent3: 1441.7726295825248
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 18:55.16[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 18:55.16[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 18:55.17[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 18:55.17[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 18:55.17[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515185517[0m
[2m2025-05-15 18:55.17[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 18:55.36[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515185517: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020555226802825926, 'time_algorithm_update': 0.0041804807186126705, 'loss': 1.7204101990908385, 'time_step': 0.0062890067100524905, 'init_value': 4.357005596160889}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 18:55.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515185517: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019830501079559325, 'time_algorithm_update': 0.003942680120468139, 'loss': 2.2218873235583305, 'time_step': 0.00597631573677063, 'init_value': 11.098565101623535}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 18:56.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515185517: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002129565715789795, 'time_algorithm_update': 0.004286664962768555, 'loss': 2.26426770311594, 'time_step': 0.006469647407531739, 'init_value': 18.86205291748047}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 18:56.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515185517: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002112522602081299, 'time_algorithm_update': 0.004391381502151489, 'loss': 2.1156848518252374, 'time_step': 0.00655806827545166, 'init_value': 26.02155876159668}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 18:56.52[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515185517: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002017641544342041, 'time_algorithm_update': 0.0040451853275299075, 'loss': 2.0378864502906797, 'time_step': 0.006114431619644165, 'init_value': 30.46910858154297}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 18:57.12[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515185517: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021043806076049805, 'time_algorithm_update': 0.004303515195846558, 'loss': 1.8995008002519607, 'time_step': 0.006460841178894043, 'init_value': 34.0803337097168}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 18:57.32[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515185517: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020871973037719727, 'time_algorithm_update': 0.0042923114299774166, 'loss': 1.8494819546341896, 'time_step': 0.0064329438209533695, 'init_value': 36.033363342285156}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 18:57.50[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515185517: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002057234525680542, 'time_algorithm_update': 0.004176376104354859, 'loss': 1.8121788892149926, 'time_step': 0.006285690307617188, 'init_value': 38.12997817993164}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 18:58.10[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515185517: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021346178054809572, 'time_algorithm_update': 0.004291774034500122, 'loss': 1.6397677819132805, 'time_step': 0.006479570627212525, 'init_value': 39.76525115966797}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 18:58.30[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515185517: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002134683132171631, 'time_algorithm_update': 0.004300451040267945, 'loss': 1.6791182802319526, 'time_step': 0.006488420486450195, 'init_value': 42.942848205566406}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.942848205566406
Starting 1000 evaluations
avg return on 3 trajectories of agent4: 1433.8081714273824
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 19:14.02[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 19:14.02[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 19:14.03[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 19:14.03[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 19:14.03[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515191403[0m
[2m2025-05-15 19:14.03[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 19:14.22[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515191403: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002046403408050537, 'time_algorithm_update': 0.00414856219291687, 'loss': 1.7517829424366356, 'time_step': 0.006247663497924804, 'init_value': 4.036688327789307}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 19:14.41[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515191403: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001980086803436279, 'time_algorithm_update': 0.003982591152191162, 'loss': 2.334676316320896, 'time_step': 0.006014436721801758, 'init_value': 10.211250305175781}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 19:15.00[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515191403: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020857818126678467, 'time_algorithm_update': 0.00427733039855957, 'loss': 2.367799192070961, 'time_step': 0.006416383266448974, 'init_value': 17.95366096496582}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 19:15.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515191403: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021076345443725585, 'time_algorithm_update': 0.004343325138092041, 'loss': 2.224644131243229, 'time_step': 0.006505108118057251, 'init_value': 23.912355422973633}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 19:15.39[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515191403: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001984884977340698, 'time_algorithm_update': 0.004000792741775513, 'loss': 1.9665323371291161, 'time_step': 0.006037506341934204, 'init_value': 29.69300651550293}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 19:15.58[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515191403: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021036593914031984, 'time_algorithm_update': 0.0042884800434112545, 'loss': 1.9117762517929078, 'time_step': 0.0064456467628479005, 'init_value': 33.21345138549805}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 19:16.18[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515191403: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002103332757949829, 'time_algorithm_update': 0.004261557340621948, 'loss': 1.7492384286522866, 'time_step': 0.006418957710266114, 'init_value': 35.01973342895508}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 19:16.37[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515191403: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002086745262145996, 'time_algorithm_update': 0.00420540976524353, 'loss': 1.5584339177012443, 'time_step': 0.006345107793807984, 'init_value': 36.391883850097656}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 19:16.57[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515191403: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021143956184387206, 'time_algorithm_update': 0.00442064642906189, 'loss': 1.617039787888527, 'time_step': 0.006589581727981567, 'init_value': 38.99420166015625}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 19:17.16[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515191403: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002131634473800659, 'time_algorithm_update': 0.004290496826171875, 'loss': 1.67566008913517, 'time_step': 0.006476133346557617, 'init_value': 41.32844543457031}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.32844543457031
Starting 1000 evaluations
avg return on 3 trajectories of agent5: 1439.3449136375116
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 19:32.41[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 19:32.41[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 19:32.43[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 19:32.43[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 19:32.43[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515193243[0m
[2m2025-05-15 19:32.43[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 19:33.02[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515193243: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002035917043685913, 'time_algorithm_update': 0.004099912881851196, 'loss': 1.481575113028288, 'time_step': 0.006188140869140625, 'init_value': 4.40826940536499}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 19:33.21[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515193243: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019847142696380617, 'time_algorithm_update': 0.003933497428894043, 'loss': 2.335351223707199, 'time_step': 0.005969155311584473, 'init_value': 11.501141548156738}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 19:33.40[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515193243: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020895583629608155, 'time_algorithm_update': 0.004246762275695801, 'loss': 2.249050343632698, 'time_step': 0.006390225887298584, 'init_value': 18.93680191040039}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 19:33.59[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515193243: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002065775394439697, 'time_algorithm_update': 0.004170534610748291, 'loss': 2.2427975269556044, 'time_step': 0.006289501428604126, 'init_value': 25.237529754638672}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 19:34.19[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515193243: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021091248989105224, 'time_algorithm_update': 0.004220052242279053, 'loss': 2.0504317230582236, 'time_step': 0.006382274150848389, 'init_value': 29.319982528686523}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 19:34.38[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515193243: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020978083610534667, 'time_algorithm_update': 0.0042797248363494874, 'loss': 1.8665048746466637, 'time_step': 0.006431772947311402, 'init_value': 32.403541564941406}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 19:34.57[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515193243: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021262922286987306, 'time_algorithm_update': 0.004224950075149536, 'loss': 1.8425099157691003, 'time_step': 0.006404464960098267, 'init_value': 34.87367630004883}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 19:35.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515193243: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020729784965515135, 'time_algorithm_update': 0.004185476303100586, 'loss': 1.7913807657957077, 'time_step': 0.006310988664627076, 'init_value': 36.38692855834961}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 19:35.36[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515193243: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002090258836746216, 'time_algorithm_update': 0.004271121501922608, 'loss': 1.7466212528347969, 'time_step': 0.006415286302566528, 'init_value': 39.408355712890625}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 19:35.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515193243: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020696005821228027, 'time_algorithm_update': 0.004179616928100586, 'loss': 1.6778793690800666, 'time_step': 0.006302697896957398, 'init_value': 41.29866027832031}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.29866027832031
Starting 1000 evaluations
avg return on 3 trajectories of agent6: 1435.3061506492645
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 19:51.23[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 19:51.23[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 19:51.24[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 19:51.24[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 19:51.24[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515195124[0m
[2m2025-05-15 19:51.24[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 19:51.43[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515195124: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019782016277313233, 'time_algorithm_update': 0.0039754691123962405, 'loss': 1.5895819523334502, 'time_step': 0.006004800796508789, 'init_value': 4.3587541580200195}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 19:52.03[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515195124: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020631189346313476, 'time_algorithm_update': 0.004224931240081787, 'loss': 2.4728340951800347, 'time_step': 0.006341090440750122, 'init_value': 10.336604118347168}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 19:52.22[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515195124: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020860772132873535, 'time_algorithm_update': 0.004299601078033447, 'loss': 2.340494359254837, 'time_step': 0.006439575672149658, 'init_value': 17.470012664794922}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 19:52.41[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515195124: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020708043575286867, 'time_algorithm_update': 0.004272709131240845, 'loss': 2.2127744196653367, 'time_step': 0.006396652698516846, 'init_value': 24.591106414794922}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 19:52.59[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515195124: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001945028305053711, 'time_algorithm_update': 0.0038590965270996094, 'loss': 2.047954985678196, 'time_step': 0.005855294227600097, 'init_value': 29.363258361816406}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 19:53.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515195124: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001941483974456787, 'time_algorithm_update': 0.003899925470352173, 'loss': 1.8451614542007446, 'time_step': 0.00589176344871521, 'init_value': 32.94358825683594}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 19:53.37[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515195124: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021094372272491453, 'time_algorithm_update': 0.0042652468681335445, 'loss': 1.737088595867157, 'time_step': 0.006428563594818115, 'init_value': 35.57405090332031}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 19:53.56[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515195124: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020285520553588866, 'time_algorithm_update': 0.004167686462402344, 'loss': 1.7743300877809525, 'time_step': 0.006248914480209351, 'init_value': 38.45265579223633}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 19:54.15[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515195124: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002057026147842407, 'time_algorithm_update': 0.004251033306121826, 'loss': 1.7834618866443634, 'time_step': 0.0063605055809021, 'init_value': 39.93050765991211}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 19:54.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515195124: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020688772201538086, 'time_algorithm_update': 0.004277443647384644, 'loss': 1.7969044430851937, 'time_step': 0.006399399995803833, 'init_value': 41.15713882446289}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.15713882446289
Starting 1000 evaluations
avg return on 3 trajectories of agent7: 1426.9464031620064
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 20:10.02[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 20:10.02[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 20:10.03[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 20:10.03[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 20:10.03[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515201003[0m
[2m2025-05-15 20:10.03[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 20:10.22[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515201003: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002017069101333618, 'time_algorithm_update': 0.004049384832382202, 'loss': 1.7537204212993383, 'time_step': 0.006117797136306763, 'init_value': 4.2050299644470215}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 20:10.41[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515201003: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020245182514190673, 'time_algorithm_update': 0.0040247211456298825, 'loss': 2.3829039600491524, 'time_step': 0.006100242614746094, 'init_value': 10.995203971862793}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 20:11.00[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515201003: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020505225658416747, 'time_algorithm_update': 0.004206783294677734, 'loss': 2.2853789404034615, 'time_step': 0.006309710741043091, 'init_value': 17.735694885253906}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 20:11.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515201003: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020836029052734373, 'time_algorithm_update': 0.004244322299957275, 'loss': 1.962238638818264, 'time_step': 0.0063808362483978275, 'init_value': 24.216955184936523}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 20:11.38[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515201003: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001955925703048706, 'time_algorithm_update': 0.003948480844497681, 'loss': 2.0190932427644728, 'time_step': 0.005954928398132324, 'init_value': 28.426637649536133}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 20:11.57[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515201003: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002126986503601074, 'time_algorithm_update': 0.0043455159664154055, 'loss': 1.8873506027460099, 'time_step': 0.006526385307312012, 'init_value': 32.469844818115234}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 20:12.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515201003: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002071645975112915, 'time_algorithm_update': 0.004241828203201294, 'loss': 1.7816817715167999, 'time_step': 0.006366896629333496, 'init_value': 36.07688903808594}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 20:12.36[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515201003: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020745961666107176, 'time_algorithm_update': 0.004209454536437988, 'loss': 1.7242939150333405, 'time_step': 0.006337082624435425, 'init_value': 37.56645202636719}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 20:12.56[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515201003: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021284830570220945, 'time_algorithm_update': 0.004429575681686402, 'loss': 1.7693132588863372, 'time_step': 0.006612236261367798, 'init_value': 39.25959014892578}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 20:13.15[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515201003: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002036787271499634, 'time_algorithm_update': 0.004187914371490478, 'loss': 1.728941664338112, 'time_step': 0.006277163982391357, 'init_value': 40.42578125}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.42578125
Starting 1000 evaluations
avg return on 3 trajectories of agent8: 1446.5804490001306
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 20:28.31[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 20:28.31[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 20:28.32[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 20:28.32[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 20:28.32[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515202832[0m
[2m2025-05-15 20:28.32[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 20:28.51[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515202832: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020245397090911865, 'time_algorithm_update': 0.004097437381744385, 'loss': 1.712682268679142, 'time_step': 0.006174040794372559, 'init_value': 4.118835926055908}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 20:29.10[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515202832: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020156636238098146, 'time_algorithm_update': 0.004085579872131348, 'loss': 2.3046364025473594, 'time_step': 0.006153345823287964, 'init_value': 10.824234008789062}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 20:29.29[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515202832: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002091092348098755, 'time_algorithm_update': 0.0042708289623260495, 'loss': 2.369260152220726, 'time_step': 0.006416256904602051, 'init_value': 18.10245704650879}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 20:29.48[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515202832: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002049314260482788, 'time_algorithm_update': 0.004172552108764649, 'loss': 2.1351080505251883, 'time_step': 0.006274584293365478, 'init_value': 24.030296325683594}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 20:30.08[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515202832: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020965354442596435, 'time_algorithm_update': 0.004262497663497925, 'loss': 1.9108685196042061, 'time_step': 0.006411991596221924, 'init_value': 28.249242782592773}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 20:30.27[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515202832: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019833168983459473, 'time_algorithm_update': 0.003982429504394531, 'loss': 1.8703143438100815, 'time_step': 0.006016932010650635, 'init_value': 31.8537540435791}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 20:30.46[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515202832: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002091466426849365, 'time_algorithm_update': 0.004296259641647339, 'loss': 1.800300212919712, 'time_step': 0.006441588640213013, 'init_value': 34.31393814086914}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 20:31.05[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515202832: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002080225944519043, 'time_algorithm_update': 0.004255719661712646, 'loss': 1.7013001197576523, 'time_step': 0.006390497207641601, 'init_value': 37.303916931152344}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 20:31.24[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515202832: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019797568321228026, 'time_algorithm_update': 0.003996705770492554, 'loss': 1.7317270805239677, 'time_step': 0.006027776956558228, 'init_value': 39.68809509277344}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 20:31.43[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515202832: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021195073127746582, 'time_algorithm_update': 0.004376062870025635, 'loss': 1.5536875926852227, 'time_step': 0.00654986047744751, 'init_value': 40.506591796875}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.506591796875
Starting 1000 evaluations
avg return on 3 trajectories of agent9: 1439.6299904707842
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 20:47.08[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 20:47.08[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 20:47.09[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 20:47.09[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 20:47.09[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515204709[0m
[2m2025-05-15 20:47.09[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 20:47.28[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515204709: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001970027208328247, 'time_algorithm_update': 0.00394748330116272, 'loss': 1.6681547925546765, 'time_step': 0.0059686415195465085, 'init_value': 4.274106025695801}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 20:47.47[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515204709: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020794692039489745, 'time_algorithm_update': 0.0042727210521698, 'loss': 2.461947889983654, 'time_step': 0.006405869007110596, 'init_value': 11.249417304992676}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 20:48.06[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515204709: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020829875469207766, 'time_algorithm_update': 0.004227018594741822, 'loss': 2.221747822403908, 'time_step': 0.006363373517990112, 'init_value': 18.915353775024414}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 20:48.25[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515204709: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002028129577636719, 'time_algorithm_update': 0.0041467781066894535, 'loss': 2.140592125415802, 'time_step': 0.006227192878723145, 'init_value': 24.933204650878906}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 20:48.45[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515204709: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021363246440887452, 'time_algorithm_update': 0.004371791839599609, 'loss': 1.9110978682637214, 'time_step': 0.006562794923782349, 'init_value': 29.12223243713379}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 20:49.04[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515204709: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020366792678833006, 'time_algorithm_update': 0.004158266305923462, 'loss': 1.89776288574934, 'time_step': 0.006247662544250489, 'init_value': 33.4492073059082}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 20:49.23[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515204709: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002039570093154907, 'time_algorithm_update': 0.004145375967025757, 'loss': 1.7657514002919197, 'time_step': 0.006237699031829834, 'init_value': 35.59237289428711}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 20:49.41[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515204709: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019151651859283447, 'time_algorithm_update': 0.0037927160263061524, 'loss': 1.8235970762372018, 'time_step': 0.005757701635360718, 'init_value': 37.52166748046875}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 20:50.01[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515204709: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002146421909332275, 'time_algorithm_update': 0.004345465183258057, 'loss': 1.7595457250475883, 'time_step': 0.006546151161193847, 'init_value': 40.05158233642578}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 20:50.21[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515204709: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002074166774749756, 'time_algorithm_update': 0.004249326705932617, 'loss': 1.687053171813488, 'time_step': 0.00637740421295166, 'init_value': 41.19104766845703}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.19104766845703
Starting 1000 evaluations
avg return on 3 trajectories of agent10: 1433.468337285838
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 21:05.44[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 21:05.44[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 21:05.45[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 21:05.45[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 21:05.45[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515210545[0m
[2m2025-05-15 21:05.45[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 21:06.04[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515210545: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002070178508758545, 'time_algorithm_update': 0.004210518836975098, 'loss': 1.7704971253052353, 'time_step': 0.0063326933383941655, 'init_value': 4.39422607421875}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 21:06.23[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515210545: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021161625385284423, 'time_algorithm_update': 0.004187027931213379, 'loss': 2.3628930695056916, 'time_step': 0.00635525894165039, 'init_value': 10.679059028625488}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 21:06.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515210545: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019813575744628904, 'time_algorithm_update': 0.00395971417427063, 'loss': 2.2756549203395844, 'time_step': 0.005992013454437256, 'init_value': 18.024795532226562}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 21:07.01[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515210545: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021476192474365234, 'time_algorithm_update': 0.0043330020904541015, 'loss': 2.187093735456467, 'time_step': 0.006534507036209106, 'init_value': 24.273643493652344}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 21:07.21[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515210545: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021184189319610595, 'time_algorithm_update': 0.004363790273666381, 'loss': 2.0527502574920655, 'time_step': 0.006535552978515625, 'init_value': 28.86839485168457}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 21:07.40[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515210545: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020918025970458986, 'time_algorithm_update': 0.004204308986663819, 'loss': 1.9241881242394447, 'time_step': 0.0063485119342803955, 'init_value': 32.395809173583984}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 21:07.59[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515210545: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020399696826934816, 'time_algorithm_update': 0.004112719297409057, 'loss': 1.8706019048094749, 'time_step': 0.00620456337928772, 'init_value': 34.395503997802734}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 21:08.19[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515210545: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002093623399734497, 'time_algorithm_update': 0.00425029993057251, 'loss': 1.626777329325676, 'time_step': 0.006396755456924439, 'init_value': 36.864715576171875}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 21:08.38[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515210545: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020761072635650637, 'time_algorithm_update': 0.004200112342834472, 'loss': 1.7453720843791962, 'time_step': 0.0063286576271057125, 'init_value': 39.04428482055664}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 21:08.57[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515210545: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002007655143737793, 'time_algorithm_update': 0.003917347431182861, 'loss': 1.70229093426466, 'time_step': 0.005975236892700195, 'init_value': 40.558597564697266}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.558597564697266
Starting 1000 evaluations
avg return on 3 trajectories of agent11: 1412.5118865601603
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 21:24.26[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 21:24.26[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 21:24.27[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 21:24.27[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 21:24.27[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515212427[0m
[2m2025-05-15 21:24.27[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 21:24.46[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515212427: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002045905828475952, 'time_algorithm_update': 0.00413667893409729, 'loss': 1.5588498858213424, 'time_step': 0.006234879970550537, 'init_value': 4.072576522827148}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 21:25.04[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515212427: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019344031810760499, 'time_algorithm_update': 0.0038310136795043945, 'loss': 2.27426720058918, 'time_step': 0.005815054893493652, 'init_value': 10.457582473754883}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 21:25.24[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515212427: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002106123685836792, 'time_algorithm_update': 0.004252097606658936, 'loss': 2.261687654495239, 'time_step': 0.006411722183227539, 'init_value': 17.30404281616211}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 21:25.43[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515212427: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020287368297576902, 'time_algorithm_update': 0.004129018783569336, 'loss': 2.0706513907313346, 'time_step': 0.006210245847702026, 'init_value': 23.619802474975586}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 21:26.02[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515212427: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020581686496734617, 'time_algorithm_update': 0.0042323853969573975, 'loss': 2.0339631327986716, 'time_step': 0.006343812704086304, 'init_value': 29.105838775634766}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 21:26.21[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515212427: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020965933799743652, 'time_algorithm_update': 0.00425436282157898, 'loss': 1.8142356572151184, 'time_step': 0.006404594898223877, 'init_value': 32.39179229736328}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 21:26.40[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515212427: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020821218490600585, 'time_algorithm_update': 0.0041440951824188235, 'loss': 1.7490956587791442, 'time_step': 0.0062791602611541745, 'init_value': 35.309959411621094}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 21:26.59[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515212427: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002046736478805542, 'time_algorithm_update': 0.004121145009994507, 'loss': 1.6646792905330658, 'time_step': 0.006220021486282349, 'init_value': 37.480403900146484}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 21:27.18[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515212427: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001966882228851318, 'time_algorithm_update': 0.0038850951194763185, 'loss': 1.725864786207676, 'time_step': 0.0059024178981781006, 'init_value': 39.74531555175781}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 21:27.37[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515212427: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002087125301361084, 'time_algorithm_update': 0.00412174654006958, 'loss': 1.6243236677646637, 'time_step': 0.006261193513870239, 'init_value': 41.70009994506836}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.70009994506836
Starting 1000 evaluations
avg return on 3 trajectories of agent12: 1437.7512324426402
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 21:43.01[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 21:43.01[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 21:43.02[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 21:43.02[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 21:43.02[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515214302[0m
[2m2025-05-15 21:43.02[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 21:43.21[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515214302: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002038332223892212, 'time_algorithm_update': 0.004150823831558227, 'loss': 1.6742080438435079, 'time_step': 0.0062418818473815914, 'init_value': 4.492079257965088}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 21:43.40[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515214302: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019712624549865724, 'time_algorithm_update': 0.0038488407135009767, 'loss': 2.257071443736553, 'time_step': 0.005870287895202637, 'init_value': 10.93925666809082}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 21:43.59[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515214302: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002093390464782715, 'time_algorithm_update': 0.004306333541870117, 'loss': 2.374822588980198, 'time_step': 0.00645452094078064, 'init_value': 18.556556701660156}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 21:44.19[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515214302: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020949721336364748, 'time_algorithm_update': 0.004184570074081421, 'loss': 2.1502286332845686, 'time_step': 0.006332248687744141, 'init_value': 25.327735900878906}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 21:44.38[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515214302: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020388951301574705, 'time_algorithm_update': 0.004122595310211182, 'loss': 1.9022624278068543, 'time_step': 0.006213807821273803, 'init_value': 29.868240356445312}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 21:44.57[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515214302: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021206047534942625, 'time_algorithm_update': 0.004264976501464844, 'loss': 1.856663402557373, 'time_step': 0.006439050674438476, 'init_value': 33.44221115112305}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 21:45.16[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515214302: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002052402973175049, 'time_algorithm_update': 0.004189079523086548, 'loss': 1.8958590749502182, 'time_step': 0.006294242858886719, 'init_value': 35.342716217041016}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 21:45.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515214302: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002068817138671875, 'time_algorithm_update': 0.004184706926345825, 'loss': 1.7867473191022873, 'time_step': 0.006306623935699463, 'init_value': 38.092044830322266}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 21:45.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515214302: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020532543659210205, 'time_algorithm_update': 0.0041761879920959475, 'loss': 1.7216643581986428, 'time_step': 0.006281983375549316, 'init_value': 39.09821319580078}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 21:46.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515214302: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021027793884277344, 'time_algorithm_update': 0.0042260816097259525, 'loss': 1.7576437485218048, 'time_step': 0.006382375717163086, 'init_value': 39.97700881958008}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 39.97700881958008
Starting 1000 evaluations
avg return on 3 trajectories of agent13: 1437.0745048244498
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 22:01.41[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 22:01.41[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 22:01.42[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 22:01.42[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 22:01.42[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515220142[0m
[2m2025-05-15 22:01.42[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 22:02.01[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515220142: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020148351192474366, 'time_algorithm_update': 0.004035914659500122, 'loss': 1.5831488647162915, 'time_step': 0.00610172700881958, 'init_value': 4.190389156341553}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 22:02.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515220142: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002107384204864502, 'time_algorithm_update': 0.004206027746200562, 'loss': 2.2275556082725525, 'time_step': 0.006366307735443115, 'init_value': 10.95231819152832}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 22:02.40[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515220142: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020619184970855713, 'time_algorithm_update': 0.0041655275821685794, 'loss': 2.2887260378003123, 'time_step': 0.0062798926830291745, 'init_value': 18.366153717041016}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 22:02.58[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515220142: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019963955879211425, 'time_algorithm_update': 0.0039043316841125488, 'loss': 2.198459006011486, 'time_step': 0.00595068883895874, 'init_value': 25.605941772460938}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 22:03.18[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515220142: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002147026062011719, 'time_algorithm_update': 0.004413675308227539, 'loss': 1.9279287682175636, 'time_step': 0.006615112066268921, 'init_value': 30.10201072692871}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 22:03.37[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515220142: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020672283172607424, 'time_algorithm_update': 0.004102550268173218, 'loss': 1.845441057741642, 'time_step': 0.0062221050262451175, 'init_value': 32.21493911743164}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 22:03.56[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515220142: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020245132446289065, 'time_algorithm_update': 0.004070130586624146, 'loss': 1.7791687664985656, 'time_step': 0.00614649748802185, 'init_value': 35.817832946777344}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 22:04.15[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515220142: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002106809377670288, 'time_algorithm_update': 0.004282884120941162, 'loss': 1.794012569963932, 'time_step': 0.006443173885345459, 'init_value': 38.19982147216797}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 22:04.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515220142: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021025424003601073, 'time_algorithm_update': 0.004183573484420776, 'loss': 1.75152987408638, 'time_step': 0.006338517665863037, 'init_value': 39.94736862182617}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 22:04.54[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515220142: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020697579383850096, 'time_algorithm_update': 0.004158642292022705, 'loss': 1.7424760411977769, 'time_step': 0.006281148910522461, 'init_value': 42.87300491333008}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.87300491333008
Starting 1000 evaluations
avg return on 3 trajectories of agent14: 1437.9315820531947
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 22:20.19[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 22:20.19[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 22:20.20[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 22:20.20[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 22:20.20[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515222020[0m
[2m2025-05-15 22:20.20[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 22:20.39[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515222020: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020441510677337645, 'time_algorithm_update': 0.004102666378021241, 'loss': 1.7467669725418091, 'time_step': 0.006198783159255981, 'init_value': 4.484346389770508}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 22:20.58[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515222020: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002082851409912109, 'time_algorithm_update': 0.004121074199676514, 'loss': 2.219913194358349, 'time_step': 0.006255942106246948, 'init_value': 11.027068138122559}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 22:21.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515222020: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020851590633392332, 'time_algorithm_update': 0.004273667573928833, 'loss': 2.3446909039616584, 'time_step': 0.006412289142608643, 'init_value': 18.09401512145996}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 22:21.36[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515222020: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002074848175048828, 'time_algorithm_update': 0.0041494033336639405, 'loss': 2.154158064186573, 'time_step': 0.006276841640472412, 'init_value': 24.718225479125977}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 22:21.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515222020: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020784542560577392, 'time_algorithm_update': 0.004315739631652832, 'loss': 1.984692649424076, 'time_step': 0.0064481601715087895, 'init_value': 29.336341857910156}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 22:22.15[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515222020: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00198530912399292, 'time_algorithm_update': 0.003912096977233887, 'loss': 1.9305471544265747, 'time_step': 0.005947919607162476, 'init_value': 32.96217346191406}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 22:22.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515222020: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021095917224884034, 'time_algorithm_update': 0.004320397138595581, 'loss': 1.8251546956300735, 'time_step': 0.006483803272247315, 'init_value': 35.97279739379883}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 22:22.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515222020: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021149492263793945, 'time_algorithm_update': 0.004237268686294556, 'loss': 1.8125275719761849, 'time_step': 0.006414237737655639, 'init_value': 37.394474029541016}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 22:23.12[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515222020: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019805843830108644, 'time_algorithm_update': 0.003994210004806519, 'loss': 1.716930699110031, 'time_step': 0.006025900840759277, 'init_value': 39.47080612182617}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 22:23.31[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515222020: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021448016166687013, 'time_algorithm_update': 0.0043498995304107665, 'loss': 1.6936448159217834, 'time_step': 0.0065495285987854, 'init_value': 41.62348937988281}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.62348937988281
Starting 1000 evaluations
avg return on 3 trajectories of agent15: 1432.9988659067535
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 22:39.00[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 22:39.00[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 22:39.01[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 22:39.01[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 22:39.01[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515223901[0m
[2m2025-05-15 22:39.01[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 22:39.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515223901: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00205652117729187, 'time_algorithm_update': 0.00415505313873291, 'loss': 1.8926024465188385, 'time_step': 0.0062639546394348145, 'init_value': 4.300447940826416}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 22:39.39[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515223901: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019992504119873047, 'time_algorithm_update': 0.003910831928253174, 'loss': 2.3136525295972823, 'time_step': 0.0059606294631958006, 'init_value': 10.785049438476562}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 22:39.59[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515223901: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021015448570251465, 'time_algorithm_update': 0.004284553289413452, 'loss': 2.2059492108225824, 'time_step': 0.006439616203308105, 'init_value': 17.306612014770508}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 22:40.18[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515223901: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002067744731903076, 'time_algorithm_update': 0.004197122812271118, 'loss': 2.0866811368465426, 'time_step': 0.0063176751136779785, 'init_value': 24.320974349975586}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 22:40.37[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515223901: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020977466106414794, 'time_algorithm_update': 0.004275920152664184, 'loss': 2.062183760046959, 'time_step': 0.006426811695098877, 'init_value': 29.58635902404785}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 22:40.56[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515223901: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021210360527038575, 'time_algorithm_update': 0.0042249467372894286, 'loss': 1.9374145687818527, 'time_step': 0.006398661613464356, 'init_value': 32.21962356567383}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 22:41.16[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515223901: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002080667734146118, 'time_algorithm_update': 0.00420143723487854, 'loss': 1.8370298330783843, 'time_step': 0.006334859132766724, 'init_value': 34.95119094848633}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 22:41.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515223901: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020786027908325194, 'time_algorithm_update': 0.004189520835876465, 'loss': 1.7662791888713836, 'time_step': 0.0063204851150512695, 'init_value': 37.219261169433594}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 22:41.54[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515223901: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00196749210357666, 'time_algorithm_update': 0.003901557922363281, 'loss': 1.7170196354389191, 'time_step': 0.005918798923492431, 'init_value': 39.51167678833008}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 22:42.13[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515223901: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021209397315979004, 'time_algorithm_update': 0.004302003383636475, 'loss': 1.7834143425226212, 'time_step': 0.006477890014648438, 'init_value': 41.19091796875}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.19091796875
Starting 1000 evaluations
avg return on 3 trajectories of agent16: 1441.3997064576465
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 22:57.31[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 22:57.31[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 22:57.32[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 22:57.32[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 22:57.32[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515225732[0m
[2m2025-05-15 22:57.32[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 22:57.51[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515225732: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020392448902130126, 'time_algorithm_update': 0.004115077257156372, 'loss': 1.945753191575408, 'time_step': 0.006206000328063965, 'init_value': 4.258577346801758}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 22:58.10[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515225732: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020785763263702394, 'time_algorithm_update': 0.004089408874511718, 'loss': 2.2460234300494193, 'time_step': 0.00622016716003418, 'init_value': 10.981728553771973}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 22:58.30[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515225732: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002092980146408081, 'time_algorithm_update': 0.004250564098358154, 'loss': 2.3284068581461907, 'time_step': 0.0063984978199005125, 'init_value': 18.250186920166016}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 22:58.49[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515225732: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020961220264434813, 'time_algorithm_update': 0.004187301874160766, 'loss': 2.0493994157910347, 'time_step': 0.0063367123603820805, 'init_value': 24.845870971679688}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 22:59.08[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515225732: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002067421913146973, 'time_algorithm_update': 0.004201690435409546, 'loss': 1.950383698284626, 'time_step': 0.006321951627731324, 'init_value': 29.702661514282227}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 22:59.27[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515225732: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002002718210220337, 'time_algorithm_update': 0.0038952541351318357, 'loss': 1.892480172097683, 'time_step': 0.005949021816253662, 'init_value': 32.891971588134766}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 22:59.46[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515225732: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002105881690979004, 'time_algorithm_update': 0.004324539184570313, 'loss': 1.794881624042988, 'time_step': 0.006484523773193359, 'init_value': 35.28293228149414}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 23:00.05[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515225732: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002086400508880615, 'time_algorithm_update': 0.004261235237121582, 'loss': 1.8518323568701744, 'time_step': 0.006401766061782837, 'init_value': 36.9361572265625}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 23:00.24[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515225732: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020530734062194824, 'time_algorithm_update': 0.004128107786178589, 'loss': 1.68697437697649, 'time_step': 0.006233131170272827, 'init_value': 38.25828552246094}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 23:00.44[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515225732: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021690704822540283, 'time_algorithm_update': 0.004401451587677002, 'loss': 1.5694371830224991, 'time_step': 0.00662455677986145, 'init_value': 40.57065200805664}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.57065200805664
Starting 1000 evaluations
avg return on 3 trajectories of agent17: 1433.3023210820356
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 23:16.10[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 23:16.10[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 23:16.11[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 23:16.11[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 23:16.11[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515231611[0m
[2m2025-05-15 23:16.11[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 23:16.30[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515231611: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002044118881225586, 'time_algorithm_update': 0.004115221023559571, 'loss': 1.6366464264392853, 'time_step': 0.006211220502853393, 'init_value': 4.569772720336914}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 23:16.48[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515231611: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001997842311859131, 'time_algorithm_update': 0.0038746857643127443, 'loss': 2.1839628353714944, 'time_step': 0.0059231059551239015, 'init_value': 11.06812572479248}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 23:17.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515231611: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020859055519104005, 'time_algorithm_update': 0.004195917129516602, 'loss': 2.309356950342655, 'time_step': 0.006334432125091553, 'init_value': 18.96309471130371}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 23:17.27[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515231611: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020741653442382813, 'time_algorithm_update': 0.004118960380554199, 'loss': 2.0590817935466768, 'time_step': 0.00624573540687561, 'init_value': 25.42835235595703}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 23:17.45[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515231611: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021063427925109863, 'time_algorithm_update': 0.004343700647354126, 'loss': 1.988430455982685, 'time_step': 0.006503430604934693, 'init_value': 29.791337966918945}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 23:18.04[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515231611: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019782397747039795, 'time_algorithm_update': 0.0038215389251708984, 'loss': 1.9254792870283126, 'time_step': 0.00584904932975769, 'init_value': 32.89730453491211}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 23:18.24[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515231611: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021140475273132326, 'time_algorithm_update': 0.004312227487564087, 'loss': 1.7800523822307586, 'time_step': 0.0064798049926757815, 'init_value': 35.195831298828125}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 23:18.43[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515231611: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021275155544281006, 'time_algorithm_update': 0.0042440156936645506, 'loss': 1.7328047401309012, 'time_step': 0.006424603939056396, 'init_value': 36.67133331298828}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 23:19.02[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515231611: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002042010545730591, 'time_algorithm_update': 0.004088048219680786, 'loss': 1.7918896815180778, 'time_step': 0.006181864976882934, 'init_value': 39.11772918701172}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 23:19.22[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515231611: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00220316481590271, 'time_algorithm_update': 0.004498998641967774, 'loss': 1.588659130692482, 'time_step': 0.006756877183914185, 'init_value': 40.159324645996094}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.159324645996094
Starting 1000 evaluations
avg return on 3 trajectories of agent18: 1420.8702057339492
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 23:34.37[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 23:34.37[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 23:34.39[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 23:34.39[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 23:34.39[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515233439[0m
[2m2025-05-15 23:34.39[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 23:34.58[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515233439: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002074499845504761, 'time_algorithm_update': 0.0042965633869171144, 'loss': 1.5454805812239647, 'time_step': 0.006424614191055298, 'init_value': 4.706511497497559}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 23:35.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515233439: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020209038257598877, 'time_algorithm_update': 0.004096845388412476, 'loss': 2.3920870765447617, 'time_step': 0.006170219421386719, 'init_value': 11.243110656738281}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 23:35.36[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515233439: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002087502479553223, 'time_algorithm_update': 0.004180930852890015, 'loss': 2.2041826476454736, 'time_step': 0.00632197904586792, 'init_value': 18.697086334228516}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 23:35.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515233439: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019819889068603516, 'time_algorithm_update': 0.003981437921524048, 'loss': 2.164379500031471, 'time_step': 0.006013827562332153, 'init_value': 25.70339584350586}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 23:36.15[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515233439: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002093017578125, 'time_algorithm_update': 0.004200591325759888, 'loss': 1.9635388022065163, 'time_step': 0.006346443176269531, 'init_value': 30.23790740966797}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 23:36.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515233439: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020340282917022706, 'time_algorithm_update': 0.004152373075485229, 'loss': 1.88770069116354, 'time_step': 0.006238925933837891, 'init_value': 33.63129425048828}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 23:36.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515233439: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001975508451461792, 'time_algorithm_update': 0.003965220212936401, 'loss': 1.8586687519550324, 'time_step': 0.005991281509399414, 'init_value': 35.965065002441406}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 23:37.12[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515233439: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020668320655822755, 'time_algorithm_update': 0.0042069251537323, 'loss': 1.752057081401348, 'time_step': 0.006327301263809204, 'init_value': 37.637367248535156}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 23:37.31[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515233439: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002105613708496094, 'time_algorithm_update': 0.004220066070556641, 'loss': 1.7445771085619926, 'time_step': 0.0063792641162872315, 'init_value': 39.229732513427734}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 23:37.50[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515233439: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020152812004089354, 'time_algorithm_update': 0.004094338178634644, 'loss': 1.6944077550172805, 'time_step': 0.006161622524261475, 'init_value': 40.93323516845703}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.93323516845703
Starting 1000 evaluations
avg return on 3 trajectories of agent19: 1415.0040287332042
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-15 23:53.10[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-15 23:53.10[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-15 23:53.12[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-15 23:53.12[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-15 23:53.12[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250515235312[0m
[2m2025-05-15 23:53.12[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-15 23:53.31[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515235312: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002158699989318848, 'time_algorithm_update': 0.004509524822235107, 'loss': 1.841111001856625, 'time_step': 0.006723540544509888, 'init_value': 4.773298263549805}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-15 23:53.51[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515235312: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021240904331207276, 'time_algorithm_update': 0.004293980598449707, 'loss': 2.3197495175600054, 'time_step': 0.00647220778465271, 'init_value': 11.49035930633545}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-15 23:54.10[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515235312: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020167627334594725, 'time_algorithm_update': 0.004096588373184204, 'loss': 2.2531667773127557, 'time_step': 0.006165281772613525, 'init_value': 18.613826751708984}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-15 23:54.29[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515235312: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002092453479766846, 'time_algorithm_update': 0.004254457950592041, 'loss': 2.2079546937346457, 'time_step': 0.006400447130203247, 'init_value': 24.233491897583008}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-15 23:54.48[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515235312: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020606746673583983, 'time_algorithm_update': 0.004255240917205811, 'loss': 1.9104634729027747, 'time_step': 0.006369102239608765, 'init_value': 28.409053802490234}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-15 23:55.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515235312: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020761818885803225, 'time_algorithm_update': 0.004152082920074463, 'loss': 1.8082458525300027, 'time_step': 0.00628058385848999, 'init_value': 32.42693328857422}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-15 23:55.27[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515235312: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020672848224639892, 'time_algorithm_update': 0.004218138694763183, 'loss': 1.9160082409381867, 'time_step': 0.006338637113571167, 'init_value': 34.47800827026367}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-15 23:55.46[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515235312: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002101644992828369, 'time_algorithm_update': 0.004248296022415161, 'loss': 1.8008971358537673, 'time_step': 0.0064037365913391115, 'init_value': 37.1710090637207}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-15 23:56.05[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515235312: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002039318084716797, 'time_algorithm_update': 0.004151532173156738, 'loss': 1.6337868334650993, 'time_step': 0.00624386739730835, 'init_value': 39.063385009765625}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-15 23:56.25[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250515235312: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00215173077583313, 'time_algorithm_update': 0.0043562443256378175, 'loss': 1.7901942687034607, 'time_step': 0.006562455177307129, 'init_value': 40.17841339111328}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.17841339111328
ave advantage rew: 41.01480693817139, std: 0.7914365825065984
avg cum rews: 1434.7175892461528, std: 9.217839342432075
Pearson correlation coefficient: 0.03274080996961615
Spearman correlation coefficient: 0.013533834586466165
Kendall Tau correlation coefficient: -0.021052631578947368
the best agent: 2, best agent cum rewards: 1447.044180601063
1968
Starting to collect rollouts
Collecting rollouts: 10000/1000000
Collecting rollouts: 20000/1000000
Collecting rollouts: 30000/1000000
Collecting rollouts: 40000/1000000
Collecting rollouts: 50000/1000000
Collecting rollouts: 60000/1000000
Collecting rollouts: 70000/1000000
Collecting rollouts: 80000/1000000
Collecting rollouts: 90000/1000000
Collecting rollouts: 100000/1000000
Collecting rollouts: 110000/1000000
Collecting rollouts: 120000/1000000
Collecting rollouts: 130000/1000000
Collecting rollouts: 140000/1000000
Collecting rollouts: 150000/1000000
Collecting rollouts: 160000/1000000
Collecting rollouts: 170000/1000000
Collecting rollouts: 180000/1000000
Collecting rollouts: 190000/1000000
Collecting rollouts: 200000/1000000
Collecting rollouts: 210000/1000000
Collecting rollouts: 220000/1000000
Collecting rollouts: 230000/1000000
Collecting rollouts: 240000/1000000
Collecting rollouts: 250000/1000000
Collecting rollouts: 260000/1000000
Collecting rollouts: 270000/1000000
Collecting rollouts: 280000/1000000
Collecting rollouts: 290000/1000000
Collecting rollouts: 300000/1000000
Collecting rollouts: 310000/1000000
Collecting rollouts: 320000/1000000
Collecting rollouts: 330000/1000000
Collecting rollouts: 340000/1000000
Collecting rollouts: 350000/1000000
Collecting rollouts: 360000/1000000
Collecting rollouts: 370000/1000000
Collecting rollouts: 380000/1000000
Collecting rollouts: 390000/1000000
Collecting rollouts: 400000/1000000
Collecting rollouts: 410000/1000000
Collecting rollouts: 420000/1000000
Collecting rollouts: 430000/1000000
Collecting rollouts: 440000/1000000
Collecting rollouts: 450000/1000000
Collecting rollouts: 460000/1000000
Collecting rollouts: 470000/1000000
Collecting rollouts: 480000/1000000
Collecting rollouts: 490000/1000000
Collecting rollouts: 500000/1000000
Collecting rollouts: 510000/1000000
Collecting rollouts: 520000/1000000
Collecting rollouts: 530000/1000000
Collecting rollouts: 540000/1000000
Collecting rollouts: 550000/1000000
Collecting rollouts: 560000/1000000
Collecting rollouts: 570000/1000000
Collecting rollouts: 580000/1000000
Collecting rollouts: 590000/1000000
Collecting rollouts: 600000/1000000
Collecting rollouts: 610000/1000000
Collecting rollouts: 620000/1000000
Collecting rollouts: 630000/1000000
Collecting rollouts: 640000/1000000
Collecting rollouts: 650000/1000000
Collecting rollouts: 660000/1000000
Collecting rollouts: 670000/1000000
Collecting rollouts: 680000/1000000
Collecting rollouts: 690000/1000000
Collecting rollouts: 700000/1000000
Collecting rollouts: 710000/1000000
Collecting rollouts: 720000/1000000
Collecting rollouts: 730000/1000000
Collecting rollouts: 740000/1000000
Collecting rollouts: 750000/1000000
Collecting rollouts: 760000/1000000
Collecting rollouts: 770000/1000000
Collecting rollouts: 780000/1000000
Collecting rollouts: 790000/1000000
Collecting rollouts: 800000/1000000
Collecting rollouts: 810000/1000000
Collecting rollouts: 820000/1000000
Collecting rollouts: 830000/1000000
Collecting rollouts: 840000/1000000
Collecting rollouts: 850000/1000000
Collecting rollouts: 860000/1000000
Collecting rollouts: 870000/1000000
Collecting rollouts: 880000/1000000
Collecting rollouts: 890000/1000000
Collecting rollouts: 900000/1000000
Collecting rollouts: 910000/1000000
Collecting rollouts: 920000/1000000
Collecting rollouts: 930000/1000000
Collecting rollouts: 940000/1000000
Collecting rollouts: 950000/1000000
Collecting rollouts: 960000/1000000
Collecting rollouts: 970000/1000000
Collecting rollouts: 980000/1000000
Collecting rollouts: 990000/1000000
Collecting rollouts: 1000000/1000000
Replay buffer size:  (1000000, 105)
Replay buffer saved
---------------------------------
Searching empty space policies
(10, 11472)
(20, 11472)
(20, 11472)
Average distance of agents to nearest neighbors: 0.019133964057130602
Starting 1000 evaluations
avg return on 3 trajectories of agent0: 1432.611481778657
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-16 00:29.48[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-16 00:29.48[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-16 00:29.50[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-16 00:29.50[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-16 00:29.50[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250516002950[0m
[2m2025-05-16 00:29.50[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-16 00:30.08[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516002950: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020299665927886964, 'time_algorithm_update': 0.004036271572113037, 'loss': 1.676259585276246, 'time_step': 0.00611812162399292, 'init_value': 3.986515760421753}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-16 00:30.27[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516002950: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021315722465515136, 'time_algorithm_update': 0.004248408079147339, 'loss': 2.346862876653671, 'time_step': 0.006433768272399902, 'init_value': 10.82913875579834}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-16 00:30.47[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516002950: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021284818649291992, 'time_algorithm_update': 0.004312842607498169, 'loss': 2.15875806415081, 'time_step': 0.006495427370071411, 'init_value': 17.69222640991211}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-16 00:31.06[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516002950: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002131582736968994, 'time_algorithm_update': 0.004250132322311402, 'loss': 2.195098805487156, 'time_step': 0.006434910774230957, 'init_value': 24.244102478027344}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-16 00:31.26[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516002950: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020228285789489747, 'time_algorithm_update': 0.004077337026596069, 'loss': 1.9850035461187363, 'time_step': 0.0061527442932128905, 'init_value': 28.122310638427734}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-16 00:31.45[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516002950: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020789437294006347, 'time_algorithm_update': 0.004238940715789795, 'loss': 1.9050697479844094, 'time_step': 0.0063718740940094, 'init_value': 31.535961151123047}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-16 00:32.04[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516002950: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002094867467880249, 'time_algorithm_update': 0.004272921323776245, 'loss': 1.829667699098587, 'time_step': 0.00642160439491272, 'init_value': 34.78770446777344}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-16 00:32.23[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516002950: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021339361667633058, 'time_algorithm_update': 0.004272444009780884, 'loss': 1.7149070427417754, 'time_step': 0.006459715366363525, 'init_value': 37.52791213989258}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-16 00:32.43[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516002950: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021189355850219724, 'time_algorithm_update': 0.004346542835235596, 'loss': 1.6167032262682914, 'time_step': 0.0065203912258148195, 'init_value': 40.08258819580078}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-16 00:33.02[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516002950: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002150932550430298, 'time_algorithm_update': 0.004336438894271851, 'loss': 1.6909315928816795, 'time_step': 0.006542404413223266, 'init_value': 42.93377685546875}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.93377685546875
Starting 1000 evaluations
avg return on 3 trajectories of agent1: 1443.1832751132313
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-16 00:48.24[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-16 00:48.24[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-16 00:48.25[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-16 00:48.25[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-16 00:48.25[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250516004825[0m
[2m2025-05-16 00:48.25[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-16 00:48.44[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516004825: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019896962642669677, 'time_algorithm_update': 0.003951878786087036, 'loss': 1.6358501448482274, 'time_step': 0.005992292881011963, 'init_value': 4.3432512283325195}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-16 00:49.03[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516004825: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001993387460708618, 'time_algorithm_update': 0.003976478815078736, 'loss': 2.406619389474392, 'time_step': 0.00602075719833374, 'init_value': 11.182003021240234}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-16 00:49.22[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516004825: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021079280376434324, 'time_algorithm_update': 0.004242749691009522, 'loss': 2.283320534169674, 'time_step': 0.006404403448104858, 'init_value': 19.32033920288086}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-16 00:49.41[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516004825: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020851821899414064, 'time_algorithm_update': 0.004362018346786499, 'loss': 2.1946775941252707, 'time_step': 0.006501050472259522, 'init_value': 25.174161911010742}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-16 00:50.00[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516004825: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019795498847961428, 'time_algorithm_update': 0.003989905834197998, 'loss': 2.035266948521137, 'time_step': 0.0060199999809265135, 'init_value': 29.712034225463867}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-16 00:50.19[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516004825: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020921905040740965, 'time_algorithm_update': 0.00429428243637085, 'loss': 1.9190435894727707, 'time_step': 0.006440121650695801, 'init_value': 31.89285659790039}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-16 00:50.38[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516004825: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002078402042388916, 'time_algorithm_update': 0.004253635406494141, 'loss': 1.7901331067681312, 'time_step': 0.006385341882705688, 'init_value': 33.71372604370117}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-16 00:50.57[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516004825: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020377137660980223, 'time_algorithm_update': 0.004038127422332763, 'loss': 1.6811929605007172, 'time_step': 0.006126939535140991, 'init_value': 36.54005813598633}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-16 00:51.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516004825: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020635755062103273, 'time_algorithm_update': 0.0042560467720031735, 'loss': 1.683037368953228, 'time_step': 0.006372829914093017, 'init_value': 38.73066711425781}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-16 00:51.36[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516004825: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021279587745666505, 'time_algorithm_update': 0.004290611028671265, 'loss': 1.7471508897542953, 'time_step': 0.006472232580184936, 'init_value': 39.95514678955078}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 39.95514678955078
Starting 1000 evaluations
avg return on 3 trajectories of agent2: 1446.755844088983
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-16 01:06.59[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-16 01:06.59[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-16 01:07.00[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-16 01:07.00[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-16 01:07.00[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250516010700[0m
[2m2025-05-16 01:07.00[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-16 01:07.19[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516010700: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002021721124649048, 'time_algorithm_update': 0.004052788496017456, 'loss': 1.5600096785873174, 'time_step': 0.006126355648040771, 'init_value': 4.432008743286133}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-16 01:07.38[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516010700: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020829339027404786, 'time_algorithm_update': 0.0042678632736206056, 'loss': 2.301066902756691, 'time_step': 0.006403757572174072, 'init_value': 11.375470161437988}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-16 01:07.57[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516010700: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021380255222320558, 'time_algorithm_update': 0.004329856634140015, 'loss': 2.372391881167889, 'time_step': 0.006521365404129028, 'init_value': 19.248523712158203}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-16 01:08.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516010700: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021130974292755127, 'time_algorithm_update': 0.004411286830902099, 'loss': 2.087692216813564, 'time_step': 0.00657796049118042, 'init_value': 25.913644790649414}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-16 01:08.36[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516010700: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020753250122070312, 'time_algorithm_update': 0.004274385929107666, 'loss': 2.100636474072933, 'time_step': 0.006402338981628418, 'init_value': 30.99251365661621}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-16 01:08.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516010700: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002067685604095459, 'time_algorithm_update': 0.004268733739852905, 'loss': 1.8659168541431428, 'time_step': 0.00638933801651001, 'init_value': 33.62479782104492}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-16 01:09.15[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516010700: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021410207748413087, 'time_algorithm_update': 0.004333821535110474, 'loss': 1.7897083096504212, 'time_step': 0.006528362989425659, 'init_value': 36.295921325683594}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-16 01:09.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516010700: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001964282035827637, 'time_algorithm_update': 0.003962196588516235, 'loss': 1.7479195768237115, 'time_step': 0.005976588010787964, 'init_value': 38.54385757446289}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-16 01:09.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516010700: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020739638805389402, 'time_algorithm_update': 0.004280438661575317, 'loss': 1.8484762416481972, 'time_step': 0.006407217025756836, 'init_value': 40.099830627441406}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-16 01:10.12[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516010700: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020987024307250975, 'time_algorithm_update': 0.0042562859058380125, 'loss': 1.7711247993707657, 'time_step': 0.006407991170883178, 'init_value': 40.472782135009766}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.472782135009766
Starting 1000 evaluations
avg return on 3 trajectories of agent3: 1450.5487070489012
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-16 01:25.38[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-16 01:25.38[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-16 01:25.40[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-16 01:25.40[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-16 01:25.40[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250516012540[0m
[2m2025-05-16 01:25.40[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-16 01:25.58[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516012540: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002049924373626709, 'time_algorithm_update': 0.004120543241500855, 'loss': 1.4754466095790266, 'time_step': 0.006223431348800659, 'init_value': 4.153300762176514}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-16 01:26.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516012540: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002044484615325928, 'time_algorithm_update': 0.004150721788406372, 'loss': 2.2695849231481553, 'time_step': 0.00624791145324707, 'init_value': 11.115218162536621}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-16 01:26.37[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516012540: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002100956678390503, 'time_algorithm_update': 0.004237399578094482, 'loss': 2.403500391483307, 'time_step': 0.006392288684844971, 'init_value': 18.60868263244629}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-16 01:26.56[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516012540: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020624892711639405, 'time_algorithm_update': 0.004194039583206177, 'loss': 2.20975282984972, 'time_step': 0.006309545516967773, 'init_value': 25.284425735473633}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-16 01:27.15[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516012540: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019979987144470215, 'time_algorithm_update': 0.003923646450042725, 'loss': 1.9363072810173034, 'time_step': 0.005972884893417359, 'init_value': 30.029142379760742}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-16 01:27.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516012540: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020698049068450927, 'time_algorithm_update': 0.004199747800827026, 'loss': 1.8099698897004128, 'time_step': 0.006322922468185424, 'init_value': 33.08620834350586}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-16 01:27.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516012540: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002097935199737549, 'time_algorithm_update': 0.004193896532058716, 'loss': 1.8731436047554015, 'time_step': 0.006345111608505249, 'init_value': 36.558536529541016}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-16 01:28.12[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516012540: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001996356725692749, 'time_algorithm_update': 0.003988624334335327, 'loss': 1.7164457525014878, 'time_step': 0.006036531686782837, 'init_value': 38.97854232788086}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-16 01:28.31[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516012540: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021335601806640623, 'time_algorithm_update': 0.004381464958190918, 'loss': 1.6669686591625215, 'time_step': 0.006569876909255982, 'init_value': 39.48080062866211}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-16 01:28.50[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516012540: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020494701862335206, 'time_algorithm_update': 0.00414547085762024, 'loss': 1.6782163057923316, 'time_step': 0.0062479784488677975, 'init_value': 40.709102630615234}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.709102630615234
Starting 1000 evaluations
avg return on 3 trajectories of agent4: 1430.3802883600326
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-16 01:44.13[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-16 01:44.13[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-16 01:44.14[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-16 01:44.14[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-16 01:44.14[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250516014414[0m
[2m2025-05-16 01:44.14[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-16 01:44.33[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516014414: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019422979354858398, 'time_algorithm_update': 0.0038426434993743897, 'loss': 1.7104050846248866, 'time_step': 0.005834452629089356, 'init_value': 4.386865615844727}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-16 01:44.52[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516014414: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002145528554916382, 'time_algorithm_update': 0.004270347118377685, 'loss': 2.275771580040455, 'time_step': 0.006469739675521851, 'init_value': 11.356034278869629}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-16 01:45.11[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516014414: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002068753480911255, 'time_algorithm_update': 0.004253567934036255, 'loss': 2.3691334300637243, 'time_step': 0.006375954866409302, 'init_value': 18.26483154296875}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-16 01:45.30[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516014414: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002018991470336914, 'time_algorithm_update': 0.0040181934833526615, 'loss': 2.152092602908611, 'time_step': 0.006088471174240113, 'init_value': 24.71307373046875}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-16 01:45.50[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516014414: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020817296504974363, 'time_algorithm_update': 0.004317677736282348, 'loss': 1.8919236053824424, 'time_step': 0.006452613830566406, 'init_value': 29.239961624145508}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-16 01:46.09[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516014414: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020954389572143553, 'time_algorithm_update': 0.004211745977401734, 'loss': 1.8259176683425904, 'time_step': 0.0063605809211730955, 'init_value': 32.60416793823242}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-16 01:46.27[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516014414: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00202466082572937, 'time_algorithm_update': 0.004123840570449829, 'loss': 1.720012376487255, 'time_step': 0.00620108437538147, 'init_value': 35.49776077270508}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-16 01:46.47[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516014414: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002127364158630371, 'time_algorithm_update': 0.004338100194931031, 'loss': 1.7006845450401307, 'time_step': 0.0065196967124938965, 'init_value': 37.48135757446289}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-16 01:47.06[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516014414: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002063293695449829, 'time_algorithm_update': 0.004266314744949341, 'loss': 1.7330160375833512, 'time_step': 0.0063831982612609865, 'init_value': 40.154930114746094}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-16 01:47.25[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516014414: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020738506317138673, 'time_algorithm_update': 0.004266757488250733, 'loss': 1.7319946185350419, 'time_step': 0.006394368171691894, 'init_value': 43.02414321899414}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 43.02414321899414
Starting 1000 evaluations
avg return on 3 trajectories of agent5: 1440.5129116400965
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-16 02:02.44[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-16 02:02.44[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-16 02:02.45[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-16 02:02.45[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-16 02:02.45[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250516020245[0m
[2m2025-05-16 02:02.45[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-16 02:03.04[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516020245: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022428581714630125, 'time_algorithm_update': 0.003929600477218628, 'loss': 1.661931164190173, 'time_step': 0.006222074985504151, 'init_value': 4.07402229309082}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-16 02:03.23[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516020245: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002057968378067017, 'time_algorithm_update': 0.004176037788391113, 'loss': 2.48419339287281, 'time_step': 0.0062866809368133545, 'init_value': 10.521221160888672}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-16 02:03.43[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516020245: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002087649583816528, 'time_algorithm_update': 0.004234869718551635, 'loss': 2.294937096118927, 'time_step': 0.00637514877319336, 'init_value': 17.722410202026367}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-16 02:04.01[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516020245: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019826979637145997, 'time_algorithm_update': 0.004046551942825318, 'loss': 2.0659638686180113, 'time_step': 0.006080045461654663, 'init_value': 24.575525283813477}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-16 02:04.21[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516020245: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002175968408584595, 'time_algorithm_update': 0.004529036283493042, 'loss': 1.9160478323101997, 'time_step': 0.006760096073150635, 'init_value': 28.668106079101562}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-16 02:04.40[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516020245: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002068791389465332, 'time_algorithm_update': 0.004274016857147217, 'loss': 1.7977653410434722, 'time_step': 0.006396059989929199, 'init_value': 31.25247573852539}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-16 02:04.59[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516020245: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002003390073776245, 'time_algorithm_update': 0.004071443557739258, 'loss': 1.7309592400193214, 'time_step': 0.0061264488697052, 'init_value': 34.094058990478516}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-16 02:05.18[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516020245: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00206545352935791, 'time_algorithm_update': 0.004279926538467407, 'loss': 1.6873046573400496, 'time_step': 0.006398785352706909, 'init_value': 36.39161682128906}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-16 02:05.38[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516020245: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020940673351287843, 'time_algorithm_update': 0.004261510133743286, 'loss': 1.6437132515907287, 'time_step': 0.006408593416213989, 'init_value': 39.718631744384766}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-16 02:05.57[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516020245: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020679306983947755, 'time_algorithm_update': 0.004146626949310303, 'loss': 1.6880568919181824, 'time_step': 0.006267109155654907, 'init_value': 41.08184051513672}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.08184051513672
Starting 1000 evaluations
avg return on 3 trajectories of agent6: 1447.449261203321
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-16 02:21.18[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-16 02:21.18[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-16 02:21.19[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-16 02:21.19[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-16 02:21.19[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250516022119[0m
[2m2025-05-16 02:21.19[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-16 02:21.39[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516022119: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020786356925964356, 'time_algorithm_update': 0.004253809452056885, 'loss': 1.3821538018882276, 'time_step': 0.006385250568389893, 'init_value': 4.292429447174072}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-16 02:21.57[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516022119: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020677695274353026, 'time_algorithm_update': 0.004151523113250732, 'loss': 2.247754680454731, 'time_step': 0.006271815061569214, 'init_value': 10.165206909179688}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-16 02:22.16[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516022119: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00202162504196167, 'time_algorithm_update': 0.004089756965637207, 'loss': 2.240033067047596, 'time_step': 0.00616341495513916, 'init_value': 17.313573837280273}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-16 02:22.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516022119: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020020015239715578, 'time_algorithm_update': 0.003969297170639038, 'loss': 2.2427876929044723, 'time_step': 0.006021183013916015, 'init_value': 24.11743927001953}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-16 02:22.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516022119: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020953218936920165, 'time_algorithm_update': 0.004297246694564819, 'loss': 1.9582231125831604, 'time_step': 0.0064458570480346675, 'init_value': 28.27357292175293}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-16 02:23.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516022119: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020624234676361085, 'time_algorithm_update': 0.0042132332324981685, 'loss': 1.8661878735423088, 'time_step': 0.006328973293304443, 'init_value': 32.31681442260742}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-16 02:23.33[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516022119: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00199733304977417, 'time_algorithm_update': 0.004033641815185547, 'loss': 1.7449830217957496, 'time_step': 0.006082187175750733, 'init_value': 34.09855270385742}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-16 02:23.52[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516022119: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021318089962005615, 'time_algorithm_update': 0.00430155348777771, 'loss': 1.7652011361718178, 'time_step': 0.006487557172775269, 'init_value': 37.59553909301758}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-16 02:24.11[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516022119: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020936968326568605, 'time_algorithm_update': 0.004309267520904541, 'loss': 1.6762314042448998, 'time_step': 0.006456550359725952, 'init_value': 39.24205017089844}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-16 02:24.31[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516022119: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021258115768432615, 'time_algorithm_update': 0.004338972806930542, 'loss': 1.6915400383472443, 'time_step': 0.0065185360908508305, 'init_value': 39.99773025512695}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 39.99773025512695
Starting 1000 evaluations
avg return on 3 trajectories of agent7: 1447.2745948229976
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-16 02:39.48[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-16 02:39.48[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-16 02:39.49[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-16 02:39.49[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-16 02:39.49[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250516023949[0m
[2m2025-05-16 02:39.49[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-16 02:40.08[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516023949: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001958301544189453, 'time_algorithm_update': 0.0039017469882965086, 'loss': 1.597730255395174, 'time_step': 0.005910384178161621, 'init_value': 4.454866409301758}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-16 02:40.27[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516023949: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020497767925262453, 'time_algorithm_update': 0.0041948044300079345, 'loss': 2.3033282973766327, 'time_step': 0.00629797101020813, 'init_value': 10.857118606567383}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-16 02:40.46[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516023949: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020737533569335936, 'time_algorithm_update': 0.004177414178848267, 'loss': 2.227542746067047, 'time_step': 0.006305033206939697, 'init_value': 17.5907039642334}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-16 02:41.05[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516023949: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019652140140533447, 'time_algorithm_update': 0.00393988823890686, 'loss': 2.178785201370716, 'time_step': 0.005955839157104492, 'init_value': 24.04437255859375}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-16 02:41.24[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516023949: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00204718279838562, 'time_algorithm_update': 0.004186421871185303, 'loss': 1.9884583556056024, 'time_step': 0.0062868397235870364, 'init_value': 28.48731803894043}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-16 02:41.43[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516023949: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020684764385223387, 'time_algorithm_update': 0.004277914762496948, 'loss': 2.0124371814131736, 'time_step': 0.0063995511531829835, 'init_value': 30.59977149963379}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-16 02:42.02[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516023949: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020608386993408202, 'time_algorithm_update': 0.004148744821548462, 'loss': 1.7555331655144693, 'time_step': 0.006261898756027222, 'init_value': 33.54341506958008}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-16 02:42.21[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516023949: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002074819326400757, 'time_algorithm_update': 0.004269473791122437, 'loss': 1.862090010881424, 'time_step': 0.006397726058959961, 'init_value': 35.62396240234375}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-16 02:42.40[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516023949: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020901761054992678, 'time_algorithm_update': 0.004323003292083741, 'loss': 1.8657168946862221, 'time_step': 0.006467842340469361, 'init_value': 38.62836456298828}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-16 02:43.00[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516023949: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020637729167938233, 'time_algorithm_update': 0.0042308964729309085, 'loss': 1.735035225570202, 'time_step': 0.006347627401351929, 'init_value': 39.78151321411133}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 39.78151321411133
Starting 1000 evaluations
avg return on 3 trajectories of agent8: 1422.8693453373844
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-16 02:58.24[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-16 02:58.24[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-16 02:58.25[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-16 02:58.25[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-16 02:58.25[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250516025825[0m
[2m2025-05-16 02:58.25[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-16 02:58.44[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516025825: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001968715190887451, 'time_algorithm_update': 0.003930431604385376, 'loss': 1.758748269163072, 'time_step': 0.0059505593776702885, 'init_value': 4.4888505935668945}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-16 02:59.03[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516025825: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020628731250762937, 'time_algorithm_update': 0.004205170154571533, 'loss': 2.294868956565857, 'time_step': 0.006321790218353271, 'init_value': 11.363203048706055}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-16 02:59.22[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516025825: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002035299777984619, 'time_algorithm_update': 0.0041637980937957765, 'loss': 2.2413564720153807, 'time_step': 0.006252205848693847, 'init_value': 18.865205764770508}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-16 02:59.41[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516025825: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020307772159576416, 'time_algorithm_update': 0.004043555498123169, 'loss': 2.204283239006996, 'time_step': 0.006125712394714355, 'init_value': 25.654582977294922}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-16 03:00.00[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516025825: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002049464702606201, 'time_algorithm_update': 0.00418206262588501, 'loss': 2.098154653429985, 'time_step': 0.006284497022628784, 'init_value': 30.5654296875}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-16 03:00.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516025825: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002093111991882324, 'time_algorithm_update': 0.004338938713073731, 'loss': 1.8856452953815461, 'time_step': 0.006486069202423095, 'init_value': 33.94954299926758}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-16 03:00.38[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516025825: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020122582912445067, 'time_algorithm_update': 0.004070743083953858, 'loss': 1.7508289104104042, 'time_step': 0.006135435581207276, 'init_value': 35.392215728759766}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-16 03:00.57[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516025825: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020725791454315186, 'time_algorithm_update': 0.004164848804473877, 'loss': 1.6426068121790887, 'time_step': 0.006290429592132568, 'init_value': 37.82073211669922}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-16 03:01.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516025825: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020603532791137694, 'time_algorithm_update': 0.004217023372650146, 'loss': 1.6980335874557495, 'time_step': 0.006330861568450928, 'init_value': 40.2416877746582}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-16 03:01.36[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516025825: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020996081829071046, 'time_algorithm_update': 0.004213899850845337, 'loss': 1.6529919638037682, 'time_step': 0.006367019176483154, 'init_value': 39.88456344604492}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 39.88456344604492
Starting 1000 evaluations
avg return on 3 trajectories of agent9: 1432.4720477062085
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-16 03:16.58[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-16 03:16.58[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-16 03:17.00[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-16 03:17.00[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-16 03:17.00[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250516031700[0m
[2m2025-05-16 03:17.00[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-16 03:17.19[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516031700: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002069246292114258, 'time_algorithm_update': 0.004174119710922241, 'loss': 1.604765993990004, 'time_step': 0.006296185493469239, 'init_value': 4.711894512176514}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-16 03:17.38[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516031700: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002136063098907471, 'time_algorithm_update': 0.004325474500656128, 'loss': 2.494994365096092, 'time_step': 0.006515282392501831, 'init_value': 12.48870849609375}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-16 03:17.57[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516031700: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020695269107818604, 'time_algorithm_update': 0.004179397821426392, 'loss': 2.364366266608238, 'time_step': 0.006301256418228149, 'init_value': 20.093801498413086}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-16 03:18.16[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516031700: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002117863655090332, 'time_algorithm_update': 0.004201925039291382, 'loss': 2.2100257794857026, 'time_step': 0.006372526407241821, 'init_value': 25.333541870117188}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-16 03:18.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516031700: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002046562671661377, 'time_algorithm_update': 0.004159647941589356, 'loss': 1.9944216027855872, 'time_step': 0.006258929967880249, 'init_value': 29.0978946685791}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-16 03:18.54[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516031700: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00207688570022583, 'time_algorithm_update': 0.00416366171836853, 'loss': 1.8340846546888352, 'time_step': 0.0062933101654052736, 'init_value': 32.285011291503906}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-16 03:19.13[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516031700: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019470934867858887, 'time_algorithm_update': 0.0038546741008758543, 'loss': 1.7785940984487534, 'time_step': 0.0058516147136688235, 'init_value': 34.450130462646484}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-16 03:19.32[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516031700: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021338753700256346, 'time_algorithm_update': 0.004305533170700073, 'loss': 1.6977957978844642, 'time_step': 0.006493164300918579, 'init_value': 37.01655197143555}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-16 03:19.52[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516031700: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020499250888824463, 'time_algorithm_update': 0.004149305105209351, 'loss': 1.6470189023017883, 'time_step': 0.0062523033618927006, 'init_value': 38.42759323120117}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-16 03:20.10[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516031700: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020201635360717774, 'time_algorithm_update': 0.004045636177062988, 'loss': 1.579921044111252, 'time_step': 0.0061176464557647706, 'init_value': 39.59191131591797}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 39.59191131591797
Starting 1000 evaluations
avg return on 3 trajectories of agent10: 1432.4736701869815
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-16 03:35.34[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-16 03:35.34[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-16 03:35.36[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-16 03:35.36[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-16 03:35.36[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250516033536[0m
[2m2025-05-16 03:35.36[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-16 03:35.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516033536: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020194299221038816, 'time_algorithm_update': 0.004102037191390991, 'loss': 1.6266792824864387, 'time_step': 0.006173377752304077, 'init_value': 4.022494792938232}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-16 03:36.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516033536: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020251240730285646, 'time_algorithm_update': 0.004098310470581055, 'loss': 2.2491364772319793, 'time_step': 0.006175189733505249, 'init_value': 11.074627876281738}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-16 03:36.32[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516033536: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001983616828918457, 'time_algorithm_update': 0.003937214374542236, 'loss': 2.2889865644574163, 'time_step': 0.005971822023391723, 'init_value': 18.724031448364258}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-16 03:36.52[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516033536: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002073531150817871, 'time_algorithm_update': 0.004220552682876587, 'loss': 2.19519380736351, 'time_step': 0.006346384048461914, 'init_value': 25.299684524536133}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-16 03:37.11[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516033536: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020445466041564943, 'time_algorithm_update': 0.004202781438827514, 'loss': 2.0466933735609056, 'time_step': 0.006299758195877075, 'init_value': 28.91987419128418}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-16 03:37.29[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516033536: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020471229553222655, 'time_algorithm_update': 0.00417266035079956, 'loss': 1.8868511171340943, 'time_step': 0.006272483348846436, 'init_value': 32.61614227294922}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-16 03:37.48[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516033536: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002022461175918579, 'time_algorithm_update': 0.004049645185470581, 'loss': 1.834575953900814, 'time_step': 0.006124170303344727, 'init_value': 34.144927978515625}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-16 03:38.08[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516033536: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002035466432571411, 'time_algorithm_update': 0.004159550666809082, 'loss': 1.644894822537899, 'time_step': 0.0062477126121521, 'init_value': 36.583534240722656}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-16 03:38.27[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516033536: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002030252933502197, 'time_algorithm_update': 0.004136303186416626, 'loss': 1.701129440009594, 'time_step': 0.006219033479690552, 'init_value': 40.38153839111328}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-16 03:38.45[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516033536: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019846835136413574, 'time_algorithm_update': 0.004001103401184082, 'loss': 1.7120343720912934, 'time_step': 0.006036754608154297, 'init_value': 41.30712890625}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.30712890625
Starting 1000 evaluations
avg return on 3 trajectories of agent11: 1426.1896622956963
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-16 03:54.08[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-16 03:54.08[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-16 03:54.09[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-16 03:54.09[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-16 03:54.09[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250516035409[0m
[2m2025-05-16 03:54.09[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-16 03:54.28[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516035409: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020286815166473387, 'time_algorithm_update': 0.004049527406692505, 'loss': 1.6108845778033136, 'time_step': 0.006129908800125122, 'init_value': 4.083656311035156}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-16 03:54.47[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516035409: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021491472721099853, 'time_algorithm_update': 0.004229297876358032, 'loss': 2.360662630558014, 'time_step': 0.006431441068649292, 'init_value': 11.136275291442871}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-16 03:55.06[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516035409: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019486231803894044, 'time_algorithm_update': 0.0038177924156188965, 'loss': 2.2826093656420707, 'time_step': 0.005815955638885498, 'init_value': 19.176546096801758}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-16 03:55.25[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516035409: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021437733173370363, 'time_algorithm_update': 0.004296329736709595, 'loss': 2.0510959011912346, 'time_step': 0.006493908882141113, 'init_value': 25.16996192932129}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-16 03:55.44[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516035409: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020706791877746584, 'time_algorithm_update': 0.004168923854827881, 'loss': 2.007695106983185, 'time_step': 0.006292408466339112, 'init_value': 29.082170486450195}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-16 03:56.03[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516035409: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020561859607696534, 'time_algorithm_update': 0.004037057399749756, 'loss': 1.9134277309775352, 'time_step': 0.006144866943359375, 'init_value': 31.984891891479492}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-16 03:56.23[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516035409: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021326634883880617, 'time_algorithm_update': 0.0043568828105926515, 'loss': 1.860110242187977, 'time_step': 0.006544250249862671, 'init_value': 35.15940475463867}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-16 03:56.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516035409: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020797550678253174, 'time_algorithm_update': 0.004195740699768066, 'loss': 1.757808018863201, 'time_step': 0.006328622579574585, 'init_value': 36.92975997924805}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-16 03:57.00[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516035409: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020447885990142823, 'time_algorithm_update': 0.004070576429367066, 'loss': 1.6881302674412728, 'time_step': 0.0061672086715698245, 'init_value': 38.29241180419922}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-16 03:57.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516035409: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021575818061828613, 'time_algorithm_update': 0.004314082145690918, 'loss': 1.6831137392520905, 'time_step': 0.006525526285171509, 'init_value': 39.87696838378906}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 39.87696838378906
Starting 1000 evaluations
avg return on 3 trajectories of agent12: 1426.511107260108
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-16 04:12.52[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-16 04:12.52[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-16 04:12.54[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-16 04:12.54[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-16 04:12.54[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250516041254[0m
[2m2025-05-16 04:12.54[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-16 04:13.12[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516041254: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001961893081665039, 'time_algorithm_update': 0.0038821399211883545, 'loss': 1.5575436099916697, 'time_step': 0.005894227266311646, 'init_value': 4.448370456695557}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-16 04:13.31[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516041254: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002173408508300781, 'time_algorithm_update': 0.004386362314224243, 'loss': 2.4522574530243872, 'time_step': 0.006613724231719971, 'init_value': 10.907106399536133}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-16 04:13.51[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516041254: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002064866542816162, 'time_algorithm_update': 0.004197332620620727, 'loss': 2.292991925418377, 'time_step': 0.006315898895263672, 'init_value': 17.486658096313477}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-16 04:14.10[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516041254: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020928945541381838, 'time_algorithm_update': 0.004203875303268432, 'loss': 2.0837667636871338, 'time_step': 0.0063495395183563235, 'init_value': 24.320697784423828}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-16 04:14.29[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516041254: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020950384140014646, 'time_algorithm_update': 0.004264721632003784, 'loss': 2.008797338068485, 'time_step': 0.006413465976715088, 'init_value': 28.55751609802246}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-16 04:14.48[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516041254: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002070812702178955, 'time_algorithm_update': 0.004197244167327881, 'loss': 1.8776828457713126, 'time_step': 0.006321038007736206, 'init_value': 33.12421417236328}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-16 04:15.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516041254: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020876111984252928, 'time_algorithm_update': 0.004245349645614624, 'loss': 1.7565551401376724, 'time_step': 0.006386271715164185, 'init_value': 33.915611267089844}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-16 04:15.26[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516041254: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019726173877716064, 'time_algorithm_update': 0.0038188462257385254, 'loss': 1.6996414843797685, 'time_step': 0.005840977668762207, 'init_value': 36.050052642822266}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-16 04:15.45[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516041254: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002111937761306763, 'time_algorithm_update': 0.0042744803428649905, 'loss': 1.6898167408704758, 'time_step': 0.0064401040077209475, 'init_value': 39.072959899902344}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-16 04:16.05[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516041254: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002114885091781616, 'time_algorithm_update': 0.0042184643745422365, 'loss': 1.7947342458963393, 'time_step': 0.006387166738510132, 'init_value': 39.915008544921875}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 39.915008544921875
Starting 1000 evaluations
avg return on 3 trajectories of agent13: 1417.4736153936838
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-16 04:31.36[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-16 04:31.36[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-16 04:31.38[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-16 04:31.38[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-16 04:31.38[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250516043138[0m
[2m2025-05-16 04:31.38[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-16 04:31.57[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516043138: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019627442359924315, 'time_algorithm_update': 0.003896237373352051, 'loss': 1.556346918039024, 'time_step': 0.005909319639205933, 'init_value': 4.024510383605957}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-16 04:32.16[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516043138: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021228880882263185, 'time_algorithm_update': 0.004285430908203125, 'loss': 2.275276301920414, 'time_step': 0.006462306022644043, 'init_value': 11.058075904846191}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-16 04:32.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516043138: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002047788143157959, 'time_algorithm_update': 0.004157835960388183, 'loss': 2.280960323512554, 'time_step': 0.0062584481239318845, 'init_value': 18.028478622436523}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-16 04:32.54[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516043138: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019742116928100585, 'time_algorithm_update': 0.0038460121154785154, 'loss': 2.151882640004158, 'time_step': 0.005869646072387696, 'init_value': 24.466102600097656}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-16 04:33.13[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516043138: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002094165802001953, 'time_algorithm_update': 0.004297107219696045, 'loss': 2.0746542712450027, 'time_step': 0.006444298505783081, 'init_value': 29.562042236328125}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-16 04:33.32[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516043138: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002076030969619751, 'time_algorithm_update': 0.004254457950592041, 'loss': 1.829476893365383, 'time_step': 0.006383643627166748, 'init_value': 34.02961730957031}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-16 04:33.51[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516043138: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001967158794403076, 'time_algorithm_update': 0.003935661554336548, 'loss': 1.8424812636375427, 'time_step': 0.005953299999237061, 'init_value': 37.33114242553711}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-16 04:34.10[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516043138: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021345820426940916, 'time_algorithm_update': 0.004328802824020385, 'loss': 1.7478289868235588, 'time_step': 0.006517052888870239, 'init_value': 38.84912872314453}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-16 04:34.29[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516043138: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020488786697387697, 'time_algorithm_update': 0.0042146692276000975, 'loss': 1.6697168969511986, 'time_step': 0.00631692099571228, 'init_value': 40.45365524291992}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-16 04:34.48[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516043138: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021093039512634277, 'time_algorithm_update': 0.004242459058761597, 'loss': 1.6507647115588189, 'time_step': 0.006405734539031983, 'init_value': 40.97673797607422}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.97673797607422
Starting 1000 evaluations
avg return on 3 trajectories of agent14: 1407.136231059888
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-16 04:50.14[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-16 04:50.14[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-16 04:50.15[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-16 04:50.15[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-16 04:50.15[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250516045015[0m
[2m2025-05-16 04:50.15[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-16 04:50.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516045015: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002015564680099487, 'time_algorithm_update': 0.0040484869480133055, 'loss': 1.5505441739335657, 'time_step': 0.006115841627120972, 'init_value': 4.606323719024658}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-16 04:50.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516045015: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002029271125793457, 'time_algorithm_update': 0.004033381223678589, 'loss': 2.246158420622349, 'time_step': 0.006114013433456421, 'init_value': 11.650433540344238}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-16 04:51.12[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516045015: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002081966161727905, 'time_algorithm_update': 0.0041998295783996584, 'loss': 2.3499862555265425, 'time_step': 0.006334381103515625, 'init_value': 19.13776206970215}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-16 04:51.31[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516045015: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020783240795135497, 'time_algorithm_update': 0.004171166658401489, 'loss': 2.1404439925551415, 'time_step': 0.006302107810974121, 'init_value': 26.115711212158203}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-16 04:51.49[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516045015: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019644339084625246, 'time_algorithm_update': 0.003912426471710205, 'loss': 2.0044846497178077, 'time_step': 0.005927772760391236, 'init_value': 30.37456512451172}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-16 04:52.09[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516045015: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002146923542022705, 'time_algorithm_update': 0.004300290822982788, 'loss': 1.8854171107411384, 'time_step': 0.006501144409179688, 'init_value': 33.783199310302734}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-16 04:52.28[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516045015: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020999784469604493, 'time_algorithm_update': 0.0043302888870239255, 'loss': 1.8607609463334083, 'time_step': 0.006484747409820557, 'init_value': 36.765594482421875}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-16 04:52.47[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516045015: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021127843856811523, 'time_algorithm_update': 0.004174162626266479, 'loss': 1.828721253335476, 'time_step': 0.0063402862548828124, 'init_value': 39.279048919677734}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-16 04:53.06[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516045015: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001979825735092163, 'time_algorithm_update': 0.003943714141845703, 'loss': 1.75522349524498, 'time_step': 0.005974502801895142, 'init_value': 40.640499114990234}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-16 04:53.25[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516045015: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002138944387435913, 'time_algorithm_update': 0.0043303780555725094, 'loss': 1.7900647169351578, 'time_step': 0.006523702383041382, 'init_value': 41.73331832885742}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.73331832885742
Starting 1000 evaluations
avg return on 3 trajectories of agent15: 1385.3868809846886
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-16 05:08.57[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-16 05:08.57[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-16 05:08.59[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-16 05:08.59[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-16 05:08.59[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250516050859[0m
[2m2025-05-16 05:08.59[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-16 05:09.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516050859: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019278509616851808, 'time_algorithm_update': 0.0037800588607788087, 'loss': 1.7446512261629104, 'time_step': 0.005757216930389404, 'init_value': 4.291837692260742}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-16 05:09.36[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516050859: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021021096706390382, 'time_algorithm_update': 0.004206310749053955, 'loss': 2.3344267956614493, 'time_step': 0.006361517906188965, 'init_value': 10.448651313781738}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-16 05:09.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516050859: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020456349849700926, 'time_algorithm_update': 0.004138164520263672, 'loss': 2.353996828198433, 'time_step': 0.006235854625701904, 'init_value': 17.23508071899414}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-16 05:10.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516050859: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020947446823120115, 'time_algorithm_update': 0.004195744276046753, 'loss': 2.2756337603330614, 'time_step': 0.0063434412479400635, 'init_value': 24.636627197265625}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-16 05:10.33[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516050859: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020127766132354737, 'time_algorithm_update': 0.004075103521347046, 'loss': 2.0622855846881865, 'time_step': 0.006139415502548218, 'init_value': 29.069883346557617}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-16 05:10.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516050859: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021340811252593996, 'time_algorithm_update': 0.004294814586639405, 'loss': 1.925062883913517, 'time_step': 0.006482744216918945, 'init_value': 33.206058502197266}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-16 05:11.12[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516050859: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002121983289718628, 'time_algorithm_update': 0.004424475431442261, 'loss': 1.8183151028156281, 'time_step': 0.00660048246383667, 'init_value': 35.712890625}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-16 05:11.31[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516050859: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001969747066497803, 'time_algorithm_update': 0.0039567253589630124, 'loss': 1.8003482508063315, 'time_step': 0.005977631092071533, 'init_value': 37.08666229248047}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-16 05:11.50[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516050859: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002094661712646484, 'time_algorithm_update': 0.004297464370727539, 'loss': 1.873277732372284, 'time_step': 0.0064459054470062255, 'init_value': 38.945640563964844}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-16 05:12.09[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516050859: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002090506553649902, 'time_algorithm_update': 0.004196753025054931, 'loss': 1.7150122353434563, 'time_step': 0.00634048581123352, 'init_value': 40.131553649902344}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.131553649902344
Starting 1000 evaluations
avg return on 3 trajectories of agent16: 1427.2211690451995
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-16 05:27.32[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-16 05:27.32[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-16 05:27.33[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-16 05:27.33[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-16 05:27.33[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250516052733[0m
[2m2025-05-16 05:27.33[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-16 05:27.52[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516052733: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002053825616836548, 'time_algorithm_update': 0.004200762748718262, 'loss': 1.780213506013155, 'time_step': 0.006308212518692017, 'init_value': 4.450232028961182}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-16 05:28.11[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516052733: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020651838779449463, 'time_algorithm_update': 0.004186014652252198, 'loss': 2.3327486231923102, 'time_step': 0.006304142951965332, 'init_value': 10.871142387390137}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-16 05:28.30[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516052733: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001989608526229858, 'time_algorithm_update': 0.00395490026473999, 'loss': 2.37192153686285, 'time_step': 0.005996224164962769, 'init_value': 18.25996208190918}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-16 05:28.49[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516052733: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020874600410461424, 'time_algorithm_update': 0.004260793924331665, 'loss': 2.1360071422457696, 'time_step': 0.006402095317840576, 'init_value': 24.987546920776367}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-16 05:29.08[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516052733: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020712943077087404, 'time_algorithm_update': 0.0041347784996032715, 'loss': 1.9335855870246887, 'time_step': 0.006258663654327393, 'init_value': 29.995399475097656}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-16 05:29.27[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516052733: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002065591812133789, 'time_algorithm_update': 0.004182402849197388, 'loss': 1.8311921616196631, 'time_step': 0.006301126718521118, 'init_value': 32.743438720703125}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-16 05:29.46[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516052733: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002057868003845215, 'time_algorithm_update': 0.004110702037811279, 'loss': 1.7554218940734863, 'time_step': 0.006220935821533203, 'init_value': 35.77189254760742}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-16 05:30.06[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516052733: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00206640362739563, 'time_algorithm_update': 0.00419531512260437, 'loss': 1.7908625071048736, 'time_step': 0.006314749717712402, 'init_value': 38.01825714111328}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-16 05:30.25[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516052733: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020383551120758056, 'time_algorithm_update': 0.004117756366729736, 'loss': 1.7545418140292168, 'time_step': 0.00620876145362854, 'init_value': 40.67495346069336}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-16 05:30.43[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516052733: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019340577125549316, 'time_algorithm_update': 0.003797407627105713, 'loss': 1.6100529839992523, 'time_step': 0.0057815792560577395, 'init_value': 42.08657455444336}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.08657455444336
Starting 1000 evaluations
avg return on 3 trajectories of agent17: 1405.4542863614047
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-16 05:46.15[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-16 05:46.15[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-16 05:46.17[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-16 05:46.17[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-16 05:46.17[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250516054617[0m
[2m2025-05-16 05:46.17[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-16 05:46.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516054617: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00203299617767334, 'time_algorithm_update': 0.004067903280258179, 'loss': 1.5882156776562333, 'time_step': 0.0061526837348937985, 'init_value': 4.2145280838012695}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-16 05:46.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516054617: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002072333097457886, 'time_algorithm_update': 0.004196833848953247, 'loss': 2.432328979253769, 'time_step': 0.006321979284286499, 'init_value': 11.338274955749512}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-16 05:47.13[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516054617: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020363972187042237, 'time_algorithm_update': 0.004111201524734497, 'loss': 2.368581969320774, 'time_step': 0.006200017690658569, 'init_value': 19.355161666870117}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-16 05:47.32[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516054617: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020410878658294676, 'time_algorithm_update': 0.00412288761138916, 'loss': 2.108352316379547, 'time_step': 0.006216227293014526, 'init_value': 25.8072566986084}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-16 05:47.51[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516054617: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019609954357147218, 'time_algorithm_update': 0.003822028398513794, 'loss': 2.0343236909508704, 'time_step': 0.00583275556564331, 'init_value': 30.815523147583008}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-16 05:48.10[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516054617: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020884530544281006, 'time_algorithm_update': 0.0042461748123168944, 'loss': 1.8111097910404206, 'time_step': 0.006387415885925293, 'init_value': 34.60199737548828}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-16 05:48.30[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516054617: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002085517168045044, 'time_algorithm_update': 0.004294382572174072, 'loss': 1.8000617666840553, 'time_step': 0.006433122873306275, 'init_value': 36.9371337890625}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-16 05:48.48[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516054617: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002022840976715088, 'time_algorithm_update': 0.004067974328994751, 'loss': 1.6974403148293495, 'time_step': 0.006142772912979126, 'init_value': 39.17321014404297}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-16 05:49.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516054617: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021305272579193115, 'time_algorithm_update': 0.0042938685417175295, 'loss': 1.7942294973134993, 'time_step': 0.0064783191680908205, 'init_value': 40.238006591796875}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-16 05:49.27[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516054617: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020465333461761473, 'time_algorithm_update': 0.004184884786605835, 'loss': 1.6813285216093063, 'time_step': 0.00628377914428711, 'init_value': 40.543460845947266}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.543460845947266
Starting 1000 evaluations
avg return on 3 trajectories of agent18: 1389.342200944836
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-16 06:04.54[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-16 06:04.54[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-16 06:04.55[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-16 06:04.55[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-16 06:04.55[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250516060455[0m
[2m2025-05-16 06:04.55[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-16 06:05.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516060455: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020627961158752443, 'time_algorithm_update': 0.004222236394882202, 'loss': 1.4960282671228051, 'time_step': 0.006338125228881836, 'init_value': 4.528580188751221}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-16 06:05.33[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516060455: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020328836441040037, 'time_algorithm_update': 0.0041250200271606445, 'loss': 2.433420409679413, 'time_step': 0.006210024833679199, 'init_value': 11.457354545593262}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-16 06:05.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516060455: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021507859230041502, 'time_algorithm_update': 0.00438129210472107, 'loss': 2.252126065611839, 'time_step': 0.0065864651203155515, 'init_value': 18.164587020874023}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-16 06:06.11[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516060455: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019420182704925537, 'time_algorithm_update': 0.0038736045360565187, 'loss': 2.037901365220547, 'time_step': 0.005865744352340698, 'init_value': 24.413904190063477}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-16 06:06.31[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516060455: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002145608901977539, 'time_algorithm_update': 0.004343953371047974, 'loss': 2.026307629108429, 'time_step': 0.0065436682701110836, 'init_value': 29.818445205688477}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-16 06:06.50[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516060455: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020532424449920656, 'time_algorithm_update': 0.004192523241043091, 'loss': 1.8947976433038711, 'time_step': 0.006298328161239624, 'init_value': 33.001319885253906}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-16 06:07.09[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516060455: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020674066543579102, 'time_algorithm_update': 0.004122426033020019, 'loss': 1.7124430824518204, 'time_step': 0.00624227499961853, 'init_value': 35.34858322143555}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-16 06:07.28[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516060455: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002107450008392334, 'time_algorithm_update': 0.004357028961181641, 'loss': 1.8366834799647331, 'time_step': 0.00651832914352417, 'init_value': 37.03758239746094}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-16 06:07.48[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516060455: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020990676879882814, 'time_algorithm_update': 0.004226805686950684, 'loss': 1.6391210842132569, 'time_step': 0.00637936520576477, 'init_value': 39.04216384887695}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-16 06:08.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516060455: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002070258378982544, 'time_algorithm_update': 0.004229012250900268, 'loss': 1.6138577119112014, 'time_step': 0.0063522789478302, 'init_value': 40.211402893066406}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.211402893066406
Starting 1000 evaluations
avg return on 3 trajectories of agent19: 1382.2124625212878
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-16 06:23.37[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-16 06:23.37[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-16 06:23.39[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-16 06:23.39[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-16 06:23.39[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250516062339[0m
[2m2025-05-16 06:23.39[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-16 06:23.58[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516062339: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020640368461608887, 'time_algorithm_update': 0.004211212873458862, 'loss': 1.6562341995984315, 'time_step': 0.006328259468078613, 'init_value': 4.48342752456665}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-16 06:24.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516062339: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020774052143096924, 'time_algorithm_update': 0.004104842662811279, 'loss': 2.4558699580430985, 'time_step': 0.006234536647796631, 'init_value': 11.47021770477295}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-16 06:24.36[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516062339: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020475471019744873, 'time_algorithm_update': 0.004174232244491577, 'loss': 2.1474760915637017, 'time_step': 0.006274564504623413, 'init_value': 18.568754196166992}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-16 06:24.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516062339: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020363867282867433, 'time_algorithm_update': 0.004016343116760254, 'loss': 2.1169705657958984, 'time_step': 0.006104145288467407, 'init_value': 24.858440399169922}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-16 06:25.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516062339: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020661756992340088, 'time_algorithm_update': 0.004224116563796997, 'loss': 1.848720390856266, 'time_step': 0.006343803882598877, 'init_value': 28.956497192382812}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-16 06:25.33[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516062339: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020733952522277834, 'time_algorithm_update': 0.0041910955905914305, 'loss': 1.9037940767407417, 'time_step': 0.006317802906036377, 'init_value': 32.74659729003906}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-16 06:25.52[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516062339: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019839532375335693, 'time_algorithm_update': 0.00400459098815918, 'loss': 1.8225871643424034, 'time_step': 0.00603865647315979, 'init_value': 36.432151794433594}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-16 06:26.11[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516062339: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002143988609313965, 'time_algorithm_update': 0.004335392951965332, 'loss': 1.7228417767286301, 'time_step': 0.006533613443374634, 'init_value': 38.648067474365234}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-16 06:26.30[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516062339: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002061911344528198, 'time_algorithm_update': 0.004237905979156494, 'loss': 1.595065046131611, 'time_step': 0.006353151559829712, 'init_value': 39.362308502197266}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-16 06:26.49[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516062339: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020695254802703855, 'time_algorithm_update': 0.004249047517776489, 'loss': 1.6234086466431619, 'time_step': 0.006372438907623291, 'init_value': 40.83562469482422}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.83562469482422
ave advantage rew: 40.75251445770264, std: 0.9912627681202972
avg cum rews: 1424.6729521576794, std: 20.416061139104773
Pearson correlation coefficient: -0.007758740978773091
Spearman correlation coefficient: -0.07969924812030076
Kendall Tau correlation coefficient: -0.042105263157894736
the best agent: 3, best agent cum rewards: 1450.5487070489012
1969
Starting to collect rollouts
Collecting rollouts: 10000/1000000
Collecting rollouts: 20000/1000000
Collecting rollouts: 30000/1000000
Collecting rollouts: 40000/1000000
Collecting rollouts: 50000/1000000
Collecting rollouts: 60000/1000000
Collecting rollouts: 70000/1000000
Collecting rollouts: 80000/1000000
Collecting rollouts: 90000/1000000
Collecting rollouts: 100000/1000000
Collecting rollouts: 110000/1000000
Collecting rollouts: 120000/1000000
Collecting rollouts: 130000/1000000
Collecting rollouts: 140000/1000000
Collecting rollouts: 150000/1000000
Collecting rollouts: 160000/1000000
Collecting rollouts: 170000/1000000
Collecting rollouts: 180000/1000000
Collecting rollouts: 190000/1000000
Collecting rollouts: 200000/1000000
Collecting rollouts: 210000/1000000
Collecting rollouts: 220000/1000000
Collecting rollouts: 230000/1000000
Collecting rollouts: 240000/1000000
Collecting rollouts: 250000/1000000
Collecting rollouts: 260000/1000000
Collecting rollouts: 270000/1000000
Collecting rollouts: 280000/1000000
Collecting rollouts: 290000/1000000
Collecting rollouts: 300000/1000000
Collecting rollouts: 310000/1000000
Collecting rollouts: 320000/1000000
Collecting rollouts: 330000/1000000
Collecting rollouts: 340000/1000000
Collecting rollouts: 350000/1000000
Collecting rollouts: 360000/1000000
Collecting rollouts: 370000/1000000
Collecting rollouts: 380000/1000000
Collecting rollouts: 390000/1000000
Collecting rollouts: 400000/1000000
Collecting rollouts: 410000/1000000
Collecting rollouts: 420000/1000000
Collecting rollouts: 430000/1000000
Collecting rollouts: 440000/1000000
Collecting rollouts: 450000/1000000
Collecting rollouts: 460000/1000000
Collecting rollouts: 470000/1000000
Collecting rollouts: 480000/1000000
Collecting rollouts: 490000/1000000
Collecting rollouts: 500000/1000000
Collecting rollouts: 510000/1000000
Collecting rollouts: 520000/1000000
Collecting rollouts: 530000/1000000
Collecting rollouts: 540000/1000000
Collecting rollouts: 550000/1000000
Collecting rollouts: 560000/1000000
Collecting rollouts: 570000/1000000
Collecting rollouts: 580000/1000000
Collecting rollouts: 590000/1000000
Collecting rollouts: 600000/1000000
Collecting rollouts: 610000/1000000
Collecting rollouts: 620000/1000000
Collecting rollouts: 630000/1000000
Collecting rollouts: 640000/1000000
Collecting rollouts: 650000/1000000
Collecting rollouts: 660000/1000000
Collecting rollouts: 670000/1000000
Collecting rollouts: 680000/1000000
Collecting rollouts: 690000/1000000
Collecting rollouts: 700000/1000000
Collecting rollouts: 710000/1000000
Collecting rollouts: 720000/1000000
Collecting rollouts: 730000/1000000
Collecting rollouts: 740000/1000000
Collecting rollouts: 750000/1000000
Collecting rollouts: 760000/1000000
Collecting rollouts: 770000/1000000
Collecting rollouts: 780000/1000000
Collecting rollouts: 790000/1000000
Collecting rollouts: 800000/1000000
Collecting rollouts: 810000/1000000
Collecting rollouts: 820000/1000000
Collecting rollouts: 830000/1000000
Collecting rollouts: 840000/1000000
Collecting rollouts: 850000/1000000
Collecting rollouts: 860000/1000000
Collecting rollouts: 870000/1000000
Collecting rollouts: 880000/1000000
Collecting rollouts: 890000/1000000
Collecting rollouts: 900000/1000000
Collecting rollouts: 910000/1000000
Collecting rollouts: 920000/1000000
Collecting rollouts: 930000/1000000
Collecting rollouts: 940000/1000000
Collecting rollouts: 950000/1000000
Collecting rollouts: 960000/1000000
Collecting rollouts: 970000/1000000
Collecting rollouts: 980000/1000000
Collecting rollouts: 990000/1000000
Collecting rollouts: 1000000/1000000
Replay buffer size:  (1000000, 105)
Replay buffer saved
---------------------------------
Searching empty space policies
(10, 11472)
(20, 11472)
(20, 11472)
Average distance of agents to nearest neighbors: 0.017759252685078747
Starting 1000 evaluations
avg return on 3 trajectories of agent0: 1445.6424515263416
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-16 07:00.17[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-16 07:00.17[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-16 07:00.19[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-16 07:00.19[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-16 07:00.19[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250516070019[0m
[2m2025-05-16 07:00.19[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-16 07:00.38[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516070019: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021220753192901613, 'time_algorithm_update': 0.0043221633434295656, 'loss': 1.862390559963882, 'time_step': 0.006497474908828735, 'init_value': 4.124733924865723}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-16 07:00.57[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516070019: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020639739036560057, 'time_algorithm_update': 0.004164262056350708, 'loss': 2.3252020306587218, 'time_step': 0.006280830383300781, 'init_value': 10.94005298614502}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-16 07:01.16[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516070019: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002129666805267334, 'time_algorithm_update': 0.004286495447158814, 'loss': 2.35667052924633, 'time_step': 0.006469933986663818, 'init_value': 18.678150177001953}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-16 07:01.36[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516070019: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020908074378967285, 'time_algorithm_update': 0.004272262334823609, 'loss': 2.1093825953006746, 'time_step': 0.0064172520637512205, 'init_value': 25.21940040588379}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-16 07:01.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516070019: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002052842378616333, 'time_algorithm_update': 0.004153727769851684, 'loss': 1.9861720409989356, 'time_step': 0.006259291172027588, 'init_value': 30.573461532592773}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-16 07:02.15[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516070019: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020919179916381835, 'time_algorithm_update': 0.004268479347229004, 'loss': 1.8737620577216147, 'time_step': 0.006413288831710815, 'init_value': 33.45429992675781}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-16 07:02.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516070019: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020784058570861817, 'time_algorithm_update': 0.0042211472988128666, 'loss': 1.7989002634882927, 'time_step': 0.006352818250656128, 'init_value': 35.65096664428711}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-16 07:02.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516070019: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020892157554626466, 'time_algorithm_update': 0.004164722204208374, 'loss': 1.6253611912727357, 'time_step': 0.006306739091873169, 'init_value': 38.30231475830078}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-16 07:03.12[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516070019: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020538463592529297, 'time_algorithm_update': 0.004045434713363647, 'loss': 1.7150031473040581, 'time_step': 0.006150558948516845, 'init_value': 38.496334075927734}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-16 07:03.32[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516070019: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021117985248565673, 'time_algorithm_update': 0.0042625293731689455, 'loss': 1.6526138062477111, 'time_step': 0.006427437782287598, 'init_value': 39.61410903930664}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 39.61410903930664
Starting 1000 evaluations
avg return on 3 trajectories of agent1: 1440.826173197786
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-16 07:18.58[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-16 07:18.58[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-16 07:18.59[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-16 07:18.59[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-16 07:18.59[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250516071859[0m
[2m2025-05-16 07:18.59[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-16 07:19.19[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516071859: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020880007743835447, 'time_algorithm_update': 0.004298624038696289, 'loss': 1.719449433669448, 'time_step': 0.006439835786819458, 'init_value': 4.127207279205322}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-16 07:19.38[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516071859: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020055055618286135, 'time_algorithm_update': 0.004029945135116577, 'loss': 2.167887593567371, 'time_step': 0.006087500810623169, 'init_value': 9.710856437683105}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-16 07:19.57[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516071859: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020932555198669434, 'time_algorithm_update': 0.004297489166259765, 'loss': 2.189262711763382, 'time_step': 0.006444468259811402, 'init_value': 17.26059341430664}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-16 07:20.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516071859: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002108711242675781, 'time_algorithm_update': 0.0043257782459259035, 'loss': 2.0523095505833626, 'time_step': 0.006488070249557495, 'init_value': 23.579387664794922}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-16 07:20.36[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516071859: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00210894775390625, 'time_algorithm_update': 0.004265354633331299, 'loss': 1.9355580216646195, 'time_step': 0.006427719593048096, 'init_value': 27.998340606689453}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-16 07:20.56[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516071859: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020899741649627684, 'time_algorithm_update': 0.004300865888595581, 'loss': 1.8440676678419112, 'time_step': 0.006444575786590576, 'init_value': 31.416006088256836}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-16 07:21.15[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516071859: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020828349590301513, 'time_algorithm_update': 0.00425666618347168, 'loss': 1.7666867390871048, 'time_step': 0.006392459630966187, 'init_value': 34.94672775268555}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-16 07:21.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516071859: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002086237907409668, 'time_algorithm_update': 0.004269048929214477, 'loss': 1.6888579515218736, 'time_step': 0.006408446311950684, 'init_value': 38.050743103027344}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-16 07:21.54[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516071859: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019953505992889404, 'time_algorithm_update': 0.0039911048412323, 'loss': 1.6397471786141395, 'time_step': 0.00603715181350708, 'init_value': 40.00761032104492}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-16 07:22.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516071859: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021305902004241945, 'time_algorithm_update': 0.004329258918762207, 'loss': 1.692277357161045, 'time_step': 0.006513387203216553, 'init_value': 40.459686279296875}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.459686279296875
Starting 1000 evaluations
avg return on 3 trajectories of agent2: 1437.6933786361494
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-16 07:37.41[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-16 07:37.41[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-16 07:37.42[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-16 07:37.42[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-16 07:37.42[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250516073742[0m
[2m2025-05-16 07:37.42[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-16 07:38.01[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516073742: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020766682624816894, 'time_algorithm_update': 0.004212683439254761, 'loss': 1.678274775788188, 'time_step': 0.006342687129974365, 'init_value': 3.9794535636901855}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-16 07:38.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516073742: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021085333824157715, 'time_algorithm_update': 0.004313985824584961, 'loss': 2.3970016315579414, 'time_step': 0.006476336240768433, 'init_value': 10.158599853515625}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-16 07:38.39[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516073742: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020020756721496583, 'time_algorithm_update': 0.004052086114883423, 'loss': 2.2462130894064902, 'time_step': 0.0061064488887786865, 'init_value': 17.933752059936523}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-16 07:38.59[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516073742: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002075047492980957, 'time_algorithm_update': 0.0042636370658874516, 'loss': 2.1784672840237618, 'time_step': 0.006392217874526977, 'init_value': 24.56361198425293}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-16 07:39.18[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516073742: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002113176107406616, 'time_algorithm_update': 0.004250727891921997, 'loss': 1.9184002332687378, 'time_step': 0.00641736626625061, 'init_value': 29.741994857788086}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-16 07:39.37[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516073742: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019990787506103517, 'time_algorithm_update': 0.004016393184661865, 'loss': 1.776959250807762, 'time_step': 0.006066867589950562, 'init_value': 32.44211196899414}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-16 07:39.56[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516073742: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020885119438171385, 'time_algorithm_update': 0.004234055519104004, 'loss': 1.810256735265255, 'time_step': 0.006376212596893311, 'init_value': 36.10074234008789}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-16 07:40.16[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516073742: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020955085754394533, 'time_algorithm_update': 0.004279981136322022, 'loss': 1.717588061749935, 'time_step': 0.00642975926399231, 'init_value': 37.53499221801758}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-16 07:40.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516073742: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019888956546783446, 'time_algorithm_update': 0.0039695565700531, 'loss': 1.5577317318916322, 'time_step': 0.0060092973709106445, 'init_value': 37.86779022216797}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-16 07:40.54[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516073742: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020871920585632323, 'time_algorithm_update': 0.004273730516433716, 'loss': 1.6448017616868018, 'time_step': 0.0064143772125244145, 'init_value': 40.52008056640625}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.52008056640625
Starting 1000 evaluations
avg return on 3 trajectories of agent3: 1438.4689084420872
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-16 07:56.18[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-16 07:56.18[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-16 07:56.19[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-16 07:56.19[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-16 07:56.19[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250516075619[0m
[2m2025-05-16 07:56.19[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-16 07:56.39[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516075619: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002048537254333496, 'time_algorithm_update': 0.004171830892562866, 'loss': 1.4966044836193324, 'time_step': 0.006274328470230102, 'init_value': 4.651333808898926}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-16 07:56.58[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516075619: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002054328680038452, 'time_algorithm_update': 0.004167672872543335, 'loss': 2.177997948050499, 'time_step': 0.006275057554244995, 'init_value': 11.409348487854004}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-16 07:57.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516075619: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021096346378326417, 'time_algorithm_update': 0.004281513214111328, 'loss': 2.404911401331425, 'time_step': 0.006445884704589844, 'init_value': 19.03680992126465}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-16 07:57.36[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516075619: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020654890537261964, 'time_algorithm_update': 0.00419992208480835, 'loss': 2.1441160069704055, 'time_step': 0.006318582773208618, 'init_value': 25.435253143310547}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-16 07:57.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516075619: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020823874473571776, 'time_algorithm_update': 0.004184267520904541, 'loss': 1.8784027583003045, 'time_step': 0.006320221900939942, 'init_value': 29.148723602294922}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-16 07:58.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516075619: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019982542991638184, 'time_algorithm_update': 0.004006639957427978, 'loss': 1.7457730015516282, 'time_step': 0.006056320190429687, 'init_value': 31.97930145263672}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-16 07:58.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516075619: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020665457248687743, 'time_algorithm_update': 0.004261747598648071, 'loss': 1.8633284156918526, 'time_step': 0.0063814857006073, 'init_value': 34.535091400146484}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-16 07:58.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516075619: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020530123710632326, 'time_algorithm_update': 0.004166822195053101, 'loss': 1.8322776273488999, 'time_step': 0.006272987365722656, 'init_value': 35.56886291503906}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-16 07:59.12[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516075619: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001995341062545776, 'time_algorithm_update': 0.003919949769973755, 'loss': 1.6581942747831344, 'time_step': 0.005966639518737793, 'init_value': 39.20415496826172}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-16 07:59.31[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516075619: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020905663967132567, 'time_algorithm_update': 0.004282229661941529, 'loss': 1.6801993020176889, 'time_step': 0.0064267065525054935, 'init_value': 42.4723014831543}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.4723014831543
Starting 1000 evaluations
avg return on 3 trajectories of agent4: 1444.9476433696473
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-16 08:14.59[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-16 08:14.59[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-16 08:15.00[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-16 08:15.00[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-16 08:15.00[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250516081500[0m
[2m2025-05-16 08:15.00[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-16 08:15.19[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516081500: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002065675973892212, 'time_algorithm_update': 0.0041527247428894045, 'loss': 1.7075344276204705, 'time_step': 0.006271279335021972, 'init_value': 4.343662738800049}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-16 08:15.39[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516081500: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002119934558868408, 'time_algorithm_update': 0.0041664581298828125, 'loss': 2.459741023480892, 'time_step': 0.006339433670043945, 'init_value': 11.364389419555664}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-16 08:15.58[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516081500: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021173529624938965, 'time_algorithm_update': 0.0043245706558227535, 'loss': 2.450650348186493, 'time_step': 0.006495460033416748, 'init_value': 19.537832260131836}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-16 08:16.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516081500: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002106494188308716, 'time_algorithm_update': 0.004256920576095581, 'loss': 2.076298704326153, 'time_step': 0.0064171462059020995, 'init_value': 25.07158088684082}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-16 08:16.37[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516081500: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020716021060943604, 'time_algorithm_update': 0.004199092626571655, 'loss': 1.8348386011123656, 'time_step': 0.006323324680328369, 'init_value': 30.31952667236328}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-16 08:16.56[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516081500: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002048386812210083, 'time_algorithm_update': 0.004023893117904663, 'loss': 1.7472587007284164, 'time_step': 0.006123762130737304, 'init_value': 33.15691375732422}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-16 08:17.16[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516081500: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002135035514831543, 'time_algorithm_update': 0.004374339818954468, 'loss': 1.7707122503519057, 'time_step': 0.00656333065032959, 'init_value': 36.699710845947266}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-16 08:17.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516081500: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021035640239715574, 'time_algorithm_update': 0.0042661700248718265, 'loss': 1.666564789235592, 'time_step': 0.006423120498657227, 'init_value': 38.69595718383789}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-16 08:17.54[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516081500: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002001122713088989, 'time_algorithm_update': 0.003962054252624512, 'loss': 1.5946067048311234, 'time_step': 0.006014056921005249, 'init_value': 38.77397155761719}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-16 08:18.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516081500: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021382155418395994, 'time_algorithm_update': 0.004282097339630127, 'loss': 1.6250944672822951, 'time_step': 0.006473824739456176, 'init_value': 41.202552795410156}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.202552795410156
Starting 1000 evaluations
avg return on 3 trajectories of agent5: 1430.6785057954687
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-16 08:33.38[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-16 08:33.38[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-16 08:33.39[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-16 08:33.39[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-16 08:33.39[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250516083339[0m
[2m2025-05-16 08:33.39[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-16 08:33.58[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516083339: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002031789064407349, 'time_algorithm_update': 0.0040961866378784175, 'loss': 1.775161851592362, 'time_step': 0.006179909467697144, 'init_value': 4.504001617431641}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-16 08:34.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516083339: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020216050148010255, 'time_algorithm_update': 0.004053035259246826, 'loss': 2.3734127009510995, 'time_step': 0.006126384258270264, 'init_value': 10.87698745727539}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-16 08:34.37[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516083339: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021552541255950926, 'time_algorithm_update': 0.004371063709259033, 'loss': 2.3148397575616837, 'time_step': 0.00658045244216919, 'init_value': 19.134212493896484}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-16 08:34.57[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516083339: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020950984954833983, 'time_algorithm_update': 0.0042507553100585935, 'loss': 2.1114090703725816, 'time_step': 0.006399592399597168, 'init_value': 25.905778884887695}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-16 08:35.16[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516083339: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020006821155548094, 'time_algorithm_update': 0.004029221057891845, 'loss': 2.028820616424084, 'time_step': 0.006081683874130249, 'init_value': 29.68521499633789}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-16 08:35.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516083339: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002139402151107788, 'time_algorithm_update': 0.004337558746337891, 'loss': 1.7289208443760873, 'time_step': 0.006530625343322754, 'init_value': 33.37619400024414}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-16 08:35.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516083339: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021130247116088866, 'time_algorithm_update': 0.0043098444938659665, 'loss': 1.7353636626601219, 'time_step': 0.006476792812347412, 'init_value': 34.900726318359375}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-16 08:36.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516083339: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020740013122558594, 'time_algorithm_update': 0.004188601016998291, 'loss': 1.7938925777077674, 'time_step': 0.006315029621124267, 'init_value': 38.11588668823242}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-16 08:36.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516083339: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021036300659179686, 'time_algorithm_update': 0.004284502983093262, 'loss': 1.7957116453051567, 'time_step': 0.006441921234130859, 'init_value': 40.27279281616211}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-16 08:36.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516083339: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00209763240814209, 'time_algorithm_update': 0.004223228693008423, 'loss': 1.6956470958590508, 'time_step': 0.00637459659576416, 'init_value': 42.9958610534668}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.9958610534668
Starting 1000 evaluations
avg return on 3 trajectories of agent6: 1421.223274350104
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-16 08:52.19[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-16 08:52.19[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-16 08:52.20[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-16 08:52.20[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-16 08:52.20[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250516085220[0m
[2m2025-05-16 08:52.20[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-16 08:52.39[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516085220: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020042061805725098, 'time_algorithm_update': 0.00400728702545166, 'loss': 1.6913319364115595, 'time_step': 0.006062990188598633, 'init_value': 4.424642562866211}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-16 08:52.58[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516085220: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020864088535308837, 'time_algorithm_update': 0.004261789798736572, 'loss': 2.28018381690979, 'time_step': 0.0064014940261840824, 'init_value': 10.469347953796387}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-16 08:53.18[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516085220: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002153641700744629, 'time_algorithm_update': 0.00440911865234375, 'loss': 2.33027283513546, 'time_step': 0.006617143630981446, 'init_value': 17.587594985961914}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-16 08:53.37[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516085220: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002075828313827515, 'time_algorithm_update': 0.004226468086242676, 'loss': 2.077511247098446, 'time_step': 0.006355395555496216, 'init_value': 24.100248336791992}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-16 08:53.57[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516085220: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002101358890533447, 'time_algorithm_update': 0.0043415679931640624, 'loss': 1.9967196535468101, 'time_step': 0.006497033357620239, 'init_value': 28.781312942504883}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-16 08:54.16[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516085220: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021229126453399657, 'time_algorithm_update': 0.0043242316246032714, 'loss': 1.804428871870041, 'time_step': 0.00650108528137207, 'init_value': 32.39109802246094}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-16 08:54.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516085220: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020566625595092774, 'time_algorithm_update': 0.004223814964294434, 'loss': 1.7168982898592948, 'time_step': 0.006333616495132447, 'init_value': 35.2740592956543}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-16 08:54.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516085220: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002053473949432373, 'time_algorithm_update': 0.004137393951416016, 'loss': 1.6799548194408416, 'time_step': 0.006243315696716309, 'init_value': 36.917598724365234}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-16 08:55.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516085220: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020525176525115966, 'time_algorithm_update': 0.004215966463088989, 'loss': 1.5575275270342828, 'time_step': 0.006322315692901611, 'init_value': 39.184226989746094}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-16 08:55.33[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516085220: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002123976707458496, 'time_algorithm_update': 0.004239171266555786, 'loss': 1.646849794268608, 'time_step': 0.006416773319244385, 'init_value': 41.690223693847656}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.690223693847656
Starting 1000 evaluations
avg return on 3 trajectories of agent7: 1401.1020920864844
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-16 09:10.59[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-16 09:10.59[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-16 09:11.00[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-16 09:11.00[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-16 09:11.00[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250516091100[0m
[2m2025-05-16 09:11.00[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-16 09:11.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516091100: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002053428888320923, 'time_algorithm_update': 0.004172796249389648, 'loss': 1.5384058867096901, 'time_step': 0.006278452157974243, 'init_value': 4.647539138793945}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-16 09:11.38[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516091100: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002077477216720581, 'time_algorithm_update': 0.004057647943496704, 'loss': 2.3024019867777823, 'time_step': 0.006186928510665894, 'init_value': 11.77524471282959}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-16 09:11.58[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516091100: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002077607870101929, 'time_algorithm_update': 0.004259772539138794, 'loss': 2.282421749830246, 'time_step': 0.006390545845031738, 'init_value': 19.049015045166016}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-16 09:12.18[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516091100: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002163701057434082, 'time_algorithm_update': 0.004443421602249146, 'loss': 2.143914062440395, 'time_step': 0.00666152024269104, 'init_value': 25.353172302246094}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-16 09:12.37[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516091100: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002025416851043701, 'time_algorithm_update': 0.004107759714126587, 'loss': 1.977070560634136, 'time_step': 0.00618447470664978, 'init_value': 29.641000747680664}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-16 09:12.56[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516091100: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020907299518585203, 'time_algorithm_update': 0.004232999563217163, 'loss': 1.7841250869631766, 'time_step': 0.0063765947818756104, 'init_value': 31.78760528564453}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-16 09:13.16[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516091100: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020649631023406984, 'time_algorithm_update': 0.00417122483253479, 'loss': 1.8250304013490677, 'time_step': 0.0062891776561737065, 'init_value': 34.37403106689453}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-16 09:13.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516091100: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020892200469970704, 'time_algorithm_update': 0.004184040307998657, 'loss': 1.7591018952131272, 'time_step': 0.006325741529464721, 'init_value': 36.31733322143555}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-16 09:13.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516091100: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020859596729278563, 'time_algorithm_update': 0.004265611410140991, 'loss': 1.7325264491438865, 'time_step': 0.0064050953388214114, 'init_value': 38.0438346862793}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-16 09:14.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516091100: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002088335037231445, 'time_algorithm_update': 0.00424865460395813, 'loss': 1.6110408130288123, 'time_step': 0.0063903071880340575, 'init_value': 40.6782341003418}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.6782341003418
Starting 1000 evaluations
avg return on 3 trajectories of agent8: 1452.337184492596
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-16 09:29.41[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-16 09:29.41[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-16 09:29.42[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-16 09:29.42[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-16 09:29.42[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250516092942[0m
[2m2025-05-16 09:29.42[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-16 09:30.02[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516092942: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020751936435699464, 'time_algorithm_update': 0.004191358566284179, 'loss': 1.615546950764954, 'time_step': 0.006319365739822388, 'init_value': 4.660048961639404}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-16 09:30.21[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516092942: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020959885120391845, 'time_algorithm_update': 0.004258728981018066, 'loss': 2.39341730427742, 'time_step': 0.006407612323760986, 'init_value': 11.08669376373291}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-16 09:30.40[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516092942: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002078866958618164, 'time_algorithm_update': 0.004223194360733032, 'loss': 2.355434246122837, 'time_step': 0.00635506010055542, 'init_value': 18.282487869262695}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-16 09:31.00[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516092942: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002081761121749878, 'time_algorithm_update': 0.004271879673004151, 'loss': 2.076966506779194, 'time_step': 0.006406258344650268, 'init_value': 24.613985061645508}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-16 09:31.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516092942: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020881500244140623, 'time_algorithm_update': 0.004282617568969726, 'loss': 1.9291784452795981, 'time_step': 0.0064239327907562255, 'init_value': 29.25760269165039}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-16 09:31.39[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516092942: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021240880489349365, 'time_algorithm_update': 0.004307172060012817, 'loss': 1.8525594154596328, 'time_step': 0.006484637260437012, 'init_value': 33.05373764038086}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-16 09:31.58[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516092942: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00202457594871521, 'time_algorithm_update': 0.004064613819122314, 'loss': 1.619623383998871, 'time_step': 0.006140671253204346, 'init_value': 35.26389694213867}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-16 09:32.18[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516092942: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021478350162506105, 'time_algorithm_update': 0.004300803899765015, 'loss': 1.697276502430439, 'time_step': 0.0065025463104248045, 'init_value': 37.31470489501953}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-16 09:32.37[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516092942: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021059772968292237, 'time_algorithm_update': 0.004328879594802856, 'loss': 1.59782699239254, 'time_step': 0.006488831520080567, 'init_value': 39.84259033203125}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-16 09:32.56[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516092942: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020416483879089355, 'time_algorithm_update': 0.004038020849227906, 'loss': 1.7060015785098075, 'time_step': 0.006130852937698364, 'init_value': 41.658748626708984}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.658748626708984
Starting 1000 evaluations
avg return on 3 trajectories of agent9: 1448.062275280709
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-16 09:48.26[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-16 09:48.26[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-16 09:48.27[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-16 09:48.27[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-16 09:48.27[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250516094827[0m
[2m2025-05-16 09:48.27[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-16 09:48.47[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516094827: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020278801918029786, 'time_algorithm_update': 0.004074744939804077, 'loss': 1.6632724719941616, 'time_step': 0.00615430212020874, 'init_value': 4.260750770568848}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-16 09:49.06[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516094827: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020565400123596193, 'time_algorithm_update': 0.004160901546478271, 'loss': 2.341463557422161, 'time_step': 0.006269260406494141, 'init_value': 10.27486515045166}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-16 09:49.25[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516094827: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00198085618019104, 'time_algorithm_update': 0.003976444244384766, 'loss': 2.2442574346065522, 'time_step': 0.006008105516433716, 'init_value': 17.70160484313965}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-16 09:49.44[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516094827: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002143497943878174, 'time_algorithm_update': 0.004385393381118774, 'loss': 2.1105397033691404, 'time_step': 0.006582684993743896, 'init_value': 24.093935012817383}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-16 09:50.04[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516094827: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020394856929779053, 'time_algorithm_update': 0.0041687719821929935, 'loss': 1.948694966852665, 'time_step': 0.0062609071731567385, 'init_value': 28.611820220947266}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-16 09:50.23[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516094827: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002061187028884888, 'time_algorithm_update': 0.004059545040130615, 'loss': 1.8819705601930619, 'time_step': 0.00617254900932312, 'init_value': 32.07587432861328}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-16 09:50.43[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516094827: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002070138692855835, 'time_algorithm_update': 0.0042292909622192384, 'loss': 1.715064942777157, 'time_step': 0.006352586269378662, 'init_value': 34.55445098876953}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-16 09:51.02[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516094827: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021103155612945557, 'time_algorithm_update': 0.0042779302597045895, 'loss': 1.7111699264645577, 'time_step': 0.00644204306602478, 'init_value': 35.76694107055664}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-16 09:51.21[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516094827: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020361104011535646, 'time_algorithm_update': 0.004123401641845703, 'loss': 1.6387682493925095, 'time_step': 0.006212110996246338, 'init_value': 40.309478759765625}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-16 09:51.41[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516094827: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00214050030708313, 'time_algorithm_update': 0.004339513540267945, 'loss': 1.61234449249506, 'time_step': 0.006534080028533936, 'init_value': 40.26236343383789}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.26236343383789
Starting 1000 evaluations
avg return on 3 trajectories of agent10: 1455.5545990226597
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-16 10:07.19[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-16 10:07.19[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-16 10:07.20[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-16 10:07.20[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-16 10:07.20[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250516100720[0m
[2m2025-05-16 10:07.20[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-16 10:07.39[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516100720: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020308833122253418, 'time_algorithm_update': 0.004094310998916626, 'loss': 1.5438355720937251, 'time_step': 0.00617698049545288, 'init_value': 3.953364849090576}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-16 10:07.58[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516100720: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020471272468566893, 'time_algorithm_update': 0.0040865705013275145, 'loss': 2.169570085465908, 'time_step': 0.006185750246047974, 'init_value': 10.923874855041504}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-16 10:08.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516100720: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002075713634490967, 'time_algorithm_update': 0.004226254463195801, 'loss': 2.1907400876283645, 'time_step': 0.006355341672897339, 'init_value': 18.451946258544922}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-16 10:08.37[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516100720: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002113962173461914, 'time_algorithm_update': 0.004245129585266114, 'loss': 2.095029850304127, 'time_step': 0.0064120149612426755, 'init_value': 25.039236068725586}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-16 10:08.56[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516100720: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001992518901824951, 'time_algorithm_update': 0.004001672506332397, 'loss': 1.8980337789058686, 'time_step': 0.0060452744960784914, 'init_value': 29.262487411499023}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-16 10:09.16[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516100720: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021408698558807375, 'time_algorithm_update': 0.00433352518081665, 'loss': 1.7454931122660637, 'time_step': 0.006528643131256104, 'init_value': 32.88600540161133}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-16 10:09.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516100720: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002115794897079468, 'time_algorithm_update': 0.004339534759521485, 'loss': 1.6709424355626106, 'time_step': 0.006509364604949951, 'init_value': 36.101524353027344}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-16 10:09.54[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516100720: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020257787704467773, 'time_algorithm_update': 0.004092903375625611, 'loss': 1.7165486196279525, 'time_step': 0.006170717000961304, 'init_value': 37.163108825683594}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-16 10:10.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516100720: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021240158081054688, 'time_algorithm_update': 0.004391893386840821, 'loss': 1.583732993721962, 'time_step': 0.006571027517318725, 'init_value': 40.721405029296875}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-16 10:10.33[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516100720: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002101294994354248, 'time_algorithm_update': 0.004227586507797241, 'loss': 1.8510564575195312, 'time_step': 0.006382282257080078, 'init_value': 42.86442947387695}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.86442947387695
Starting 1000 evaluations
avg return on 3 trajectories of agent11: 1451.847612158063
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-16 10:25.51[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-16 10:25.51[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-16 10:25.52[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-16 10:25.52[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-16 10:25.52[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250516102552[0m
[2m2025-05-16 10:25.52[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-16 10:26.11[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516102552: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020220661163330078, 'time_algorithm_update': 0.0040906059741973875, 'loss': 1.4063934802636504, 'time_step': 0.0061646044254302975, 'init_value': 4.118027687072754}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-16 10:26.31[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516102552: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020417509078979493, 'time_algorithm_update': 0.004110298871994019, 'loss': 2.3098605896234514, 'time_step': 0.006204508066177368, 'init_value': 10.861327171325684}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-16 10:26.49[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516102552: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019450745582580567, 'time_algorithm_update': 0.0038406326770782473, 'loss': 2.213786117851734, 'time_step': 0.005836238622665405, 'init_value': 17.725797653198242}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-16 10:27.09[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516102552: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002079949855804443, 'time_algorithm_update': 0.004257631778717041, 'loss': 2.1191144759058953, 'time_step': 0.006391450166702271, 'init_value': 23.659347534179688}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-16 10:27.28[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516102552: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002092835187911987, 'time_algorithm_update': 0.004215927839279175, 'loss': 1.9694268680214881, 'time_step': 0.006362400054931641, 'init_value': 28.823537826538086}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-16 10:27.48[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516102552: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020724215507507324, 'time_algorithm_update': 0.004202125072479248, 'loss': 1.8065707716345787, 'time_step': 0.006328132152557373, 'init_value': 32.64447784423828}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-16 10:28.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516102552: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021257827281951905, 'time_algorithm_update': 0.004346215009689331, 'loss': 1.657132671892643, 'time_step': 0.006526237487792969, 'init_value': 35.99395751953125}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-16 10:28.26[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516102552: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002080253601074219, 'time_algorithm_update': 0.0042230143547058105, 'loss': 1.664562179505825, 'time_step': 0.006356694221496582, 'init_value': 38.11911392211914}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-16 10:28.46[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516102552: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021023967266082765, 'time_algorithm_update': 0.004293178796768189, 'loss': 1.586685167312622, 'time_step': 0.0064492919445037844, 'init_value': 39.48762512207031}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-16 10:29.05[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516102552: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001969102382659912, 'time_algorithm_update': 0.0038551809787750243, 'loss': 1.5695490390062332, 'time_step': 0.005874518156051636, 'init_value': 40.7487907409668}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.7487907409668
Starting 1000 evaluations
avg return on 3 trajectories of agent12: 1441.4156731545338
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-16 10:44.23[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-16 10:44.23[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-16 10:44.24[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-16 10:44.24[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-16 10:44.24[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250516104424[0m
[2m2025-05-16 10:44.24[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-16 10:44.43[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516104424: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002070364236831665, 'time_algorithm_update': 0.004205544471740722, 'loss': 1.582364526487887, 'time_step': 0.006328641176223755, 'init_value': 4.257040500640869}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-16 10:45.02[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516104424: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020542616844177247, 'time_algorithm_update': 0.00407386565208435, 'loss': 2.336949237883091, 'time_step': 0.00618051552772522, 'init_value': 10.431220054626465}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-16 10:45.21[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516104424: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020506198406219484, 'time_algorithm_update': 0.004161444664001465, 'loss': 2.300280700981617, 'time_step': 0.0062654163837432865, 'init_value': 18.19718360900879}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-16 10:45.40[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516104424: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001969030141830444, 'time_algorithm_update': 0.00386706018447876, 'loss': 2.115449450492859, 'time_step': 0.005886662483215332, 'init_value': 24.751373291015625}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-16 10:45.59[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516104424: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00205772590637207, 'time_algorithm_update': 0.004201659440994263, 'loss': 1.9350560418367386, 'time_step': 0.00631253981590271, 'init_value': 29.013879776000977}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-16 10:46.19[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516104424: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002082847833633423, 'time_algorithm_update': 0.004148716688156128, 'loss': 1.9005427963137627, 'time_step': 0.006284186124801636, 'init_value': 32.791015625}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-16 10:46.37[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516104424: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020145883560180665, 'time_algorithm_update': 0.004057317018508911, 'loss': 1.7423540575504304, 'time_step': 0.00612328052520752, 'init_value': 34.73835754394531}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-16 10:46.57[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516104424: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021222896575927735, 'time_algorithm_update': 0.004253036975860595, 'loss': 1.7647168353796006, 'time_step': 0.00642866849899292, 'init_value': 37.07258987426758}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-16 10:47.16[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516104424: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021076536178588866, 'time_algorithm_update': 0.004343746423721313, 'loss': 1.614211065709591, 'time_step': 0.006505349159240723, 'init_value': 38.09541320800781}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-16 10:47.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516104424: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020426692962646482, 'time_algorithm_update': 0.004142799139022827, 'loss': 1.5291184812784195, 'time_step': 0.006238074064254761, 'init_value': 39.63249588012695}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 39.63249588012695
Starting 1000 evaluations
avg return on 3 trajectories of agent13: 1451.9672978199608
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-16 11:02.48[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-16 11:02.48[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-16 11:02.49[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-16 11:02.49[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-16 11:02.49[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250516110249[0m
[2m2025-05-16 11:02.49[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-16 11:03.08[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516110249: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020336480140686034, 'time_algorithm_update': 0.004061780452728272, 'loss': 1.615572742059827, 'time_step': 0.006146912336349487, 'init_value': 4.034592628479004}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-16 11:03.28[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516110249: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021315016746520994, 'time_algorithm_update': 0.004269882917404175, 'loss': 2.2896091373562815, 'time_step': 0.006454795837402344, 'init_value': 10.411494255065918}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-16 11:03.47[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516110249: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020694546699523927, 'time_algorithm_update': 0.004149078607559204, 'loss': 2.3072069439888, 'time_step': 0.006270962715148926, 'init_value': 17.98346519470215}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-16 11:04.06[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516110249: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021140584945678713, 'time_algorithm_update': 0.004198163986206055, 'loss': 2.0107966271042823, 'time_step': 0.006364013910293579, 'init_value': 24.639760971069336}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-16 11:04.25[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516110249: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020144970417022706, 'time_algorithm_update': 0.004021401882171631, 'loss': 1.8819691265225411, 'time_step': 0.006086491584777832, 'init_value': 28.272146224975586}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-16 11:04.44[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516110249: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020987215042114257, 'time_algorithm_update': 0.004165072679519653, 'loss': 1.8301635887026786, 'time_step': 0.006316950798034668, 'init_value': 31.646465301513672}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-16 11:05.03[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516110249: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002041346311569214, 'time_algorithm_update': 0.004076320886611939, 'loss': 1.8254736756682397, 'time_step': 0.006169748306274414, 'init_value': 34.82664108276367}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-16 11:05.22[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516110249: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020274500846862793, 'time_algorithm_update': 0.003987272024154663, 'loss': 1.7739795789718629, 'time_step': 0.006065730571746826, 'init_value': 37.58388137817383}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-16 11:05.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516110249: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020588481426239012, 'time_algorithm_update': 0.004181657552719116, 'loss': 1.711081952393055, 'time_step': 0.00629337739944458, 'init_value': 39.71541976928711}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-16 11:06.01[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516110249: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020803844928741454, 'time_algorithm_update': 0.004151504516601562, 'loss': 1.758739082813263, 'time_step': 0.006285134792327881, 'init_value': 42.80754089355469}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.80754089355469
Starting 1000 evaluations
avg return on 3 trajectories of agent14: 1448.9119996298948
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-16 11:21.18[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-16 11:21.18[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-16 11:21.20[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-16 11:21.20[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-16 11:21.20[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250516112120[0m
[2m2025-05-16 11:21.20[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-16 11:21.38[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516112120: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020219454765319825, 'time_algorithm_update': 0.0040498337745666505, 'loss': 1.563806892633438, 'time_step': 0.006122847557067871, 'init_value': 3.9658992290496826}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-16 11:21.57[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516112120: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020825746059417722, 'time_algorithm_update': 0.0041961190700531, 'loss': 2.2403914551734925, 'time_step': 0.006331467390060424, 'init_value': 11.496197700500488}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-16 11:22.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516112120: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00210213565826416, 'time_algorithm_update': 0.004130257368087769, 'loss': 2.323736323058605, 'time_step': 0.006284651994705201, 'init_value': 20.038713455200195}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-16 11:22.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516112120: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002071368455886841, 'time_algorithm_update': 0.0041886608600616455, 'loss': 2.163508150935173, 'time_step': 0.006312052011489868, 'init_value': 25.399044036865234}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-16 11:22.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516112120: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020068695545196534, 'time_algorithm_update': 0.003931975841522216, 'loss': 1.9825380337834357, 'time_step': 0.005989248752593994, 'init_value': 29.51580047607422}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-16 11:23.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516112120: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020614280700683592, 'time_algorithm_update': 0.004167751789093017, 'loss': 1.8811708668470382, 'time_step': 0.006281656265258789, 'init_value': 33.69785690307617}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-16 11:23.33[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516112120: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002029810667037964, 'time_algorithm_update': 0.004067271709442139, 'loss': 1.7392812071442605, 'time_step': 0.006148929357528686, 'init_value': 35.7933349609375}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-16 11:23.51[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516112120: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002004873991012573, 'time_algorithm_update': 0.00400779390335083, 'loss': 1.7759122056961059, 'time_step': 0.006063956022262573, 'init_value': 38.58944320678711}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-16 11:24.11[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516112120: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020997743606567384, 'time_algorithm_update': 0.004209072351455689, 'loss': 1.7814265100955964, 'time_step': 0.006362229108810425, 'init_value': 40.02114486694336}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-16 11:24.30[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516112120: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020782535076141356, 'time_algorithm_update': 0.004259355545043945, 'loss': 1.6919232169389724, 'time_step': 0.006390788555145264, 'init_value': 41.510704040527344}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.510704040527344
Starting 1000 evaluations
avg return on 3 trajectories of agent15: 1437.9737364299447
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-16 11:39.44[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-16 11:39.44[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-16 11:39.45[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-16 11:39.45[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-16 11:39.45[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250516113945[0m
[2m2025-05-16 11:39.45[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-16 11:40.04[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516113945: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002081336259841919, 'time_algorithm_update': 0.004286914110183716, 'loss': 1.5536755707785488, 'time_step': 0.006421681642532349, 'init_value': 3.9004008769989014}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-16 11:40.23[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516113945: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019788227081298827, 'time_algorithm_update': 0.0039397714138031, 'loss': 2.406565217554569, 'time_step': 0.0059697425365448, 'init_value': 10.631311416625977}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-16 11:40.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516113945: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002100546360015869, 'time_algorithm_update': 0.004266546487808227, 'loss': 2.1854678171873094, 'time_step': 0.0064212424755096436, 'init_value': 18.55660057067871}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-16 11:41.01[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516113945: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020186612606048586, 'time_algorithm_update': 0.0041005973815917965, 'loss': 2.0599283155798913, 'time_step': 0.00617147970199585, 'init_value': 25.317283630371094}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-16 11:41.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516113945: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020186183452606202, 'time_algorithm_update': 0.004075181007385254, 'loss': 1.90660979616642, 'time_step': 0.006146240234375, 'init_value': 30.070018768310547}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-16 11:41.40[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516113945: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022187814712524415, 'time_algorithm_update': 0.00450782322883606, 'loss': 1.8215014989376068, 'time_step': 0.006782459735870361, 'init_value': 33.26001739501953}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-16 11:42.01[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516113945: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002215829610824585, 'time_algorithm_update': 0.004437467813491821, 'loss': 1.702698550760746, 'time_step': 0.00670882511138916, 'init_value': 34.975975036621094}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-16 11:42.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516113945: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021608731746673585, 'time_algorithm_update': 0.004355776309967041, 'loss': 1.5661176424026488, 'time_step': 0.006570636034011841, 'init_value': 36.94322204589844}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-16 11:42.40[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516113945: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020563099384307863, 'time_algorithm_update': 0.00414287805557251, 'loss': 1.6656848945617675, 'time_step': 0.0062509520053863525, 'init_value': 37.6201171875}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-16 11:43.00[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516113945: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022560796737670897, 'time_algorithm_update': 0.004628913879394531, 'loss': 1.5657525870203972, 'time_step': 0.006942477703094483, 'init_value': 39.1052360534668}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 39.1052360534668
Starting 1000 evaluations
avg return on 3 trajectories of agent16: 1451.2410401144982
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-16 11:59.14[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-16 11:59.14[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-16 11:59.15[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-16 11:59.15[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-16 11:59.15[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250516115915[0m
[2m2025-05-16 11:59.15[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-16 11:59.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516115915: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002177065849304199, 'time_algorithm_update': 0.004461913108825683, 'loss': 1.623898571126163, 'time_step': 0.006693438768386841, 'init_value': 4.406222820281982}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-16 11:59.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516115915: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021934731006622316, 'time_algorithm_update': 0.004411973237991333, 'loss': 2.2212263100743295, 'time_step': 0.006659740209579467, 'init_value': 10.973841667175293}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-16 12:00.15[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516115915: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002148237943649292, 'time_algorithm_update': 0.004383625507354737, 'loss': 2.2202787645459177, 'time_step': 0.0065860898494720455, 'init_value': 18.302120208740234}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-16 12:00.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516115915: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021799697875976563, 'time_algorithm_update': 0.004424994945526123, 'loss': 2.058558823764324, 'time_step': 0.0066591246128082275, 'init_value': 23.680715560913086}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-16 12:00.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516115915: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021493330001831055, 'time_algorithm_update': 0.004419211387634277, 'loss': 1.8956552217006684, 'time_step': 0.00662248158454895, 'init_value': 27.82737922668457}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-16 12:01.15[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516115915: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002180368185043335, 'time_algorithm_update': 0.004503665685653686, 'loss': 1.7818007581830024, 'time_step': 0.006739165544509888, 'init_value': 31.30414581298828}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-16 12:01.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516115915: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002054471969604492, 'time_algorithm_update': 0.004117075443267822, 'loss': 1.7749551909565926, 'time_step': 0.006222753047943115, 'init_value': 34.04722595214844}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-16 12:01.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516115915: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002195183515548706, 'time_algorithm_update': 0.004455516576766968, 'loss': 1.6987406710386277, 'time_step': 0.006704869985580444, 'init_value': 35.219024658203125}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-16 12:02.15[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516115915: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021781270503997805, 'time_algorithm_update': 0.004497830867767334, 'loss': 1.6712557793855667, 'time_step': 0.006731003761291504, 'init_value': 38.17351531982422}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-16 12:02.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516115915: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002157663822174072, 'time_algorithm_update': 0.0043302028179168705, 'loss': 1.6768987904787063, 'time_step': 0.0065411548614501954, 'init_value': 40.43859100341797}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.43859100341797
Starting 1000 evaluations
avg return on 3 trajectories of agent17: 1447.2588159847717
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-16 12:18.46[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-16 12:18.46[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-16 12:18.48[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-16 12:18.48[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-16 12:18.48[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250516121848[0m
[2m2025-05-16 12:18.48[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-16 12:19.08[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516121848: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00213130784034729, 'time_algorithm_update': 0.00431327509880066, 'loss': 1.5981154628843068, 'time_step': 0.006498375177383423, 'init_value': 4.359426021575928}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-16 12:19.27[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516121848: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002168419361114502, 'time_algorithm_update': 0.004240622758865356, 'loss': 2.2581339135766028, 'time_step': 0.006462528705596924, 'init_value': 11.579257011413574}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-16 12:19.47[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516121848: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002182566165924072, 'time_algorithm_update': 0.0044158935546875, 'loss': 2.4200084047317505, 'time_step': 0.006653481006622315, 'init_value': 20.174781799316406}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-16 12:20.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516121848: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002187092065811157, 'time_algorithm_update': 0.00436346697807312, 'loss': 2.119884137570858, 'time_step': 0.006605471849441528, 'init_value': 26.12662696838379}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-16 12:20.27[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516121848: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002172948360443115, 'time_algorithm_update': 0.004384499311447143, 'loss': 1.9404685719013215, 'time_step': 0.00661223316192627, 'init_value': 30.32535171508789}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-16 12:20.47[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516121848: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021637520790100096, 'time_algorithm_update': 0.004408027410507202, 'loss': 1.7570162998437882, 'time_step': 0.0066264293193817134, 'init_value': 33.52122497558594}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-16 12:21.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516121848: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021739606857299806, 'time_algorithm_update': 0.0043995225429534915, 'loss': 1.6713710522651672, 'time_step': 0.0066282241344451905, 'init_value': 35.4419059753418}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-16 12:21.27[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516121848: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022041592597961427, 'time_algorithm_update': 0.004379710912704468, 'loss': 1.6247954450845719, 'time_step': 0.006638784170150757, 'init_value': 36.405757904052734}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-16 12:21.46[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516121848: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002092729091644287, 'time_algorithm_update': 0.004186385631561279, 'loss': 1.5986385344266891, 'time_step': 0.006331528902053833, 'init_value': 38.959556579589844}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-16 12:22.06[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516121848: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00223408842086792, 'time_algorithm_update': 0.004482059240341186, 'loss': 1.6255424952507018, 'time_step': 0.006772168397903442, 'init_value': 40.69242858886719}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.69242858886719
Starting 1000 evaluations
avg return on 3 trajectories of agent18: 1443.7889453076348
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-16 12:38.22[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-16 12:38.22[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-16 12:38.23[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-16 12:38.23[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-16 12:38.23[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250516123823[0m
[2m2025-05-16 12:38.23[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-16 12:38.43[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516123823: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00213560152053833, 'time_algorithm_update': 0.004313839435577393, 'loss': 1.5283160588741302, 'time_step': 0.00650266170501709, 'init_value': 3.980067014694214}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-16 12:39.02[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516123823: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002135338544845581, 'time_algorithm_update': 0.0042759647369384765, 'loss': 2.424923643112183, 'time_step': 0.006465063810348511, 'init_value': 10.736616134643555}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-16 12:39.22[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516123823: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021928555965423585, 'time_algorithm_update': 0.004481432676315308, 'loss': 2.4061181312799453, 'time_step': 0.0067293915748596195, 'init_value': 17.77470588684082}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-16 12:39.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516123823: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002220881462097168, 'time_algorithm_update': 0.004440758228302002, 'loss': 2.2083451985120774, 'time_step': 0.006716583013534546, 'init_value': 24.4244384765625}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-16 12:40.02[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516123823: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021746580600738525, 'time_algorithm_update': 0.004477982997894287, 'loss': 1.9167388768196105, 'time_step': 0.006707811832427978, 'init_value': 29.166425704956055}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-16 12:40.22[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516123823: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021093196868896486, 'time_algorithm_update': 0.004281170129776001, 'loss': 1.7681522817015647, 'time_step': 0.006443480253219605, 'init_value': 33.05535888671875}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-16 12:40.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516123823: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002159127950668335, 'time_algorithm_update': 0.004402115821838379, 'loss': 1.7582181780934334, 'time_step': 0.006615632772445678, 'init_value': 34.7241325378418}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-16 12:41.02[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516123823: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021652636528015135, 'time_algorithm_update': 0.004411700963973999, 'loss': 1.6900761312246322, 'time_step': 0.006631520986557007, 'init_value': 37.52214431762695}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-16 12:41.22[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516123823: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00209435248374939, 'time_algorithm_update': 0.0041756749153137205, 'loss': 1.6687976905703545, 'time_step': 0.006321804285049438, 'init_value': 38.385982513427734}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-16 12:41.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516123823: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021937954425811767, 'time_algorithm_update': 0.004539267778396606, 'loss': 1.74715307700634, 'time_step': 0.00678847861289978, 'init_value': 40.15451431274414}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.15451431274414
Starting 1000 evaluations
avg return on 3 trajectories of agent19: 1430.6689488764448
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-16 12:57.54[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-16 12:57.54[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-16 12:57.55[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-16 12:57.55[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-16 12:57.55[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250516125755[0m
[2m2025-05-16 12:57.55[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-16 12:58.15[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516125755: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021623692512512207, 'time_algorithm_update': 0.00440389895439148, 'loss': 1.6561073425412178, 'time_step': 0.0066210942268371585, 'init_value': 4.156177997589111}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-16 12:58.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516125755: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002145051956176758, 'time_algorithm_update': 0.004348212957382202, 'loss': 2.3885518046617507, 'time_step': 0.006547763347625733, 'init_value': 9.83234691619873}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-16 12:58.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516125755: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002072322607040405, 'time_algorithm_update': 0.004079027652740479, 'loss': 2.3675102521181106, 'time_step': 0.006203155994415283, 'init_value': 17.159868240356445}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-16 12:59.15[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516125755: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002167546272277832, 'time_algorithm_update': 0.004458995342254639, 'loss': 2.154227977514267, 'time_step': 0.0066818628311157225, 'init_value': 25.43828010559082}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-16 12:59.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516125755: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002129735469818115, 'time_algorithm_update': 0.00436278510093689, 'loss': 2.022168438196182, 'time_step': 0.006546730041503906, 'init_value': 30.3880615234375}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-16 12:59.54[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516125755: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002097187042236328, 'time_algorithm_update': 0.00420007586479187, 'loss': 1.8348701192736625, 'time_step': 0.00634896469116211, 'init_value': 33.600460052490234}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-16 13:00.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516125755: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021832275390625, 'time_algorithm_update': 0.004493738889694214, 'loss': 1.6798047424554825, 'time_step': 0.006732307195663452, 'init_value': 35.98373794555664}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-16 13:00.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516125755: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002205157279968262, 'time_algorithm_update': 0.004443594217300415, 'loss': 1.7239929704666137, 'time_step': 0.0067035617828369145, 'init_value': 38.45952606201172}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-16 13:00.54[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516125755: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002118133783340454, 'time_algorithm_update': 0.004335025072097778, 'loss': 1.6308418640494347, 'time_step': 0.006506700277328492, 'init_value': 40.30508041381836}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-16 13:01.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516125755: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021970596313476564, 'time_algorithm_update': 0.004579944372177124, 'loss': 1.6791190806031226, 'time_step': 0.006833067178726196, 'init_value': 42.162174224853516}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.162174224853516
ave advantage rew: 41.083553314208984, std: 1.119289764519426
avg cum rews: 1441.0805277837892, std: 12.455038269418964
Pearson correlation coefficient: 0.015902028219208143
Spearman correlation coefficient: 0.081203007518797
Kendall Tau correlation coefficient: 0.10526315789473685
the best agent: 10, best agent cum rewards: 1455.5545990226597
1970
Starting to collect rollouts
Collecting rollouts: 10000/1000000
Collecting rollouts: 20000/1000000
Collecting rollouts: 30000/1000000
Collecting rollouts: 40000/1000000
Collecting rollouts: 50000/1000000
Collecting rollouts: 60000/1000000
Collecting rollouts: 70000/1000000
Collecting rollouts: 80000/1000000
Collecting rollouts: 90000/1000000
Collecting rollouts: 100000/1000000
Collecting rollouts: 110000/1000000
Collecting rollouts: 120000/1000000
Collecting rollouts: 130000/1000000
Collecting rollouts: 140000/1000000
Collecting rollouts: 150000/1000000
Collecting rollouts: 160000/1000000
Collecting rollouts: 170000/1000000
Collecting rollouts: 180000/1000000
Collecting rollouts: 190000/1000000
Collecting rollouts: 200000/1000000
Collecting rollouts: 210000/1000000
Collecting rollouts: 220000/1000000
Collecting rollouts: 230000/1000000
Collecting rollouts: 240000/1000000
Collecting rollouts: 250000/1000000
Collecting rollouts: 260000/1000000
Collecting rollouts: 270000/1000000
Collecting rollouts: 280000/1000000
Collecting rollouts: 290000/1000000
Collecting rollouts: 300000/1000000
Collecting rollouts: 310000/1000000
Collecting rollouts: 320000/1000000
Collecting rollouts: 330000/1000000
Collecting rollouts: 340000/1000000
Collecting rollouts: 350000/1000000
Collecting rollouts: 360000/1000000
Collecting rollouts: 370000/1000000
Collecting rollouts: 380000/1000000
Collecting rollouts: 390000/1000000
Collecting rollouts: 400000/1000000
Collecting rollouts: 410000/1000000
Collecting rollouts: 420000/1000000
Collecting rollouts: 430000/1000000
Collecting rollouts: 440000/1000000
Collecting rollouts: 450000/1000000
Collecting rollouts: 460000/1000000
Collecting rollouts: 470000/1000000
Collecting rollouts: 480000/1000000
Collecting rollouts: 490000/1000000
Collecting rollouts: 500000/1000000
Collecting rollouts: 510000/1000000
Collecting rollouts: 520000/1000000
Collecting rollouts: 530000/1000000
Collecting rollouts: 540000/1000000
Collecting rollouts: 550000/1000000
Collecting rollouts: 560000/1000000
Collecting rollouts: 570000/1000000
Collecting rollouts: 580000/1000000
Collecting rollouts: 590000/1000000
Collecting rollouts: 600000/1000000
Collecting rollouts: 610000/1000000
Collecting rollouts: 620000/1000000
Collecting rollouts: 630000/1000000
Collecting rollouts: 640000/1000000
Collecting rollouts: 650000/1000000
Collecting rollouts: 660000/1000000
Collecting rollouts: 670000/1000000
Collecting rollouts: 680000/1000000
Collecting rollouts: 690000/1000000
Collecting rollouts: 700000/1000000
Collecting rollouts: 710000/1000000
Collecting rollouts: 720000/1000000
Collecting rollouts: 730000/1000000
Collecting rollouts: 740000/1000000
Collecting rollouts: 750000/1000000
Collecting rollouts: 760000/1000000
Collecting rollouts: 770000/1000000
Collecting rollouts: 780000/1000000
Collecting rollouts: 790000/1000000
Collecting rollouts: 800000/1000000
Collecting rollouts: 810000/1000000
Collecting rollouts: 820000/1000000
Collecting rollouts: 830000/1000000
Collecting rollouts: 840000/1000000
Collecting rollouts: 850000/1000000
Collecting rollouts: 860000/1000000
Collecting rollouts: 870000/1000000
Collecting rollouts: 880000/1000000
Collecting rollouts: 890000/1000000
Collecting rollouts: 900000/1000000
Collecting rollouts: 910000/1000000
Collecting rollouts: 920000/1000000
Collecting rollouts: 930000/1000000
Collecting rollouts: 940000/1000000
Collecting rollouts: 950000/1000000
Collecting rollouts: 960000/1000000
Collecting rollouts: 970000/1000000
Collecting rollouts: 980000/1000000
Collecting rollouts: 990000/1000000
Collecting rollouts: 1000000/1000000
Replay buffer size:  (1000000, 105)
Replay buffer saved
---------------------------------
Searching empty space policies
(10, 11472)
(20, 11472)
(20, 11472)
Average distance of agents to nearest neighbors: 0.01904006529557406
Starting 1000 evaluations
avg return on 3 trajectories of agent0: 1455.3648450401201
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-16 13:36.37[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-16 13:36.37[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-16 13:36.39[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-16 13:36.39[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-16 13:36.39[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250516133639[0m
[2m2025-05-16 13:36.39[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-16 13:36.59[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516133639: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00217679762840271, 'time_algorithm_update': 0.00436559247970581, 'loss': 1.67481727322191, 'time_step': 0.006596822738647461, 'init_value': 4.227128982543945}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-16 13:37.18[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516133639: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021616792678833007, 'time_algorithm_update': 0.004361377716064453, 'loss': 2.4049437425732614, 'time_step': 0.006577367544174194, 'init_value': 10.500924110412598}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-16 13:37.38[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516133639: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002101618766784668, 'time_algorithm_update': 0.004153977870941162, 'loss': 2.4710450788736344, 'time_step': 0.006307695865631104, 'init_value': 18.66936492919922}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-16 13:37.59[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516133639: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00219744873046875, 'time_algorithm_update': 0.004494739770889282, 'loss': 2.1566510751247407, 'time_step': 0.006747585535049438, 'init_value': 25.270357131958008}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-16 13:38.19[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516133639: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002169300317764282, 'time_algorithm_update': 0.00440955901145935, 'loss': 1.997144062936306, 'time_step': 0.006633594036102295, 'init_value': 29.85378646850586}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-16 13:38.38[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516133639: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002130581617355347, 'time_algorithm_update': 0.00433312201499939, 'loss': 1.7461341671943664, 'time_step': 0.006517387151718139, 'init_value': 32.684410095214844}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-16 13:38.58[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516133639: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002212905168533325, 'time_algorithm_update': 0.0045340807437896724, 'loss': 1.7329706956744193, 'time_step': 0.006802752256393433, 'init_value': 34.987117767333984}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-16 13:39.18[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516133639: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002203056812286377, 'time_algorithm_update': 0.004391034364700317, 'loss': 1.6818382515907289, 'time_step': 0.006649033308029175, 'init_value': 38.50132751464844}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-16 13:39.38[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516133639: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021480958461761474, 'time_algorithm_update': 0.004372976303100586, 'loss': 1.7017362209558486, 'time_step': 0.006575256824493408, 'init_value': 40.83094787597656}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-16 13:39.58[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516133639: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002204277753829956, 'time_algorithm_update': 0.004399181127548218, 'loss': 1.73599542593956, 'time_step': 0.006657967567443848, 'init_value': 41.79291915893555}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.79291915893555
Starting 1000 evaluations
avg return on 3 trajectories of agent1: 1435.2428461800446
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-16 13:55.53[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-16 13:55.53[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-16 13:55.55[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-16 13:55.55[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-16 13:55.55[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250516135555[0m
[2m2025-05-16 13:55.55[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-16 13:56.12[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516135555: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018918876647949219, 'time_algorithm_update': 0.003702953338623047, 'loss': 1.6854566453099251, 'time_step': 0.005641227006912232, 'init_value': 4.223896503448486}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-16 13:56.30[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516135555: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001949864625930786, 'time_algorithm_update': 0.0037577579021453858, 'loss': 2.3809759390354155, 'time_step': 0.005754612684249878, 'init_value': 11.119505882263184}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-16 13:56.47[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516135555: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018997185230255128, 'time_algorithm_update': 0.0037571074962615965, 'loss': 2.329279334664345, 'time_step': 0.005703246593475342, 'init_value': 18.682903289794922}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-16 13:57.04[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516135555: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001955744743347168, 'time_algorithm_update': 0.003786536455154419, 'loss': 2.1477612258195875, 'time_step': 0.005789028406143188, 'init_value': 24.8304500579834}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-16 13:57.22[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516135555: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019142174720764161, 'time_algorithm_update': 0.003777936935424805, 'loss': 2.0215668095350265, 'time_step': 0.005739015817642212, 'init_value': 30.62934112548828}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-16 13:57.40[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516135555: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001915372610092163, 'time_algorithm_update': 0.0038211784362792967, 'loss': 1.8933125712275505, 'time_step': 0.005783922672271728, 'init_value': 34.527870178222656}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-16 13:57.57[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516135555: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018962008953094483, 'time_algorithm_update': 0.003771107912063599, 'loss': 1.7066373015642167, 'time_step': 0.005713534832000732, 'init_value': 37.06088638305664}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-16 13:58.15[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516135555: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019106349945068359, 'time_algorithm_update': 0.003777775049209595, 'loss': 1.7274914973974227, 'time_step': 0.005734772205352783, 'init_value': 38.63990020751953}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-16 13:58.32[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516135555: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019006619453430175, 'time_algorithm_update': 0.0037655022144317627, 'loss': 1.5817318120598793, 'time_step': 0.005712398529052734, 'init_value': 40.083251953125}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-16 13:58.49[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516135555: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001903456449508667, 'time_algorithm_update': 0.0037773301601409914, 'loss': 1.6365166343450546, 'time_step': 0.005727550506591797, 'init_value': 42.391456604003906}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.391456604003906
Starting 1000 evaluations
avg return on 3 trajectories of agent2: 1394.553128722859
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-16 14:13.48[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-16 14:13.48[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-16 14:13.50[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-16 14:13.50[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-16 14:13.50[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250516141350[0m
[2m2025-05-16 14:13.50[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-16 14:14.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516141350: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001864868402481079, 'time_algorithm_update': 0.003694094896316528, 'loss': 1.570809941329062, 'time_step': 0.00560614275932312, 'init_value': 4.216521739959717}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-16 14:14.24[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516141350: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018713533878326415, 'time_algorithm_update': 0.0037281663417816162, 'loss': 2.531482057213783, 'time_step': 0.0056466257572174074, 'init_value': 10.896333694458008}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-16 14:14.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516141350: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001881735324859619, 'time_algorithm_update': 0.003672740697860718, 'loss': 2.245872061252594, 'time_step': 0.005601375818252563, 'init_value': 17.981935501098633}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-16 14:14.59[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516141350: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019100840091705322, 'time_algorithm_update': 0.0038353469371795656, 'loss': 2.1483426985144614, 'time_step': 0.005793741226196289, 'init_value': 24.122182846069336}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-16 14:15.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516141350: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001907243013381958, 'time_algorithm_update': 0.0037140698432922364, 'loss': 1.9656384000182152, 'time_step': 0.005667600870132446, 'init_value': 29.144617080688477}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-16 14:15.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516141350: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018765475749969482, 'time_algorithm_update': 0.003724916934967041, 'loss': 1.8693418567180633, 'time_step': 0.005647793531417846, 'init_value': 32.92185974121094}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-16 14:15.52[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516141350: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019194228649139404, 'time_algorithm_update': 0.0037257206439971925, 'loss': 1.719711401820183, 'time_step': 0.005692208051681518, 'init_value': 35.61225891113281}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-16 14:16.09[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516141350: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019062175750732423, 'time_algorithm_update': 0.0037783401012420653, 'loss': 1.6568012320399284, 'time_step': 0.005731967210769654, 'init_value': 38.51909637451172}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-16 14:16.27[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516141350: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019555211067199705, 'time_algorithm_update': 0.0038611443042755127, 'loss': 1.6560795704722404, 'time_step': 0.005865344762802124, 'init_value': 40.04154586791992}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-16 14:16.44[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516141350: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019114964008331299, 'time_algorithm_update': 0.003827733516693115, 'loss': 1.6459406933784484, 'time_step': 0.005787484884262085, 'init_value': 41.94768142700195}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.94768142700195
Starting 1000 evaluations
avg return on 3 trajectories of agent3: 1334.4356024761935
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-16 14:31.42[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-16 14:31.42[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-16 14:31.43[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-16 14:31.43[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-16 14:31.43[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250516143143[0m
[2m2025-05-16 14:31.43[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-16 14:32.01[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516143143: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018735625743865967, 'time_algorithm_update': 0.003703692674636841, 'loss': 1.7302811678349972, 'time_step': 0.005624980688095093, 'init_value': 4.267014503479004}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-16 14:32.18[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516143143: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001859053611755371, 'time_algorithm_update': 0.003631652355194092, 'loss': 2.326211903810501, 'time_step': 0.005537119865417481, 'init_value': 10.65738296508789}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-16 14:32.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516143143: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018519647121429444, 'time_algorithm_update': 0.0036793580055236815, 'loss': 2.334572278320789, 'time_step': 0.005577708721160889, 'init_value': 18.3967227935791}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-16 14:32.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516143143: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019109385013580322, 'time_algorithm_update': 0.003698756694793701, 'loss': 2.1938410294651987, 'time_step': 0.005656166791915894, 'init_value': 23.67455291748047}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-16 14:33.10[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516143143: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001877925157546997, 'time_algorithm_update': 0.003727738618850708, 'loss': 1.9618216726779938, 'time_step': 0.00565217399597168, 'init_value': 28.01120948791504}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-16 14:33.27[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516143143: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019478085041046143, 'time_algorithm_update': 0.003890312433242798, 'loss': 1.8066428705453872, 'time_step': 0.005887319564819336, 'init_value': 31.248437881469727}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-16 14:33.45[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516143143: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018911404609680176, 'time_algorithm_update': 0.0037270944118499754, 'loss': 1.7850686006546022, 'time_step': 0.005665076971054077, 'init_value': 33.672325134277344}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-16 14:34.02[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516143143: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001923403263092041, 'time_algorithm_update': 0.0037856621742248537, 'loss': 1.6933537459373473, 'time_step': 0.005756612777709961, 'init_value': 36.27493667602539}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-16 14:34.19[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516143143: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018844799995422364, 'time_algorithm_update': 0.0037430624961853026, 'loss': 1.721347734093666, 'time_step': 0.005674647808074951, 'init_value': 38.66334915161133}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-16 14:34.37[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516143143: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018718969821929932, 'time_algorithm_update': 0.003725900650024414, 'loss': 1.6165782746076585, 'time_step': 0.005644582271575928, 'init_value': 39.864768981933594}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 39.864768981933594
Starting 1000 evaluations
avg return on 3 trajectories of agent4: 1452.8406801157857
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-16 14:49.25[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-16 14:49.25[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-16 14:49.27[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-16 14:49.27[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-16 14:49.27[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250516144927[0m
[2m2025-05-16 14:49.27[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-16 14:49.44[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516144927: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018528985977172851, 'time_algorithm_update': 0.003576076030731201, 'loss': 1.7492399562969805, 'time_step': 0.005476611375808716, 'init_value': 4.135554313659668}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-16 14:50.01[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516144927: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018826711177825927, 'time_algorithm_update': 0.0036478414535522463, 'loss': 2.261121986091137, 'time_step': 0.005577111482620239, 'init_value': 10.221175193786621}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-16 14:50.19[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516144927: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001870696544647217, 'time_algorithm_update': 0.003691078424453735, 'loss': 2.2729135440587998, 'time_step': 0.005608438014984131, 'init_value': 18.636760711669922}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-16 14:50.36[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516144927: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019164698123931884, 'time_algorithm_update': 0.003783480882644653, 'loss': 2.1643289783000945, 'time_step': 0.005748033285140991, 'init_value': 25.197277069091797}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-16 14:50.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516144927: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018858535289764404, 'time_algorithm_update': 0.0037214176654815673, 'loss': 1.9624724977612495, 'time_step': 0.005653960704803467, 'init_value': 30.17913246154785}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-16 14:51.11[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516144927: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018925044536590575, 'time_algorithm_update': 0.003735692739486694, 'loss': 1.8678206210136414, 'time_step': 0.005675378799438476, 'init_value': 34.212158203125}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-16 14:51.28[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516144927: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019074969291687012, 'time_algorithm_update': 0.0037788026332855225, 'loss': 1.8595165863037109, 'time_step': 0.0057334885597229, 'init_value': 35.94506072998047}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-16 14:51.46[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516144927: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001902003288269043, 'time_algorithm_update': 0.003773555040359497, 'loss': 1.667310738861561, 'time_step': 0.005722992897033692, 'init_value': 37.54027557373047}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-16 14:52.04[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516144927: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020172057151794432, 'time_algorithm_update': 0.003991033792495728, 'loss': 1.6944867759346962, 'time_step': 0.006058217525482178, 'init_value': 39.4074821472168}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-16 14:52.21[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516144927: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018894450664520264, 'time_algorithm_update': 0.0037365875244140625, 'loss': 1.6234050800800324, 'time_step': 0.0056724283695220945, 'init_value': 41.89200973510742}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.89200973510742
Starting 1000 evaluations
avg return on 3 trajectories of agent5: 1429.575025464452
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-16 15:07.13[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-16 15:07.13[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-16 15:07.14[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-16 15:07.14[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-16 15:07.14[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250516150714[0m
[2m2025-05-16 15:07.14[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-16 15:07.32[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516150714: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018794572353363038, 'time_algorithm_update': 0.00370184063911438, 'loss': 1.6520036968812346, 'time_step': 0.005628040790557861, 'init_value': 4.1878228187561035}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-16 15:07.49[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516150714: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019886491298675537, 'time_algorithm_update': 0.003844529151916504, 'loss': 2.247474822282791, 'time_step': 0.005882145643234253, 'init_value': 10.57015609741211}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-16 15:08.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516150714: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019102282524108888, 'time_algorithm_update': 0.003770251989364624, 'loss': 2.2217123461365698, 'time_step': 0.005727853536605835, 'init_value': 17.375450134277344}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-16 15:08.25[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516150714: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019505295753479003, 'time_algorithm_update': 0.0038244059085845946, 'loss': 2.1766650581359865, 'time_step': 0.005823580980300903, 'init_value': 23.846445083618164}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-16 15:08.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516150714: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019071035385131835, 'time_algorithm_update': 0.003758723497390747, 'loss': 1.93641758954525, 'time_step': 0.00571391749382019, 'init_value': 28.92620849609375}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-16 15:09.00[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516150714: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019170234203338622, 'time_algorithm_update': 0.0037446410655975343, 'loss': 1.7029939399957656, 'time_step': 0.005708970546722412, 'init_value': 32.165443420410156}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-16 15:09.18[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516150714: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019505672454833984, 'time_algorithm_update': 0.003880479335784912, 'loss': 1.7017705526947975, 'time_step': 0.0058798322677612305, 'init_value': 34.475677490234375}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-16 15:09.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516150714: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019796264171600343, 'time_algorithm_update': 0.0038771467208862306, 'loss': 1.6248434094190598, 'time_step': 0.005905993938446045, 'init_value': 37.25741195678711}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-16 15:09.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516150714: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019244279861450196, 'time_algorithm_update': 0.0038129453659057617, 'loss': 1.73106717389822, 'time_step': 0.005785877704620361, 'init_value': 38.22590255737305}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-16 15:10.10[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516150714: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019227607250213623, 'time_algorithm_update': 0.0038112406730651856, 'loss': 1.6773713260293006, 'time_step': 0.0057820360660552975, 'init_value': 39.72856903076172}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 39.72856903076172
Starting 1000 evaluations
avg return on 3 trajectories of agent6: 1377.4136781916318
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-16 15:25.07[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-16 15:25.07[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-16 15:25.09[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-16 15:25.09[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-16 15:25.09[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250516152509[0m
[2m2025-05-16 15:25.09[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-16 15:25.26[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516152509: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018709771633148194, 'time_algorithm_update': 0.003641892671585083, 'loss': 1.734486471310258, 'time_step': 0.005558964490890503, 'init_value': 4.0117974281311035}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-16 15:25.43[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516152509: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018883619308471679, 'time_algorithm_update': 0.0036886386871337893, 'loss': 2.4029675480127333, 'time_step': 0.005623539686203003, 'init_value': 9.765579223632812}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-16 15:26.01[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516152509: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019031713008880616, 'time_algorithm_update': 0.0036748604774475098, 'loss': 2.3316281189918517, 'time_step': 0.005624022006988525, 'init_value': 17.368240356445312}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-16 15:26.19[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516152509: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019511802196502685, 'time_algorithm_update': 0.0038995182514190672, 'loss': 2.119371991634369, 'time_step': 0.005899113893508911, 'init_value': 25.287595748901367}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-16 15:26.36[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516152509: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019341561794281007, 'time_algorithm_update': 0.0037293832302093505, 'loss': 2.0230987051725386, 'time_step': 0.00571050763130188, 'init_value': 28.656808853149414}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-16 15:26.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516152509: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019066944122314454, 'time_algorithm_update': 0.00375388240814209, 'loss': 1.7637567082047463, 'time_step': 0.005707638025283813, 'init_value': 31.224817276000977}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-16 15:27.11[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516152509: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019466195106506348, 'time_algorithm_update': 0.0037247447967529296, 'loss': 1.7553827151656152, 'time_step': 0.005718064069747925, 'init_value': 34.95211410522461}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-16 15:27.29[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516152509: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019033429622650146, 'time_algorithm_update': 0.003749380111694336, 'loss': 1.7863900371193886, 'time_step': 0.005699476718902588, 'init_value': 37.8128662109375}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-16 15:27.46[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516152509: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019239280223846435, 'time_algorithm_update': 0.0037607672214508055, 'loss': 1.7075163075327873, 'time_step': 0.005731598377227783, 'init_value': 39.05919647216797}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-16 15:28.03[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516152509: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019077658653259277, 'time_algorithm_update': 0.0037526614665985107, 'loss': 1.62822405564785, 'time_step': 0.0057070300579071045, 'init_value': 40.38988494873047}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.38988494873047
Starting 1000 evaluations
avg return on 3 trajectories of agent7: 1323.1165221979554
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-16 15:43.05[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-16 15:43.05[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-16 15:43.06[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-16 15:43.06[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-16 15:43.06[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250516154306[0m
[2m2025-05-16 15:43.06[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-16 15:43.23[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516154306: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018620216846466065, 'time_algorithm_update': 0.003667851448059082, 'loss': 1.5140227643772959, 'time_step': 0.0055769217014312745, 'init_value': 4.468709945678711}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-16 15:43.41[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516154306: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019074141979217528, 'time_algorithm_update': 0.0038063015937805176, 'loss': 2.4138808470368387, 'time_step': 0.0057620503902435305, 'init_value': 10.714098930358887}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-16 15:43.58[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516154306: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019252750873565675, 'time_algorithm_update': 0.0037668640613555907, 'loss': 2.2412591931819916, 'time_step': 0.005747095108032226, 'init_value': 17.53118133544922}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-16 15:44.16[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516154306: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019139199256896972, 'time_algorithm_update': 0.003800407886505127, 'loss': 2.0963513001799585, 'time_step': 0.005762050867080689, 'init_value': 23.87723159790039}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-16 15:44.33[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516154306: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019138033390045167, 'time_algorithm_update': 0.0037567460536956786, 'loss': 1.9256014285683631, 'time_step': 0.005717756509780883, 'init_value': 28.448301315307617}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-16 15:44.51[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516154306: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019207613468170165, 'time_algorithm_update': 0.003849702835083008, 'loss': 1.8949819306731224, 'time_step': 0.005819111585617065, 'init_value': 32.17658996582031}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-16 15:45.08[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516154306: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019067909717559815, 'time_algorithm_update': 0.0037509236335754393, 'loss': 1.8579065716266632, 'time_step': 0.005704801797866821, 'init_value': 34.41183090209961}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-16 15:45.26[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516154306: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018989107608795167, 'time_algorithm_update': 0.0037540998458862303, 'loss': 1.7217645225524902, 'time_step': 0.005700192213058472, 'init_value': 38.55619430541992}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-16 15:45.44[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516154306: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019201414585113526, 'time_algorithm_update': 0.0037816681861877442, 'loss': 1.7777278164625168, 'time_step': 0.005749412775039673, 'init_value': 40.92256164550781}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-16 15:46.01[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516154306: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019116275310516358, 'time_algorithm_update': 0.003790593147277832, 'loss': 1.6882331131696702, 'time_step': 0.005750195264816284, 'init_value': 42.31344223022461}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.31344223022461
Starting 1000 evaluations
avg return on 3 trajectories of agent8: 1449.412283162027
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-16 16:00.51[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-16 16:00.51[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-16 16:00.52[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-16 16:00.52[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-16 16:00.52[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250516160052[0m
[2m2025-05-16 16:00.52[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-16 16:01.09[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516160052: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018603477478027343, 'time_algorithm_update': 0.003676922798156738, 'loss': 1.7305626750588416, 'time_step': 0.0055838639736175534, 'init_value': 4.1421098709106445}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-16 16:01.26[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516160052: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018758590221405029, 'time_algorithm_update': 0.0037164223194122315, 'loss': 2.3194730861783026, 'time_step': 0.005639040946960449, 'init_value': 10.930917739868164}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-16 16:01.44[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516160052: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019101693630218506, 'time_algorithm_update': 0.003736365795135498, 'loss': 2.3788571182489395, 'time_step': 0.005693406343460083, 'init_value': 18.420230865478516}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-16 16:02.01[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516160052: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018956398963928223, 'time_algorithm_update': 0.0037687203884124755, 'loss': 2.1137240083813666, 'time_step': 0.005711402893066406, 'init_value': 24.681949615478516}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-16 16:02.19[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516160052: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019567439556121826, 'time_algorithm_update': 0.003916538953781128, 'loss': 1.9985335543155671, 'time_step': 0.005922004699707031, 'init_value': 29.273099899291992}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-16 16:02.36[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516160052: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001908097743988037, 'time_algorithm_update': 0.0038051495552062988, 'loss': 1.7621294010877608, 'time_step': 0.00576037073135376, 'init_value': 32.42509460449219}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-16 16:02.54[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516160052: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019267637729644775, 'time_algorithm_update': 0.0037893490791320802, 'loss': 1.7341196221113204, 'time_step': 0.005763465881347656, 'init_value': 35.42268371582031}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-16 16:03.11[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516160052: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019153070449829102, 'time_algorithm_update': 0.003826324224472046, 'loss': 1.7498244927525521, 'time_step': 0.005789885520935059, 'init_value': 37.58888244628906}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-16 16:03.29[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516160052: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019349048137664794, 'time_algorithm_update': 0.0038135643005371093, 'loss': 1.6668539755940437, 'time_step': 0.005795868873596191, 'init_value': 40.39841842651367}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-16 16:03.47[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516160052: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018949995040893554, 'time_algorithm_update': 0.0037852845191955566, 'loss': 1.6947788801193238, 'time_step': 0.005727701663970948, 'init_value': 42.75471115112305}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.75471115112305
Starting 1000 evaluations
avg return on 3 trajectories of agent9: 1449.013142826478
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-16 16:18.41[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-16 16:18.41[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-16 16:18.43[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-16 16:18.43[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-16 16:18.43[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250516161843[0m
[2m2025-05-16 16:18.43[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-16 16:19.00[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516161843: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018606646060943604, 'time_algorithm_update': 0.0036649041175842285, 'loss': 1.642356456965208, 'time_step': 0.005572357416152954, 'init_value': 4.339698791503906}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-16 16:19.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516161843: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018744242191314697, 'time_algorithm_update': 0.003729994297027588, 'loss': 2.398941238105297, 'time_step': 0.005651387453079223, 'init_value': 10.649208068847656}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-16 16:19.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516161843: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001977670907974243, 'time_algorithm_update': 0.004012147665023804, 'loss': 2.401289929986, 'time_step': 0.0060393943786621095, 'init_value': 18.095237731933594}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-16 16:19.52[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516161843: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018970723152160645, 'time_algorithm_update': 0.003768162727355957, 'loss': 2.1077992116808892, 'time_step': 0.005712284088134766, 'init_value': 25.10879135131836}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-16 16:20.10[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516161843: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001930567741394043, 'time_algorithm_update': 0.003813457250595093, 'loss': 1.9992608561515808, 'time_step': 0.005791497707366943, 'init_value': 29.841901779174805}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-16 16:20.27[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516161843: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018740594387054443, 'time_algorithm_update': 0.003747584342956543, 'loss': 1.8256210837960243, 'time_step': 0.005667914152145386, 'init_value': 33.03641128540039}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-16 16:20.45[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516161843: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001915682554244995, 'time_algorithm_update': 0.003779843807220459, 'loss': 1.7077214642167091, 'time_step': 0.005742422580718994, 'init_value': 35.809425354003906}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-16 16:21.03[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516161843: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018803071975708008, 'time_algorithm_update': 0.003753931283950806, 'loss': 1.7636465064287186, 'time_step': 0.005681186199188232, 'init_value': 38.673545837402344}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-16 16:21.20[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516161843: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019209473133087159, 'time_algorithm_update': 0.003756617307662964, 'loss': 1.6330071850419043, 'time_step': 0.005724090576171875, 'init_value': 39.7978401184082}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-16 16:21.38[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516161843: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019046485424041748, 'time_algorithm_update': 0.00382389497756958, 'loss': 1.6123987715244292, 'time_step': 0.005776003837585449, 'init_value': 41.80607223510742}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.80607223510742
Starting 1000 evaluations
avg return on 3 trajectories of agent10: 1438.8266601435728
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-16 16:36.30[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-16 16:36.30[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-16 16:36.31[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-16 16:36.31[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-16 16:36.31[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250516163631[0m
[2m2025-05-16 16:36.31[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-16 16:36.49[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516163631: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019216370582580567, 'time_algorithm_update': 0.003829751491546631, 'loss': 1.7070031922310591, 'time_step': 0.005800287008285523, 'init_value': 4.300078392028809}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-16 16:37.07[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516163631: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018827354907989503, 'time_algorithm_update': 0.003732551097869873, 'loss': 2.3571452577114105, 'time_step': 0.0056619133949279785, 'init_value': 10.574610710144043}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-16 16:37.24[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516163631: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018905718326568603, 'time_algorithm_update': 0.0037705698013305662, 'loss': 2.3247138704061507, 'time_step': 0.005707630872726441, 'init_value': 18.0120849609375}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-16 16:37.42[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516163631: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018964612483978272, 'time_algorithm_update': 0.0037739460468292235, 'loss': 2.158869472682476, 'time_step': 0.005716919898986816, 'init_value': 24.495607376098633}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-16 16:37.59[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516163631: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019282801151275634, 'time_algorithm_update': 0.0037963275909423826, 'loss': 2.0299291685819627, 'time_step': 0.005771152496337891, 'init_value': 29.18282127380371}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-16 16:38.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516163631: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019467859268188477, 'time_algorithm_update': 0.0039391424655914305, 'loss': 1.9317478111982345, 'time_step': 0.005933830976486206, 'init_value': 32.686187744140625}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-16 16:38.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516163631: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0018890955448150634, 'time_algorithm_update': 0.003753151893615723, 'loss': 1.7720203217864037, 'time_step': 0.005688902616500855, 'init_value': 34.738983154296875}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-16 16:38.52[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516163631: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0019203922748565673, 'time_algorithm_update': 0.003832564353942871, 'loss': 1.6765076001882553, 'time_step': 0.005800441026687622, 'init_value': 37.22694778442383}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-16 16:39.10[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516163631: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001964324951171875, 'time_algorithm_update': 0.0038793962001800538, 'loss': 1.6595019317269326, 'time_step': 0.00589171838760376, 'init_value': 39.58143997192383}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-16 16:39.28[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516163631: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.001947615146636963, 'time_algorithm_update': 0.0039137938022613524, 'loss': 1.7570799216628075, 'time_step': 0.005910007953643799, 'init_value': 40.548439025878906}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.548439025878906
Starting 1000 evaluations
avg return on 3 trajectories of agent11: 1435.322380316038
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-16 16:55.33[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-16 16:55.33[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-16 16:55.34[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-16 16:55.34[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-16 16:55.34[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250516165534[0m
[2m2025-05-16 16:55.34[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-16 16:55.54[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516165534: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022030911445617674, 'time_algorithm_update': 0.004459497213363648, 'loss': 1.729371021233499, 'time_step': 0.006717456579208374, 'init_value': 4.179174423217773}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-16 16:56.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516165534: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022324738502502444, 'time_algorithm_update': 0.004440507411956787, 'loss': 2.3753242519497872, 'time_step': 0.00672856879234314, 'init_value': 9.870452880859375}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-16 16:56.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516165534: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002091550588607788, 'time_algorithm_update': 0.004182020664215088, 'loss': 2.2713981202244757, 'time_step': 0.006325427293777466, 'init_value': 17.225584030151367}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-16 16:56.54[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516165534: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002215415954589844, 'time_algorithm_update': 0.004456853151321411, 'loss': 2.099403849720955, 'time_step': 0.006727738857269287, 'init_value': 23.553892135620117}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-16 16:57.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516165534: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021656200885772706, 'time_algorithm_update': 0.004396182298660278, 'loss': 2.0141590574383734, 'time_step': 0.0066165015697479245, 'init_value': 28.60155487060547}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-16 16:57.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516165534: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002154954671859741, 'time_algorithm_update': 0.004310729503631591, 'loss': 1.912048595547676, 'time_step': 0.006518943786621094, 'init_value': 31.408096313476562}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-16 16:57.54[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516165534: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002223001718521118, 'time_algorithm_update': 0.004519965171813965, 'loss': 1.7114931001663207, 'time_step': 0.006798473119735718, 'init_value': 34.55976486206055}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-16 16:58.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516165534: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002221642971038818, 'time_algorithm_update': 0.004524855613708496, 'loss': 1.7338546103239059, 'time_step': 0.006801674604415894, 'init_value': 36.4600944519043}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-16 16:58.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516165534: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002168499231338501, 'time_algorithm_update': 0.004287138938903808, 'loss': 1.6978953302502633, 'time_step': 0.00650853157043457, 'init_value': 37.68951416015625}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-16 16:58.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516165534: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002234384536743164, 'time_algorithm_update': 0.004573848009109497, 'loss': 1.6499935063719748, 'time_step': 0.00686369800567627, 'init_value': 39.763633728027344}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 39.763633728027344
Starting 1000 evaluations
avg return on 3 trajectories of agent12: 1451.4120397368977
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-16 17:15.11[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-16 17:15.11[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-16 17:15.12[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-16 17:15.12[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-16 17:15.12[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250516171512[0m
[2m2025-05-16 17:15.12[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-16 17:15.32[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516171512: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021926674842834473, 'time_algorithm_update': 0.004488867044448852, 'loss': 1.5933921382501721, 'time_step': 0.006736601591110229, 'init_value': 3.8940744400024414}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-16 17:15.52[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516171512: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00215929913520813, 'time_algorithm_update': 0.004417241096496582, 'loss': 2.3922385724782944, 'time_step': 0.006631810665130616, 'init_value': 10.636764526367188}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-16 17:16.12[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516171512: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021629259586334226, 'time_algorithm_update': 0.0044172370433807374, 'loss': 2.293656461536884, 'time_step': 0.006634569168090821, 'init_value': 17.955230712890625}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-16 17:16.32[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516171512: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021982057094573973, 'time_algorithm_update': 0.004504601240158081, 'loss': 2.122422044336796, 'time_step': 0.006758005857467652, 'init_value': 24.067590713500977}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-16 17:16.52[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516171512: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021934664249420167, 'time_algorithm_update': 0.00447857666015625, 'loss': 1.9672178228497506, 'time_step': 0.006727147102355957, 'init_value': 29.582191467285156}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-16 17:17.12[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516171512: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002159827709197998, 'time_algorithm_update': 0.004404041290283203, 'loss': 1.863402554988861, 'time_step': 0.006618505954742432, 'init_value': 32.2356071472168}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-16 17:17.32[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516171512: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002194620847702026, 'time_algorithm_update': 0.004461134672164917, 'loss': 1.735989655673504, 'time_step': 0.006710957765579223, 'init_value': 35.358585357666016}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-16 17:17.52[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516171512: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022040109634399413, 'time_algorithm_update': 0.004456492185592652, 'loss': 1.696304060637951, 'time_step': 0.006715024709701538, 'init_value': 38.48540496826172}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-16 17:18.12[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516171512: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002125073432922363, 'time_algorithm_update': 0.004312971591949463, 'loss': 1.6908867115378379, 'time_step': 0.0064919829368591305, 'init_value': 41.050418853759766}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-16 17:18.32[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516171512: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002210824489593506, 'time_algorithm_update': 0.0044971809387207035, 'loss': 1.7102635548114777, 'time_step': 0.006763816356658936, 'init_value': 42.607383728027344}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 42.607383728027344
Starting 1000 evaluations
avg return on 3 trajectories of agent13: 1444.4417779478863
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-16 17:34.49[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-16 17:34.49[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-16 17:34.51[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-16 17:34.51[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-16 17:34.51[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250516173451[0m
[2m2025-05-16 17:34.51[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-16 17:35.10[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516173451: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020727989673614503, 'time_algorithm_update': 0.00410982346534729, 'loss': 1.7126012475267052, 'time_step': 0.006234061479568481, 'init_value': 4.074708461761475}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-16 17:35.31[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516173451: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002204319715499878, 'time_algorithm_update': 0.004458701372146607, 'loss': 2.255151707649231, 'time_step': 0.006717860460281372, 'init_value': 10.190789222717285}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-16 17:35.50[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516173451: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002220057487487793, 'time_algorithm_update': 0.004504365921020508, 'loss': 2.3987564359903337, 'time_step': 0.006779301404953003, 'init_value': 17.36444664001465}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-16 17:36.11[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516173451: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002134049415588379, 'time_algorithm_update': 0.004363741636276245, 'loss': 2.1596738602519037, 'time_step': 0.006551065444946289, 'init_value': 24.23854637145996}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-16 17:36.31[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516173451: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00220961594581604, 'time_algorithm_update': 0.004563637018203735, 'loss': 2.035766295731068, 'time_step': 0.0068291442394256595, 'init_value': 29.027942657470703}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-16 17:36.51[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516173451: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022457776069641114, 'time_algorithm_update': 0.004645039319992065, 'loss': 1.835768867611885, 'time_step': 0.0069468791484832764, 'init_value': 32.320072174072266}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-16 17:37.11[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516173451: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021683571338653564, 'time_algorithm_update': 0.004450728178024292, 'loss': 1.8475441088676452, 'time_step': 0.006673736333847046, 'init_value': 35.79024124145508}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-16 17:37.31[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516173451: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022321932315826415, 'time_algorithm_update': 0.0044927821159362795, 'loss': 1.7344830513000489, 'time_step': 0.006780083179473877, 'init_value': 39.061309814453125}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-16 17:37.51[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516173451: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021844918727874757, 'time_algorithm_update': 0.0044514319896698, 'loss': 1.7078428480625152, 'time_step': 0.0066903533935546875, 'init_value': 40.248924255371094}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-16 17:38.12[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516173451: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022140889167785644, 'time_algorithm_update': 0.004422403812408447, 'loss': 1.6594506170153618, 'time_step': 0.006691542387008667, 'init_value': 41.9394645690918}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.9394645690918
Starting 1000 evaluations
avg return on 3 trajectories of agent14: 1443.3944705905515
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-16 17:54.32[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-16 17:54.32[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-16 17:54.33[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-16 17:54.33[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-16 17:54.33[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250516175433[0m
[2m2025-05-16 17:54.33[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-16 17:54.53[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516175433: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002221522569656372, 'time_algorithm_update': 0.0045327508449554445, 'loss': 1.6649983627796172, 'time_step': 0.006810173034667969, 'init_value': 4.609490394592285}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-16 17:55.13[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516175433: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021199722290039065, 'time_algorithm_update': 0.004271747827529907, 'loss': 2.3417551258802414, 'time_step': 0.006445338487625122, 'init_value': 10.25007152557373}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-16 17:55.33[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516175433: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021794273853302003, 'time_algorithm_update': 0.0044739353656768795, 'loss': 2.309867058694363, 'time_step': 0.006708299160003662, 'init_value': 18.097320556640625}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-16 17:55.54[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516175433: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002196185827255249, 'time_algorithm_update': 0.004483416318893433, 'loss': 2.1761165039539336, 'time_step': 0.006735154628753662, 'init_value': 25.1618595123291}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-16 17:56.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516175433: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021491026878356933, 'time_algorithm_update': 0.0043697781562805176, 'loss': 2.032279680907726, 'time_step': 0.006573273181915283, 'init_value': 30.310226440429688}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-16 17:56.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516175433: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022722179889678954, 'time_algorithm_update': 0.004604870080947876, 'loss': 1.9261773372888564, 'time_step': 0.006933307886123658, 'init_value': 33.51639938354492}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-16 17:56.54[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516175433: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021908738613128664, 'time_algorithm_update': 0.004494918346405029, 'loss': 1.793790771305561, 'time_step': 0.006741676330566406, 'init_value': 36.055450439453125}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-16 17:57.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516175433: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021796610355377197, 'time_algorithm_update': 0.004376671552658081, 'loss': 1.7768751940131187, 'time_step': 0.0066111102104187015, 'init_value': 37.8978271484375}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-16 17:57.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516175433: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022252583503723144, 'time_algorithm_update': 0.004562939643859863, 'loss': 1.7331103941202164, 'time_step': 0.00684448504447937, 'init_value': 39.8130989074707}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-16 17:57.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516175433: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002208563566207886, 'time_algorithm_update': 0.004534887075424194, 'loss': 1.657045965075493, 'time_step': 0.006799926042556762, 'init_value': 40.892333984375}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.892333984375
Starting 1000 evaluations
avg return on 3 trajectories of agent15: 1428.9357849679116
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-16 18:14.13[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-16 18:14.13[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-16 18:14.15[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-16 18:14.15[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-16 18:14.15[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250516181415[0m
[2m2025-05-16 18:14.15[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-16 18:14.34[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516181415: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021804499626159666, 'time_algorithm_update': 0.0044299297332763676, 'loss': 1.6269656051546335, 'time_step': 0.006665278434753418, 'init_value': 4.122535705566406}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-16 18:14.54[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516181415: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002070847988128662, 'time_algorithm_update': 0.0041150603294372555, 'loss': 2.2272634886503218, 'time_step': 0.006236965179443359, 'init_value': 10.855379104614258}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-16 18:15.15[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516181415: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022248177528381347, 'time_algorithm_update': 0.004458707571029663, 'loss': 2.154843704164028, 'time_step': 0.006738678216934204, 'init_value': 18.59649658203125}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-16 18:15.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516181415: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021967024803161623, 'time_algorithm_update': 0.004469666957855225, 'loss': 2.071331247985363, 'time_step': 0.006721421003341675, 'init_value': 24.75678062438965}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-16 18:15.54[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516181415: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020798153877258302, 'time_algorithm_update': 0.004144989967346192, 'loss': 1.8790559888482095, 'time_step': 0.006276693820953369, 'init_value': 28.487483978271484}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-16 18:16.15[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516181415: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022368006706237793, 'time_algorithm_update': 0.004510061025619507, 'loss': 1.8102853689193725, 'time_step': 0.006801929712295532, 'init_value': 31.64460563659668}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-16 18:16.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516181415: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002159456491470337, 'time_algorithm_update': 0.00440283203125, 'loss': 1.77087762093544, 'time_step': 0.006616825103759765, 'init_value': 34.84439468383789}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-16 18:16.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516181415: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021405372619628907, 'time_algorithm_update': 0.004254222631454468, 'loss': 1.7237097679972648, 'time_step': 0.006448167324066162, 'init_value': 37.9228630065918}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-16 18:17.15[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516181415: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021814839839935304, 'time_algorithm_update': 0.004442177295684815, 'loss': 1.6652650755047798, 'time_step': 0.006678537130355835, 'init_value': 39.392601013183594}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-16 18:17.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516181415: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022061634063720702, 'time_algorithm_update': 0.004437333106994629, 'loss': 1.6348487939238547, 'time_step': 0.006698121309280395, 'init_value': 40.272613525390625}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.272613525390625
Starting 1000 evaluations
avg return on 3 trajectories of agent16: 1450.9417704963255
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-16 18:33.56[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-16 18:33.56[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-16 18:33.57[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-16 18:33.57[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-16 18:33.57[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250516183357[0m
[2m2025-05-16 18:33.57[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-16 18:34.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516183357: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021608405113220214, 'time_algorithm_update': 0.004388825178146362, 'loss': 1.6300071717649698, 'time_step': 0.006603760242462158, 'init_value': 3.8124260902404785}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-16 18:34.37[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516183357: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021633551120758057, 'time_algorithm_update': 0.004299827814102173, 'loss': 2.270325365841389, 'time_step': 0.006516089677810669, 'init_value': 10.424933433532715}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-16 18:34.57[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516183357: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002168678045272827, 'time_algorithm_update': 0.00443286681175232, 'loss': 2.3563497713804247, 'time_step': 0.00665604019165039, 'init_value': 18.812559127807617}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-16 18:35.17[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516183357: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0022066304683685304, 'time_algorithm_update': 0.004442921876907349, 'loss': 2.1904756774306295, 'time_step': 0.00670408296585083, 'init_value': 25.909706115722656}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-16 18:35.37[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516183357: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021610183715820314, 'time_algorithm_update': 0.004408555746078491, 'loss': 1.9469480739831924, 'time_step': 0.006623898267745972, 'init_value': 29.276609420776367}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-16 18:35.58[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516183357: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002257715702056885, 'time_algorithm_update': 0.0046123366355896, 'loss': 1.7120415157079696, 'time_step': 0.006926491260528565, 'init_value': 32.985389709472656}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-16 18:36.18[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516183357: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021812760829925536, 'time_algorithm_update': 0.004486974000930786, 'loss': 1.6633576287031173, 'time_step': 0.0067236566543579105, 'init_value': 35.06277084350586}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-16 18:36.38[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516183357: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002217455625534058, 'time_algorithm_update': 0.004496119022369385, 'loss': 1.716975881397724, 'time_step': 0.006768801927566528, 'init_value': 37.234310150146484}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-16 18:36.58[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516183357: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021736855506896973, 'time_algorithm_update': 0.004449632167816162, 'loss': 1.7125852988958359, 'time_step': 0.006678682565689087, 'init_value': 40.21902084350586}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-16 18:37.18[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516183357: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002184213876724243, 'time_algorithm_update': 0.004500705480575562, 'loss': 1.6917250170111655, 'time_step': 0.006740529537200928, 'init_value': 41.5011100769043}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 41.5011100769043
Starting 1000 evaluations
avg return on 3 trajectories of agent17: 1455.3647506769578
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-16 18:53.34[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-16 18:53.34[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-16 18:53.35[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-16 18:53.35[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-16 18:53.35[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250516185335[0m
[2m2025-05-16 18:53.35[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-16 18:53.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516185335: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021326370239257812, 'time_algorithm_update': 0.004314900636672974, 'loss': 1.7302133288905024, 'time_step': 0.0065016839504241945, 'init_value': 4.664119720458984}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-16 18:54.14[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516185335: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021368191242218016, 'time_algorithm_update': 0.0043480384349822996, 'loss': 2.4189480530023575, 'time_step': 0.006539776802062989, 'init_value': 11.127625465393066}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-16 18:54.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516185335: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021480510234832763, 'time_algorithm_update': 0.004398698329925537, 'loss': 2.434705834269524, 'time_step': 0.006601529359817505, 'init_value': 18.966812133789062}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-16 18:54.55[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516185335: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021829743385314944, 'time_algorithm_update': 0.004466940402984619, 'loss': 2.114376452207565, 'time_step': 0.006705216884613037, 'init_value': 25.11628532409668}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-16 18:55.15[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516185335: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021859769821166992, 'time_algorithm_update': 0.0044346506595611575, 'loss': 1.9801056094169616, 'time_step': 0.00667542839050293, 'init_value': 30.344703674316406}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-16 18:55.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516185335: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002281242847442627, 'time_algorithm_update': 0.004689421653747559, 'loss': 1.9290505749583244, 'time_step': 0.007027926683425903, 'init_value': 33.83940124511719}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-16 18:55.56[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516185335: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021837117671966552, 'time_algorithm_update': 0.004513742208480835, 'loss': 1.7682717664241792, 'time_step': 0.006753392934799194, 'init_value': 36.41300582885742}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-16 18:56.15[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516185335: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021708879470825194, 'time_algorithm_update': 0.004448604106903076, 'loss': 1.7646892690062523, 'time_step': 0.006674877882003784, 'init_value': 37.81573486328125}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-16 18:56.35[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516185335: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002180422306060791, 'time_algorithm_update': 0.004489393472671509, 'loss': 1.694953434586525, 'time_step': 0.006725468635559082, 'init_value': 38.4602165222168}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-16 18:56.56[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516185335: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002213237762451172, 'time_algorithm_update': 0.0044636914730072025, 'loss': 1.6506746409535409, 'time_step': 0.0067325284481048586, 'init_value': 39.6860237121582}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 39.6860237121582
Starting 1000 evaluations
avg return on 3 trajectories of agent18: 1446.9510239146366
Loading replay buffer
Replay buffer loaded
Replay buffer shape:  (1000000, 105) (1000000, 8) (1000000, 1) (1000000, 1)
Episode generator created
[2m2025-05-16 19:12.44[0m [[32m[1minfo     [0m] [1mAction-space has been automatically determined.[0m [36maction_space[0m=[35m<ActionSpace.CONTINUOUS: 1>[0m
[2m2025-05-16 19:12.44[0m [[32m[1minfo     [0m] [1mAction size has been automatically determined.[0m [36maction_size[0m=[35m8[0m
PPOQWrapper initialized on device: cpu
--------------------------------------------------------------------------------
Fitting d3rlpy FQE...
[2m2025-05-16 19:12.45[0m [[32m[1mdebug    [0m] [1mBuilding models...            [0m
[2m2025-05-16 19:12.45[0m [[32m[1mdebug    [0m] [1mModels have been built.       [0m
[2m2025-05-16 19:12.45[0m [[32m[1minfo     [0m] [1mDirectory is created at d3rlpy_logs/Ant-v5-PPO_discussion_1_20250516191245[0m
[2m2025-05-16 19:12.45[0m [[32m[1minfo     [0m] [1mParameters                    [0m [36mparams[0m=[35m{'observation_shape': [105], 'action_size': 8, 'config': {'type': 'fqe', 'params': {'batch_size': 100, 'gamma': 0.98, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 100}}}[0m
[2m2025-05-16 19:13.05[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516191245: epoch=1 step=1000[0m [36mepoch[0m=[35m1[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0020945196151733398, 'time_algorithm_update': 0.004228964805603027, 'loss': 1.6209938254356384, 'time_step': 0.006376022100448608, 'init_value': 3.892507553100586}[0m [36mstep[0m=[35m1000[0m
[2m2025-05-16 19:13.25[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516191245: epoch=2 step=2000[0m [36mepoch[0m=[35m2[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002195688247680664, 'time_algorithm_update': 0.004425039768218994, 'loss': 2.397531445145607, 'time_step': 0.006675287961959839, 'init_value': 9.65749740600586}[0m [36mstep[0m=[35m2000[0m
[2m2025-05-16 19:13.44[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516191245: epoch=3 step=3000[0m [36mepoch[0m=[35m3[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002161727428436279, 'time_algorithm_update': 0.004423571825027466, 'loss': 2.216647588014603, 'time_step': 0.006639137029647827, 'init_value': 16.353191375732422}[0m [36mstep[0m=[35m3000[0m
[2m2025-05-16 19:14.04[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516191245: epoch=4 step=4000[0m [36mepoch[0m=[35m4[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002164317607879639, 'time_algorithm_update': 0.004312971591949463, 'loss': 2.1986699125766753, 'time_step': 0.006530720472335816, 'init_value': 23.18446922302246}[0m [36mstep[0m=[35m4000[0m
[2m2025-05-16 19:14.24[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516191245: epoch=5 step=5000[0m [36mepoch[0m=[35m5[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.00216424822807312, 'time_algorithm_update': 0.004403176546096801, 'loss': 2.0660046095252036, 'time_step': 0.0066217477321624755, 'init_value': 28.108699798583984}[0m [36mstep[0m=[35m5000[0m
[2m2025-05-16 19:14.44[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516191245: epoch=6 step=6000[0m [36mepoch[0m=[35m6[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021605424880981445, 'time_algorithm_update': 0.004406590223312378, 'loss': 1.853217505812645, 'time_step': 0.006621083259582519, 'init_value': 32.76664352416992}[0m [36mstep[0m=[35m6000[0m
[2m2025-05-16 19:15.03[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516191245: epoch=7 step=7000[0m [36mepoch[0m=[35m7[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021436114311218263, 'time_algorithm_update': 0.004375424861907959, 'loss': 1.85327333009243, 'time_step': 0.006572953224182129, 'init_value': 35.80214309692383}[0m [36mstep[0m=[35m7000[0m
[2m2025-05-16 19:15.23[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516191245: epoch=8 step=8000[0m [36mepoch[0m=[35m8[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.0021976962089538575, 'time_algorithm_update': 0.004423842906951904, 'loss': 1.7731888590455056, 'time_step': 0.006675697565078735, 'init_value': 37.40278244018555}[0m [36mstep[0m=[35m8000[0m
[2m2025-05-16 19:15.43[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516191245: epoch=9 step=9000[0m [36mepoch[0m=[35m9[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002158608675003052, 'time_algorithm_update': 0.004418663263320923, 'loss': 1.6258187086582183, 'time_step': 0.006631620407104492, 'init_value': 40.09998321533203}[0m [36mstep[0m=[35m9000[0m
[2m2025-05-16 19:16.03[0m [[32m[1minfo     [0m] [1mAnt-v5-PPO_discussion_1_20250516191245: epoch=10 step=10000[0m [36mepoch[0m=[35m10[0m [36mmetrics[0m=[35m{'time_sample_batch': 0.002149900197982788, 'time_algorithm_update': 0.004373837947845459, 'loss': 1.6940138491988181, 'time_step': 0.0065780763626098636, 'init_value': 40.86165237426758}[0m [36mstep[0m=[35m10000[0m

FQE Fitting completed.
Estimated Initial State Value: 40.86165237426758
Starting 1000 evaluations
