Log Name, Output Name, Description, JobId, Status
Ant-v5
PPO_empty_space_1, ppo_empty_space_out, PPO_empty_space on 100 iterations
PPO_neighbor_search_random_walk, ppo_neighbor_search_random_walk_out, PPO_neighbor_search_random_walk on 100 iterations
PPO_empty_space_Annoy_1, ppo_empty_space_annoy_out, PPO_empty_space with Annoy on 100 iterations with max_episode_steps=200
PPO_empty_space_Faiss_1, ppo_empty_space_faiss_out, PPO_empty_space with Faiss on 100 iterations with max_episode_steps=200
PPO_empty_space_hnswlib_1, ppo_empty_space_hnswlib_out, PPO_empty_space with hnswlib on 100 iterations with max_episode_steps=200
--------------------
PPO_empty_space_2, ppo_empty_space_out, PPO_empty_space on 100 iterations without max_episode_steps=200; gamma=0.9
PPO_neighbor_search_random_walk_2, ppo_neighbor_search_random_walk_out, PPO_neighbor_search_random_walk on 100 iterations without max_episode_steps=200
PPO_random_search_random_walk_2, ppo_random_search_random_walk_out, PPO_random_search random walk on 100 iterations without max_episode_steps=200
PPO_normal_train_2, ppo_normal_train_out, PPO normal train on 100 iterations without max_episode_steps=200
-------------------
PPO_empty_space_Annoy_2, ppo_empty_space_annoy_out, PPO_empty_space with Annoy on 100 iterations without max_episode_steps=200
PPO_empty_space_Faiss_2, ppo_empty_space_faiss_out, PPO_empty_space with Faiss on 100 iterations without max_episode_steps=200
PPO_empty_space_hnswlib_2, ppo_empty_space_hnswlib_out, PPO_empty_space with hnswlib on 100 iterations without max_episode_steps=200
-----------------
PPO_empty_space_optimal, ppo_empty_space_out, PPO_empty_space on 100 iterations with Xinyu hyperparameters
PPO_neighbor_search_random_walk_optimal, ppo_neighbor_search_random_walk_out, PPO_neighbor_search_random_walk on 100 iterations with Xinyu hyperparameters
PPO_random_search_optimal, ppo_random_search_out, PPO_random_search on 100 iterations with Xinyu hyperparameters
PPO_random_search_empty_space_optimal, ppo_random_search_empty_space_out, PPO_random_search_empty_space on 100 iterations with Xinyu hyperparameters
PPO_random_search_random_walk_optimal, ppo_random_search_random_walk_out, PPO_random_search_random_walk on 100 iterations with Xinyu hyperparameters
----------------
PPO_empty_space_optimal_5M_1, ppo_empty_space_5M_out, PPO_empty_space on 5M iterations with Xinyu hyperparameters; gamma=0.9, , Stopped
PPO_neighbor_search_random_walk_optimal_5M, ppo_neighbor_search_random_walk_5M_out, PPO_neighbor_search_random_walk on 5M iterations with Xinyu hyperparameters, , Stopped
PPO_random_search_random_walk_optimal_5M, ppo_random_search_random_walk_5M_out, PPO_random_search_random_walk on 5M iterations with Xinyu hyperparameters, , Stopped
PPO_empty_space_optimal_5M_2, ppo_empty_space_5M_2_out, PPO_empty_space on 5M iterations with Xinyu hyperparameters; gamma=0.5, , Stopped
PPO_normal_train_optimal_5M, ppo_normal_train_5M_out, PPO normal train on 5M iterations with Xinyu hyperparameters
----------------
AntDir-v0
----------------
PPO_1, ppo_init_1M_out, ppo_antdir_1M.zip; PPO Init for 1M steps with Xinyu hyperparameters
PPO_2, ppo_init_5M_out, ppo_antdir_5M.zip; PPO Init for 5M steps with Xinyu hyperparameters
----------------
PPO_empty_space_optimal_5M_1, ppo_empty_space_5M_out, PPO_empty_space on 5M iterations with Xinyu hyperparameters; gamma=0.9, , Stopped
PPO_empty_space_optimal_5M_2_1, ppo_empty_space_5M_2_out, PPO_empty_space on 5M iterations with Xinyu hyperparameters; gamma=0.5, , Stopped
PPO_empty_space_optimal_5M_3_1, ppo_empty_space_5M_3_out, PPO_empty_space on 5M iterations with Xinyu hyperparameters; gamma=0.3, , Stopped
PPO_neighbor_search_random_walk_optimal_5M_1, ppo_neighbor_search_random_walk_5M_out, PPO_neighbor_search_random_walk on 5M iterations with Xinyu hyperparameters, , Stopped
PPO_random_search_random_walk_optimal_5M_1, ppo_random_search_random_walk_5M_out, PPO_random_search_random_walk on 5M iterations with Xinyu hyperparameters, , Stopped
PPO_normal_train_optimal_5M, ppo_normal_train_5M_out, PPO normal train on 5M iterations with Xinyu hyperparameters
----------------
Ant-v5 Less Evaluations
----------------
PPO_empty_space_ls_1, ppo_empty_space_ls_out, PPO_empty_space with 100 iterations - 300k; gamma=0.9, , Stopped
PPO_empty_space_ls_2, ppo_empty_space_ls_2_out, PPO_empty_space with 60 iterations & 3 evaluation - 120k; gamma=0.9, , Stopped
PPO_empty_space_ls_3, ppo_empty_space_ls_3_out, PPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.9,
PPO_empty_space_ls_4, ppo_empty_space_ls_4_out, PPO_empty_space with 100 iterations & advantage estimation - 300k; gamma=0.9, , Stopped
PPO_empty_space_ls_5, ppo_empty_space_ls_5_out, PPO_empty_space with 60 iterations & 3 evaluation & advantage estimation - 120k; gamma=0.9, , Stopped
PPO_empty_space_ls_6, ppo_empty_space_ls_6_out, PPO_empty_space normal & advantage estimation - 1M; gamma=0.9, , Stopped
PPO_empty_space_ls_7, ppo_empty_space_ls_7_out, PPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.5
PPO_empty_space_ls_9, ppo_empty_space_ls_9_out, PPO_empty_space normal & advantage estimation for fqe v1- 1M; gamma=0.3, , Stopped
-----------------
Ant-v5
----------------
PPO_1, ppo_init_1M_out, ppo_ant_1M.zip; PPO Init for 1M steps with Xinyu hyperparameters and replay buffer
PPO_2, ppo_init_5M_out, ppo_ant_5M.zip; PPO Init for 5M steps with Xinyu hyperparameters
PPO_empty_space_ls_8, ppo_empty_space_ls_8_out, PPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.3
PPO_empty_space_ls_11, ppo_empty_space_ls_11_out, Advantage estimation using top 5 agent and 2 evaluation & new fqe & search=1- 10k; gamma=0.3, , Stopped
PPO_empty_space_ls_12, ppo_empty_space_ls_12_out, Advantage estimation using top 5 agent & 2 evaluation & new fqe & search=2- 10k; gamma=0.3, , Stopped
PPO_empty_space_ls_13, ppo_empty_space_ls_13_out, Advantage estimation using top 5 agent & 2 evaluation & new fqe & search=3- 10k; gamma=0.3, , Stopped
PPO_baseline_1, ppo_baseline_1_out, Normal training with 10512 steps per rollout & batch_size=657; search=1
PPO_baseline_2, ppo_baseline_2_out, Normal training with 5512 steps per rollout & batch_size=345; search=2
PPO_baseline_3, ppo_baseline_3_out, Normal training with 3845 steps per rollout & batch_size=240; search=3
PPO_FQE_1, ppo_fqe_1_out, PPO FQE with 60 iterations & every other point; gamma=0.3
----------------
HalfCheetah-v5
----------------
PPO_1, ppo_init_1M_out, ppo_half_cheetah_1M.zip; PPO Init for 1M steps with Xinyu hyperparameters and replay buffer
PPO_2, ppo_init_5M_out, ppo_half_cheetah_5M.zip; PPO Init for 5M steps with Xinyu hyperparameters
PPO_empty_space, ppo_empty_space_out, PPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.3
PPO_empty_space_ls_1, ppo_empty_space_ls_1_out, Advantage estimation using top 5 agent and 2 evaluation & new fqe & search=1- 10k; gamma=0.3, , Stopped
PPO_empty_space_ls_2, ppo_empty_space_ls_2_out, Advantage estimation using top 5 agent & 2 evaluation & new fqe & search=2- 10k; gamma=0.3, , Stopped
PPO_empty_space_ls_3, ppo_empty_space_ls_3_out, Advantage estimation using top 5 agent & 2 evaluation & new fqe & search=3- 10k; gamma=0.3, , Stopped
PPO_baseline_1, ppo_baseline_1_out, Normal training with 10512 steps per rollout & batch_size=657; search=1
PPO_baseline_2, ppo_baseline_2_out, Normal training with 5512 steps per rollout & batch_size=345; search=2
PPO_baseline_3, ppo_baseline_3_out, Normal training with 3845 steps per rollout & batch_size=240; search=3
----------------
Hopper-v5
----------------
PPO_1, ppo_init_1M_out, ppo_hopper_1M.zip; PPO Init for 1M steps with new hyperparameters
PPO_2, ppo_init_5M_out, ppo_hopper_5M.zip; PPO Init for 5M steps with new hyperparameters
PPO_empty_space, ppo_empty_space_out, PPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.3
PPO_empty_space_ls_1, ppo_empty_space_ls_1_out, Advantage estimation using top 5 agent and 2 evaluation & new fqe & search=2- 10k; gamma=0.3, , Stopped
PPO_baseline_1, ppo_baseline_1_out, Normal training with 5512 steps per rollout & batch_size=345; search=2
----------------
Walker2d-v5
----------------
PPO_1, ppo_init_1M_out, ppo_walker2d_1M.zip; PPO Init for 1M steps with Xinyu hyperparameters and replay buffer
PPO_2, ppo_init_5M_out, ppo_walker2d_5M.zip; PPO Init for 5M steps with new hyperparameters
PPO_empty_space, ppo_empty_space_out, PPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.3
PPO_FQE_1, ppo_fqe_1_out, PPO FQE with 60 iterations & every other point - 60k; gamma=0.3, , Stopped
----------------
Humanoid-v5
----------------
PPO_1, ppo_init_1M_out, ppo_humanoid_1M.zip; PPO Init for 1M steps with new hyperparameters and replay buffer
PPO_2, ppo_init_5M_out, ppo_humanoid_5M.zip; PPO Init for 5M steps with new hyperparameters
PPO_empty_space_1, ppo_empty_space_out, PPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.3
PPO_empty_space_ls_1, ppo_empty_space_ls_1_out, Advantage estimation using top 5 agent and 2 evaluation & new fqe & search=1- 10k; gamma=0.3, , Stopped
PPO_empty_space_ls_2, ppo_empty_space_ls_2_out, Advantage estimation using top 5 agent & 2 evaluation & new fqe & search=2- 10k; gamma=0.3, , Stopped
PPO_empty_space_ls_3, ppo_empty_space_ls_3_out, Advantage estimation using top 5 agent & 2 evaluation & new fqe & search=3- 10k; gamma=0.3, , Stopped
PPO_baseline_1, ppo_baseline_1_out, Normal training with 10512 steps per rollout & batch_size=657; search=1
PPO_baseline_2, ppo_baseline_2_out, Normal training with 5512 steps per rollout & batch_size=345; search=2
PPO_baseline_3, ppo_baseline_3_out, Normal training with 3845 steps per rollout & batch_size=240; search=3
-----------------
Swimmer-v5
-----------------
PPO_1, ppo_init_1M_out, ppo_swimmer_1M.zip; PPO Init for 1M steps with new hyperparameters and replay buffer
PPO_FQE_1, ppo_fqe_1_out, PPO FQE with 60 iterations & every other point - 60k; gamma=0.3, , Stopped
----------------
CartPole-v1
----------------
PPO_1, ppo_init_1M_out, ppo_cartpole_1M.zip; PPO Init for 1M steps with new hyperparameters
PPO_2, ppo_init_3M_out, ppo_cartpole_3M.zip; PPO Init for 3M steps with new hyperparameters
PPO_empty_space_1, ppo_empty_space_out, PPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.3, , //Exited due to error
----------------
MountainCar-v0
----------------
PPO_1, ppo_init_1M_out, ppo_mountaincar_1M.zip; PPO Init for 1M steps with new hyperparameters
PPO_2, ppo_init_3M_out, ppo_mountaincar_3M.zip; PPO Init for 3M steps with new hyperparameters
PPO_empty_space_1, ppo_empty_space_out, PPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.3, , //Need to run
----------------
Pendulum-v1
----------------
PPO_1, ppo_init_1M_out, ppo_pendulum_1M.zip; PPO Init for 1M steps with new hyperparameters
PPO_2, ppo_init_3M_out, ppo_pendulum_3M.zip; PPO Init for 3M steps with new hyperparameters
PPO_empty_space_1, ppo_empty_space_out, PPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.3
PPO_baseline_1, ppo_baseline_1_out, Normal training with 11024 steps per rollout & batch_size=689; search=1


#####################################################################################################################################################################

------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------
Ant-v5
------------------------------------------------------------------------------------------------
Seed 0         |
----------------
PPO_1, ppo_init_1M_out, ppo_ant_1M_0.zip; PPO Init for 1M steps with Xinyu hyperparameters and replay buffer
PPO_FQE_1, ppo_fqe_1_out, PPO FQE with 60 iterations & every other point; gamma=0.3, , Stopped
PPO_normal_training_1, ppo_normal_training_1_out, PPO Normal Training
PPO_Ablation4_1, ppo_ablation4_1_out, PPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.3 and search=3
PPO_neghrand_1, ppo_neghrand_1_out, PPO_neghrand with 60 iterations & 3 evaluation & every other point - 60k; gamma=0
PPO_discussion_1, ppo_discussion_1_out, PPO discussion with 60 iterations & every other point; gamma=0.3, Stopped
PPO_contour_1, ppo_contour_1_out, PPO contour with 60 iterations & every other point; gamma=0.3, Stopped
PPO_contour_2, ppo_contour_2_out, PPO contour with 60 iterations & every other point; gamma=0.3, Stopped
PPO_plot_1, ppo_plot_out, PPO plot with 60 iterations & every other point; gamma=0.3
TRPO_1, trpo_init_1M_out, trpo_ant_1M_0.zip; TRPO Init for 1M steps with Xinyu hyperparameters
TRPO_normal_training_1, trpo_normal_training_1_out, TRPO Normal Training
TRPO_plot_1, trpo_plot_out, TRPO plot with 60 iterations & every other point; gamma=0.3
TRPO_upper_bound_1, trpo_upper_bound_1_out, TRPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.3
----------------
Seed 1         |
----------------
PPO_2, ppo_init_1M_1_out, ppo_ant_1M_1.zip; PPO Init for 1M steps with Xinyu hyperparameters and replay buffer
PPO_FQE_2, ppo_fqe_2_out, PPO FQE with 60 iterations & every other point; gamma=0.3, , Stopped
PPO_normal_training_2, ppo_normal_training_2_out, PPO Normal Training
PPO_Ablation4_2, ppo_ablation4_2_out, PPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.3 and search=3
PPO_plot_2, ppo_plot_1_out, PPO plot with 60 iterations & every other point; gamma=0.3
PPO_neghrand_2, ppo_neghrand_2_out, PPO_neghrand with 60 iterations & 3 evaluation & every other point - 60k; gamma=0
TRPO_2, trpo_init_1M_1_out, trpo_ant_1M_1.zip; TRPO Init for 1M steps with Xinyu hyperparameters
TRPO_normal_training_2, trpo_normal_training_2_out, TRPO Normal Training
TRPO_plot_2, trpo_plot_1_out, TRPO plot with 60 iterations & every other point; gamma=0.3
TRPO_upper_bound_2, trpo_upper_bound_2_out, TRPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.3
-----------------
Seed 2         |
----------------
PPO_3, ppo_init_1M_2_out, ppo_ant_1M_2.zip; PPO Init for 1M steps with Xinyu hyperparameters and replay buffer
PPO_normal_training_3, ppo_normal_training_3_out, PPO Normal Training
PPO_FQE_3, ppo_fqe_3_out, PPO FQE with 60 iterations & every other point; gamma=0.3, , Stopped
PPO_Ablation4_3, ppo_ablation4_3_out, PPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.3 and search=3
PPO_neghrand_3, ppo_neghrand_3_out, PPO_neghrand with 60 iterations & 3 evaluation & every other point - 60k; gamma=0
PPO_plot_3, ppo_plot_2_out, PPO plot with 60 iterations & every other point; gamma=0.3
TRPO_3, trpo_init_1M_2_out, trpo_ant_1M_2.zip; TRPO Init for 1M steps with Xinyu hyperparameters
TRPO_normal_training_3, trpo_normal_training_3_out, TRPO Normal Training
TRPO_plot_3, trpo_plot_2_out, TRPO plot with 60 iterations & every other point; gamma=0.3
TRPO_upper_bound_3, trpo_upper_bound_3_out, TRPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.3
----------------
Seed 3         |
----------------
PPO_4, ppo_init_1M_3_out, ppo_ant_1M_3.zip; PPO Init for 1M steps with Xinyu hyperparameters and replay buffer
PPO_normal_training_4, ppo_normal_training_4_out, PPO Normal Training
PPO_plot_4, ppo_plot_3_out, PPO plot with 60 iterations & every other point; gamma=0.3
TRPO_4, trpo_init_1M_3_out, trpo_ant_1M_3.zip; TRPO Init for 1M steps with Xinyu hyperparameters
TRPO_normal_training_4, trpo_normal_training_4_out, TRPO Normal Training
TRPO_plot_4, trpo_plot_3_out, TRPO plot with 60 iterations & every other point; gamma=0.3
TRPO_upper_bound_4, trpo_upper_bound_4_out, TRPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.3
------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------
HalfCheetah-v5
------------------------------------------------------------------------------------------------
Seed 0         |
----------------
PPO_1, ppo_init_1M_out, ppo_half_cheetah_1M_0.zip; PPO Init for 1M steps with Xinyu hyperparameters and replay buffer
PPO_FQE_1, ppo_fqe_1_out, PPO FQE with 60 iterations & every other point; gamma=0.3, , Stopped
PPO_normal_training_1, ppo_normal_training_1_out, PPO Normal Training
TRPO_1, trpo_init_1M_out, trpo_half_cheetah_1M_0.zip; TRPO Init for 1M steps with Xinyu hyperparameters
PPO_Ablation3_1, ppo_ablation3_1_out, PPO FQE with 60 iterations & every other point; gamma=0.3 and search=2, , Stopped
PPO_Ablation4_1, ppo_ablation4_1_out, PPO FQE with 60 iterations & every other point; gamma=0.3 and search=3, , Stopped
TRPO_normal_training_1, trpo_normal_training_1_out, TRPO Normal Training
----------------
Seed 1         |
----------------
PPO_2, ppo_init_1M_1_out, ppo_half_cheetah_1M_1.zip; PPO Init for 1M steps with Xinyu hyperparameters and replay buffer
PPO_normal_training_2, ppo_normal_training_2_out, PPO Normal Training
PPO_FQE_2, ppo_fqe_2_out, PPO FQE with 60 iterations & every other point; gamma=0.3, , Stopped
TRPO_2, trpo_init_1M_1_out, trpo_half_cheetah_1M_1.zip; TRPO Init for 1M steps with Xinyu hyperparameters
TRPO_normal_training_2, trpo_normal_training_2_out, TRPO Normal Training
----------------
Seed 2         |
----------------
PPO_3, ppo_init_1M_2_out, ppo_half_cheetah_1M_2.zip; PPO Init for 1M steps with Xinyu hyperparameters and replay buffer
PPO_normal_training_3, ppo_normal_training_3_out, PPO Normal Training
PPO_FQE_3, ppo_fqe_3_out, PPO FQE with 60 iterations & every other point; gamma=0.3, , Stopped
TRPO_3, trpo_init_1M_2_out, trpo_half_cheetah_1M_2.zip; TRPO Init for 1M steps with Xinyu hyperparameters
TRPO_normal_training_3, trpo_normal_training_3_out, TRPO Normal Training
------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------
Walker2d-v5
------------------------------------------------------------------------------------------------
Seed 0         |
----------------
PPO_1, ppo_init_1M_out, ppo_walker2d_1M_0.zip; PPO Init for 1M steps with Xinyu hyperparameters and replay buffer
PPO_normal_training_1, ppo_normal_training_1_out, PPO Normal Training
PPO_upper_bound_1, ppo_upper_bound_1_out, PPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.3
PPO_contour_1, ppo_contour_1_out, PPO contour with 60 iterations & every other point; gamma=0.3
PPO_contour_2, ppo_contour_2_out, PPO contour with 60 iterations & every other point; gamma=0.3, , Stopped
PPO_plot_1, ppo_plot_out, PPO plot with 60 iterations & every other point; gamma=0.3
PPO_Ablation1_1, ppo_ablation1_1_out, PPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.5 and search=1
PPO_Ablation2_1, ppo_ablation2_1_out, PPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0 and search=1
PPO_Ablation3_1, ppo_ablation3_1_out, PPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.9 and search=1
TRPO_1, trpo_init_1M_out, trpo_walker2d_1M_0.zip; TRPO Init for 1M steps with Xinyu hyperparameters
TRPO_normal_training_1, trpo_normal_training_1_out, TRPO Normal Training
TRPO_plot_1, trpo_plot_out, TRPO plot with 60 iterations & every other point; gamma=0.3
TRPO_upper_bound_1, trpo_upper_bound_1_out, TRPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.3
----------------
Seed 1         |
----------------
PPO_2, ppo_init_1M_1_out, ppo_walker2d_1M_1.zip; PPO Init for 1M steps with Xinyu hyperparameters and replay buffer
PPO_normal_training_2, ppo_normal_training_2_out, PPO Normal Training
PPO_upper_bound_2, ppo_upper_bound_2_out, PPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.3
PPO_plot_2, ppo_plot_1_out, PPO plot with 60 iterations & every other point; gamma=0.3
PPO_Ablation1_2, ppo_ablation1_2_out, PPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.5 and search=1
PPO_Ablation2_2, ppo_ablation2_2_out, PPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0 and search=1
PPO_Ablation3_2, ppo_ablation3_2_out, PPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.9 and search=1, , First Half
PPO_Ablation3_2_1, ppo_ablation3_2_1_out, PPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.9 and search=1, , Second Half
TRPO_2, trpo_init_1M_1_out, trpo_walker2d_1M_1.zip; TRPO Init for 1M steps with Xinyu hyperparameters
TRPO_normal_training_2, trpo_normal_training_2_out, TRPO Normal Training
TRPO_plot_2, trpo_plot_1_out, TRPO plot with 60 iterations & every other point; gamma=0.3
TRPO_upper_bound_2, trpo_upper_bound_2_out, TRPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.3
----------------
Seed 2         |
----------------
PPO_3, ppo_init_1M_2_out, ppo_walker2d_1M_2.zip; PPO Init for 1M steps with Xinyu hyperparameters and replay buffer
PPO_normal_training_3, ppo_normal_training_3_out, PPO Normal Training
PPO_upper_bound_3, ppo_upper_bound_3_out, PPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.3
PPO_plot_3, ppo_plot_2_out, PPO plot with 60 iterations & every other point; gamma=0.3
PPO_Ablation1_3, ppo_ablation1_3_out, PPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.5 and search=1
PPO_Ablation2_3, ppo_ablation2_3_out, PPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0 and search=1
PPO_Ablation3_3, ppo_ablation3_3_out, PPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.9 and search=1
TRPO_3, trpo_init_1M_2_out, trpo_walker2d_1M_2.zip; TRPO Init for 1M steps with Xinyu hyperparameters
TRPO_normal_training_3, trpo_normal_training_3_out, TRPO Normal Training
TRPO_plot_3, trpo_plot_2_out, TRPO plot with 60 iterations & every other point; gamma=0.3
TRPO_upper_bound_3, trpo_upper_bound_3_out, TRPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.3
----------------
Seed 3         |
----------------
PPO_4, ppo_init_1M_3_out, ppo_walker2d_1M_3.zip; PPO Init for 1M steps with Xinyu hyperparameters and replay buffer
PPO_upper_bound_4, ppo_upper_bound_4_out, PPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.3
PPO_normal_training_4, ppo_normal_training_4_out, PPO Normal Training
PPO_plot_4, ppo_plot_3_out, PPO plot with 60 iterations & every other point; gamma=0.3
TRPO_4, trpo_init_1M_3_out, trpo_walker2d_1M_3.zip; TRPO Init for 1M steps with Xinyu hyperparameters
TRPO_normal_training_4, trpo_normal_training_4_out, TRPO Normal Training
TRPO_plot_4, trpo_plot_3_out, TRPO plot with 60 iterations & every other point; gamma=0.3
TRPO_upper_bound_4, trpo_upper_bound_4_out, TRPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.3
------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------
Humanoid-v5
------------------------------------------------------------------------------------------------
Seed 0         |
----------------
PPO_1, ppo_init_1M_out, ppo_humanoid_1M_0.zip; PPO Init for 1M steps with new hyperparameters and replay buffer
PPO_normal_training_1, ppo_normal_training_1_out, PPO Normal Training
PPO_upper_bound_1, ppo_upper_bound_1_out, PPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.3
PPO_contour_1, ppo_contour_1_out, PPO contour with 60 iterations & every other point; gamma=0.3
PPO_contour_2, ppo_contour_2_out, PPO contour with 60 iterations & every other point; gamma=0.3
PPO_plot_1, ppo_plot_out, PPO plot with 60 iterations & every other point; gamma=0.3
PPO_Ablation1_1, ppo_ablation1_1_out, PPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.5 and search=1
PPO_Ablation2_1, ppo_ablation2_1_out, PPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0 and search=1
PPO_Ablation5_1, ppo_ablation5_1_out, PPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.9 and search=1
TRPO_1, trpo_init_1M_out, trpo_humanoid_1M_0.zip; TRPO Init for 1M steps with new hyperparameters
TRPO_normal_training_1, trpo_normal_training_1_out, TRPO Normal Training
TRPO_plot_1, trpo_plot_out, TRPO plot with 60 iterations & every other point; gamma=0.3
TRPO_upper_bound_1, trpo_upper_bound_1_out, TRPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.3
----------------
Seed 1         |
----------------
PPO_2, ppo_init_1M_1_out, ppo_humanoid_1M_1.zip; PPO Init for 1M steps with new hyperparameters and replay buffer
PPO_normal_training_2, ppo_normal_training_2_out, PPO Normal Training
PPO_upper_bound_2, ppo_upper_bound_2_out, PPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.3
PPO_plot_2, ppo_plot_1_out, PPO plot with 60 iterations & every other point; gamma=0.3
PPO_Ablation1_2, ppo_ablation1_2_out, PPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.5 and search=1
PPO_Ablation2_2, ppo_ablation2_2_out, PPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0 and search=1
PPO_Ablation5_2, ppo_ablation5_2_out, PPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.9 and search=1
TRPO_2, trpo_init_1M_1_out, trpo_humanoid_1M_1.zip; TRPO Init for 1M steps with new hyperparameters
TRPO_normal_training_2, trpo_normal_training_2_out, TRPO Normal Training
TRPO_plot_2, trpo_plot_1_out, TRPO plot with 60 iterations & every other point; gamma=0.3
TRPO_upper_bound_2, trpo_upper_bound_2_out, TRPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.3
----------------
Seed 2         |
----------------
PPO_3, ppo_init_1M_2_out, ppo_humanoid_1M_2.zip; PPO Init for 1M steps with new hyperparameters and replay buffer
PPO_normal_training_3, ppo_normal_training_3_out, PPO Normal Training
PPO_upper_bound_3, ppo_upper_bound_3_out, PPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.3
PPO_plot_3, ppo_plot_2_out, PPO plot with 60 iterations & every other point; gamma=0.3
PPO_Ablation1_3, ppo_ablation1_3_out, PPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.5 and search=1
PPO_Ablation2_3, ppo_ablation2_3_out, PPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0 and search=1
PPO_Ablation5_3, ppo_ablation5_3_out, PPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.9 and search=1
TRPO_3, trpo_init_1M_2_out, trpo_humanoid_1M_2.zip; TRPO Init for 1M steps with new hyperparameters
TRPO_normal_training_3, trpo_normal_training_3_out, TRPO Normal Training
TRPO_plot_3, trpo_plot_2_out, TRPO plot with 60 iterations & every other point; gamma=0.3
TRPO_upper_bound_3, trpo_upper_bound_3_out, TRPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.3
----------------
Seed 3         |
----------------
PPO_4, ppo_init_1M_3_out, ppo_humanoid_1M_3.zip; PPO Init for 1M steps with Xinyu hyperparameters and replay buffer
PPO_upper_bound_4, ppo_upper_bound_4_out, PPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.3
PPO_normal_training_4, ppo_normal_training_4_out, PPO Normal Training
PPO_plot_4, ppo_plot_3_out, PPO plot with 60 iterations & every other point; gamma=0.3
TRPO_4, trpo_init_1M_3_out, trpo_humanoid_1M_3.zip; TRPO Init for 1M steps with Xinyu hyperparameters
TRPO_normal_training_4, trpo_normal_training_4_out, TRPO Normal Training
TRPO_plot_4, trpo_plot_3_out, TRPO plot with 60 iterations & every other point; gamma=0.3
TRPO_upper_bound_4, trpo_upper_bound_4_out, TRPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.3
------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------
Swimmer-v5
------------------------------------------------------------------------------------------------
Seed 0         |
----------------
PPO_1, ppo_init_1M_out, ppo_swimmer_1M_0.zip; PPO Init for 1M steps with new hyperparameters and replay buffer
PPO_normal_training_1, ppo_normal_training_1_out, PPO Normal Training
PPO_upper_bound_1, ppo_upper_bound_1_out, PPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.3
PPO_plot_1, ppo_plot_out, PPO plot with 60 iterations & every other point; gamma=0.3
TRPO_1, trpo_init_1M_out, trpo_swimmer_1M_0.zip; TRPO Init for 1M steps with new hyperparameters
TRPO_normal_training_1, trpo_normal_training_1_out, TRPO Normal Training
TRPO_plot_1, trpo_plot_out, TRPO plot with 60 iterations & every other point; gamma=0.3
TRPO_upper_bound_1, trpo_upper_bound_1_out, TRPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.3
TRPO_Ablation1_1, trpo_ablation1_1_out, TRPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.5 and search=1
TRPO_Ablation2_1, trpo_ablation2_1_out, TRPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0 and search=1
TRPO_Ablation5_1, trpo_ablation5_1_out, TRPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.9 and search=1, , First Half
TRPO_Ablation5_1_1, trpo_ablation5_1_1_out, TRPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.9 and search=1, , Second Half
----------------
Seed 1         |
----------------
PPO_2, ppo_init_1M_1_out, ppo_swimmer_1M_1.zip; PPO Init for 1M steps with new hyperparameters and replay buffer
PPO_normal_training_2, ppo_normal_training_2_out, PPO Normal Training
PPO_upper_bound_2, ppo_upper_bound_2_out, PPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.3
PPO_plot_2, ppo_plot_1_out, PPO plot with 60 iterations & every other point; gamma=0.3
TRPO_2, trpo_init_1M_1_out, trpo_swimmer_1M_1.zip; TRPO Init for 1M steps with new hyperparameters
TRPO_normal_training_2, trpo_normal_training_2_out, TRPO Normal Training
TRPO_plot_2, trpo_plot_1_out, TRPO plot with 60 iterations & every other point; gamma=0.3
TRPO_upper_bound_2, trpo_upper_bound_2_out, TRPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.3
TRPO_Ablation1_2, trpo_ablation1_2_out, TRPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.5 and search=1
TRPO_Ablation2_2, trpo_ablation2_2_out, TRPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0 and search=1
TRPO_Ablation5_2, trpo_ablation5_2_out, TRPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.9 and search=1, , First Half
TRPO_Ablation5_2_1, trpo_ablation5_2_1_out, TRPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.9 and search=1, , Second Half
----------------
Seed 2         |
----------------
PPO_3, ppo_init_1M_2_out, ppo_swimmer_1M_2.zip; PPO Init for 1M steps with new hyperparameters and replay buffer
PPO_normal_training_3, ppo_normal_training_3_out, PPO Normal Training
PPO_upper_bound_3, ppo_upper_bound_3_out, PPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.3
PPO_plot_3, ppo_plot_2_out, PPO plot with 60 iterations & every other point; gamma=0.3
TRPO_3, trpo_init_1M_2_out, trpo_swimmer_1M_2.zip; TRPO Init for 1M steps with new hyperparameters
TRPO_normal_training_3, trpo_normal_training_3_out, TRPO Normal Training
TRPO_plot_3, trpo_plot_2_out, TRPO plot with 60 iterations & every other point; gamma=0.3
TRPO_upper_bound_3, trpo_upper_bound_3_out, TRPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.3
TRPO_Ablation1_3, trpo_ablation1_3_out, TRPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.5 and search=1
TRPO_Ablation2_3, trpo_ablation2_3_out, TRPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0 and search=1
TRPO_Ablation5_3, trpo_ablation5_3_out, TRPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.9 and search=1, , First Half
TRPO_Ablation5_3_1, trpo_ablation5_3_1_out, TRPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.9 and search=1, , Second Half
----------------
Seed 3         |
----------------
PPO_4, ppo_init_1M_3_out, ppo_swimmer_1M_3.zip; PPO Init for 1M steps with Xinyu hyperparameters and replay buffer
PPO_upper_bound_4, ppo_upper_bound_4_out, PPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.3
PPO_normal_training_4, ppo_normal_training_4_out, PPO Normal Training
PPO_plot_4, ppo_plot_3_out, PPO plot with 60 iterations & every other point; gamma=0.3
TRPO_4, trpo_init_1M_3_out, trpo_swimmer_1M_3.zip; TRPO Init for 1M steps with Xinyu hyperparameters
TRPO_normal_training_4, trpo_normal_training_4_out, TRPO Normal Training
TRPO_plot_4, trpo_plot_3_out, TRPO plot with 60 iterations & every other point; gamma=0.3
TRPO_upper_bound_4, trpo_upper_bound_4_out, TRPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.3
------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------
Pendulum-v1
------------------------------------------------------------------------------------------------
Seed 0         |
----------------
PPO_1, ppo_init_40k_out, ppo_pendulum_40k_0.zip; PPO Init for 40k steps with new hyperparameters and replay buffer
PPO_normal_training_1, ppo_normal_training_1_out, PPO Normal Training with eval=1 from scratch
PPO_upper_bound_1, ppo_upper_bound_1_out, PPO_empty_space with 60 iterations & 1 evaluation & every other point - 20k; gamma=0.3 from scratch
PPO_FQE_1, ppo_fqe_1_out, PPO FQE with 60 iterations & every other point; gamma=0.3 from scratch
PPO_normal_training_4, ppo_normal_training_4_out, PPO Normal Training with eval=1
PPO_upper_bound_4, ppo_upper_bound_4_out, PPO_empty_space with 60 iterations & 1 evaluation & every other point - 20k; gamma=0.3
PPO_Ablation1_1, ppo_ablation1_1_out, PPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.5 and search=1
PPO_Ablation2_1, ppo_ablation2_1_out, PPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0 and search=1, espace1, Ongoing
TRPO_normal_training_1, trpo_normal_training_1_out, TRPO Normal Training with eval=1 from scratch
TRPO_upper_bound_1, trpo_upper_bound_1_out, TRPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.3
----------------
Seed 1         |
----------------
PPO_2, ppo_init_40k_1_out, ppo_pendulum_40k_1.zip; PPO Init for 40k steps with new hyperparameters and replay buffer
PPO_normal_training_2, ppo_normal_training_2_out, PPO Normal Training with eval=1 from scratch
PPO_upper_bound_2, ppo_upper_bound_2_out, PPO_empty_space with 60 iterations & 1 evaluation & every other point - 20k; gamma=0.3 from scratch
PPO_normal_training_5, ppo_normal_training_5_out, PPO Normal Training with eval=1
PPO_upper_bound_5, ppo_upper_bound_5_out, PPO_empty_space with 60 iterations & 1 evaluation & every other point - 20k; gamma=0.3
PPO_Ablation1_2, ppo_ablation1_2_out, PPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.5 and search=1
PPO_Ablation2_2, ppo_ablation2_2_out, PPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0 and search=1, espace2, Ongoing
TRPO_normal_training_2, trpo_normal_training_2_out, TRPO Normal Training with eval=1 from scratch
TRPO_upper_bound_2, trpo_upper_bound_2_out, TRPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.3
----------------
Seed 2         |
----------------
PPO_3, ppo_init_40k_2_out, ppo_pendulum_40k_2.zip; PPO Init for 40k steps with new hyperparameters and replay buffer
PPO_normal_training_3, ppo_normal_training_3_out, PPO Normal Training with eval=1 from scratch
PPO_upper_bound_3, ppo_upper_bound_3_out, PPO_empty_space with 60 iterations & 1 evaluation & every other point - 20k; gamma=0.3 from scratch
PPO_normal_training_6, ppo_normal_training_6_out, PPO Normal Training with eval=1
PPO_upper_bound_6, ppo_upper_bound_6_out, PPO_empty_space with 60 iterations & 1 evaluation & every other point - 20k; gamma=0.3
PPO_Ablation1_3, ppo_ablation1_3_out, PPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.5 and search=1
PPO_Ablation2_3, ppo_ablation2_3_out, PPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0 and search=1, espace3, Ongoing
TRPO_normal_training_3, trpo_normal_training_3_out, TRPO Normal Training with eval=1 from scratch
TRPO_upper_bound_3, trpo_upper_bound_3_out, TRPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.3
----------------
Seed 3         |
----------------
PPO_normal_training_7, ppo_normal_training_7_out, PPO Normal Training with eval=1 from scratch
PPO_upper_bound_7, ppo_upper_bound_7_out, PPO_empty_space with 60 iterations & 1 evaluation & every other point - 20k; gamma=0.3 from scratch
TRPO_normal_training_4, trpo_normal_training_4_out, TRPO Normal Training with eval=1 from scratch
TRPO_upper_bound_4, trpo_upper_bound_4_out, TRPO_empty_space with 60 iterations & 3 evaluation & every other point - 60k; gamma=0.3
------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------
BipedalWalker-v3
------------------------------------------------------------------------------------------------
Seed 0         |
----------------
PPO_1, ppo_init_1M_out, ppo_bipedalwalker_1M_0.zip; PPO Init for 1M steps with new hyperparameters and replay buffer
PPO_normal_training_1, ppo_normal_training_1_out, PPO Normal Training with eval=1 from scratch
PPO_upper_bound_1, ppo_upper_bound_1_out, PPO_empty_space with 60 iterations & 1 evaluation & every other point - 20k; gamma=0.3 from scratch
PPO_FQE_1, ppo_fqe_1_out, PPO FQE with 60 iterations & every other point; gamma=0.3 from scratch, , Stopped
TRPO_normal_training_1, trpo_normal_training_1_out, TRPO Normal Training with eval=1 from scratch
----------------
Seed 1         |
----------------
PPO_2, ppo_init_1M_1_out, ppo_bipedalwalker_1M_1.zip; PPO Init for 1M steps with new hyperparameters and replay buffer
PPO_normal_training_2, ppo_normal_training_2_out, PPO Normal Training with eval=1 from scratch
PPO_upper_bound_2, ppo_upper_bound_2_out, PPO_empty_space with 60 iterations & 1 evaluation & every other point - 20k; gamma=0.3 from scratch
TRPO_normal_training_2, trpo_normal_training_2_out, TRPO Normal Training with eval=1 from scratch
----------------
Seed 2         |
----------------
PPO_3, ppo_init_1M_2_out, ppo_bipedalwalker_1M_2.zip; PPO Init for 1M steps with new hyperparameters and replay buffer
PPO_normal_training_3, ppo_normal_training_3_out, PPO Normal Training with eval=1 from scratch
PPO_upper_bound_3, ppo_upper_bound_3_out, PPO_empty_space with 60 iterations & 1 evaluation & every other point - 20k; gamma=0.3 from scratch
TRPO_normal_training_3, trpo_normal_training_3_out, TRPO Normal Training with eval=1 from scratch
----------------
Seed 3         |
----------------
PPO_normal_training_4, ppo_normal_training_4_out, PPO Normal Training with eval=1 from scratch
PPO_upper_bound_4, ppo_upper_bound_4_out, PPO_empty_space with 60 iterations & 1 evaluation & every other point - 20k; gamma=0.3 from scratch
TRPO_normal_training_4, trpo_normal_training_4_out, TRPO Normal Training with eval=1 from scratch